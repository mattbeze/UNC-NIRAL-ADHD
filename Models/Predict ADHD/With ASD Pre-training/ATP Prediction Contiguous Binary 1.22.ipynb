{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving config to \"C:\\Users\\mattbeze\\.comet.config\"... done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/mattbeze/atp-contiguous-classification/18cef2be00e6490db40d6cc3db2185b1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#COMET ML API KEY YarDlAXZLHepLKBFlSPyWbDPt\n",
    "import comet_ml\n",
    "comet_ml.config.save(api_key=\"YarDlAXZLHepLKBFlSPyWbDPt\")\n",
    "from comet_ml import Experiment\n",
    "experiment = Experiment(\n",
    "    api_key=\"YarDlAXZLHepLKBFlSPyWbDPt\",\n",
    "    project_name=\"atp-contiguous-classification\",\n",
    "    workspace=\"mattbeze\",\n",
    "    auto_metric_logging=True,\n",
    "    auto_param_logging=True,\n",
    "    auto_histogram_weight_logging=True,\n",
    "    auto_histogram_gradient_logging=True,\n",
    "    auto_histogram_activation_logging=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sn\n",
    "from imblearn.over_sampling import SMOTE \n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras import losses\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import recall_score, confusion_matrix, multilabel_confusion_matrix, precision_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "import time\n",
    "\n",
    "seed_value = 7\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "#Extra features that are available: Sex, Gestational Age \n",
    "\n",
    "#22 1s Atypicals defined as having an attention problem t-score >= 65 in BASC2 6year\n",
    "#115 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Data = pd.ExcelFile(\"Scaled_Gilmore_Data_CT_SA_1_2.xlsx\") #Training Data already pre-scaled to the IBIS Data set\n",
    "Label_Data = pd.ExcelFile(\"Labels.xlsx\") #Labels\n",
    "data = Training_Data.parse(Training_Data.sheet_names[0])\n",
    "label_data = Label_Data.parse(Label_Data.sheet_names[0])\n",
    "data_features = data.loc[:, data.columns]\n",
    "data_features = data_features.drop(['ROI','MATCH','INDEX','MATCH2','INDEX2', 'ATP', 'HYP', 'ATP Middle', 'HYP Middle', 'HYP Label'], axis=1)\n",
    "data_features = data_features.dropna()\n",
    "data_features = data_features.drop(['ATP Label'], axis=1)\n",
    "labels = label_data.loc[:, label_data.columns]\n",
    "labels = labels.drop(['ROI','ATP Middle', 'HYP Middle', 'HYP Label'], axis=1)\n",
    "labels = labels.dropna()\n",
    "print(data_features.shape)\n",
    "print(labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = data_features.to_numpy()\n",
    "labels = labels.to_numpy()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=8, random_state = seed_value)\n",
    "skf.get_n_splits(data_features, labels)\n",
    "print(skf)\n",
    "\n",
    "training_folds_X = []\n",
    "testing_folds_X = []\n",
    "training_folds_Y = []\n",
    "testing_folds_Y = []\n",
    "\n",
    "for train_index, test_index in skf.split(data_features, labels):\n",
    "  \n",
    "    X_train, X_test = data_features[train_index], data_features[test_index]\n",
    "    Y_train, Y_test = labels[train_index], labels[test_index]\n",
    "   \n",
    "    sm = SMOTE(sampling_strategy = 'minority', random_state = seed_value, k_neighbors=2) \n",
    "    X_train_smoted, Y_train_smoted = sm.fit_sample(X_train, Y_train) #Only smote the training set.\n",
    "    \n",
    "    training_folds_X.append(X_train_smoted)\n",
    "    testing_folds_X.append(X_test)\n",
    "    training_folds_Y.append(Y_train_smoted)\n",
    "    testing_folds_Y.append(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_matrix(p0, p1, p2, p3, p4, p5, p6, p7, t0, t1, t2, t3, t4, t5, t6, t7):\n",
    "    predictions = []\n",
    "    true = []\n",
    "    \n",
    "    for i in range(0,p0.size):\n",
    "        if p0[i] == 0:\n",
    "            predictions.append(0)\n",
    "        if p0[i] == 1:\n",
    "            predictions.append(1)\n",
    "        if t0[i] == 0:\n",
    "            true.append(0)\n",
    "        if t0[i] == 1:\n",
    "            true.append(1)\n",
    "    for i in range(0,p1.size):\n",
    "        if p1[i] == 0:\n",
    "            predictions.append(0)\n",
    "        if p1[i] == 1:\n",
    "            predictions.append(1)\n",
    "        if t1[i] == 0:\n",
    "            true.append(0)\n",
    "        if t1[i] == 1:\n",
    "            true.append(1)\n",
    "    for i in range(0,p2.size):\n",
    "        if p2[i] == 0:\n",
    "            predictions.append(0)\n",
    "        if p2[i] == 1:\n",
    "            predictions.append(1)\n",
    "        if t2[i] == 0:\n",
    "            true.append(0)\n",
    "        if t2[i] == 1:\n",
    "            true.append(1)\n",
    "    for i in range(0,p3.size):\n",
    "        if p3[i] == 0:\n",
    "            predictions.append(0)\n",
    "        if p3[i] == 1:\n",
    "            predictions.append(1)\n",
    "        if t3[i] == 0:\n",
    "            true.append(0)\n",
    "        if t3[i] == 1:\n",
    "            true.append(1)\n",
    "    for i in range(0,p4.size):\n",
    "        if p4[i] == 0:\n",
    "            predictions.append(0)\n",
    "        if p4[i] == 1:\n",
    "            predictions.append(1)\n",
    "        if t4[i] == 0:\n",
    "            true.append(0)\n",
    "        if t4[i] == 1:\n",
    "            true.append(1)\n",
    "    for i in range(0,p5.size):\n",
    "        if p5[i] == 0:\n",
    "            predictions.append(0)\n",
    "        if p5[i] == 1:\n",
    "            predictions.append(1)\n",
    "        if t5[i] == 0:\n",
    "            true.append(0)\n",
    "        if t5[i] == 1:\n",
    "            true.append(1)\n",
    "    for i in range(0,p6.size):\n",
    "        if p6[i] == 0:\n",
    "            predictions.append(0)\n",
    "        if p6[i] == 1:\n",
    "            predictions.append(1)\n",
    "        if t6[i] == 0:\n",
    "            true.append(0)\n",
    "        if t6[i] == 1:\n",
    "            true.append(1)\n",
    "    for i in range(0,p7.size):\n",
    "        if p7[i] == 0:\n",
    "            predictions.append(0)\n",
    "        if p7[i] == 1:\n",
    "            predictions.append(1)\n",
    "        if t7[i] == 0:\n",
    "            true.append(0)\n",
    "        if t7[i] == 1:\n",
    "            true.append(1)\n",
    "    \n",
    "    \n",
    "    prec_score = precision_score(true, predictions, average=None)\n",
    "    print('Positive Predictive Value tp/(tp+fp): ',prec_score[1])\n",
    "    \n",
    "    rec_score = recall_score(true, predictions, average=None)\n",
    "    print('Recall Value tp/(tp+fn): ',rec_score[1])\n",
    "    \n",
    "    cf_matrix = confusion_matrix(true, predictions)\n",
    "    print(cf_matrix)\n",
    "    sn.heatmap(cf_matrix, annot=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best: 0.508814 using {'batch_size': 35, 'dropout': 0.15, 'epochs': 35, 'layer1_size': 100, 'layer2_size': 15}\n",
    "def run_model(n):\n",
    "    predictor = keras.models.load_model('ASD Pre_Trained Model for ATP Contiguous') #Model with ASD Pre-training\n",
    "    \n",
    "    seed_value = 7\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    import numpy as np\n",
    "    np.random.seed(seed_value)\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(seed_value)\n",
    "    \n",
    "    \n",
    "    class_weights={0:1, 1:5} \n",
    "    \n",
    "    p = predictor.fit(training_folds_X[n], training_folds_Y[n],\n",
    "    epochs=100,\n",
    "    batch_size=35,\n",
    "    shuffle=False,\n",
    "    validation_data=(testing_folds_X[n], testing_folds_Y[n]), class_weight=class_weights)\n",
    "\n",
    "    #Plotting loss\n",
    "    plt.plot(p.history['loss'])\n",
    "    plt.plot(p.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.axis([0, 100, 0.0, 1.10])\n",
    "    plt.show()\n",
    "\n",
    "    #Plotting Accuracy\n",
    "    plt.plot(p.history['acc'])\n",
    "    plt.plot(p.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['acc', 'val_acc'], loc='upper left')\n",
    "    plt.axis([0, 100, 0.0, 1.05])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    predictions = predictor.predict(testing_folds_X[n])\n",
    "    predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "    #Heatmap for the confusion matrix\n",
    "    cf_matrix = confusion_matrix(testing_folds_Y[n], predicted_classes)\n",
    "    print(cf_matrix)\n",
    "    sn.heatmap(cf_matrix, annot=True)\n",
    "    average_precision = average_precision_score(predicted_classes, testing_folds_Y[n])\n",
    "\n",
    "    \n",
    "    prec_score = precision_score(testing_folds_Y[n], predicted_classes, average=None)\n",
    "    print('PPV: ',prec_score[1])\n",
    "    \n",
    "    rec_score = recall_score(testing_folds_Y[n], predicted_classes, average=None)\n",
    "    print('Recall: ',rec_score[1])\n",
    "\n",
    "    \n",
    "    return predicted_classes, testing_folds_Y[n]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0, t0 = run_model(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, t1 = run_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2, t2 = run_model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3, t3 = run_model(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4, t4 = run_model(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p5, t5 = run_model(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p6, t6 = run_model(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p7, t7 = run_model(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_summary_matrix(p0, p1, p2, p3, p4, p5, p6, p7, t0, t1, t2, t3, t4, t5, t6, t7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
