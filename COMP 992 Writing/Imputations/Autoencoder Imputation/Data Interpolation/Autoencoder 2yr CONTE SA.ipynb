{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras import losses\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "\n",
    "ct_sheet = pd.ExcelFile(\"Training Data.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290, 148)\n",
      "(290, 148)\n",
      "Tensor(\"input_1:0\", shape=(None, 148), dtype=float32)\n",
      "Train on 261 samples, validate on 29 samples\n",
      "Epoch 1/150\n",
      "261/261 [==============================] - 1s 4ms/step - loss: 0.2615 - val_loss: 0.1551\n",
      "Epoch 2/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1602 - val_loss: 0.1411\n",
      "Epoch 3/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1495 - val_loss: 0.1358\n",
      "Epoch 4/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1424 - val_loss: 0.1401\n",
      "Epoch 5/150\n",
      "261/261 [==============================] - 0s 326us/step - loss: 0.1392 - val_loss: 0.1317\n",
      "Epoch 6/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1366 - val_loss: 0.1299\n",
      "Epoch 7/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1355 - val_loss: 0.1347\n",
      "Epoch 8/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1378 - val_loss: 0.1348\n",
      "Epoch 9/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1326 - val_loss: 0.1291\n",
      "Epoch 10/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1328 - val_loss: 0.1309\n",
      "Epoch 11/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1304 - val_loss: 0.1279\n",
      "Epoch 12/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1296 - val_loss: 0.1272\n",
      "Epoch 13/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1277 - val_loss: 0.1284\n",
      "Epoch 14/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1281 - val_loss: 0.1311\n",
      "Epoch 15/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1290 - val_loss: 0.1272\n",
      "Epoch 16/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1272 - val_loss: 0.1263\n",
      "Epoch 17/150\n",
      "261/261 [==============================] - 0s 326us/step - loss: 0.1266 - val_loss: 0.1263\n",
      "Epoch 18/150\n",
      "261/261 [==============================] - 0s 333us/step - loss: 0.1257 - val_loss: 0.1312\n",
      "Epoch 19/150\n",
      "261/261 [==============================] - 0s 333us/step - loss: 0.1247 - val_loss: 0.1255\n",
      "Epoch 20/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1251 - val_loss: 0.1263\n",
      "Epoch 21/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1236 - val_loss: 0.1271\n",
      "Epoch 22/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1223 - val_loss: 0.1284\n",
      "Epoch 23/150\n",
      "261/261 [==============================] - 0s 356us/step - loss: 0.1218 - val_loss: 0.1250\n",
      "Epoch 24/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1221 - val_loss: 0.1259\n",
      "Epoch 25/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1215 - val_loss: 0.1262\n",
      "Epoch 26/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1204 - val_loss: 0.1257\n",
      "Epoch 27/150\n",
      "261/261 [==============================] - 0s 433us/step - loss: 0.1204 - val_loss: 0.1242\n",
      "Epoch 28/150\n",
      "261/261 [==============================] - 0s 375us/step - loss: 0.1199 - val_loss: 0.1268\n",
      "Epoch 29/150\n",
      "261/261 [==============================] - 0s 387us/step - loss: 0.1202 - val_loss: 0.1245\n",
      "Epoch 30/150\n",
      "261/261 [==============================] - 0s 467us/step - loss: 0.1202 - val_loss: 0.1246\n",
      "Epoch 31/150\n",
      "261/261 [==============================] - 0s 402us/step - loss: 0.1188 - val_loss: 0.1236\n",
      "Epoch 32/150\n",
      "261/261 [==============================] - 0s 391us/step - loss: 0.1173 - val_loss: 0.1231\n",
      "Epoch 33/150\n",
      "261/261 [==============================] - 0s 375us/step - loss: 0.1193 - val_loss: 0.1227\n",
      "Epoch 34/150\n",
      "261/261 [==============================] - 0s 410us/step - loss: 0.1177 - val_loss: 0.1227\n",
      "Epoch 35/150\n",
      "261/261 [==============================] - 0s 375us/step - loss: 0.1171 - val_loss: 0.1228\n",
      "Epoch 36/150\n",
      "261/261 [==============================] - 0s 410us/step - loss: 0.1156 - val_loss: 0.1217\n",
      "Epoch 37/150\n",
      "261/261 [==============================] - 0s 368us/step - loss: 0.1161 - val_loss: 0.1244\n",
      "Epoch 38/150\n",
      "261/261 [==============================] - 0s 398us/step - loss: 0.1180 - val_loss: 0.1223\n",
      "Epoch 39/150\n",
      "261/261 [==============================] - 0s 406us/step - loss: 0.1163 - val_loss: 0.1226\n",
      "Epoch 40/150\n",
      "261/261 [==============================] - 0s 379us/step - loss: 0.1156 - val_loss: 0.1225\n",
      "Epoch 41/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1145 - val_loss: 0.1217\n",
      "Epoch 42/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1141 - val_loss: 0.1317\n",
      "Epoch 43/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1214 - val_loss: 0.1223\n",
      "Epoch 44/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1142 - val_loss: 0.1235\n",
      "Epoch 45/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1149 - val_loss: 0.1214\n",
      "Epoch 46/150\n",
      "261/261 [==============================] - 0s 333us/step - loss: 0.1138 - val_loss: 0.1231\n",
      "Epoch 47/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1145 - val_loss: 0.1245\n",
      "Epoch 48/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1143 - val_loss: 0.1201\n",
      "Epoch 49/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1124 - val_loss: 0.1216\n",
      "Epoch 50/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1125 - val_loss: 0.1203\n",
      "Epoch 51/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1134 - val_loss: 0.1213\n",
      "Epoch 52/150\n",
      "261/261 [==============================] - 0s 364us/step - loss: 0.1122 - val_loss: 0.1209\n",
      "Epoch 53/150\n",
      "261/261 [==============================] - 0s 398us/step - loss: 0.1112 - val_loss: 0.1204\n",
      "Epoch 54/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1109 - val_loss: 0.1230\n",
      "Epoch 55/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1120 - val_loss: 0.1204\n",
      "Epoch 56/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1103 - val_loss: 0.1242\n",
      "Epoch 57/150\n",
      "261/261 [==============================] - 0s 333us/step - loss: 0.1138 - val_loss: 0.1224\n",
      "Epoch 58/150\n",
      "261/261 [==============================] - 0s 379us/step - loss: 0.1104 - val_loss: 0.1223\n",
      "Epoch 59/150\n",
      "261/261 [==============================] - 0s 318us/step - loss: 0.1108 - val_loss: 0.1220\n",
      "Epoch 60/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1100 - val_loss: 0.1228\n",
      "Epoch 61/150\n",
      "261/261 [==============================] - 0s 333us/step - loss: 0.1106 - val_loss: 0.1232\n",
      "Epoch 62/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1103 - val_loss: 0.1201\n",
      "Epoch 63/150\n",
      "261/261 [==============================] - 0s 353us/step - loss: 0.1092 - val_loss: 0.1211\n",
      "Epoch 64/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1097 - val_loss: 0.1207\n",
      "Epoch 65/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1098 - val_loss: 0.1207\n",
      "Epoch 66/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1086 - val_loss: 0.1216\n",
      "Epoch 67/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1102 - val_loss: 0.1215\n",
      "Epoch 68/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1089 - val_loss: 0.1216\n",
      "Epoch 69/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1089 - val_loss: 0.1207\n",
      "Epoch 70/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1081 - val_loss: 0.1213\n",
      "Epoch 71/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1079 - val_loss: 0.1201\n",
      "Epoch 72/150\n",
      "261/261 [==============================] - 0s 356us/step - loss: 0.1081 - val_loss: 0.1206\n",
      "Epoch 73/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1076 - val_loss: 0.1214\n",
      "Epoch 74/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1074 - val_loss: 0.1208\n",
      "Epoch 75/150\n",
      "261/261 [==============================] - 0s 356us/step - loss: 0.1082 - val_loss: 0.1197\n",
      "Epoch 76/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1073 - val_loss: 0.1215\n",
      "Epoch 77/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1080 - val_loss: 0.1197\n",
      "Epoch 78/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1075 - val_loss: 0.1203\n",
      "Epoch 79/150\n",
      "261/261 [==============================] - 0s 330us/step - loss: 0.1072 - val_loss: 0.1194\n",
      "Epoch 80/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1070 - val_loss: 0.1204\n",
      "Epoch 81/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1063 - val_loss: 0.1214\n",
      "Epoch 82/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1069 - val_loss: 0.1194\n",
      "Epoch 83/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1069 - val_loss: 0.1202\n",
      "Epoch 84/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1057 - val_loss: 0.1203\n",
      "Epoch 85/150\n",
      "261/261 [==============================] - 0s 333us/step - loss: 0.1059 - val_loss: 0.1199\n",
      "Epoch 86/150\n",
      "261/261 [==============================] - 0s 333us/step - loss: 0.1051 - val_loss: 0.1196\n",
      "Epoch 87/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1061 - val_loss: 0.1213\n",
      "Epoch 88/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1056 - val_loss: 0.1194\n",
      "Epoch 89/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1052 - val_loss: 0.1209\n",
      "Epoch 90/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1068 - val_loss: 0.1209\n",
      "Epoch 91/150\n",
      "261/261 [==============================] - 0s 330us/step - loss: 0.1055 - val_loss: 0.1193\n",
      "Epoch 92/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1052 - val_loss: 0.1194\n",
      "Epoch 93/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1050 - val_loss: 0.1197\n",
      "Epoch 94/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1046 - val_loss: 0.1185\n",
      "Epoch 95/150\n",
      "261/261 [==============================] - 0s 375us/step - loss: 0.1051 - val_loss: 0.1205\n",
      "Epoch 96/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1049 - val_loss: 0.1192\n",
      "Epoch 97/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1060 - val_loss: 0.1192\n",
      "Epoch 98/150\n",
      "261/261 [==============================] - 0s 333us/step - loss: 0.1055 - val_loss: 0.1189\n",
      "Epoch 99/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1052 - val_loss: 0.1189\n",
      "Epoch 100/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1053 - val_loss: 0.1197\n",
      "Epoch 101/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1043 - val_loss: 0.1184\n",
      "Epoch 102/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1039 - val_loss: 0.1198\n",
      "Epoch 103/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1043 - val_loss: 0.1199\n",
      "Epoch 104/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1041 - val_loss: 0.1192\n",
      "Epoch 105/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1044 - val_loss: 0.1207\n",
      "Epoch 106/150\n",
      "261/261 [==============================] - 0s 356us/step - loss: 0.1042 - val_loss: 0.1201\n",
      "Epoch 107/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1037 - val_loss: 0.1186\n",
      "Epoch 108/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1034 - val_loss: 0.1188\n",
      "Epoch 109/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1032 - val_loss: 0.1195\n",
      "Epoch 110/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1036 - val_loss: 0.1193\n",
      "Epoch 111/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1037 - val_loss: 0.1191\n",
      "Epoch 112/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1047 - val_loss: 0.1187\n",
      "Epoch 113/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1042 - val_loss: 0.1192\n",
      "Epoch 114/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1041 - val_loss: 0.1192\n",
      "Epoch 115/150\n",
      "261/261 [==============================] - 0s 391us/step - loss: 0.1033 - val_loss: 0.1185\n",
      "Epoch 116/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1033 - val_loss: 0.1189\n",
      "Epoch 117/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1025 - val_loss: 0.1199\n",
      "Epoch 118/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1035 - val_loss: 0.1186\n",
      "Epoch 119/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1035 - val_loss: 0.1178\n",
      "Epoch 120/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1037 - val_loss: 0.1194\n",
      "Epoch 121/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1035 - val_loss: 0.1190\n",
      "Epoch 122/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1034 - val_loss: 0.1181\n",
      "Epoch 123/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1028 - val_loss: 0.1180\n",
      "Epoch 124/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1029 - val_loss: 0.1186\n",
      "Epoch 125/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1027 - val_loss: 0.1185\n",
      "Epoch 126/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1028 - val_loss: 0.1182\n",
      "Epoch 127/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1026 - val_loss: 0.1190\n",
      "Epoch 128/150\n",
      "261/261 [==============================] - 0s 333us/step - loss: 0.1026 - val_loss: 0.1199\n",
      "Epoch 129/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1036 - val_loss: 0.1196\n",
      "Epoch 130/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1027 - val_loss: 0.1189\n",
      "Epoch 131/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1033 - val_loss: 0.1182\n",
      "Epoch 132/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1032 - val_loss: 0.1190\n",
      "Epoch 133/150\n",
      "261/261 [==============================] - 0s 356us/step - loss: 0.1024 - val_loss: 0.1183\n",
      "Epoch 134/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1022 - val_loss: 0.1187\n",
      "Epoch 135/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1027 - val_loss: 0.1180\n",
      "Epoch 136/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1027 - val_loss: 0.1186\n",
      "Epoch 137/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1027 - val_loss: 0.1188\n",
      "Epoch 138/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1021 - val_loss: 0.1185\n",
      "Epoch 139/150\n",
      "261/261 [==============================] - 0s 364us/step - loss: 0.1021 - val_loss: 0.1212\n",
      "Epoch 140/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1040 - val_loss: 0.1190\n",
      "Epoch 141/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1027 - val_loss: 0.1186\n",
      "Epoch 142/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1024 - val_loss: 0.1212\n",
      "Epoch 143/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1026 - val_loss: 0.1191\n",
      "Epoch 144/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1023 - val_loss: 0.1186\n",
      "Epoch 145/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1027 - val_loss: 0.1196\n",
      "Epoch 146/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1032 - val_loss: 0.1194\n",
      "Epoch 147/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.1029 - val_loss: 0.1189\n",
      "Epoch 148/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1023 - val_loss: 0.1212\n",
      "Epoch 149/150\n",
      "261/261 [==============================] - 0s 375us/step - loss: 0.1019 - val_loss: 0.1186\n",
      "Epoch 150/150\n",
      "261/261 [==============================] - 0s 333us/step - loss: 0.1015 - val_loss: 0.1191\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parsee = ct_sheet.sheet_names[2]\n",
    "data = ct_sheet.parse(parsee)\n",
    "data_features = data.loc[:, data.columns] \n",
    "data_features = data_features.drop(['ROI',11142,12142], axis=1)  \n",
    "\n",
    "parsee2 = ct_sheet.sheet_names[3]\n",
    "data2 = ct_sheet.parse(parsee2)\n",
    "data_labels = data2.loc[:, data2.columns] \n",
    "data_labels = data_labels.drop(['ROI',11142,12142], axis=1)  \n",
    "#Get rid of subject names to only have features now. #Need to remove ROIs. They don't convert to floats.\n",
    "#Get rid of ctx_rh_Medial_wall and ctx_lh_Medial_wall, not needed for analysis.\n",
    "#Have to standardize data. Scikit learn here. Need to create stratified K folds to avoid uneven distribution of risk groups.pcaCT1Y = PCA(n_components=150) #150 Features\n",
    "scaler_filename = \"IBIS_scaledSA1y.save\"\n",
    "scaler = joblib.load(scaler_filename)\n",
    "scaled_data_1y = scaler.transform(data_features)\n",
    "\n",
    "scaler_filename2 = \"IBIS_scaledSA2y.save\"\n",
    "scaler2 = joblib.load(scaler_filename2)\n",
    "scaled_data_2y = scaler.transform(data_labels)\n",
    "print(scaled_data_1y.shape)\n",
    "print(scaled_data_2y.shape)\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(scaled_data, scaled_labels, test_size=0.10, random_state=20)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(scaled_data_1y, scaled_data_2y, test_size=0.10, random_state=20)\n",
    "#Size of encoded representation\n",
    "#{'batch_size': 10, 'dropout': 0.15, 'encoded_layer_size': 25, 'epochs': 150, 'layer1_size': 100, 'layer2_size': 40}\n",
    "input_size = 148\n",
    "hidden_size = 100 #100\n",
    "hidden_size_2 = 40 #40\n",
    "encoding_dim = 25 #25\n",
    "dropout = 0.15\n",
    "#Increase layer size\n",
    "# Input Placeholder\n",
    "input_data = Input(shape=(input_size,))\n",
    "print(input_data)\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "hidden_e_1 = Dense(hidden_size, activation='tanh')(input_data) \n",
    "hidden_e_2 = Dense(hidden_size_2, activation='tanh')(hidden_e_1)\n",
    "dropout_layer = Dropout(dropout)(hidden_e_2)\n",
    "encoded = Dense(encoding_dim, activation='tanh')(dropout_layer)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "hidden_d_1 = Dense(hidden_size, activation='tanh')(encoded)\n",
    "dropout_layer_d = Dropout(dropout)(hidden_d_1)\n",
    "hidden_d_2 = Dense(hidden_size, activation='tanh')(dropout_layer_d)\n",
    "decoded = Dense(input_size, activation='tanh')(hidden_d_2) \n",
    "# this model maps an input to its prediction\n",
    "autoencoder = Model(input_data, decoded)\n",
    "# configure our model to use mean_absolute_error loss function, and the Adam optimizer:\n",
    "autoencoder.compile(optimizer='Adam', loss='mean_absolute_error')\n",
    "\n",
    "ac = autoencoder.fit(X_train, Y_train,\n",
    "epochs=150,\n",
    "batch_size=10,\n",
    "validation_data=(X_test, Y_test),\n",
    "shuffle=True)\n",
    "\n",
    "#print(ac.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(ac.history['loss'])\n",
    "plt.plot(ac.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "#plt.legend(['train'], loc='upper left')\n",
    "plt.axis([0, 150, 0.0, 0.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261, 148)\n",
      "(261, 148)\n",
      "(29, 148)\n",
      "(29, 148)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"Autoencoder Input 1 year Output 2 year SA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA2y\n",
      "SA1y\n",
      "MAE 2y AC 0.23384510976405568 \n"
     ]
    }
   ],
   "source": [
    "#Now calculate MAE on the original Gilmore Dataset\n",
    "#Input\n",
    "sa_sheet_2y = pd.ExcelFile(\"Scaled Gilmore Data for MAE.xlsx\") \n",
    "parsee = sa_sheet_2y.sheet_names[1]\n",
    "print(parsee)\n",
    "data = sa_sheet_2y.parse(parsee)\n",
    "data_features_sa2y = data.loc[:, data.columns] \n",
    "data_features_sa2y = data_features_sa2y.drop(['ROI'], axis=1)\n",
    "#Ground truth\n",
    "sa_sheet_1y = pd.ExcelFile(\"Scaled Gilmore Data for MAE.xlsx\") \n",
    "parsee = sa_sheet_1y.sheet_names[0]\n",
    "print(parsee)\n",
    "data = sa_sheet_1y.parse(parsee)\n",
    "data_features_sa1y = data.loc[:, data.columns] \n",
    "data_features_sa1y = data_features_sa1y.drop(['ROI'], axis=1)\n",
    "\n",
    "#Predict\n",
    "predicted_2yr_sa = autoencoder.predict(data_features_sa1y)\n",
    "truth_2yr_sa = data_features_sa2y.to_numpy()\n",
    "\n",
    "#Save\n",
    "#y_pred = pd.DataFrame(predicted_1yr_sa_gilmore)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE 2y AC {} '.format(mean_absolute_error(truth_2yr_sa, predicted_2yr_sa)))\n",
    "\n",
    "\n",
    "######Complete below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Y SA Scaled\n",
      "(36, 148)\n"
     ]
    }
   ],
   "source": [
    "sa_sheet_1y = pd.ExcelFile(\"Data to be Interpolated.xlsx\") \n",
    "parsee = sa_sheet_1y.sheet_names[4]\n",
    "print(parsee)\n",
    "data = sa_sheet_1y.parse(parsee)\n",
    "data_features_sa1y = data.loc[:, data.columns] \n",
    "data_features_sa1y = data_features_sa1y.drop(['ROI'], axis=1)\n",
    "\n",
    "print(data_features_sa1y.shape)\n",
    "\n",
    "predicted_2yr_sa = autoencoder.predict(data_features_sa1y)\n",
    "df = pd.DataFrame(predicted_2yr_sa)\n",
    "df.to_excel(\"Interpolated SA 2y.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
