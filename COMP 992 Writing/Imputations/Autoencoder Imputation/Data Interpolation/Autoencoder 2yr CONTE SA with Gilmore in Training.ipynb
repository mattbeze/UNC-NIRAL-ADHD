{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras import losses\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "\n",
    "ct_sheet = pd.ExcelFile(\"Training Data.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA2y\n",
      "SA1y\n"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "sa_sheet_2y = pd.ExcelFile(\"Scaled Gilmore Data for MAE.xlsx\") \n",
    "parsee = sa_sheet_2y.sheet_names[1]\n",
    "print(parsee)\n",
    "data = sa_sheet_2y.parse(parsee)\n",
    "data_features_sa2y = data.loc[:, data.columns] \n",
    "data_features_sa2y = data_features_sa2y.drop(['ROI'], axis=1)\n",
    "#Ground truth\n",
    "sa_sheet_1y = pd.ExcelFile(\"Scaled Gilmore Data for MAE.xlsx\") \n",
    "parsee = sa_sheet_1y.sheet_names[0]\n",
    "print(parsee)\n",
    "data = sa_sheet_1y.parse(parsee)\n",
    "data_features_sa1y = data.loc[:, data.columns] \n",
    "data_features_sa1y = data_features_sa1y.drop(['ROI'], axis=1)\n",
    "\n",
    "X_train_Gilmore, X_test_Gilmore, Y_train_Gilmore, Y_test_Gilmore = train_test_split(data_features_sa1y, data_features_sa2y, test_size=0.50, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290, 148)\n",
      "(290, 148)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "parsee = ct_sheet.sheet_names[2]\n",
    "data = ct_sheet.parse(parsee)\n",
    "data_features = data.loc[:, data.columns] \n",
    "data_features = data_features.drop(['ROI',11142,12142], axis=1)  \n",
    "\n",
    "parsee2 = ct_sheet.sheet_names[3]\n",
    "data2 = ct_sheet.parse(parsee2)\n",
    "data_labels = data2.loc[:, data2.columns] \n",
    "data_labels = data_labels.drop(['ROI',11142,12142], axis=1)  \n",
    "#Get rid of subject names to only have features now. #Need to remove ROIs. They don't convert to floats.\n",
    "#Get rid of ctx_rh_Medial_wall and ctx_lh_Medial_wall, not needed for analysis.\n",
    "#Have to standardize data. Scikit learn here. Need to create stratified K folds to avoid uneven distribution of risk groups.pcaCT1Y = PCA(n_components=150) #150 Features\n",
    "scaler_filename = \"IBIS_scaledSA1y.save\"\n",
    "scaler = joblib.load(scaler_filename)\n",
    "scaled_data_1y = scaler.transform(data_features)\n",
    "\n",
    "scaler_filename2 = \"IBIS_scaledSA2y.save\"\n",
    "scaler2 = joblib.load(scaler_filename2)\n",
    "scaled_data_2y = scaler.transform(data_labels)\n",
    "print(scaled_data_1y.shape)\n",
    "print(scaled_data_2y.shape)\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(scaled_data, scaled_labels, test_size=0.10, random_state=20)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(scaled_data_1y, scaled_data_2y, test_size=0.10, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(325, 148)\n",
      "(325, 148)\n"
     ]
    }
   ],
   "source": [
    "X_train_Gilmore_np = X_train_Gilmore.to_numpy()\n",
    "Y_train_Gilmore_np = Y_train_Gilmore.to_numpy()\n",
    "\n",
    "X_train_full = np.concatenate((X_train, X_train_Gilmore_np), axis=0)\n",
    "Y_train_full = np.concatenate((Y_train, Y_train_Gilmore_np), axis=0)\n",
    "\n",
    "print(X_train_full.shape)\n",
    "print(Y_train_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(None, 148), dtype=float32)\n",
      "Train on 325 samples, validate on 29 samples\n",
      "Epoch 1/150\n",
      "325/325 [==============================] - 1s 3ms/step - loss: 0.2519 - val_loss: 0.1498\n",
      "Epoch 2/150\n",
      "325/325 [==============================] - 0s 314us/step - loss: 0.1626 - val_loss: 0.1424\n",
      "Epoch 3/150\n",
      "325/325 [==============================] - 0s 323us/step - loss: 0.1493 - val_loss: 0.1412\n",
      "Epoch 4/150\n",
      "325/325 [==============================] - 0s 318us/step - loss: 0.1444 - val_loss: 0.1383\n",
      "Epoch 5/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1444 - val_loss: 0.1392\n",
      "Epoch 6/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1396 - val_loss: 0.1356\n",
      "Epoch 7/150\n",
      "325/325 [==============================] - 0s 291us/step - loss: 0.1359 - val_loss: 0.1382\n",
      "Epoch 8/150\n",
      "325/325 [==============================] - 0s 325us/step - loss: 0.1354 - val_loss: 0.1315\n",
      "Epoch 9/150\n",
      "325/325 [==============================] - 0s 323us/step - loss: 0.1322 - val_loss: 0.1310\n",
      "Epoch 10/150\n",
      "325/325 [==============================] - 0s 320us/step - loss: 0.1324 - val_loss: 0.1316\n",
      "Epoch 11/150\n",
      "325/325 [==============================] - 0s 318us/step - loss: 0.1315 - val_loss: 0.1306\n",
      "Epoch 12/150\n",
      "325/325 [==============================] - 0s 320us/step - loss: 0.1304 - val_loss: 0.1301\n",
      "Epoch 13/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1286 - val_loss: 0.1299\n",
      "Epoch 14/150\n",
      "325/325 [==============================] - 0s 306us/step - loss: 0.1276 - val_loss: 0.1315\n",
      "Epoch 15/150\n",
      "325/325 [==============================] - 0s 320us/step - loss: 0.1278 - val_loss: 0.1302\n",
      "Epoch 16/150\n",
      "325/325 [==============================] - 0s 311us/step - loss: 0.1270 - val_loss: 0.1292\n",
      "Epoch 17/150\n",
      "325/325 [==============================] - 0s 355us/step - loss: 0.1257 - val_loss: 0.1284\n",
      "Epoch 18/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1252 - val_loss: 0.1293\n",
      "Epoch 19/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1244 - val_loss: 0.1291\n",
      "Epoch 20/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1237 - val_loss: 0.1287\n",
      "Epoch 21/150\n",
      "325/325 [==============================] - 0s 323us/step - loss: 0.1232 - val_loss: 0.1268\n",
      "Epoch 22/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1231 - val_loss: 0.1277\n",
      "Epoch 23/150\n",
      "325/325 [==============================] - 0s 328us/step - loss: 0.1214 - val_loss: 0.1262\n",
      "Epoch 24/150\n",
      "325/325 [==============================] - 0s 311us/step - loss: 0.1236 - val_loss: 0.1268\n",
      "Epoch 25/150\n",
      "325/325 [==============================] - 0s 306us/step - loss: 0.1208 - val_loss: 0.1276\n",
      "Epoch 26/150\n",
      "325/325 [==============================] - 0s 293us/step - loss: 0.1209 - val_loss: 0.1282\n",
      "Epoch 27/150\n",
      "325/325 [==============================] - 0s 323us/step - loss: 0.1209 - val_loss: 0.1250\n",
      "Epoch 28/150\n",
      "325/325 [==============================] - 0s 320us/step - loss: 0.1193 - val_loss: 0.1337\n",
      "Epoch 29/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1209 - val_loss: 0.1253\n",
      "Epoch 30/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1195 - val_loss: 0.1281\n",
      "Epoch 31/150\n",
      "325/325 [==============================] - 0s 306us/step - loss: 0.1210 - val_loss: 0.1250\n",
      "Epoch 32/150\n",
      "325/325 [==============================] - 0s 294us/step - loss: 0.1183 - val_loss: 0.1240\n",
      "Epoch 33/150\n",
      "325/325 [==============================] - 0s 347us/step - loss: 0.1186 - val_loss: 0.1252\n",
      "Epoch 34/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1166 - val_loss: 0.1239\n",
      "Epoch 35/150\n",
      "325/325 [==============================] - 0s 320us/step - loss: 0.1170 - val_loss: 0.1243\n",
      "Epoch 36/150\n",
      "325/325 [==============================] - 0s 323us/step - loss: 0.1166 - val_loss: 0.1229\n",
      "Epoch 37/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1170 - val_loss: 0.1253\n",
      "Epoch 38/150\n",
      "325/325 [==============================] - 0s 303us/step - loss: 0.1162 - val_loss: 0.1233\n",
      "Epoch 39/150\n",
      "325/325 [==============================] - 0s 298us/step - loss: 0.1153 - val_loss: 0.1240\n",
      "Epoch 40/150\n",
      "325/325 [==============================] - 0s 292us/step - loss: 0.1156 - val_loss: 0.1232\n",
      "Epoch 41/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1153 - val_loss: 0.1240\n",
      "Epoch 42/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1151 - val_loss: 0.1250\n",
      "Epoch 43/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1151 - val_loss: 0.1233\n",
      "Epoch 44/150\n",
      "325/325 [==============================] - 0s 323us/step - loss: 0.1146 - val_loss: 0.1223\n",
      "Epoch 45/150\n",
      "325/325 [==============================] - 0s 318us/step - loss: 0.1148 - val_loss: 0.1236\n",
      "Epoch 46/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1145 - val_loss: 0.1233\n",
      "Epoch 47/150\n",
      "325/325 [==============================] - 0s 308us/step - loss: 0.1157 - val_loss: 0.1225\n",
      "Epoch 48/150\n",
      "325/325 [==============================] - 0s 270us/step - loss: 0.1142 - val_loss: 0.1242\n",
      "Epoch 49/150\n",
      "325/325 [==============================] - 0s 303us/step - loss: 0.1136 - val_loss: 0.1222\n",
      "Epoch 50/150\n",
      "325/325 [==============================] - 0s 300us/step - loss: 0.1140 - val_loss: 0.1247\n",
      "Epoch 51/150\n",
      "325/325 [==============================] - 0s 316us/step - loss: 0.1141 - val_loss: 0.1230\n",
      "Epoch 52/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1132 - val_loss: 0.1229\n",
      "Epoch 53/150\n",
      "325/325 [==============================] - 0s 323us/step - loss: 0.1123 - val_loss: 0.1219\n",
      "Epoch 54/150\n",
      "325/325 [==============================] - 0s 318us/step - loss: 0.1124 - val_loss: 0.1227\n",
      "Epoch 55/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1121 - val_loss: 0.1217\n",
      "Epoch 56/150\n",
      "325/325 [==============================] - 0s 320us/step - loss: 0.1123 - val_loss: 0.1237\n",
      "Epoch 57/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1126 - val_loss: 0.1215\n",
      "Epoch 58/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1122 - val_loss: 0.1222\n",
      "Epoch 59/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1116 - val_loss: 0.1216\n",
      "Epoch 60/150\n",
      "325/325 [==============================] - 0s 298us/step - loss: 0.1112 - val_loss: 0.1225\n",
      "Epoch 61/150\n",
      "325/325 [==============================] - 0s 281us/step - loss: 0.1112 - val_loss: 0.1214\n",
      "Epoch 62/150\n",
      "325/325 [==============================] - 0s 272us/step - loss: 0.1107 - val_loss: 0.1210\n",
      "Epoch 63/150\n",
      "325/325 [==============================] - 0s 308us/step - loss: 0.1107 - val_loss: 0.1211\n",
      "Epoch 64/150\n",
      "325/325 [==============================] - 0s 293us/step - loss: 0.1109 - val_loss: 0.1210\n",
      "Epoch 65/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1110 - val_loss: 0.1205\n",
      "Epoch 66/150\n",
      "325/325 [==============================] - 0s 320us/step - loss: 0.1112 - val_loss: 0.1207\n",
      "Epoch 67/150\n",
      "325/325 [==============================] - 0s 298us/step - loss: 0.1106 - val_loss: 0.1216\n",
      "Epoch 68/150\n",
      "325/325 [==============================] - 0s 318us/step - loss: 0.1105 - val_loss: 0.1217\n",
      "Epoch 69/150\n",
      "325/325 [==============================] - 0s 307us/step - loss: 0.1110 - val_loss: 0.1205\n",
      "Epoch 70/150\n",
      "325/325 [==============================] - 0s 273us/step - loss: 0.1110 - val_loss: 0.1232\n",
      "Epoch 71/150\n",
      "325/325 [==============================] - 0s 306us/step - loss: 0.1108 - val_loss: 0.1204\n",
      "Epoch 72/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1107 - val_loss: 0.1209\n",
      "Epoch 73/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1090 - val_loss: 0.1205\n",
      "Epoch 74/150\n",
      "325/325 [==============================] - 0s 348us/step - loss: 0.1095 - val_loss: 0.1208\n",
      "Epoch 75/150\n",
      "325/325 [==============================] - 0s 392us/step - loss: 0.1090 - val_loss: 0.1202\n",
      "Epoch 76/150\n",
      "325/325 [==============================] - 0s 347us/step - loss: 0.1092 - val_loss: 0.1206\n",
      "Epoch 77/150\n",
      "325/325 [==============================] - 0s 375us/step - loss: 0.1090 - val_loss: 0.1210\n",
      "Epoch 78/150\n",
      "325/325 [==============================] - 0s 387us/step - loss: 0.1086 - val_loss: 0.1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/150\n",
      "325/325 [==============================] - 0s 387us/step - loss: 0.1086 - val_loss: 0.1209\n",
      "Epoch 80/150\n",
      "325/325 [==============================] - 0s 385us/step - loss: 0.1083 - val_loss: 0.1206\n",
      "Epoch 81/150\n",
      "325/325 [==============================] - 0s 394us/step - loss: 0.1082 - val_loss: 0.1199\n",
      "Epoch 82/150\n",
      "325/325 [==============================] - 0s 373us/step - loss: 0.1097 - val_loss: 0.1217\n",
      "Epoch 83/150\n",
      "325/325 [==============================] - 0s 336us/step - loss: 0.1088 - val_loss: 0.1207\n",
      "Epoch 84/150\n",
      "325/325 [==============================] - 0s 342us/step - loss: 0.1088 - val_loss: 0.1211\n",
      "Epoch 85/150\n",
      "325/325 [==============================] - 0s 348us/step - loss: 0.1088 - val_loss: 0.1197\n",
      "Epoch 86/150\n",
      "325/325 [==============================] - 0s 293us/step - loss: 0.1083 - val_loss: 0.1202\n",
      "Epoch 87/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1082 - val_loss: 0.1190\n",
      "Epoch 88/150\n",
      "325/325 [==============================] - 0s 299us/step - loss: 0.1080 - val_loss: 0.1201\n",
      "Epoch 89/150\n",
      "325/325 [==============================] - 0s 318us/step - loss: 0.1086 - val_loss: 0.1197\n",
      "Epoch 90/150\n",
      "325/325 [==============================] - 0s 320us/step - loss: 0.1083 - val_loss: 0.1212\n",
      "Epoch 91/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1081 - val_loss: 0.1212\n",
      "Epoch 92/150\n",
      "325/325 [==============================] - 0s 299us/step - loss: 0.1082 - val_loss: 0.1210\n",
      "Epoch 93/150\n",
      "325/325 [==============================] - 0s 303us/step - loss: 0.1080 - val_loss: 0.1205\n",
      "Epoch 94/150\n",
      "325/325 [==============================] - 0s 298us/step - loss: 0.1081 - val_loss: 0.1190\n",
      "Epoch 95/150\n",
      "325/325 [==============================] - 0s 293us/step - loss: 0.1081 - val_loss: 0.1213\n",
      "Epoch 96/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1075 - val_loss: 0.1193\n",
      "Epoch 97/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1078 - val_loss: 0.1196\n",
      "Epoch 98/150\n",
      "325/325 [==============================] - 0s 283us/step - loss: 0.1086 - val_loss: 0.1194\n",
      "Epoch 99/150\n",
      "325/325 [==============================] - 0s 308us/step - loss: 0.1087 - val_loss: 0.1200\n",
      "Epoch 100/150\n",
      "325/325 [==============================] - 0s 355us/step - loss: 0.1081 - val_loss: 0.1194\n",
      "Epoch 101/150\n",
      "325/325 [==============================] - 0s 298us/step - loss: 0.1074 - val_loss: 0.1191\n",
      "Epoch 102/150\n",
      "325/325 [==============================] - 0s 293us/step - loss: 0.1077 - val_loss: 0.1203\n",
      "Epoch 103/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1068 - val_loss: 0.1201\n",
      "Epoch 104/150\n",
      "325/325 [==============================] - 0s 299us/step - loss: 0.1072 - val_loss: 0.1199\n",
      "Epoch 105/150\n",
      "325/325 [==============================] - 0s 318us/step - loss: 0.1077 - val_loss: 0.1198\n",
      "Epoch 106/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1077 - val_loss: 0.1219\n",
      "Epoch 107/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1077 - val_loss: 0.1226\n",
      "Epoch 108/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1075 - val_loss: 0.1198\n",
      "Epoch 109/150\n",
      "325/325 [==============================] - 0s 306us/step - loss: 0.1073 - val_loss: 0.1203\n",
      "Epoch 110/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1072 - val_loss: 0.1200\n",
      "Epoch 111/150\n",
      "325/325 [==============================] - 0s 298us/step - loss: 0.1068 - val_loss: 0.1197\n",
      "Epoch 112/150\n",
      "325/325 [==============================] - 0s 318us/step - loss: 0.1071 - val_loss: 0.1197\n",
      "Epoch 113/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1076 - val_loss: 0.1200\n",
      "Epoch 114/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1066 - val_loss: 0.1222\n",
      "Epoch 115/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1067 - val_loss: 0.1213\n",
      "Epoch 116/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1076 - val_loss: 0.1210\n",
      "Epoch 117/150\n",
      "325/325 [==============================] - 0s 281us/step - loss: 0.1072 - val_loss: 0.1195\n",
      "Epoch 118/150\n",
      "325/325 [==============================] - 0s 269us/step - loss: 0.1065 - val_loss: 0.1203\n",
      "Epoch 119/150\n",
      "325/325 [==============================] - 0s 306us/step - loss: 0.1070 - val_loss: 0.1195\n",
      "Epoch 120/150\n",
      "325/325 [==============================] - 0s 294us/step - loss: 0.1066 - val_loss: 0.1192\n",
      "Epoch 121/150\n",
      "325/325 [==============================] - 0s 323us/step - loss: 0.1064 - val_loss: 0.1192\n",
      "Epoch 122/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1067 - val_loss: 0.1224\n",
      "Epoch 123/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1067 - val_loss: 0.1194\n",
      "Epoch 124/150\n",
      "325/325 [==============================] - 0s 320us/step - loss: 0.1063 - val_loss: 0.1190\n",
      "Epoch 125/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1071 - val_loss: 0.1194\n",
      "Epoch 126/150\n",
      "325/325 [==============================] - 0s 320us/step - loss: 0.1068 - val_loss: 0.1199\n",
      "Epoch 127/150\n",
      "325/325 [==============================] - 0s 330us/step - loss: 0.1062 - val_loss: 0.1194\n",
      "Epoch 128/150\n",
      "325/325 [==============================] - 0s 311us/step - loss: 0.1061 - val_loss: 0.1194\n",
      "Epoch 129/150\n",
      "325/325 [==============================] - 0s 306us/step - loss: 0.1069 - val_loss: 0.1211\n",
      "Epoch 130/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1067 - val_loss: 0.1195\n",
      "Epoch 131/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1060 - val_loss: 0.1190\n",
      "Epoch 132/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1069 - val_loss: 0.1210\n",
      "Epoch 133/150\n",
      "325/325 [==============================] - 0s 320us/step - loss: 0.1066 - val_loss: 0.1218\n",
      "Epoch 134/150\n",
      "325/325 [==============================] - 0s 347us/step - loss: 0.1066 - val_loss: 0.1191\n",
      "Epoch 135/150\n",
      "325/325 [==============================] - 0s 295us/step - loss: 0.1066 - val_loss: 0.1200\n",
      "Epoch 136/150\n",
      "325/325 [==============================] - 0s 319us/step - loss: 0.1076 - val_loss: 0.1197\n",
      "Epoch 137/150\n",
      "325/325 [==============================] - 0s 345us/step - loss: 0.1057 - val_loss: 0.1198\n",
      "Epoch 138/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1062 - val_loss: 0.1198\n",
      "Epoch 139/150\n",
      "325/325 [==============================] - 0s 299us/step - loss: 0.1058 - val_loss: 0.1212\n",
      "Epoch 140/150\n",
      "325/325 [==============================] - 0s 293us/step - loss: 0.1063 - val_loss: 0.1190\n",
      "Epoch 141/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1058 - val_loss: 0.1205\n",
      "Epoch 142/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1067 - val_loss: 0.1191\n",
      "Epoch 143/150\n",
      "325/325 [==============================] - 0s 345us/step - loss: 0.1066 - val_loss: 0.1200\n",
      "Epoch 144/150\n",
      "325/325 [==============================] - 0s 360us/step - loss: 0.1072 - val_loss: 0.1202\n",
      "Epoch 145/150\n",
      "325/325 [==============================] - 0s 321us/step - loss: 0.1061 - val_loss: 0.1192\n",
      "Epoch 146/150\n",
      "325/325 [==============================] - 0s 296us/step - loss: 0.1060 - val_loss: 0.1197\n",
      "Epoch 147/150\n",
      "325/325 [==============================] - 0s 320us/step - loss: 0.1053 - val_loss: 0.1197\n",
      "Epoch 148/150\n",
      "325/325 [==============================] - 0s 299us/step - loss: 0.1056 - val_loss: 0.1191\n",
      "Epoch 149/150\n",
      "325/325 [==============================] - 0s 329us/step - loss: 0.1058 - val_loss: 0.1203\n",
      "Epoch 150/150\n",
      "325/325 [==============================] - 0s 273us/step - loss: 0.1061 - val_loss: 0.1199\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Size of encoded representation\n",
    "#{'batch_size': 10, 'dropout': 0.15, 'encoded_layer_size': 25, 'epochs': 150, 'layer1_size': 100, 'layer2_size': 40}\n",
    "input_size = 148\n",
    "hidden_size = 100 #100\n",
    "hidden_size_2 = 40 #40\n",
    "encoding_dim = 25 #25\n",
    "dropout = 0.15\n",
    "#Increase layer size\n",
    "# Input Placeholder\n",
    "input_data = Input(shape=(input_size,))\n",
    "print(input_data)\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "hidden_e_1 = Dense(hidden_size, activation='tanh')(input_data) \n",
    "hidden_e_2 = Dense(hidden_size_2, activation='tanh')(hidden_e_1)\n",
    "dropout_layer = Dropout(dropout)(hidden_e_2)\n",
    "encoded = Dense(encoding_dim, activation='tanh')(dropout_layer)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "hidden_d_1 = Dense(hidden_size, activation='tanh')(encoded)\n",
    "dropout_layer_d = Dropout(dropout)(hidden_d_1)\n",
    "hidden_d_2 = Dense(hidden_size, activation='tanh')(dropout_layer_d)\n",
    "decoded = Dense(input_size, activation='tanh')(hidden_d_2) \n",
    "# this model maps an input to its prediction\n",
    "autoencoder = Model(input_data, decoded)\n",
    "# configure our model to use mean_absolute_error loss function, and the Adam optimizer:\n",
    "autoencoder.compile(optimizer='Adam', loss='mean_absolute_error')\n",
    "\n",
    "ac = autoencoder.fit(X_train_full, Y_train_full,\n",
    "epochs=150,\n",
    "batch_size=10,\n",
    "validation_data=(X_test, Y_test),\n",
    "shuffle=True)\n",
    "\n",
    "#print(ac.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(ac.history['loss'])\n",
    "plt.plot(ac.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "#plt.legend(['train'], loc='upper left')\n",
    "plt.axis([0, 150, 0.0, 0.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"Autoencoder Input 1 year Output 2 year SA with Gilmore in training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 2y AC 0.11855218016640681 \n"
     ]
    }
   ],
   "source": [
    "#Now calculate MAE on the original Gilmore Dataset\n",
    "\n",
    "#Predict\n",
    "predicted_2yr_sa = autoencoder.predict(X_test_Gilmore)\n",
    "truth_2yr_sa = Y_test_Gilmore.to_numpy()\n",
    "\n",
    "#Save\n",
    "#y_pred = pd.DataFrame(predicted_1yr_sa_gilmore)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE 2y AC {} '.format(mean_absolute_error(truth_2yr_sa, predicted_2yr_sa)))\n",
    "\n",
    "\n",
    "######Complete below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Y SA Scaled\n",
      "(36, 148)\n"
     ]
    }
   ],
   "source": [
    "sa_sheet_1y = pd.ExcelFile(\"Data to be Interpolated.xlsx\") \n",
    "parsee = sa_sheet_1y.sheet_names[4]\n",
    "print(parsee)\n",
    "data = sa_sheet_1y.parse(parsee)\n",
    "data_features_sa1y = data.loc[:, data.columns] \n",
    "data_features_sa1y = data_features_sa1y.drop(['ROI'], axis=1)\n",
    "\n",
    "print(data_features_sa1y.shape)\n",
    "\n",
    "predicted_2yr_sa = autoencoder.predict(data_features_sa1y)\n",
    "df = pd.DataFrame(predicted_2yr_sa)\n",
    "df.to_excel(\"Interpolated SA 2y with Gilmore in training.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
