{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras import losses\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "\n",
    "ct_sheet = pd.ExcelFile(\"Training Data.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA2y\n",
      "SA1y\n"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "sa_sheet_2y = pd.ExcelFile(\"Scaled Gilmore Data for MAE.xlsx\") \n",
    "parsee = sa_sheet_2y.sheet_names[1]\n",
    "print(parsee)\n",
    "data = sa_sheet_2y.parse(parsee)\n",
    "data_features_sa2y = data.loc[:, data.columns] \n",
    "data_features_sa2y = data_features_sa2y.drop(['ROI'], axis=1)\n",
    "#Ground truth\n",
    "sa_sheet_1y = pd.ExcelFile(\"Scaled Gilmore Data for MAE.xlsx\") \n",
    "parsee = sa_sheet_1y.sheet_names[0]\n",
    "print(parsee)\n",
    "data = sa_sheet_1y.parse(parsee)\n",
    "data_features_sa1y = data.loc[:, data.columns] \n",
    "data_features_sa1y = data_features_sa1y.drop(['ROI'], axis=1)\n",
    "\n",
    "X_train_Gilmore, X_test_Gilmore, Y_train_Gilmore, Y_test_Gilmore = train_test_split(data_features_sa2y, data_features_sa1y, test_size=0.50, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290, 148)\n",
      "(290, 148)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "parsee = ct_sheet.sheet_names[2]\n",
    "data = ct_sheet.parse(parsee)\n",
    "data_features = data.loc[:, data.columns] \n",
    "data_features = data_features.drop(['ROI',11142,12142], axis=1)  \n",
    "\n",
    "parsee2 = ct_sheet.sheet_names[3]\n",
    "data2 = ct_sheet.parse(parsee2)\n",
    "data_labels = data2.loc[:, data2.columns] \n",
    "data_labels = data_labels.drop(['ROI',11142,12142], axis=1)  \n",
    "#Get rid of subject names to only have features now. #Need to remove ROIs. They don't convert to floats.\n",
    "#Get rid of ctx_rh_Medial_wall and ctx_lh_Medial_wall, not needed for analysis.\n",
    "#Have to standardize data. Scikit learn here. Need to create stratified K folds to avoid uneven distribution of risk groups.pcaCT1Y = PCA(n_components=150) #150 Features\n",
    "scaler_filename = \"IBIS_scaledSA1y.save\"\n",
    "scaler = joblib.load(scaler_filename)\n",
    "scaled_data_1y = scaler.transform(data_features)\n",
    "\n",
    "scaler_filename2 = \"IBIS_scaledSA2y.save\"\n",
    "scaler2 = joblib.load(scaler_filename2)\n",
    "scaled_data_2y = scaler.transform(data_labels)\n",
    "print(scaled_data_1y.shape)\n",
    "print(scaled_data_2y.shape)\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(scaled_data, scaled_labels, test_size=0.10, random_state=20)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(scaled_data_2y, scaled_data_1y, test_size=0.10, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(325, 148)\n",
      "(325, 148)\n"
     ]
    }
   ],
   "source": [
    "X_train_Gilmore_np = X_train_Gilmore.to_numpy()\n",
    "Y_train_Gilmore_np = Y_train_Gilmore.to_numpy()\n",
    "\n",
    "X_train_full = np.concatenate((X_train, X_train_Gilmore_np), axis=0)\n",
    "Y_train_full = np.concatenate((Y_train, Y_train_Gilmore_np), axis=0)\n",
    "\n",
    "print(X_train_full.shape)\n",
    "print(Y_train_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(None, 148), dtype=float32)\n",
      "Train on 325 samples, validate on 29 samples\n",
      "Epoch 1/150\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.2155 - val_loss: 0.1278\n",
      "Epoch 2/150\n",
      "325/325 [==============================] - 0s 320us/step - loss: 0.1440 - val_loss: 0.1278\n",
      "Epoch 3/150\n",
      "325/325 [==============================] - 0s 340us/step - loss: 0.1339 - val_loss: 0.1179\n",
      "Epoch 4/150\n",
      "325/325 [==============================] - 0s 295us/step - loss: 0.1274 - val_loss: 0.1138\n",
      "Epoch 5/150\n",
      "325/325 [==============================] - 0s 293us/step - loss: 0.1228 - val_loss: 0.1131\n",
      "Epoch 6/150\n",
      "325/325 [==============================] - 0s 240us/step - loss: 0.1203 - val_loss: 0.1111\n",
      "Epoch 7/150\n",
      "325/325 [==============================] - 0s 240us/step - loss: 0.1184 - val_loss: 0.1141\n",
      "Epoch 8/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1174 - val_loss: 0.1115\n",
      "Epoch 9/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1149 - val_loss: 0.1125\n",
      "Epoch 10/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1141 - val_loss: 0.1115\n",
      "Epoch 11/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1136 - val_loss: 0.1149\n",
      "Epoch 12/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1119 - val_loss: 0.1077\n",
      "Epoch 13/150\n",
      "325/325 [==============================] - 0s 381us/step - loss: 0.1104 - val_loss: 0.1078\n",
      "Epoch 14/150\n",
      "325/325 [==============================] - 0s 345us/step - loss: 0.1099 - val_loss: 0.1079\n",
      "Epoch 15/150\n",
      "325/325 [==============================] - 0s 385us/step - loss: 0.1103 - val_loss: 0.1072\n",
      "Epoch 16/150\n",
      "325/325 [==============================] - 0s 339us/step - loss: 0.1092 - val_loss: 0.1142\n",
      "Epoch 17/150\n",
      "325/325 [==============================] - 0s 337us/step - loss: 0.1095 - val_loss: 0.1072\n",
      "Epoch 18/150\n",
      "325/325 [==============================] - 0s 337us/step - loss: 0.1091 - val_loss: 0.1088\n",
      "Epoch 19/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1073 - val_loss: 0.1075\n",
      "Epoch 20/150\n",
      "325/325 [==============================] - 0s 435us/step - loss: 0.1069 - val_loss: 0.1081\n",
      "Epoch 21/150\n",
      "325/325 [==============================] - 0s 346us/step - loss: 0.1082 - val_loss: 0.1089\n",
      "Epoch 22/150\n",
      "325/325 [==============================] - 0s 407us/step - loss: 0.1062 - val_loss: 0.1089\n",
      "Epoch 23/150\n",
      "325/325 [==============================] - 0s 478us/step - loss: 0.1059 - val_loss: 0.1059\n",
      "Epoch 24/150\n",
      "325/325 [==============================] - 0s 436us/step - loss: 0.1052 - val_loss: 0.1062\n",
      "Epoch 25/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1038 - val_loss: 0.1057\n",
      "Epoch 26/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1041 - val_loss: 0.1055\n",
      "Epoch 27/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1041 - val_loss: 0.1045\n",
      "Epoch 28/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1036 - val_loss: 0.1069\n",
      "Epoch 29/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1029 - val_loss: 0.1052\n",
      "Epoch 30/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1028 - val_loss: 0.1050\n",
      "Epoch 31/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1029 - val_loss: 0.1059\n",
      "Epoch 32/150\n",
      "325/325 [==============================] - 0s 292us/step - loss: 0.1015 - val_loss: 0.1049\n",
      "Epoch 33/150\n",
      "325/325 [==============================] - 0s 295us/step - loss: 0.1006 - val_loss: 0.1056\n",
      "Epoch 34/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1006 - val_loss: 0.1041\n",
      "Epoch 35/150\n",
      "325/325 [==============================] - 0s 295us/step - loss: 0.1006 - val_loss: 0.1054\n",
      "Epoch 36/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0999 - val_loss: 0.1046\n",
      "Epoch 37/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0999 - val_loss: 0.1037\n",
      "Epoch 38/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0992 - val_loss: 0.1037\n",
      "Epoch 39/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0987 - val_loss: 0.1025\n",
      "Epoch 40/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.1004 - val_loss: 0.1044\n",
      "Epoch 41/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0992 - val_loss: 0.1032\n",
      "Epoch 42/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0979 - val_loss: 0.1036\n",
      "Epoch 43/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0985 - val_loss: 0.1042\n",
      "Epoch 44/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0986 - val_loss: 0.1029\n",
      "Epoch 45/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0986 - val_loss: 0.1029\n",
      "Epoch 46/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0974 - val_loss: 0.1045\n",
      "Epoch 47/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0973 - val_loss: 0.1044\n",
      "Epoch 48/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0983 - val_loss: 0.1032\n",
      "Epoch 49/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0975 - val_loss: 0.1056\n",
      "Epoch 50/150\n",
      "325/325 [==============================] - 0s 337us/step - loss: 0.0970 - val_loss: 0.1031\n",
      "Epoch 51/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0972 - val_loss: 0.1029\n",
      "Epoch 52/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0970 - val_loss: 0.1020\n",
      "Epoch 53/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0965 - val_loss: 0.1038\n",
      "Epoch 54/150\n",
      "325/325 [==============================] - 0s 337us/step - loss: 0.0966 - val_loss: 0.1029\n",
      "Epoch 55/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0967 - val_loss: 0.1034\n",
      "Epoch 56/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0958 - val_loss: 0.1030\n",
      "Epoch 57/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0966 - val_loss: 0.1037\n",
      "Epoch 58/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0963 - val_loss: 0.1023\n",
      "Epoch 59/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0949 - val_loss: 0.1026\n",
      "Epoch 60/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0956 - val_loss: 0.1023\n",
      "Epoch 61/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0950 - val_loss: 0.1024\n",
      "Epoch 62/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0949 - val_loss: 0.1026\n",
      "Epoch 63/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0944 - val_loss: 0.1014\n",
      "Epoch 64/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0947 - val_loss: 0.1016\n",
      "Epoch 65/150\n",
      "325/325 [==============================] - 0s 337us/step - loss: 0.0947 - val_loss: 0.1038\n",
      "Epoch 66/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0944 - val_loss: 0.1019\n",
      "Epoch 67/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0948 - val_loss: 0.1028\n",
      "Epoch 68/150\n",
      "325/325 [==============================] - 0s 407us/step - loss: 0.0956 - val_loss: 0.1036\n",
      "Epoch 69/150\n",
      "325/325 [==============================] - 0s 311us/step - loss: 0.0948 - val_loss: 0.1017\n",
      "Epoch 70/150\n",
      "325/325 [==============================] - 0s 337us/step - loss: 0.0943 - val_loss: 0.1027\n",
      "Epoch 71/150\n",
      "325/325 [==============================] - 0s 332us/step - loss: 0.0940 - val_loss: 0.1028\n",
      "Epoch 72/150\n",
      "325/325 [==============================] - 0s 418us/step - loss: 0.0945 - val_loss: 0.1009\n",
      "Epoch 73/150\n",
      "325/325 [==============================] - 0s 474us/step - loss: 0.0948 - val_loss: 0.1040\n",
      "Epoch 74/150\n",
      "325/325 [==============================] - 0s 442us/step - loss: 0.0941 - val_loss: 0.1030\n",
      "Epoch 75/150\n",
      "325/325 [==============================] - 0s 430us/step - loss: 0.0940 - val_loss: 0.1023\n",
      "Epoch 76/150\n",
      "325/325 [==============================] - 0s 395us/step - loss: 0.0937 - val_loss: 0.1017\n",
      "Epoch 77/150\n",
      "325/325 [==============================] - 0s 479us/step - loss: 0.0935 - val_loss: 0.1029\n",
      "Epoch 78/150\n",
      "325/325 [==============================] - 0s 385us/step - loss: 0.0933 - val_loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/150\n",
      "325/325 [==============================] - 0s 398us/step - loss: 0.0935 - val_loss: 0.1011\n",
      "Epoch 80/150\n",
      "325/325 [==============================] - 0s 448us/step - loss: 0.0936 - val_loss: 0.1015\n",
      "Epoch 81/150\n",
      "325/325 [==============================] - 0s 433us/step - loss: 0.0936 - val_loss: 0.1018\n",
      "Epoch 82/150\n",
      "325/325 [==============================] - 0s 425us/step - loss: 0.0931 - val_loss: 0.1052\n",
      "Epoch 83/150\n",
      "325/325 [==============================] - 0s 424us/step - loss: 0.0937 - val_loss: 0.1020\n",
      "Epoch 84/150\n",
      "325/325 [==============================] - 0s 378us/step - loss: 0.0934 - val_loss: 0.1022\n",
      "Epoch 85/150\n",
      "325/325 [==============================] - 0s 449us/step - loss: 0.0931 - val_loss: 0.1012\n",
      "Epoch 86/150\n",
      "325/325 [==============================] - 0s 406us/step - loss: 0.0931 - val_loss: 0.1018\n",
      "Epoch 87/150\n",
      "325/325 [==============================] - 0s 449us/step - loss: 0.0940 - val_loss: 0.1029\n",
      "Epoch 88/150\n",
      "325/325 [==============================] - 0s 423us/step - loss: 0.0935 - val_loss: 0.1020\n",
      "Epoch 89/150\n",
      "325/325 [==============================] - 0s 409us/step - loss: 0.0927 - val_loss: 0.1012\n",
      "Epoch 90/150\n",
      "325/325 [==============================] - 0s 446us/step - loss: 0.0923 - val_loss: 0.1020\n",
      "Epoch 91/150\n",
      "325/325 [==============================] - 0s 400us/step - loss: 0.0921 - val_loss: 0.1013\n",
      "Epoch 92/150\n",
      "325/325 [==============================] - 0s 473us/step - loss: 0.0926 - val_loss: 0.1020\n",
      "Epoch 93/150\n",
      "325/325 [==============================] - 0s 385us/step - loss: 0.0923 - val_loss: 0.1006\n",
      "Epoch 94/150\n",
      "325/325 [==============================] - 0s 424us/step - loss: 0.0926 - val_loss: 0.1012\n",
      "Epoch 95/150\n",
      "325/325 [==============================] - 0s 473us/step - loss: 0.0921 - val_loss: 0.1011\n",
      "Epoch 96/150\n",
      "325/325 [==============================] - 0s 424us/step - loss: 0.0923 - val_loss: 0.1005\n",
      "Epoch 97/150\n",
      "325/325 [==============================] - 0s 385us/step - loss: 0.0922 - val_loss: 0.1013\n",
      "Epoch 98/150\n",
      "325/325 [==============================] - 0s 425us/step - loss: 0.0919 - val_loss: 0.1019\n",
      "Epoch 99/150\n",
      "325/325 [==============================] - 0s 448us/step - loss: 0.0921 - val_loss: 0.1013\n",
      "Epoch 100/150\n",
      "325/325 [==============================] - 0s 403us/step - loss: 0.0923 - val_loss: 0.1016\n",
      "Epoch 101/150\n",
      "325/325 [==============================] - 0s 454us/step - loss: 0.0920 - val_loss: 0.1020\n",
      "Epoch 102/150\n",
      "325/325 [==============================] - 0s 415us/step - loss: 0.0919 - val_loss: 0.1009\n",
      "Epoch 103/150\n",
      "325/325 [==============================] - 0s 449us/step - loss: 0.0925 - val_loss: 0.1033\n",
      "Epoch 104/150\n",
      "325/325 [==============================] - 0s 433us/step - loss: 0.0931 - val_loss: 0.1016\n",
      "Epoch 105/150\n",
      "325/325 [==============================] - 0s 446us/step - loss: 0.0926 - val_loss: 0.1014\n",
      "Epoch 106/150\n",
      "325/325 [==============================] - 0s 433us/step - loss: 0.0923 - val_loss: 0.1011\n",
      "Epoch 107/150\n",
      "325/325 [==============================] - 0s 449us/step - loss: 0.0926 - val_loss: 0.1009\n",
      "Epoch 108/150\n",
      "325/325 [==============================] - 0s 409us/step - loss: 0.0914 - val_loss: 0.1010\n",
      "Epoch 109/150\n",
      "325/325 [==============================] - 0s 424us/step - loss: 0.0915 - val_loss: 0.1009\n",
      "Epoch 110/150\n",
      "325/325 [==============================] - 0s 385us/step - loss: 0.0915 - val_loss: 0.1017\n",
      "Epoch 111/150\n",
      "325/325 [==============================] - 0s 465us/step - loss: 0.0920 - val_loss: 0.1023\n",
      "Epoch 112/150\n",
      "325/325 [==============================] - 0s 503us/step - loss: 0.0924 - val_loss: 0.1013\n",
      "Epoch 113/150\n",
      "325/325 [==============================] - 0s 533us/step - loss: 0.0913 - val_loss: 0.1017\n",
      "Epoch 114/150\n",
      "325/325 [==============================] - 0s 507us/step - loss: 0.0923 - val_loss: 0.1011\n",
      "Epoch 115/150\n",
      "325/325 [==============================] - 0s 495us/step - loss: 0.0924 - val_loss: 0.1014\n",
      "Epoch 116/150\n",
      "325/325 [==============================] - 0s 581us/step - loss: 0.0923 - val_loss: 0.1014\n",
      "Epoch 117/150\n",
      "325/325 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.1015\n",
      "Epoch 118/150\n",
      "325/325 [==============================] - 0s 1ms/step - loss: 0.0919 - val_loss: 0.1005\n",
      "Epoch 119/150\n",
      "325/325 [==============================] - 0s 369us/step - loss: 0.0919 - val_loss: 0.1015\n",
      "Epoch 120/150\n",
      "325/325 [==============================] - 0s 309us/step - loss: 0.0926 - val_loss: 0.1016\n",
      "Epoch 121/150\n",
      "325/325 [==============================] - 0s 337us/step - loss: 0.0918 - val_loss: 0.1005\n",
      "Epoch 122/150\n",
      "325/325 [==============================] - 0s 340us/step - loss: 0.0907 - val_loss: 0.1004\n",
      "Epoch 123/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0915 - val_loss: 0.1009\n",
      "Epoch 124/150\n",
      "325/325 [==============================] - 0s 337us/step - loss: 0.0908 - val_loss: 0.1013\n",
      "Epoch 125/150\n",
      "325/325 [==============================] - 0s 314us/step - loss: 0.0910 - val_loss: 0.1010\n",
      "Epoch 126/150\n",
      "325/325 [==============================] - 0s 314us/step - loss: 0.0906 - val_loss: 0.1016\n",
      "Epoch 127/150\n",
      "325/325 [==============================] - 0s 346us/step - loss: 0.0912 - val_loss: 0.1014\n",
      "Epoch 128/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0913 - val_loss: 0.1000\n",
      "Epoch 129/150\n",
      "325/325 [==============================] - 0s 337us/step - loss: 0.0908 - val_loss: 0.1017\n",
      "Epoch 130/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0913 - val_loss: 0.1007\n",
      "Epoch 131/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0907 - val_loss: 0.1015\n",
      "Epoch 132/150\n",
      "325/325 [==============================] - 0s 341us/step - loss: 0.0910 - val_loss: 0.1008\n",
      "Epoch 133/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0923 - val_loss: 0.1022\n",
      "Epoch 134/150\n",
      "325/325 [==============================] - 0s 337us/step - loss: 0.0909 - val_loss: 0.1011\n",
      "Epoch 135/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0910 - val_loss: 0.1005\n",
      "Epoch 136/150\n",
      "325/325 [==============================] - 0s 337us/step - loss: 0.0908 - val_loss: 0.1008\n",
      "Epoch 137/150\n",
      "325/325 [==============================] - 0s 332us/step - loss: 0.0908 - val_loss: 0.1003\n",
      "Epoch 138/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0905 - val_loss: 0.1008\n",
      "Epoch 139/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0907 - val_loss: 0.1002\n",
      "Epoch 140/150\n",
      "325/325 [==============================] - 0s 337us/step - loss: 0.0910 - val_loss: 0.1025\n",
      "Epoch 141/150\n",
      "325/325 [==============================] - 0s 288us/step - loss: 0.0909 - val_loss: 0.1024\n",
      "Epoch 142/150\n",
      "325/325 [==============================] - 0s 329us/step - loss: 0.0912 - val_loss: 0.1010\n",
      "Epoch 143/150\n",
      "325/325 [==============================] - 0s 285us/step - loss: 0.0910 - val_loss: 0.1008\n",
      "Epoch 144/150\n",
      "325/325 [==============================] - 0s 433us/step - loss: 0.0910 - val_loss: 0.1016\n",
      "Epoch 145/150\n",
      "325/325 [==============================] - 0s 433us/step - loss: 0.0910 - val_loss: 0.1019\n",
      "Epoch 146/150\n",
      "325/325 [==============================] - 0s 443us/step - loss: 0.0910 - val_loss: 0.1006\n",
      "Epoch 147/150\n",
      "325/325 [==============================] - 0s 392us/step - loss: 0.0907 - val_loss: 0.1005\n",
      "Epoch 148/150\n",
      "325/325 [==============================] - 0s 481us/step - loss: 0.0906 - val_loss: 0.1018\n",
      "Epoch 149/150\n",
      "325/325 [==============================] - 0s 481us/step - loss: 0.0906 - val_loss: 0.1009\n",
      "Epoch 150/150\n",
      "325/325 [==============================] - 0s 417us/step - loss: 0.0903 - val_loss: 0.1012\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXyU1b348c93Mtn3DQgJOyj7GhEX3BdwwypVrLXa2tJ6662tba/aXm9bb3trb73W2p9t1brXtViUWi1u4L4QEMMuO4QASYCE7Mlkvr8/zhMYQhIykCGBfN+v17wyz3nO88yZZzLPd845zzmPqCrGGGNMR/m6ugDGGGOOLRY4jDHGhMUChzHGmLBY4DDGGBMWCxzGGGPCYoHDGGNMWCxwGBNBIvK4iPyyg3k3ich5R7ofYyLNAocxxpiwWOAwxhgTFgscpsfzmoh+LCKFIlItIo+ISG8ReU1EKkXkTRFJD8l/mYisEJFyEVkoIiNC1k0QkSXeds8DcS1e6xIRWept+6GIjD3MMn9LRNaJyG4RmScifb10EZHfiUiJiFR472m0t+4iEVnplW2biPzosA6Y6fEscBjjXAmcD5wAXAq8BvwEyMJ9T74HICInAM8C3weygVeBf4hIjIjEAC8BTwEZwN+8/eJtOxF4FPg2kAk8CMwTkdhwCioi5wC/Bq4CcoDNwHPe6guAM7z3kQZcDezy1j0CfFtVk4HRwNvhvK4xzSxwGOP8QVV3quo24D3gE1X9TFXrgbnABC/f1cA/VfUNVW0E7gHigVOBKUA0cJ+qNqrqHGBRyGt8C3hQVT9R1SZVfQKo97YLx7XAo6q6xCvfHcApIjIQaASSgeGAqOoqVd3ubdcIjBSRFFXdo6pLwnxdYwALHMY02xnyvLaV5STveV/cL3wAVDUIbAVyvXXb9MCZQzeHPB8A/NBrpioXkXKgn7ddOFqWoQpXq8hV1beB/wc8AOwUkYdEJMXLeiVwEbBZRN4RkVPCfF1jAAscxoSrGBcAANengDv5bwO2A7leWrP+Ic+3Ar9S1bSQR4KqPnuEZUjENX1tA1DV+1V1EjAK12T1Yy99karOAHrhmtReCPN1jQEscBgTrheAi0XkXBGJBn6Ia276EPgICADfExG/iFwBTA7Z9mHgOyJysteJnSgiF4tIcphleAb4uoiM9/pH/gfXtLZJRE7y9h8NVAN1QJPXB3OtiKR6TWx7gaYjOA6mB7PAYUwYVHUN8FXgD0AZriP9UlVtUNUG4ArgBmAPrj/k7yHbFuD6Of6ft36dlzfcMrwF3Am8iKvlDAFmeatTcAFqD645axeuHwbgOmCTiOwFvuO9D2PCJnYjJ2OMMeGwGocxxpiwRDRwiMg0EVnjDVS6vZX1t3oDkgpF5C0RCe3wu15E1nqP60PSJ4nIMm+f97foiDTGGBNhEWuqEpEo4AvcoKoi3PXs16jqypA8Z+M69WpE5CbgLFW9WkQygAIgH1BgMTBJVfeIyKfALcDHuMFX96vqaxF5E8YYYw4SyRrHZGCdqm7wOg2fA2aEZlDVBapa4y1+DOR5zy8E3lDV3aq6B3gDmCYiOUCKqn7kXSv/JHB5BN+DMcaYFvwR3Hcu7rr1ZkXAye3kvxE3zUNb2+Z6j6JW0g8iIrOB2QC++JRJY4cPJcpnrVrGGNNRixcvLlPV7JbpkQwcrZ2lW20XE5Gv4pqlzjzEth3ep6o+BDwEEJszTOe/8wG9kuNay2qMMaYVIrK5tfRINlUV4UbUNsvDjXg9gHfjmp8Cl3nz7rS3bRH7m7Pa3GdrGgLBDhfcGGNM2yIZOBYBw0RkkDdr6CxgXmgGEZmAmyH0MlUtCVk1H7hARNK96awvAOZ7k7VVisgU72qqrwEvd6Qw9RY4jDGmU0SsqUpVAyJyMy4IROFm81whIncBBao6D/gtbvK4v3lX1W5R1ctUdbeI/Df7Zxa9S1V3e89vAh7HzUj6Gvv7RdplNQ5jjOkcPWLkeGzOMP3000WM65e2L62xsZGioiLq6uq6sGTHj7i4OPLy8oiOju7qohhjOomILFbV/Jbpkewc71ZaNlUVFRWRnJzMwIEDsTGER0ZV2bVrF0VFRQwaNKiri2OMibAeM+VIy6aquro6MjMzLWh0AhEhMzPTam/G9BA9J3A0HTyDtAWNzmPH0pieo8cEjvpG6xw3xpjO0GMCR0NT9woc5eXl/PGPfwx7u4suuojy8vIIlMgYYzqmxwSO7jaOo63A0dRKk1qoV199lbS0tHbzGGNMJPXYq6q62u2338769esZP3480dHRJCUlkZOTw9KlS1m5ciWXX345W7dupa6ujltuuYXZs2cDMHDgQAoKCqiqqmL69OmcfvrpfPjhh+Tm5vLyyy8THx/fxe/MGHO86zGBo70BgL/4xwpWFu/t1Ncb2TeFn106qs31d999N8uXL2fp0qUsXLiQiy++mOXLl++7nPXRRx8lIyOD2tpaTjrpJK688koyMzMP2MfatWt59tlnefjhh7nqqqt48cUX+epX7W6gxpjIssDRTUyePPmAMRD3338/c+fOBWDr1q2sXbv2oMAxaNAgxo8fD8CkSZPYtGnTUSuvMabn6jGBoz7Qdt9BezWDoyUxMXHf84ULF/Lmm2/y0UcfkZCQwFlnndXqGInY2Nh9z6OioqitrT0qZTXG9Gw9onNc6H41juTkZCorK1tdV1FRQXp6OgkJCaxevZqPP/74KJfOGGPa1iNqHCLS7QJHZmYmp512GqNHjyY+Pp7evXvvWzdt2jT+/Oc/M3bsWE488USmTJnShSU1xpgD9ZDA0f2uqgJ45plnWk2PjY3ltddan/S3uR8jKyuL5cuX70v/0Y9+1OnlM8aY1lhTlTHGmLD0iMDhE+l2I8eNMeZY1SMCh2uqan9EtjHGmI7pIYGj+3WOG2PMsapnBA66Z+e4McYciyIaOERkmoisEZF1InJ7K+vPEJElIhIQkZkh6WeLyNKQR52IXO6te1xENoasG3+ocvhELHAYY0wniVjgEJEo4AFgOjASuEZERrbItgW4ATjgulRVXaCq41V1PHAOUAO8HpLlx83rVXXpocty7F9VlZSUBEBxcTEzZ85sNc9ZZ51FQUFBu/u57777qKmp2bds07QbY8IVyRrHZGCdqm5Q1QbgOWBGaAZV3aSqhUB7Z/WZwGuqWtNOnnb5joPA0axv377MmTPnsLdvGThsmnZjTLgiGThyga0hy0VeWrhmAc+2SPuViBSKyO9EJLa1jUKJSLe7quq222474H4cP//5z/nFL37Bueeey8SJExkzZgwvv/zyQdtt2rSJ0aNHA1BbW8usWbMYO3YsV1999QFzVd10003k5+czatQofvaznwFu4sTi4mLOPvtszj77bMBN015WVgbAvffey+jRoxk9ejT33XffvtcbMWIE3/rWtxg1ahQXXHCBzYllTA8XyZHjrd2EWsPagUgOMAaYH5J8B7ADiAEeAm4D7mpl29nAbIDUvoPbH8fx2u2wY1k4RTu0PmNg+t1trp41axbf//73+bd/+zcAXnjhBf71r3/xgx/8gJSUFMrKypgyZQqXXXZZm/fz/tOf/kRCQgKFhYUUFhYyceLEfet+9atfkZGRQVNTE+eeey6FhYV873vf495772XBggVkZWUdsK/Fixfz2GOP8cknn6CqnHzyyZx55pmkp6fb9O3GmANEssZRBPQLWc4DisPcx1XAXFVtbE5Q1e3q1AOP4ZrEDqKqD6lqvqrmx8XFdbumqgkTJlBSUkJxcTGff/456enp5OTk8JOf/ISxY8dy3nnnsW3bNnbu3NnmPt599919J/CxY8cyduzYfeteeOEFJk6cyIQJE1ixYgUrV65stzzvv/8+X/rSl0hMTCQpKYkrrriC9957D7Dp240xB4pkjWMRMExEBgHbcE1OXwlzH9fgahj7iEiOqm4X9zP8cmB5q1uG8B1qrqp2agaRNHPmTObMmcOOHTuYNWsWTz/9NKWlpSxevJjo6GgGDhzY6nTqoVqrjWzcuJF77rmHRYsWkZ6ezg033HDI/ai2XRm06duNMaEiVuNQ1QBwM66ZaRXwgqquEJG7ROQyABE5SUSKgC8DD4rIiubtRWQgrsbyTotdPy0iy4BlQBbwy0OVpbsOAJw1axbPPfccc+bMYebMmVRUVNCrVy+io6NZsGABmzdvbnf7M844g6effhqA5cuXU1hYCMDevXtJTEwkNTWVnTt3HjBhYlvTuZ9xxhm89NJL1NTUUF1dzdy5c5k6dWonvltjzPEiorPjquqrwKst0v4r5PkiXBNWa9tuopXOdFU9J9xydNfLcUeNGkVlZSW5ubnk5ORw7bXXcumll5Kfn8/48eMZPnx4u9vfdNNNfP3rX2fs2LGMHz+eyZNdq924ceOYMGECo0aNYvDgwZx22mn7tpk9ezbTp08nJyeHBQsW7EufOHEiN9xww759fPOb32TChAnWLGWMOYi010RxvOh/whj1XXE36//nIqJ8rmln1apVjBgxootLdnyxY2rM8UVEFqtqfsv0njHliNcN0B1rHcYYc6yxwGGMMSYsPSJw+LzI0XIQYE9opjta7Fga03P0iMDRXOMIvSQ3Li6OXbt22QmvE6gqu3btIi4urquLYow5CnrGPce9Qeyho8fz8vIoKiqitLS0q4p1XImLiyMvr9UL5Iwxx5keETh8zTWOxv2BIzo6mkGDBnVRiYwx5tjVo5qq7L7jxhhz5HpI4PCaquyqKmOMOWI9JHC4v91tanVjjDkW9YjA4cNqHMYY01l6ROCwAYDGGNN5ekjgaB4AaIHDGGOOVA8JHO6v1TiMMebI9YjA0daUI8YYY8LXIwJH8z3yrKnKGGOOXI8IHM01DhsAaIwxR65HBA5pZcoRY4wxh6dHBA6A6CixGocxxnSCiAYOEZkmImtEZJ2I3N7K+jNEZImIBERkZot1TSKy1HvMC0kfJCKfiMhaEXleRGI6UpZYf5RdVWWMMZ0gYoFDRKKAB4DpwEjgGhEZ2SLbFuAG4JlWdlGrquO9x2Uh6b8Bfqeqw4A9wI0dKU+M32dXVRljTCeIZI1jMrBOVTeoagPwHDAjNIOqblLVQqBDVQFxI/nOAeZ4SU8Al3dk25gon9U4jDGmE0QycOQCW0OWi7y0jooTkQIR+VhEmoNDJlCuqoFD7VNEZnvbF5SWlhIbbYHDGGM6QyRv5CStpIVzn9b+qlosIoOBt0VkGbC3o/tU1YeAhwDy8/M1Jspn4ziMMaYTRLLGUQT0C1nOA4o7urGqFnt/NwALgQlAGZAmIs0Br8P7jPFbjcMYYzpDJAPHImCYdxVUDDALmHeIbQAQkXQRifWeZwGnAStVVYEFQPMVWNcDL3dkn7F+n12Oa4wxnSBigcPrh7gZmA+sAl5Q1RUicpeIXAYgIieJSBHwZeBBEVnhbT4CKBCRz3GB4m5VXemtuw24VUTW4fo8HulIeWL8PhsAaIwxnSCSfRyo6qvAqy3S/ivk+SJcc1PL7T4ExrSxzw24K7bCEuOPoqK2MdzNjDHGtNBjRo6nxkdTVlnf1cUwxphjXo8JHKP7prCtvJbd1Q1dXRRjjDmm9ZjAMSYvFYDCovIuLokxxhzbekzgGJ3rAseyooouLokxxhzbekzgSImLZnB2IoXbLHAYY8yR6DGBA2Bsbqo1VRljzBHqWYEjL42de+vZubeuq4tijDHHrB4WOKyfwxhjjlSPChwj+6bgE7uyyhhjjkSPChwJMX5O6J1sHeTGGHMEelTgABiTm0phUQVuvkRjjDHh6nGBI39gOrurG1i9o7Kri2KMMcekHhc4zhneGxF4fcXOri6KMcYck3pc4MhOjmVS/3Tmr9jR1UUxxphjUo8LHAAXjOrNyu172bq7pquLYowxx5yeGThG9gHg9ZXWXGWMMeHqkYFjYFYiJ/ZOtuYqY4w5DD0jcOxcAb8bDa/dvi/pwlG9Kdi0m11VdnMnY4wJR0QDh4hME5E1IrJORG5vZf0ZIrJERAIiMjMkfbyIfCQiK0SkUESuDln3uIhsFJGl3mP8IQsSmwyxKfDZXyHYBMD0MTkEFeZ+tq1z3qwxxvQQEQscIhIFPABMB0YC14jIyBbZtgA3AM+0SK8Bvqaqo4BpwH0ikhay/seqOt57LD1kYdL6wynfhYZKKFsLwIicFCYPyuCxDzYRaAoexjs0xpieKZI1jsnAOlXdoKoNwHPAjNAMqrpJVQuBYIv0L1R1rfe8GCgBso+oNLkT3d/iJfuSbjx9ENvKa5lvYzqMMabDIhk4coGtIctFXlpYRGQyEAOsD0n+ldeE9TsRiW1ju9kiUiAiBaWlpZB1AsQkwbb9geO8Eb3pn5HAI+9vCLdYxhjTY0UycEgraWFNECUiOcBTwNdVtblWcgcwHDgJyABua21bVX1IVfNVNT87Oxt8UZAz/oAaR5RP+MZpA1mypZwlW/aEUzRjjOmxIhk4ioB+Ict5QHFHNxaRFOCfwH+q6sfN6aq6XZ164DFck1jH5E6AHcsg0LAv6cv5/chIjOH2Fwupqg90eFfGGNNTRTJwLAKGicggEYkBZgHzOrKhl38u8KSq/q3FuhzvrwCXA8s7XKLcSdDUADv3b5IY6+cP10xgfWk1P3h+KcGgzZprjDHtiVjgUNUAcDMwH1gFvKCqK0TkLhG5DEBEThKRIuDLwIMissLb/CrgDOCGVi67fVpElgHLgCzglx0uVN+DO8gBThuaxX9ePII3Vu7k7n+ttinXjTGmHf5I7lxVXwVebZH2XyHPF+GasFpu91fgr23s85zDLlBaf0jIhG2fuR6SEDecOpD1pVU89O4G6hub+Nmlo/D5WuumMcaYni2igaPbEXHNVdsWt7JK+O8Zo4mPjuLh9zZSUlnP7dOHMyAzsQsKaowx3VfPmHIkVO4kKF0NFQePGBcRfnLRCG6fPpy3VpVw9j0LufmZJeyta+yCghpjTPfU8wLHuGvcpbkf3NfqahHhO2cO4f3bzubbZw7hX8t3cKt1mhtjzD49L3CkD4DxX4HFj8Petq8O7pUSx23ThvNfl47kzVUl3PfmF0evjMYY0431vMABMPWHoEF4v/VaBwDelVXXTRnAVfl53P/2Om5/sZCPN+xytY+CR2He9zr2eqpQt7cTCm6MMV2vZ3WON0sfCONmuVpH71Ew/BJIzNy/fuFvYNkLcMM/keQ+/PfloxGEl5cW89yirYxO2MPf9TZitAHOugNSctp/vYJH4Y2fwfcLISEjku/MGGMirmfWOADOvA3S+sE/vgf3DHPBQhW2fAILfw271sEL10OggdgoH785K4GC207j97PGc3fCM/jUTc/+0pwnDj277oq5bmbe9W8fhTdmjDGR1TNrHODGdNxcADsKXZPVwv+BQC2snAepeXDGj+Aft8Dfvwl7t0PRpyQm9WbGiEuh6gOC5/6Cynf/QMzGt7j+sbO4f9YEMpNamW+xrgK2fOSer30dxsw8OI8xxhxDem6NA9y4jpxxcOUjMP6r8P7vYPd6mPEATLoBTrkZVr4MVTvg3J+5GXYX/QWyTsR3yr+RPOYizo9dyWebSrno/vf4ZMOug19j/QIIBiBzKKx9Y9+NpIwx5ljVc2scoXw+uOwPkJQNcWkw+EyXfv5dMHKGm6okyg9Tb4WixZDcG/wxMPR8opc8yT8vj+EbC/1c8/DHjO+XxsT+6dQFmlhZvJdba55hSmwq/jP+A+bOdtO69zup/fIYY0w3ZoGjmc8H5/28RVoU9Gsx+W7epP3PB58FPj+D9nzIP/79Th58Zz0frd/Fkx9vJjbKx8g+SYyo+phXm0by8kfpPISPh//yR15MvYEpGZVcfvoEJg1tcYuS2j2ultLUCFHRcMI0iEno/PdrjDGHyQLHkYhLgf6nwNrXScr/Bj8crzAqjkB9E1HZJyAVRfCXCuSEC9m2K471sSOZ4VtGhv+fXLHpYbZvzOTTqb9m8lmXweYPYNkcgstexNdUt/81RlwKVz3lmtWMMaYbkJ4wE2x+fr4WFBREZucf3A9v3NnKCoHkPlC5A3683l3u+9698NYvAGgccgElm1aS21REo8QSrfU0RsXzYuNpPN84lazeOfx+5DoSPvxfuOJhGHtVx8rTWAeBOohPO3ReY4xph4gsVtX8lulW4zhS+d+AuFTw+SE6HqITXBNT0SJY9Q8YcNr+MSKjLodFj8DJs4k+9Xtk1tUw75GfsWfnFhY2jeWj4EhOH9GPa0b14T9fWs4Vy0/hmcwJpL7yQ5riexFTs8PdT2TgVMgYdHBZ6qvg8YtgzyaY+RgMPfeoHgpjTM9gNY5uoK6xiZXb99IUVPIHpCMifLiujNlPLSazoYjXYu4gQeoP3CglF1L7QUpfd4nvsAvh+a/C2vmQPgj2bIQz/gMGnAr+WFg2B5bPgYwhcOq/Q1JvWPY3qCuH837hxrTUV8GSJyBtgOtbiTqKvytU4Z3/dUF4yneO3usea1TdBRY5Y90PFGMiqK0aR4cCh4jcgrtNayXwF2ACcLuqvt7ZBY2E7h442lJdH2DTrmrK137E+rWr+duWJGoag9w6ZDsXpm7BV7WDYOla/DU7CcRn4a8tg4vucRM5vnQTrAq54WJULJw4HbZ/7oIKgD8exOcCyxk/hk/+BOVb3LqUXJh4PUz8Wtsj4ze845rEcsYdmB5ocAMos090FxiE2vopFD7vameJvdy8YYlZ8O498PZ/uzzhNM31NCvnwQvXweRvw0X/29WlMce5Iw0cn6vqOBG5EPgucCfwmKpO7Pyidr5jNXC0VNMQ4J75X/DoBxtJjvNT09AEwQCX+D7iRv9rfKBj+Vefb3P60Ey+ND6Xof4S2LsNasth4OluupNgE3wxHxprXK2icoc7EZWshIzB7rLk2nIoeMSNdJco6D/F1QQSs2HKTZA9HD68H97w7sk15ioYfSXsWuua6Na97UbK953o9tdntMu35El45VaIinFzhQVqITbVNeEteQLGfNkbbLkIvv4q5LX4f22sc/1JvmiY/C03dczuDe6RPdzVvrZ8BF/8C/pOgFFXHP5FBdW74LUfw9ir4YQL96cHg7DhbSj+DKZ899BXvG35BJ65yh3rqbe6YHq4GmrggZPdZ6pB+OabBx+j7kzV/TBJ628XexwjjjRwFKrqWBH5PbBQVeeKyGeqOiEShe1sx0vgaPbR+l38rWArfdPiGZydSIzfR2NTkLU7qyjYtIfFW/bQFFSG9koiJc6PP8pHTUOAmvomLhzdhx+cdwIx/pCxnw018MVrcML0A0+Eu9bD4sfcya+x1tVUGmug38nuBD3qCtfX8tEDrkMeXE1l6HlusOT797qR89kjAHX3eh9yDsx8FOLToWQ1zP8JrH/L9dt89UXXXPbw2VC+2TWnZQ6DcVe7S5/n3AhFn7r+pGCTq6lUl+4vb1QsNNUD4l5v6Plw0jehaic0VEPmEBdsAvWuia5imzuRZQ2FkV9yl2QD1FfCE5e5WwxLlAt+J06Hz/7q5h1rrrH1PxW+8pwry6JH9h+fnHFw6i3umPz5NDfBZWONO4YDT3dzow2/yJ1Ag0HXZLj8RTj7Dhfw2rLgf+Cd38A1z8MrP3A/BGYvdCdk8R3ctLh+gQvwKbkwebZr3upKzbXK8dfCxfdCdNzh7SfQADVl7ofCsSzQ4MaDHY5d62HjuxCT6JqsB5zSuWXzHGngeAzIBQYB44AoXACZdIjtpgG/9/L/RVXvbrH+DOA+YCwwS1XnhKy7HvhPb/GXqvqElz4JeByIx92W9hY9xJs43gLHoZRU1jFvaTEfrd9FfSBIY1OQxFg/gaDy7heljMlN5d6rxjGsd3J4O67Z7fohFv0FTroRLvy1O9nu3e5OmtnDD5zEsXoXvPtbFwSCAXcTrak/OvAEp+pO0NnD3ZcA3Mn88+fcdkWLoXSVS/fHwRUPQd5J7gRevhX6n+yCS+lq1zyWdxIMuwCWPgNv3QWN1R17b3mT4bRbAIVPH4JNH7jX+uyvsGHB/qDU/xQXjIIBePm7rj+oOTCl5Lr3tmcTjJ7pguOih+H6f0Cvke64rXhp//vpM9a93o5lrhYlPrj0Ptd8B24sz/ZCVxvcu81dlTfiEhd4V70Cz1/rBqzWVbjjfvJNbsDq1k9cf9aGhZDc1wXJxhroN8XV1PqMcbW/9QtcQB4z0x27Vf9wPwTOvP3QNalg0H1uX8x32w6a6vZVvcuVt3Q1lKxyVxZO/RFsXwov3gi9x8DOZZCbD6feDKn9Xf9aYnb7tZCmRtj4jpv3bdUr7j0NPR9O+5479tsL3X5OmOaORd1e73OpcgG7ocYF8v5T3A8OgOoy13TaUO3+j0+8yDWhtlmGwP7/3epdsPl9V66ETDdZalIvt66+Cta86l4rrb9LK1vn3l/mEFeWN+6EgsfcZ332Tw89UWqosrXwyPluzFezMV92zdTNV1MGm9xMFdsKoHK7u2jn9B8cGGwD9e4HD7hJX5u/u4F61yogcsSBwweMBzaoarmIZAB5qlrYzjZRwBfA+UARsAi4RlVXhuQZCKQAPwLmNQcOb/8FQD6gwGJgkqruEZFPgVuAj3GB435Vfa298ve0wNGefy3fwe1/L6S8ppGpw7K4ZGwOcdFRiAg+gSgRxuSlkpfezokjUA/+WKrqA8T6fURHRXDmGlVXu1k2x/1SzWv3t8qBKne6ZqzUPPfF2bXOBaPoeNf0lpLrHstfhDd/DtUlbjvxwYw/wvhr3K/C13/qypH/dXeCaPbF6/D3b7la1Jn/Ab1GuHwf3Of2B3DSt+Diew4s1671sPqfsPoV9+Wf+iMYcjbM+QZseg9ikt3JrWqnO+E3yzoBrnsJUr1Bo+/8r3s/KXmu6Wzt/P15k/q4iyAmf8vtY+kz8OnD+2tLPr93G+UlEPTucJnYyx2DjCFuyp0NC6GowP0qjk12geeEC9yJa8lTULHFHavEXm5anlDRCZA1zJ0wA3UuX7/JcN1cN2fb3Jtcc2Yzf5z7nFL7uZpmU707wTYrWgS1u92xGX6xOyEXPAI1Lab5EZ/7bENPqi3Llf8Nd2Jd/LhrLm2Wkgfn/NQ1sYrP/YAp/swFveKlsLfIBYn4dPcZEnLujElyMy+PDPcAABxUSURBVE0MnOqafktXu9rqidOhosjtA1zQbqhxUxsNPd8dY5/fNYcOORtiU9xnirhgnD3cfUbbl7rnmUPhyctcMLx2jvtclv8d3rnbBd8Bp0JClmtBKPc+n6Te7kefzw+nf9+VIVAHb//SfSfA/TDKGed+oOwthh8sh9S8Iw4cpwFLVbVaRL4KTAR+r6qb29nmFODnqnqht3wHgKr+upW8jwOvhASOa4CzVPXb3vKDwELvsUBVh7eWry0WOA5UVlXPs59s4ZlPt7C9oq7VPGPzUhnVNwW/z0ef1DguGZtzwP3XP1xfxr89vYS0+Gh+efkYTh+WdbSKHxn1lbBzhTuxJPV208p0hGrrv5QLX3C/4C//E8QmdWxfTQHX11O21p3AE7JcE0TOePdL0d/KJJqhdiyHrR+7E3zvUQeXKxiEdW+6k9aoL7naQPUu1yeUOcTVuja952pSFVtdAGmefqe6zDWN1JW75cFnwbivwLDz3Ym0dI0bxJrS153g0ga4X/FVJfDe/7kT6czH9v+qbaiG3Rvd65RvdUGofKtbripxgSQmARDQJrfPUV+CIefub+Kqr3LBMiUXeo+Gsi/cL/3qMnfDtpRcd0KPjne1WQ26X/nLXnD7HXs1TLreBYPyLa6G2nyCD5UxBPqOd39rylzzaO8x7kQfl+oC/Hv/54KA+NzxuOi3Lth89lcXEMdd49Ytn+P+16b/rzu2uze6OfLWvu5qBh0RnQA3vOICf7Nti+HtX7kfSpU7IHcinPxtV4uKinavM/8n7vg0Sx8IF/8fJOe4mkfpave5pQ90wTUp+8j7OHBNVGOBp4BHgCtU9cx2tpkJTFPVb3rL1wEnq+rNreR9nAMDx4+AOFX9pbd8J1CLCxx3q+p5XvpU4DZVvaSVfc4GZgP0799/0ubNbca4HivQFGTrnlqaggqou99UY5AP1pcxf8UOivbU0tgUpKK2EVUYl5fKSQMzSIz188CCdQzMSqQpqGwsq+ZLE3L56cUjyPJmCK5taKK6IUB9IEh9YxP1gSB9U+NJTbBLSLu9hhoXuNIGHBh8mgLuBJXUq/VxRMeKiiJ3Em/ZRxIMwqZ3XS0mGHQ/HnLGueBwKKquBrNhIVz4KxcswqHqfjA0NbjaVKDOBeqyL1wNKHeia9Lc+K4bnzXojPD232zPZldza6x1/WntNc1x5AMAA6qqIjIDV9N4xOuDaPc1W0nr6KCRtrbt8D5V9SHgIXA1jg6+bo/ij/IxKCvxoPQxeal858wh+5aLy2uZ93kxr6/YwZMfb6YhEOSsE7P5wzUTiI7y8ccF6/jTO+t5e3UJsyb347PN5RRs3k3L27Qnx/r5j2kn8pWTBxDlE1SVN1eV8OynW+ifkcCX8/MY1bcDX1ITWTEJEDPw4PQov+tTOta1dVL3+VxN6nCIuKbM/K8f/vbZJ4QkpBx8C4ah5x75oN70Ae5xhDoaOCq9pqbrgKle/8WhfjoWAf1ClvOAtm/yffC2Z7XYdqGXntcivaP7NIepb1o83zlzCN85cwgNgSDbK2rpl56Az+fi+K0XnMil4/ryk7nLePCdDQzvk8xNZw2hT0ocsf4oYqN9+H0+nvl0M3e+vIK/vL+R7KRYdtc0sKG0mt4psby/tozHP9zE4KxEThmSydBeSeypaaSyrpGUuGgyk2IYk5vKmNxU/F6fiqpS29iEKiTG2iQIxhwtHW2q6gN8BVikqu+JSH9c38KT7Wzjx3WOnwtsw3WOf0VVV7SS93EObKrKwHWIN48TWYLrHN8tIouAfwc+wXWO/0FVX225z1DWx3F0qCp7awNtNkepKi8vLeYfnxdT29iECFwxIY/Lxveluj7APz4vZsGaUj7duJuq+gAikBAdRXXD/nuYJMf6SU+MobKukcq6AIGgEuUTpo3qwxUTc/lsSzmvFBYTVBiUlcjUYVnccOrAfcHGGNNxR9TH4e2gN9B8I4lPVbWkA9tchLvcNgp4VFV/JSJ3AQWqOk9ETgLmAulAHbBDVUd5234D+Im3q1+p6mNeej77L8d9Dfh3uxz3+BJoClJe20hafDT+KB+BpiBlVQ0s2rSbD9fvorYhQHJcNMlxfpLjoimrqudvBVvZWxfAJ3D6sGxS4vysK6li9Y5KxuSmctNZQ/h0424KNu9mVE4qZ56YTb/0BOKiXed/ctyh+16CQaVg8x7mflbE8m17OWd4L66cmEf/zPYvXQ0GdV/tzJhjyZF2jl8F/BbXXCTAVODHoeMuujMLHMe/moYAH2/Yxei+qfRK2T+w7NVl27nzpeXsqm4g1u9jXF4aq7bvpbI+sC+PCJzYO5m89Hi27q5le0Ut0VE+4qKj6JMaR7/0eHZVN/D51nL21gVIiInihN7JfF5UjioM75PM1GFZjM51lzFX1jXy4fpdfLZlD5t21bCrqp7JgzK4dFxfhvdJJiUumozEGDISY5AIj6Au2VtHQqyfJGvKM4fhiKccAc5vrmWISDbwpqqOa3/L7sECR8+2p7qB5cUVTBqQTkKMn8amIIVFFeyubqCusYkNpdUUbN5Nyd56+mUk0DctjqagUtPQxPaKWrburiUlPprx/dI4eVAG54/sTWKsf99FA+9+UUrBpj00NAX3vWZMlI+xeakMykokNT6at1eXsKHswMGIsX4fuWnx5KTF0Tc1npy0ePqkxFFR28i28hr21DRSXR+gsSlIdJSPpFg/E/qnMyY3lcKichasKUEQhmQnMrRXEkOyk8hJi6c+0MS2PbX89ePNLFhTSpRPGJObynkjenH1Sf3JTj7EZb1HQXlNA0mxfmtC7OaONHAsU9UxIcs+4PPQtO7MAoeJtLrGJrburmHrnhpioqKYNCCd+Jj9EzyqKmtLqigur6WyLkBZVT3bK+rYVl5LcXkt28vr2FlZR/PXMTXeXRCQFOvH7xMCQWVXVQPbyvcPWBveJ5lYv4/1pdVUhdSgmmUlxfCVyf1pUvVqQOVERwlnn9iLUX1TGdoriV4psaTGR7O+pIrPtroxGkOzk0iK87O+pIqyqnpG5KQwrl8aIlBR04jPJyTF+slIjCE7KRafd4VceU0jZVX1lFU1kJ4YzaCsRGL9UfuOT8GmPbzzRQnvflHGmp2VJMX6mTQgfV+ATYz1s3lXNZV1Aa4+qV+7g1ADTUHW7KxkU1kNpw/N2tevVlJZx7KiCsqq6qmqbyI+Ooq0hGhOH5ZFSivNkdX1Ad5ctZPCogrOG9GbKYMzIl4LBGgKKmt2VDIiJ/movN7hOtLA8VvcGI5nvaSrgUJVva1TSxkhFjjMsaCxKUhpZT0p8dFtNi0Vl9eyfFsFI3JS6JfhTqyqys699awrqWLH3joSYqJIiYvmpEHp+07cAOtLq3jqo828vbqErXtqaPnVb56/rCGwv+aUEBPlJtNsQ0yUj5T4aMprGgi0uP7aJ5CeEIPPJ+ytbaQ+ECQmykf+wHROHZLJjr11fLJhNxvKqr2xRI4IRPt8fO2UAZzQJ5nGpiCNgSCNTUpxRS2FRRWsKK6grtGVMyXOz7emDqZoTy1zP9t2QM2vWVy0j+mj3bQeK4v3sreukSifUFZVT11jEJ9AUGForyRmnzGYL03Ixe8TlmzZQ1lVA6cNzWrzM2kKKntqGqipdxd85KXHIyI0NgVZs6OSnNQ4MpP21/IWb97NnS+tYOX2vZx9YjZ3XzmW3imHOW+XJ+iVISU+ulNncuiMzvErgdNwfRzvqurcTitdhFngMOZANQ0BNpXVUFZVz56aBvpnJDDSmylg6+4aquoDDM5OJD46ig1l1SzfVkF0lI/U+GiCqlR5taai8lrKqxvJSIohKymW7ORYMhNjKKuqZ31JFbuqGwiqkhjj59ShmUwZnElCzIEn4IZAkC27a6iuDzAwM5HqhgD3vvEFLy4pOii4xUdHMTo3hbF5aYzNS6V3Shx/eW8Db64qIdbv46r8flw+oS+9kuNIjvNT2+ia7V5cso1XPi8mMdbPyL4pZCXFEGhSUuKjmT66D6NzU3l12XYe/3ATK4r30i8jHkHYsttNe9Lc9NgYVGobAvTPSGRETjKbdtXw3tpSymsa95UxLSGawVmJrNlRSXWDCyYT+6eTnRTLxrJq1uyspE9KHJeOy+GpjzcTHeVjcFYidY1BYqN9ZCXFkhTrJxAM4hNhcFYiAzIT2VPT4NVqa9myu4bahqZ9wWzz7mrqGoNuOqzEWOJjXPAQb+ibiDtx+3xCr+RY+qbGkxIfTWJs1L5AkxjjZ2ivJIb1TiI3zQW/Iw4cxzILHMYce1xtoImYKDcfWrTfR3x0FFGtXKG2rqSK9IToA37Zt6Sqh2wWUlXeXl3Cg+9uICbKx5cm5NI3LZ63Vu3k86Jy4mP8xPl9bCyrZn1pFRmJsZx5Qjbj+qWSFOunrjFIYVE560urGN4nhfyB6Wworebt1SVUe8F4fL80vn7aIBJj/Wwsq+b/Xl9DZV2AuGgfdY1Byqrqqa4P4I/y0RAIUrSnZt9g2qRYP/0yEuifEU9SbDRV9Y00BWFAZgJ90+KpqG2kZG8dDYHgvpHRqrrveWNTkJK9rpl0b53rQ2s5UBfgX9+fyvA+KYcXOESkktZHZosrj6a0+yl0ExY4jDGdrT7QRLTPF/FLresam9hWXktGQgxpCdGd2icSev6vqG1kbUkVa3dWceWkXGL9UYc35YiqhjnvtjHG9Ayh/UeRFBcdxZDsDk6UGabQIJSWEMNJAzM4aWBGO1s4di2cMcaYsFjgMMYYExYLHMYYY8JigcMYY0xYLHAYY4wJiwUOY4wxYbHAYYwxJiwWOIwxxoTFAocxxpiwWOAwxhgTFgscxhhjwhLRwCEi00RkjYisE5HbW1kfKyLPe+s/EZGBXvq1IrI05BEUkfHeuoXePpvX9YrkezDGGHOgiAUOEYkCHgCmAyOBa0RkZItsNwJ7VHUo8DvgNwCq+rSqjlfV8cB1wCZVXRqy3bXN65tvZ2uMMeboiGSNYzKwTlU3qGoD8Bwwo0WeGcAT3vM5wLly8JzB17D/zoPGGGO6WCQDRy6wNWS5yEtrNY+qBoAKILNFnqs5OHA85jVT3dlKoAFARGaLSIGIFJSWlh7uezDGGNNCJANHayf0ljeFajePiJwM1Kjq8pD116rqGGCq97iutRdX1YdUNV9V87Ozs8MruTHGmDZFMnAUAf1ClvOA4rbyiIgfSAV2h6yfRYvahqpu8/5WAs/gmsSMMcYcJZEMHIuAYSIySERicEFgXos884DrveczgbfVu5ehiPiAL+P6RvDS/CKS5T2PBi4BlmOMMeaoaffWsUdCVQMicjMwH4gCHlXVFSJyF1CgqvOAR4CnRGQdrqYxK2QXZwBFqrohJC0WmO8FjSjgTeDhSL0HY4wxB5PQm5Ufr/Lz87WgoKCri2GMMccUEVmsqvkt023kuDHGmLBY4DDGGBMWCxzGGGPCYoHDGGNMWCxwGGOMCYsFDmOMMWGxwGGMMSYsFjiMMcaExQKHMcaYsFjgMMYYExYLHMYYY8JigcMYY0xYLHAYY4wJiwUOY4wxYbHAYYwxJiwWOIwxxoTFAocxxpiwWOAwxhgTlogGDhGZJiJrRGSdiNzeyvpYEXneW/+JiAz00geKSK2ILPUefw7ZZpKILPO2uV9EJJLvwRhjzIEiFjhEJAp4AJgOjASuEZGRLbLdCOxR1aHA74DfhKxbr6rjvcd3QtL/BMwGhnmPaZF6D8YYYw4WyRrHZGCdqm5Q1QbgOWBGizwzgCe853OAc9urQYhIDpCiqh+pqgJPApd3ftGNMca0JZKBIxfYGrJc5KW1mkdVA0AFkOmtGyQin4nIOyIyNSR/0SH2CYCIzBaRAhEpKC0tPbJ3YowxZp9IBo7Wag7awTzbgf6qOgG4FXhGRFI6uE+XqPqQquaran52dnYYxTbGGNOeSAaOIqBfyHIeUNxWHhHxA6nAblWtV9VdAKq6GFgPnODlzzvEPo0xxkRQJAPHImCYiAwSkRhgFjCvRZ55wPXe85nA26qqIpLtda4jIoNxneAbVHU7UCkiU7y+kK8BL0fwPRhjjGnBH6kdq2pARG4G5gNRwKOqukJE7gIKVHUe8AjwlIisA3bjggvAGcBdIhIAmoDvqOpub91NwONAPPCa9zDGGHOUiLs46fiWn5+vBQUFXV0MY4w5pojIYlXNb5luI8eNMcaExQKHMcaYsFjgMMYYExYLHMYYY8JigcMYY0xYLHAYY4wJiwUOY4wxYbHAYYwxJiwWOIwxxoTFAocxxpiwWOAwxhgTFgscxhhjwmKBwxhjTFgscBhjjAmLBQ5jjDFhscBhjDEmLBY4jDHGhMUChzHGmLBENHCIyDQRWSMi60Tk9lbWx4rI8976T0RkoJd+vogsFpFl3t9zQrZZ6O1zqffoFcn3YIwx5kD+SO1YRKKAB4DzgSJgkYjMU9WVIdluBPao6lARmQX8BrgaKAMuVdViERkNzAdyQ7a7VlXtJuLGGNMFIlnjmAysU9UNqtoAPAfMaJFnBvCE93wOcK6IiKp+pqrFXvoKIE5EYiNYVmOMMR0UycCRC2wNWS7iwFrDAXlUNQBUAJkt8lwJfKaq9SFpj3nNVHeKiHRusY0xxrQnkoGjtRO6hpNHREbhmq++HbL+WlUdA0z1Hte1+uIis0WkQEQKSktLwyq4McaYtkUycBQB/UKW84DitvKIiB9IBXZ7y3nAXOBrqrq+eQNV3eb9rQSewTWJHURVH1LVfFXNz87O7pQ3ZIwxJrKBYxEwTEQGiUgMMAuY1yLPPOB67/lM4G1VVRFJA/4J3KGqHzRnFhG/iGR5z6OBS4DlEXwPxhhjWohY4PD6LG7GXRG1CnhBVVeIyF0icpmX7REgU0TWAbcCzZfs3gwMBe5scdltLDBfRAqBpcA24OFIvQdjjDEHE9WW3Q7Hn/z8fC0osKt3jTEmHCKyWFXzW6bbyHFjjDFhscBhjDEmLBY4jDHGhMUChzHGmLBY4DDGGBMWCxzGGGPCYoHDGGNMWCxwGGOMCYsFDmOMMWGxwGGMMSYsFjiMMcaExQKHMcaYsFjgMMYYExYLHMYYY8JigcMYY0xYLHAYY4wJiwUOY4wxYbHAYYwxJiwWOIwxxoQlooFDRKaJyBoRWScit7eyPlZEnvfWfyIiA0PW3eGlrxGRCzu6T2OMMZEVscAhIlHAA8B0YCRwjYiMbJHtRmCPqg4Ffgf8xtt2JDALGAVMA/4oIlEd3KcxxpgIimSNYzKwTlU3qGoD8Bwwo0WeGcAT3vM5wLkiIl76c6par6obgXXe/jqyT2OMMRHkj+C+c4GtIctFwMlt5VHVgIhUAJle+sctts31nh9qnwCIyGxgtrdYLyLLD+M9dJUsoKyrCxEmK3PkHWvlBSvz0RDJ8g5oLTGSgUNaSdMO5mkrvbUaUst9ukTVh4CHAESkQFXz2y5q93KslReszEfDsVZesDIfDV1R3kg2VRUB/UKW84DitvKIiB9IBXa3s21H9mmMMSaCIhk4FgHDRGSQiMTgOrvntcgzD7jeez4TeFtV1Uuf5V11NQgYBnzawX0aY4yJoIg1VXl9FjcD84Eo4FFVXSEidwEFqjoPeAR4SkTW4Woas7xtV4jIC8BKIAB8V1WbAFrbZweK81Anv71IO9bKC1bmo+FYKy9YmY+Go15ecT/wjTHGmI6xkePGGGPCYoHDGGNMWI7rwHEsTE8iIv1EZIGIrBKRFSJyi5eeISJviMha7296V5c1lDeS/zMRecVbHuRNG7PWm0YmpqvLGEpE0kRkjois9o71KcfAMf6B9z+xXESeFZG47nacReRRESkJHSfV1nEV537v+1goIhO7SXl/6/1fFIrIXBFJC1nX6tRHXV3mkHU/EhEVkSxv+agc4+M2cBxD05MEgB+q6ghgCvBdr5y3A2+p6jDgLW+5O7kFWBWy/Bvgd1559+Cmk+lOfg/8S1WHA+NwZe+2x1hEcoHvAfmqOhp3Mcgsut9xfhw3LVCoto7rdNwVksNwg3P/dJTKGOpxDi7vG8BoVR0LfAHcAW1PfXT0irrP4xxcZkSkH3A+sCUk+agc4+M2cHCMTE+iqttVdYn3vBJ3QsvlwOlYngAu75oSHkxE8oCLgb94ywKcg5s2BrpfeVOAM3BX8aGqDapaTjc+xh4/EO+NcUoAttPNjrOqvou7IjJUW8d1BvCkOh8DaSKSc3RK6rRWXlV9XVUD3uLHuPFh0PbUR0dVG8cY3Px+/8GBg6CPyjE+ngNHa1Oe5LaRt1sQNzvwBOAToLeqbgcXXIBeXVeyg9yH+4cNesuZQHnIl6+7HevBQCnwmNe89hcRSaQbH2NV3Qbcg/s1uR2oABbTvY9zs7aO67HwnfwG8Jr3vNuWV0QuA7ap6uctVh2VMh/PgaMjU550GyKSBLwIfF9V93Z1edoiIpcAJaq6ODS5lazd6Vj7gYnAn1R1AlBNN2qWao3XLzADGAT0BRJxzRAtdafjfCjd+v9ERH6Kazp+ujmplWxdXl4RSQB+CvxXa6tbSev0Mh/PgeOYmZ5ERKJxQeNpVf27l7yzuYrp/S3pqvK1cBpwmYhswjX/nYOrgaR5TSrQ/Y51EVCkqp94y3NwgaS7HmOA84CNqlqqqo3A34FT6d7HuVlbx7XbfidF5HrgEuBa3T+4rbuWdwjuB8Xn3vcwD1giIn04SmU+ngPHMTE9idc/8AiwSlXvDVkVOh3L9cDLR7tsrVHVO1Q1T1UH4o7p26p6LbAAN20MdKPyAqjqDmCriJzoJZ2Lm5WgWx5jzxZgiogkeP8jzWXutsc5RFvHdR7wNe/KnylARXOTVlcSkWnAbcBlqloTsqqtqY+6lKouU9VeqjrQ+x4WARO9//Ojc4xV9bh9ABfhrpJYD/y0q8vTRhlPx1UlC4Gl3uMiXL/BW8Ba729GV5e1lbKfBbziPR+M+1KtA/4GxHZ1+VqUdTxQ4B3nl4D07n6MgV8Aq4HlwFNAbHc7zsCzuD6YRtwJ7Ma2jiuuGeUB7/u4DHfFWHco7zpcv0Dz9+/PIfl/6pV3DTC9uxzjFus3AVlH8xjblCPGGGPCcjw3VRljjIkACxzGGGPCYoHDGGNMWCxwGGOMCYsFDmOMMWGxwGFMNyciZ4k3C7Ex3YEFDmOMMWGxwGFMJxGRr4rIpyKyVEQeFHfPkioR+T8RWSIib4lItpd3vIh8HHIPiOZ7VgwVkTdF5HNvmyHe7pNk//1EnvZGkxvTJSxwGNMJRGQEcDVwmqqOB5qAa3GTEy5R1YnAO8DPvE2eBG5Tdw+IZSHpTwMPqOo43NxUzdNFTAC+j7u3zGDcnGHGdAn/obMYYzrgXGASsMirDMTjJvcLAs97ef4K/F1EUoE0VX3HS38C+JuIJAO5qjoXQFXrALz9faqqRd7yUmAg8H7k35YxB7PAYUznEOAJVb3jgESRO1vka2+On/aan+pDnjdh313ThaypypjO8RYwU0R6wb77bg/AfceaZ7P9CvC+qlYAe0Rkqpd+HfCOuvuwFInI5d4+Yr17LxjTrdivFmM6gaquFJH/BF4XER9uJtPv4m4aNUpEFuPu4ne1t8n1wJ+9wLAB+LqXfh3woIjc5e3jy0fxbRjTITY7rjERJCJVqprU1eUwpjNZU5UxxpiwWI3DGGNMWKzGYYwxJiwWOIwxxoTFAocxxpiwWOAwxhgTFgscxhhjwvL/AWE1KvuqztmRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Size of encoded representation\n",
    "#{'batch_size': 10, 'dropout': 0.15, 'encoded_layer_size': 25, 'epochs': 150, 'layer1_size': 100, 'layer2_size': 40}\n",
    "input_size = 148\n",
    "hidden_size = 100\n",
    "hidden_size_2 = 40\n",
    "encoding_dim = 25\n",
    "dropout = 0.15\n",
    "\n",
    "# Input Placeholder\n",
    "input_data = Input(shape=(input_size,))\n",
    "print(input_data)\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "hidden_e_1 = Dense(hidden_size, activation='tanh')(input_data) \n",
    "hidden_e_2 = Dense(hidden_size_2, activation='tanh')(hidden_e_1)\n",
    "dropout_layer = Dropout(dropout)(hidden_e_2)\n",
    "encoded = Dense(encoding_dim, activation='tanh')(dropout_layer)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "hidden_d_1 = Dense(hidden_size, activation='tanh')(encoded)\n",
    "dropout_layer_d = Dropout(dropout)(hidden_d_1)\n",
    "hidden_d_2 = Dense(hidden_size, activation='tanh')(dropout_layer_d)\n",
    "decoded = Dense(input_size, activation='tanh')(hidden_d_2) \n",
    "# this model maps an input to its prediction\n",
    "autoencoder = Model(input_data, decoded)\n",
    "# configure our model to use mean_absolute_error loss function, and the Adam optimizer:\n",
    "autoencoder.compile(optimizer='Adam', loss='mean_absolute_error')\n",
    "\n",
    "ac = autoencoder.fit(X_train_full, Y_train_full,\n",
    "epochs=150,\n",
    "batch_size=10,\n",
    "validation_data=(X_test, Y_test),\n",
    "shuffle=True)\n",
    "\n",
    "#print(ac.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(ac.history['loss'])\n",
    "plt.plot(ac.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "#plt.legend(['train'], loc='upper left')\n",
    "plt.axis([0, 150, 0.0, 0.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"Autoencoder Input 2 year Output 1 year SA with Gilmore in training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 1y AC 0.10326359576903399 \n"
     ]
    }
   ],
   "source": [
    "#Now calculate MAE on the original Gilmore Dataset\n",
    "\n",
    "#Predict\n",
    "predicted_1yr_sa = autoencoder.predict(X_test_Gilmore)\n",
    "truth_1yr_sa = Y_test_Gilmore.to_numpy()\n",
    "\n",
    "#Save\n",
    "#y_pred = pd.DataFrame(predicted_1yr_sa_gilmore)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE 1y AC {} '.format(mean_absolute_error(truth_1yr_sa, predicted_1yr_sa)))\n",
    "####Complete Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Y SA Scaled\n",
      "(20, 148)\n"
     ]
    }
   ],
   "source": [
    "sa_sheet_2y = pd.ExcelFile(\"Data to be Interpolated.xlsx\") \n",
    "parsee = sa_sheet_2y.sheet_names[9]\n",
    "print(parsee)\n",
    "data = sa_sheet_2y.parse(parsee)\n",
    "data_features_sa2y = data.loc[:, data.columns] \n",
    "data_features_sa2y = data_features_sa2y.drop(['ROI'], axis=1)\n",
    "\n",
    "print(data_features_sa2y.shape)\n",
    "\n",
    "predicted_1yr_sa = autoencoder.predict(data_features_sa2y)\n",
    "df = pd.DataFrame(predicted_1yr_sa)\n",
    "df.to_excel(\"Interpolated SA 1y with Gilmore in Training.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
