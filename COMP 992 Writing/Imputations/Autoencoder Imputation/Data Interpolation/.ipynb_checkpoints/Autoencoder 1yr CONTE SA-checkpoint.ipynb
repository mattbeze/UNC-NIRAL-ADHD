{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras import losses\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "\n",
    "ct_sheet = pd.ExcelFile(\"Training Data.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290, 148)\n",
      "(290, 148)\n",
      "Tensor(\"input_1:0\", shape=(None, 148), dtype=float32)\n",
      "Train on 261 samples, validate on 29 samples\n",
      "Epoch 1/150\n",
      "261/261 [==============================] - 1s 4ms/step - loss: 0.2320 - val_loss: 0.1289\n",
      "Epoch 2/150\n",
      "261/261 [==============================] - 0s 406us/step - loss: 0.1421 - val_loss: 0.1195\n",
      "Epoch 3/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.1292 - val_loss: 0.1170\n",
      "Epoch 4/150\n",
      "261/261 [==============================] - 0s 372us/step - loss: 0.1223 - val_loss: 0.1190\n",
      "Epoch 5/150\n",
      "261/261 [==============================] - 0s 368us/step - loss: 0.1213 - val_loss: 0.1137\n",
      "Epoch 6/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.1166 - val_loss: 0.1102\n",
      "Epoch 7/150\n",
      "261/261 [==============================] - 0s 368us/step - loss: 0.1144 - val_loss: 0.1105\n",
      "Epoch 8/150\n",
      "261/261 [==============================] - 0s 364us/step - loss: 0.1176 - val_loss: 0.1099\n",
      "Epoch 9/150\n",
      "261/261 [==============================] - 0s 368us/step - loss: 0.1133 - val_loss: 0.1099\n",
      "Epoch 10/150\n",
      "261/261 [==============================] - 0s 372us/step - loss: 0.1104 - val_loss: 0.1149\n",
      "Epoch 11/150\n",
      "261/261 [==============================] - 0s 398us/step - loss: 0.1154 - val_loss: 0.1084\n",
      "Epoch 12/150\n",
      "261/261 [==============================] - 0s 467us/step - loss: 0.1095 - val_loss: 0.1089\n",
      "Epoch 13/150\n",
      "261/261 [==============================] - 0s 475us/step - loss: 0.1083 - val_loss: 0.1086\n",
      "Epoch 14/150\n",
      "261/261 [==============================] - 0s 372us/step - loss: 0.1071 - val_loss: 0.1068\n",
      "Epoch 15/150\n",
      "261/261 [==============================] - 0s 375us/step - loss: 0.1070 - val_loss: 0.1069\n",
      "Epoch 16/150\n",
      "261/261 [==============================] - 0s 372us/step - loss: 0.1069 - val_loss: 0.1065\n",
      "Epoch 17/150\n",
      "261/261 [==============================] - 0s 414us/step - loss: 0.1056 - val_loss: 0.1065\n",
      "Epoch 18/150\n",
      "261/261 [==============================] - 0s 383us/step - loss: 0.1051 - val_loss: 0.1066\n",
      "Epoch 19/150\n",
      "261/261 [==============================] - 0s 364us/step - loss: 0.1042 - val_loss: 0.1060\n",
      "Epoch 20/150\n",
      "261/261 [==============================] - 0s 387us/step - loss: 0.1044 - val_loss: 0.1072\n",
      "Epoch 21/150\n",
      "261/261 [==============================] - 0s 448us/step - loss: 0.1040 - val_loss: 0.1090\n",
      "Epoch 22/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.1035 - val_loss: 0.1075\n",
      "Epoch 23/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.1034 - val_loss: 0.1073\n",
      "Epoch 24/150\n",
      "261/261 [==============================] - 0s 387us/step - loss: 0.1038 - val_loss: 0.1057\n",
      "Epoch 25/150\n",
      "261/261 [==============================] - 0s 356us/step - loss: 0.1019 - val_loss: 0.1073\n",
      "Epoch 26/150\n",
      "261/261 [==============================] - 0s 383us/step - loss: 0.1018 - val_loss: 0.1060\n",
      "Epoch 27/150\n",
      "261/261 [==============================] - 0s 406us/step - loss: 0.1016 - val_loss: 0.1094\n",
      "Epoch 28/150\n",
      "261/261 [==============================] - 0s 418us/step - loss: 0.1012 - val_loss: 0.1060\n",
      "Epoch 29/150\n",
      "261/261 [==============================] - 0s 402us/step - loss: 0.1008 - val_loss: 0.1080\n",
      "Epoch 30/150\n",
      "261/261 [==============================] - 0s 375us/step - loss: 0.1013 - val_loss: 0.1058\n",
      "Epoch 31/150\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.0994 - val_loss: 0.1047\n",
      "Epoch 32/150\n",
      "261/261 [==============================] - 0s 402us/step - loss: 0.0985 - val_loss: 0.1043\n",
      "Epoch 33/150\n",
      "261/261 [==============================] - 0s 460us/step - loss: 0.0986 - val_loss: 0.1036\n",
      "Epoch 34/150\n",
      "261/261 [==============================] - 0s 494us/step - loss: 0.0981 - val_loss: 0.1040\n",
      "Epoch 35/150\n",
      "261/261 [==============================] - 0s 372us/step - loss: 0.0979 - val_loss: 0.1039\n",
      "Epoch 36/150\n",
      "261/261 [==============================] - 0s 360us/step - loss: 0.0969 - val_loss: 0.1062\n",
      "Epoch 37/150\n",
      "261/261 [==============================] - 0s 372us/step - loss: 0.0981 - val_loss: 0.1074\n",
      "Epoch 38/150\n",
      "261/261 [==============================] - 0s 360us/step - loss: 0.0979 - val_loss: 0.1052\n",
      "Epoch 39/150\n",
      "261/261 [==============================] - 0s 437us/step - loss: 0.0979 - val_loss: 0.1047\n",
      "Epoch 40/150\n",
      "261/261 [==============================] - 0s 398us/step - loss: 0.0968 - val_loss: 0.1065\n",
      "Epoch 41/150\n",
      "261/261 [==============================] - 0s 406us/step - loss: 0.0972 - val_loss: 0.1063\n",
      "Epoch 42/150\n",
      "261/261 [==============================] - 0s 368us/step - loss: 0.0969 - val_loss: 0.1054\n",
      "Epoch 43/150\n",
      "261/261 [==============================] - 0s 372us/step - loss: 0.0982 - val_loss: 0.1090\n",
      "Epoch 44/150\n",
      "261/261 [==============================] - 0s 437us/step - loss: 0.0966 - val_loss: 0.1048\n",
      "Epoch 45/150\n",
      "261/261 [==============================] - 0s 414us/step - loss: 0.0965 - val_loss: 0.1029\n",
      "Epoch 46/150\n",
      "261/261 [==============================] - 0s 410us/step - loss: 0.0955 - val_loss: 0.1037\n",
      "Epoch 47/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.0951 - val_loss: 0.1038\n",
      "Epoch 48/150\n",
      "261/261 [==============================] - 0s 383us/step - loss: 0.0950 - val_loss: 0.1034\n",
      "Epoch 49/150\n",
      "261/261 [==============================] - 0s 391us/step - loss: 0.0950 - val_loss: 0.1045\n",
      "Epoch 50/150\n",
      "261/261 [==============================] - 0s 414us/step - loss: 0.0958 - val_loss: 0.1067\n",
      "Epoch 51/150\n",
      "261/261 [==============================] - 0s 379us/step - loss: 0.0970 - val_loss: 0.1032\n",
      "Epoch 52/150\n",
      "261/261 [==============================] - 0s 372us/step - loss: 0.0940 - val_loss: 0.1036\n",
      "Epoch 53/150\n",
      "261/261 [==============================] - 0s 383us/step - loss: 0.0946 - val_loss: 0.1031\n",
      "Epoch 54/150\n",
      "261/261 [==============================] - 0s 356us/step - loss: 0.0939 - val_loss: 0.1037\n",
      "Epoch 55/150\n",
      "261/261 [==============================] - 0s 383us/step - loss: 0.0945 - val_loss: 0.1045\n",
      "Epoch 56/150\n",
      "261/261 [==============================] - 0s 345us/step - loss: 0.0939 - val_loss: 0.1025\n",
      "Epoch 57/150\n",
      "261/261 [==============================] - 0s 379us/step - loss: 0.0934 - val_loss: 0.1035\n",
      "Epoch 58/150\n",
      "261/261 [==============================] - 0s 379us/step - loss: 0.0929 - val_loss: 0.1038\n",
      "Epoch 59/150\n",
      "261/261 [==============================] - 0s 387us/step - loss: 0.0936 - val_loss: 0.1033\n",
      "Epoch 60/150\n",
      "261/261 [==============================] - 0s 391us/step - loss: 0.0935 - val_loss: 0.1031\n",
      "Epoch 61/150\n",
      "261/261 [==============================] - 0s 414us/step - loss: 0.0924 - val_loss: 0.1061\n",
      "Epoch 62/150\n",
      "261/261 [==============================] - 0s 368us/step - loss: 0.0934 - val_loss: 0.1036\n",
      "Epoch 63/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.0917 - val_loss: 0.1030\n",
      "Epoch 64/150\n",
      "261/261 [==============================] - 0s 364us/step - loss: 0.0931 - val_loss: 0.1042\n",
      "Epoch 65/150\n",
      "261/261 [==============================] - 0s 375us/step - loss: 0.0928 - val_loss: 0.1030\n",
      "Epoch 66/150\n",
      "261/261 [==============================] - 0s 383us/step - loss: 0.0920 - val_loss: 0.1024\n",
      "Epoch 67/150\n",
      "261/261 [==============================] - 0s 437us/step - loss: 0.0917 - val_loss: 0.1029\n",
      "Epoch 68/150\n",
      "261/261 [==============================] - 0s 406us/step - loss: 0.0917 - val_loss: 0.1020\n",
      "Epoch 69/150\n",
      "261/261 [==============================] - 0s 387us/step - loss: 0.0912 - val_loss: 0.1037\n",
      "Epoch 70/150\n",
      "261/261 [==============================] - 0s 356us/step - loss: 0.0915 - val_loss: 0.1022\n",
      "Epoch 71/150\n",
      "261/261 [==============================] - 0s 372us/step - loss: 0.0911 - val_loss: 0.1041\n",
      "Epoch 72/150\n",
      "261/261 [==============================] - 0s 372us/step - loss: 0.0941 - val_loss: 0.1033\n",
      "Epoch 73/150\n",
      "261/261 [==============================] - 0s 398us/step - loss: 0.0921 - val_loss: 0.1037\n",
      "Epoch 74/150\n",
      "261/261 [==============================] - 0s 444us/step - loss: 0.0914 - val_loss: 0.1018\n",
      "Epoch 75/150\n",
      "261/261 [==============================] - 0s 418us/step - loss: 0.0911 - val_loss: 0.1020\n",
      "Epoch 76/150\n",
      "261/261 [==============================] - 0s 356us/step - loss: 0.0909 - val_loss: 0.1028\n",
      "Epoch 77/150\n",
      "261/261 [==============================] - 0s 349us/step - loss: 0.0910 - val_loss: 0.1026\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 383us/step - loss: 0.0919 - val_loss: 0.1021\n",
      "Epoch 79/150\n",
      "261/261 [==============================] - 0s 383us/step - loss: 0.0907 - val_loss: 0.1024\n",
      "Epoch 80/150\n",
      "261/261 [==============================] - 0s 356us/step - loss: 0.0909 - val_loss: 0.1028\n",
      "Epoch 81/150\n",
      "261/261 [==============================] - 0s 310us/step - loss: 0.0902 - val_loss: 0.1031\n",
      "Epoch 82/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.0918 - val_loss: 0.1045\n",
      "Epoch 83/150\n",
      "261/261 [==============================] - 0s 383us/step - loss: 0.0907 - val_loss: 0.1027\n",
      "Epoch 84/150\n",
      "261/261 [==============================] - 0s 383us/step - loss: 0.0903 - val_loss: 0.1024\n",
      "Epoch 85/150\n",
      "261/261 [==============================] - 0s 425us/step - loss: 0.0908 - val_loss: 0.1027\n",
      "Epoch 86/150\n",
      "261/261 [==============================] - 0s 395us/step - loss: 0.0898 - val_loss: 0.1030\n",
      "Epoch 87/150\n",
      "261/261 [==============================] - 0s 464us/step - loss: 0.0898 - val_loss: 0.1050\n",
      "Epoch 88/150\n",
      "261/261 [==============================] - 0s 429us/step - loss: 0.0903 - val_loss: 0.1029\n",
      "Epoch 89/150\n",
      "261/261 [==============================] - 0s 418us/step - loss: 0.0901 - val_loss: 0.1023\n",
      "Epoch 90/150\n",
      "261/261 [==============================] - 0s 414us/step - loss: 0.0899 - val_loss: 0.1047\n",
      "Epoch 91/150\n",
      "261/261 [==============================] - 0s 402us/step - loss: 0.0907 - val_loss: 0.1027\n",
      "Epoch 92/150\n",
      "261/261 [==============================] - 0s 529us/step - loss: 0.0898 - val_loss: 0.1025\n",
      "Epoch 93/150\n",
      "261/261 [==============================] - 0s 556us/step - loss: 0.0901 - val_loss: 0.1032\n",
      "Epoch 94/150\n",
      "261/261 [==============================] - 0s 460us/step - loss: 0.0900 - val_loss: 0.1032\n",
      "Epoch 95/150\n",
      "261/261 [==============================] - 0s 414us/step - loss: 0.0897 - val_loss: 0.1034\n",
      "Epoch 96/150\n",
      "261/261 [==============================] - 0s 471us/step - loss: 0.0901 - val_loss: 0.1031\n",
      "Epoch 97/150\n",
      "261/261 [==============================] - 0s 575us/step - loss: 0.0895 - val_loss: 0.1022\n",
      "Epoch 98/150\n",
      "261/261 [==============================] - 0s 479us/step - loss: 0.0891 - val_loss: 0.1031\n",
      "Epoch 99/150\n",
      "261/261 [==============================] - 0s 460us/step - loss: 0.0909 - val_loss: 0.1045\n",
      "Epoch 100/150\n",
      "261/261 [==============================] - 0s 602us/step - loss: 0.0898 - val_loss: 0.1026\n",
      "Epoch 101/150\n",
      "261/261 [==============================] - 0s 456us/step - loss: 0.0898 - val_loss: 0.1018\n",
      "Epoch 102/150\n",
      "261/261 [==============================] - 0s 402us/step - loss: 0.0885 - val_loss: 0.1013\n",
      "Epoch 103/150\n",
      "261/261 [==============================] - 0s 326us/step - loss: 0.0887 - val_loss: 0.1018\n",
      "Epoch 104/150\n",
      "261/261 [==============================] - 0s 379us/step - loss: 0.0889 - val_loss: 0.1028\n",
      "Epoch 105/150\n",
      "261/261 [==============================] - 0s 391us/step - loss: 0.0884 - val_loss: 0.1023\n",
      "Epoch 106/150\n",
      "261/261 [==============================] - 0s 421us/step - loss: 0.0888 - val_loss: 0.1015\n",
      "Epoch 107/150\n",
      "261/261 [==============================] - 0s 456us/step - loss: 0.0885 - val_loss: 0.1020\n",
      "Epoch 108/150\n",
      "261/261 [==============================] - 0s 379us/step - loss: 0.0885 - val_loss: 0.1017\n",
      "Epoch 109/150\n",
      "261/261 [==============================] - 0s 333us/step - loss: 0.0884 - val_loss: 0.1019\n",
      "Epoch 110/150\n",
      "261/261 [==============================] - 0s 383us/step - loss: 0.0884 - val_loss: 0.1023\n",
      "Epoch 111/150\n",
      "261/261 [==============================] - 0s 414us/step - loss: 0.0886 - val_loss: 0.1033\n",
      "Epoch 112/150\n",
      "261/261 [==============================] - 0s 421us/step - loss: 0.0885 - val_loss: 0.1018\n",
      "Epoch 113/150\n",
      "261/261 [==============================] - 0s 398us/step - loss: 0.0894 - val_loss: 0.1021\n",
      "Epoch 114/150\n",
      "261/261 [==============================] - 0s 337us/step - loss: 0.0888 - val_loss: 0.1021\n",
      "Epoch 115/150\n",
      "261/261 [==============================] - 0s 379us/step - loss: 0.0880 - val_loss: 0.1012\n",
      "Epoch 116/150\n",
      "261/261 [==============================] - 0s 406us/step - loss: 0.0885 - val_loss: 0.1010\n",
      "Epoch 117/150\n",
      "261/261 [==============================] - 0s 475us/step - loss: 0.0879 - val_loss: 0.1024\n",
      "Epoch 118/150\n",
      "261/261 [==============================] - 0s 467us/step - loss: 0.0880 - val_loss: 0.1025\n",
      "Epoch 119/150\n",
      "261/261 [==============================] - 0s 375us/step - loss: 0.0884 - val_loss: 0.1013\n",
      "Epoch 120/150\n",
      "261/261 [==============================] - 0s 410us/step - loss: 0.0886 - val_loss: 0.1015\n",
      "Epoch 121/150\n",
      "261/261 [==============================] - 0s 356us/step - loss: 0.0884 - val_loss: 0.1032\n",
      "Epoch 122/150\n",
      "261/261 [==============================] - 0s 364us/step - loss: 0.0890 - val_loss: 0.1021\n",
      "Epoch 123/150\n",
      "261/261 [==============================] - 0s 433us/step - loss: 0.0879 - val_loss: 0.1013\n",
      "Epoch 124/150\n",
      "261/261 [==============================] - 0s 387us/step - loss: 0.0880 - val_loss: 0.1017\n",
      "Epoch 125/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.0875 - val_loss: 0.1023\n",
      "Epoch 126/150\n",
      "261/261 [==============================] - 0s 364us/step - loss: 0.0881 - val_loss: 0.1030\n",
      "Epoch 127/150\n",
      "261/261 [==============================] - 0s 383us/step - loss: 0.0892 - val_loss: 0.1016\n",
      "Epoch 128/150\n",
      "261/261 [==============================] - 0s 395us/step - loss: 0.0887 - val_loss: 0.1022\n",
      "Epoch 129/150\n",
      "261/261 [==============================] - 0s 310us/step - loss: 0.0875 - val_loss: 0.1009\n",
      "Epoch 130/150\n",
      "261/261 [==============================] - 0s 452us/step - loss: 0.0878 - val_loss: 0.1030\n",
      "Epoch 131/150\n",
      "261/261 [==============================] - 0s 402us/step - loss: 0.0882 - val_loss: 0.1020\n",
      "Epoch 132/150\n",
      "261/261 [==============================] - 0s 360us/step - loss: 0.0878 - val_loss: 0.1020\n",
      "Epoch 133/150\n",
      "261/261 [==============================] - 0s 375us/step - loss: 0.0882 - val_loss: 0.1013\n",
      "Epoch 134/150\n",
      "261/261 [==============================] - 0s 387us/step - loss: 0.0878 - val_loss: 0.1029\n",
      "Epoch 135/150\n",
      "261/261 [==============================] - 0s 395us/step - loss: 0.0874 - val_loss: 0.1014\n",
      "Epoch 136/150\n",
      "261/261 [==============================] - 0s 475us/step - loss: 0.0876 - val_loss: 0.1016\n",
      "Epoch 137/150\n",
      "261/261 [==============================] - 0s 437us/step - loss: 0.0872 - val_loss: 0.1025\n",
      "Epoch 138/150\n",
      "261/261 [==============================] - 0s 391us/step - loss: 0.0877 - val_loss: 0.1015\n",
      "Epoch 139/150\n",
      "261/261 [==============================] - 0s 352us/step - loss: 0.0890 - val_loss: 0.1028\n",
      "Epoch 140/150\n",
      "261/261 [==============================] - 0s 391us/step - loss: 0.0877 - val_loss: 0.1016\n",
      "Epoch 141/150\n",
      "261/261 [==============================] - 0s 444us/step - loss: 0.0885 - val_loss: 0.1028\n",
      "Epoch 142/150\n",
      "261/261 [==============================] - 0s 421us/step - loss: 0.0873 - val_loss: 0.1018\n",
      "Epoch 143/150\n",
      "261/261 [==============================] - 0s 383us/step - loss: 0.0877 - val_loss: 0.1011\n",
      "Epoch 144/150\n",
      "261/261 [==============================] - 0s 372us/step - loss: 0.0873 - val_loss: 0.1013\n",
      "Epoch 145/150\n",
      "261/261 [==============================] - 0s 375us/step - loss: 0.0873 - val_loss: 0.1020\n",
      "Epoch 146/150\n",
      "261/261 [==============================] - 0s 372us/step - loss: 0.0888 - val_loss: 0.1017\n",
      "Epoch 147/150\n",
      "261/261 [==============================] - 0s 433us/step - loss: 0.0874 - val_loss: 0.1012\n",
      "Epoch 148/150\n",
      "261/261 [==============================] - 0s 414us/step - loss: 0.0872 - val_loss: 0.1012\n",
      "Epoch 149/150\n",
      "261/261 [==============================] - 0s 425us/step - loss: 0.0871 - val_loss: 0.1014\n",
      "Epoch 150/150\n",
      "261/261 [==============================] - 0s 333us/step - loss: 0.0864 - val_loss: 0.1015\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parsee = ct_sheet.sheet_names[2]\n",
    "data = ct_sheet.parse(parsee)\n",
    "data_features = data.loc[:, data.columns] \n",
    "data_features = data_features.drop(['ROI',11142,12142], axis=1)  \n",
    "\n",
    "parsee2 = ct_sheet.sheet_names[3]\n",
    "data2 = ct_sheet.parse(parsee2)\n",
    "data_labels = data2.loc[:, data2.columns] \n",
    "data_labels = data_labels.drop(['ROI',11142,12142], axis=1)  \n",
    "#Get rid of subject names to only have features now. #Need to remove ROIs. They don't convert to floats.\n",
    "#Get rid of ctx_rh_Medial_wall and ctx_lh_Medial_wall, not needed for analysis.\n",
    "#Have to standardize data. Scikit learn here. Need to create stratified K folds to avoid uneven distribution of risk groups.pcaCT1Y = PCA(n_components=150) #150 Features\n",
    "scaler_filename = \"IBIS_scaledSA1y.save\"\n",
    "scaler = joblib.load(scaler_filename)\n",
    "scaled_data_1y = scaler.transform(data_features)\n",
    "\n",
    "scaler_filename2 = \"IBIS_scaledSA2y.save\"\n",
    "scaler2 = joblib.load(scaler_filename2)\n",
    "scaled_data_2y = scaler.transform(data_labels)\n",
    "print(scaled_data_1y.shape)\n",
    "print(scaled_data_2y.shape)\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(scaled_data, scaled_labels, test_size=0.10, random_state=20)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(scaled_data_2y, scaled_data_1y, test_size=0.10, random_state=20)\n",
    "#Size of encoded representation\n",
    "#{'batch_size': 10, 'dropout': 0.15, 'encoded_layer_size': 25, 'epochs': 150, 'layer1_size': 100, 'layer2_size': 40}\n",
    "input_size = 148\n",
    "hidden_size = 100\n",
    "hidden_size_2 = 40\n",
    "encoding_dim = 25\n",
    "dropout = 0.15\n",
    "\n",
    "# Input Placeholder\n",
    "input_data = Input(shape=(input_size,))\n",
    "print(input_data)\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "hidden_e_1 = Dense(hidden_size, activation='tanh')(input_data) \n",
    "hidden_e_2 = Dense(hidden_size_2, activation='tanh')(hidden_e_1)\n",
    "dropout_layer = Dropout(dropout)(hidden_e_2)\n",
    "encoded = Dense(encoding_dim, activation='tanh')(dropout_layer)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "hidden_d_1 = Dense(hidden_size, activation='tanh')(encoded)\n",
    "dropout_layer_d = Dropout(dropout)(hidden_d_1)\n",
    "hidden_d_2 = Dense(hidden_size, activation='tanh')(dropout_layer_d)\n",
    "decoded = Dense(input_size, activation='tanh')(hidden_d_2) \n",
    "# this model maps an input to its prediction\n",
    "autoencoder = Model(input_data, decoded)\n",
    "# configure our model to use mean_absolute_error loss function, and the Adam optimizer:\n",
    "autoencoder.compile(optimizer='Adam', loss='mean_absolute_error')\n",
    "\n",
    "ac = autoencoder.fit(X_train, Y_train,\n",
    "epochs=150,\n",
    "batch_size=10,\n",
    "validation_data=(X_test, Y_test),\n",
    "shuffle=True)\n",
    "\n",
    "#print(ac.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(ac.history['loss'])\n",
    "plt.plot(ac.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "#plt.legend(['train'], loc='upper left')\n",
    "plt.axis([0, 150, 0.0, 0.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"Autoencoder Input 2 year Output 1 year SA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA2y\n",
      "SA1y\n",
      "MAE 1y AC 0.18036785761199137 \n"
     ]
    }
   ],
   "source": [
    "#Now calculate MAE on the original Gilmore Dataset\n",
    "#Input\n",
    "sa_sheet_2y = pd.ExcelFile(\"Scaled Gilmore Data for MAE.xlsx\") \n",
    "parsee = sa_sheet_2y.sheet_names[1]\n",
    "print(parsee)\n",
    "data = sa_sheet_2y.parse(parsee)\n",
    "data_features_sa2y = data.loc[:, data.columns] \n",
    "data_features_sa2y = data_features_sa2y.drop(['ROI'], axis=1)\n",
    "#Ground truth\n",
    "sa_sheet_1y = pd.ExcelFile(\"Scaled Gilmore Data for MAE.xlsx\") \n",
    "parsee = sa_sheet_1y.sheet_names[0]\n",
    "print(parsee)\n",
    "data = sa_sheet_1y.parse(parsee)\n",
    "data_features_sa1y = data.loc[:, data.columns] \n",
    "data_features_sa1y = data_features_sa1y.drop(['ROI'], axis=1)\n",
    "\n",
    "#Predict\n",
    "predicted_1yr_sa = autoencoder.predict(data_features_sa2y)\n",
    "truth_1yr_sa = data_features_sa1y.to_numpy()\n",
    "\n",
    "#Save\n",
    "#y_pred = pd.DataFrame(predicted_1yr_sa_gilmore)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE 1y AC {} '.format(mean_absolute_error(truth_1yr_sa, predicted_1yr_sa)))\n",
    "####Complete Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Y SA Scaled\n",
      "(20, 148)\n"
     ]
    }
   ],
   "source": [
    "sa_sheet_2y = pd.ExcelFile(\"Data to be Interpolated.xlsx\") \n",
    "parsee = sa_sheet_2y.sheet_names[9]\n",
    "print(parsee)\n",
    "data = sa_sheet_2y.parse(parsee)\n",
    "data_features_sa2y = data.loc[:, data.columns] \n",
    "data_features_sa2y = data_features_sa2y.drop(['ROI'], axis=1)\n",
    "\n",
    "print(data_features_sa2y.shape)\n",
    "\n",
    "predicted_1yr_sa = autoencoder.predict(data_features_sa2y)\n",
    "df = pd.DataFrame(predicted_1yr_sa)\n",
    "df.to_excel(\"Interpolated SA 1y.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
