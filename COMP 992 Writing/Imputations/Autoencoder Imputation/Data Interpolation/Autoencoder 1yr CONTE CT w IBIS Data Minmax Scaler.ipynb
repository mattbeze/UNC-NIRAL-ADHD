{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras import losses\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "\n",
    "ct_sheet = pd.ExcelFile(\"All CTSA 2-1yr No Interpolated Samples.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(585, 148)\n",
      "(585, 148)\n",
      "Tensor(\"input_1:0\", shape=(None, 148), dtype=float32)\n",
      "Epoch 1/150\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.2115\n",
      "Epoch 2/150\n",
      "585/585 [==============================] - 0s 413us/step - loss: 0.1237\n",
      "Epoch 3/150\n",
      "585/585 [==============================] - 0s 404us/step - loss: 0.1170\n",
      "Epoch 4/150\n",
      "585/585 [==============================] - 0s 375us/step - loss: 0.1093\n",
      "Epoch 5/150\n",
      "585/585 [==============================] - 0s 374us/step - loss: 0.1056\n",
      "Epoch 6/150\n",
      "585/585 [==============================] - 0s 442us/step - loss: 0.1049\n",
      "Epoch 7/150\n",
      "585/585 [==============================] - 0s 399us/step - loss: 0.1034\n",
      "Epoch 8/150\n",
      "585/585 [==============================] - 0s 363us/step - loss: 0.1030\n",
      "Epoch 9/150\n",
      "585/585 [==============================] - 0s 385us/step - loss: 0.1009\n",
      "Epoch 10/150\n",
      "585/585 [==============================] - 0s 374us/step - loss: 0.1001\n",
      "Epoch 11/150\n",
      "585/585 [==============================] - 0s 407us/step - loss: 0.0998\n",
      "Epoch 12/150\n",
      "585/585 [==============================] - 0s 401us/step - loss: 0.0992\n",
      "Epoch 13/150\n",
      "585/585 [==============================] - 0s 399us/step - loss: 0.0995\n",
      "Epoch 14/150\n",
      "585/585 [==============================] - 0s 410us/step - loss: 0.0998 0s - loss: 0.1\n",
      "Epoch 15/150\n",
      "585/585 [==============================] - 0s 429us/step - loss: 0.0979\n",
      "Epoch 16/150\n",
      "585/585 [==============================] - 0s 386us/step - loss: 0.0983\n",
      "Epoch 17/150\n",
      "585/585 [==============================] - 0s 432us/step - loss: 0.0979\n",
      "Epoch 18/150\n",
      "585/585 [==============================] - 0s 439us/step - loss: 0.0979\n",
      "Epoch 19/150\n",
      "585/585 [==============================] - 0s 512us/step - loss: 0.0968\n",
      "Epoch 20/150\n",
      "585/585 [==============================] - 0s 422us/step - loss: 0.0963\n",
      "Epoch 21/150\n",
      "585/585 [==============================] - 0s 616us/step - loss: 0.0964\n",
      "Epoch 22/150\n",
      "585/585 [==============================] - 0s 447us/step - loss: 0.0980\n",
      "Epoch 23/150\n",
      "585/585 [==============================] - 0s 411us/step - loss: 0.0981\n",
      "Epoch 24/150\n",
      "585/585 [==============================] - 0s 447us/step - loss: 0.0959\n",
      "Epoch 25/150\n",
      "585/585 [==============================] - 0s 509us/step - loss: 0.0946\n",
      "Epoch 26/150\n",
      "585/585 [==============================] - 0s 330us/step - loss: 0.0965\n",
      "Epoch 27/150\n",
      "585/585 [==============================] - 0s 328us/step - loss: 0.0963\n",
      "Epoch 28/150\n",
      "585/585 [==============================] - 0s 295us/step - loss: 0.0951\n",
      "Epoch 29/150\n",
      "585/585 [==============================] - 0s 292us/step - loss: 0.0947\n",
      "Epoch 30/150\n",
      "585/585 [==============================] - 0s 285us/step - loss: 0.0953\n",
      "Epoch 31/150\n",
      "585/585 [==============================] - 0s 299us/step - loss: 0.0956\n",
      "Epoch 32/150\n",
      "585/585 [==============================] - 0s 301us/step - loss: 0.0947\n",
      "Epoch 33/150\n",
      "585/585 [==============================] - 0s 330us/step - loss: 0.0936\n",
      "Epoch 34/150\n",
      "585/585 [==============================] - 0s 364us/step - loss: 0.0947\n",
      "Epoch 35/150\n",
      "585/585 [==============================] - 0s 318us/step - loss: 0.0947\n",
      "Epoch 36/150\n",
      "585/585 [==============================] - 0s 313us/step - loss: 0.0951\n",
      "Epoch 37/150\n",
      "585/585 [==============================] - 0s 216us/step - loss: 0.0942\n",
      "Epoch 38/150\n",
      "585/585 [==============================] - 0s 214us/step - loss: 0.0946\n",
      "Epoch 39/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0942\n",
      "Epoch 40/150\n",
      "585/585 [==============================] - 0s 214us/step - loss: 0.0933\n",
      "Epoch 41/150\n",
      "585/585 [==============================] - 0s 300us/step - loss: 0.0926\n",
      "Epoch 42/150\n",
      "585/585 [==============================] - 0s 191us/step - loss: 0.0939\n",
      "Epoch 43/150\n",
      "585/585 [==============================] - 0s 168us/step - loss: 0.0926\n",
      "Epoch 44/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0928\n",
      "Epoch 45/150\n",
      "585/585 [==============================] - 0s 214us/step - loss: 0.0937\n",
      "Epoch 46/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0947\n",
      "Epoch 47/150\n",
      "585/585 [==============================] - 0s 240us/step - loss: 0.0929\n",
      "Epoch 48/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0920\n",
      "Epoch 49/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0926\n",
      "Epoch 50/150\n",
      "585/585 [==============================] - 0s 259us/step - loss: 0.0925\n",
      "Epoch 51/150\n",
      "585/585 [==============================] - 0s 283us/step - loss: 0.0921\n",
      "Epoch 52/150\n",
      "585/585 [==============================] - 0s 292us/step - loss: 0.0923\n",
      "Epoch 53/150\n",
      "585/585 [==============================] - 0s 218us/step - loss: 0.0924\n",
      "Epoch 54/150\n",
      "585/585 [==============================] - 0s 188us/step - loss: 0.0927\n",
      "Epoch 55/150\n",
      "585/585 [==============================] - 0s 337us/step - loss: 0.0934\n",
      "Epoch 56/150\n",
      "585/585 [==============================] - 0s 256us/step - loss: 0.0916\n",
      "Epoch 57/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0920\n",
      "Epoch 58/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0926\n",
      "Epoch 59/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0926\n",
      "Epoch 60/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0921\n",
      "Epoch 61/150\n",
      "585/585 [==============================] - 0s 214us/step - loss: 0.0916\n",
      "Epoch 62/150\n",
      "585/585 [==============================] - 0s 267us/step - loss: 0.0920\n",
      "Epoch 63/150\n",
      "585/585 [==============================] - 0s 214us/step - loss: 0.0910\n",
      "Epoch 64/150\n",
      "585/585 [==============================] - 0s 184us/step - loss: 0.0919\n",
      "Epoch 65/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0915\n",
      "Epoch 66/150\n",
      "585/585 [==============================] - 0s 480us/step - loss: 0.0922\n",
      "Epoch 67/150\n",
      "585/585 [==============================] - 0s 321us/step - loss: 0.0918\n",
      "Epoch 68/150\n",
      "585/585 [==============================] - 0s 321us/step - loss: 0.0915\n",
      "Epoch 69/150\n",
      "585/585 [==============================] - 0s 294us/step - loss: 0.0920\n",
      "Epoch 70/150\n",
      "585/585 [==============================] - 0s 294us/step - loss: 0.0909\n",
      "Epoch 71/150\n",
      "585/585 [==============================] - 0s 321us/step - loss: 0.0911\n",
      "Epoch 72/150\n",
      "585/585 [==============================] - 0s 267us/step - loss: 0.0907\n",
      "Epoch 73/150\n",
      "585/585 [==============================] - ETA: 0s - loss: 0.089 - 0s 294us/step - loss: 0.0908\n",
      "Epoch 74/150\n",
      "585/585 [==============================] - 0s 214us/step - loss: 0.0921\n",
      "Epoch 75/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0906\n",
      "Epoch 76/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0912\n",
      "Epoch 77/150\n",
      "585/585 [==============================] - 0s 200us/step - loss: 0.0914\n",
      "Epoch 78/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0908\n",
      "Epoch 79/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0905\n",
      "Epoch 80/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0903\n",
      "Epoch 81/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0907\n",
      "Epoch 82/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0907\n",
      "Epoch 83/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0905\n",
      "Epoch 84/150\n",
      "585/585 [==============================] - ETA: 0s - loss: 0.089 - 0s 134us/step - loss: 0.0902\n",
      "Epoch 85/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0902\n",
      "Epoch 86/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0897\n",
      "Epoch 87/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0897\n",
      "Epoch 88/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0909\n",
      "Epoch 89/150\n",
      "585/585 [==============================] - 0s 303us/step - loss: 0.0915\n",
      "Epoch 90/150\n",
      "585/585 [==============================] - 0s 478us/step - loss: 0.0904\n",
      "Epoch 91/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0901\n",
      "Epoch 92/150\n",
      "585/585 [==============================] - 0s 294us/step - loss: 0.0897\n",
      "Epoch 93/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0894\n",
      "Epoch 94/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0904\n",
      "Epoch 95/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 0s 161us/step - loss: 0.0905\n",
      "Epoch 96/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0901\n",
      "Epoch 97/150\n",
      "585/585 [==============================] - 0s 425us/step - loss: 0.0912\n",
      "Epoch 98/150\n",
      "585/585 [==============================] - 0s 294us/step - loss: 0.0902\n",
      "Epoch 99/150\n",
      "585/585 [==============================] - 0s 151us/step - loss: 0.0898\n",
      "Epoch 100/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0897\n",
      "Epoch 101/150\n",
      "585/585 [==============================] - 0s 204us/step - loss: 0.0907\n",
      "Epoch 102/150\n",
      "585/585 [==============================] - 0s 214us/step - loss: 0.0898\n",
      "Epoch 103/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0904\n",
      "Epoch 104/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0891\n",
      "Epoch 105/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0897\n",
      "Epoch 106/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0898\n",
      "Epoch 107/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0891\n",
      "Epoch 108/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0889\n",
      "Epoch 109/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0895\n",
      "Epoch 110/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0893\n",
      "Epoch 111/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0899\n",
      "Epoch 112/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0889\n",
      "Epoch 113/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0889\n",
      "Epoch 114/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0896\n",
      "Epoch 115/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0907\n",
      "Epoch 116/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0896\n",
      "Epoch 117/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0899\n",
      "Epoch 118/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0882\n",
      "Epoch 119/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0884\n",
      "Epoch 120/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0894\n",
      "Epoch 121/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0889\n",
      "Epoch 122/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0898\n",
      "Epoch 123/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0889\n",
      "Epoch 124/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0885\n",
      "Epoch 125/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0886\n",
      "Epoch 126/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0884\n",
      "Epoch 127/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0894\n",
      "Epoch 128/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0885\n",
      "Epoch 129/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0898\n",
      "Epoch 130/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0897\n",
      "Epoch 131/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0885\n",
      "Epoch 132/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0882\n",
      "Epoch 133/150\n",
      "585/585 [==============================] - 0s 164us/step - loss: 0.0887\n",
      "Epoch 134/150\n",
      "585/585 [==============================] - 0s 145us/step - loss: 0.0886\n",
      "Epoch 135/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0888\n",
      "Epoch 136/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0884\n",
      "Epoch 137/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0885\n",
      "Epoch 138/150\n",
      "585/585 [==============================] - 0s 134us/step - loss: 0.0879\n",
      "Epoch 139/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0881\n",
      "Epoch 140/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0888\n",
      "Epoch 141/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0883\n",
      "Epoch 142/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0894\n",
      "Epoch 143/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0881\n",
      "Epoch 144/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0887\n",
      "Epoch 145/150\n",
      "585/585 [==============================] - 0s 214us/step - loss: 0.0884\n",
      "Epoch 146/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0877\n",
      "Epoch 147/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0881\n",
      "Epoch 148/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0882\n",
      "Epoch 149/150\n",
      "585/585 [==============================] - 0s 160us/step - loss: 0.0898\n",
      "Epoch 150/150\n",
      "585/585 [==============================] - 0s 187us/step - loss: 0.0887\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parsee = ct_sheet.sheet_names[0]\n",
    "data = ct_sheet.parse(parsee)\n",
    "data_features = data.loc[:, data.columns] \n",
    "data_features = data_features.drop(['ROI',11142,12142], axis=1)  \n",
    "\n",
    "parsee2 = ct_sheet.sheet_names[1]\n",
    "data2 = ct_sheet.parse(parsee2)\n",
    "data_labels = data2.loc[:, data2.columns] \n",
    "data_labels = data_labels.drop(['ROI',11142,12142], axis=1)  \n",
    "#Get rid of subject names to only have features now. #Need to remove ROIs. They don't convert to floats.\n",
    "#Get rid of ctx_rh_Medial_wall and ctx_lh_Medial_wall, not needed for analysis.\n",
    "scaler_filename = \"IBIS_scaledCT1y.save\"\n",
    "scaler = joblib.load(scaler_filename)\n",
    "scaled_data_1y = scaler.transform(data_features)\n",
    "\n",
    "scaler_filename2 = \"IBIS_scaledCT2y.save\"\n",
    "scaler2 = joblib.load(scaler_filename2)\n",
    "scaled_data_2y = scaler.transform(data_labels)\n",
    "print(scaled_data_1y.shape)\n",
    "print(scaled_data_2y.shape)\n",
    "\n",
    "#Size of encoded representation\n",
    "#{'batch_size': 20, 'dropout': 0.2, 'encoded_layer_size': 25, 'epochs': 150, 'layer1_size': 100, 'layer2_size': 25}\n",
    "input_size = 148\n",
    "hidden_size = 100\n",
    "hidden_size_2 = 25\n",
    "encoding_dim = 25\n",
    "dropout = 0.2\n",
    "\n",
    "# Input Placeholder\n",
    "input_data = Input(shape=(input_size,))\n",
    "print(input_data)\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "hidden_e_1 = Dense(hidden_size, activation='tanh')(input_data) \n",
    "hidden_e_2 = Dense(hidden_size_2, activation='tanh')(hidden_e_1)\n",
    "dropout_layer = Dropout(dropout)(hidden_e_2)\n",
    "encoded = Dense(encoding_dim, activation='tanh')(dropout_layer)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "hidden_d_1 = Dense(hidden_size, activation='tanh')(encoded)\n",
    "dropout_layer_d = Dropout(dropout)(hidden_d_1)\n",
    "hidden_d_2 = Dense(hidden_size, activation='tanh')(dropout_layer_d)\n",
    "decoded = Dense(input_size, activation='tanh')(hidden_d_2) \n",
    "# this model maps an input to its prediction\n",
    "autoencoder = Model(input_data, decoded)\n",
    "# configure our model to use mean_absolute_error loss function, and the Adam optimizer:\n",
    "autoencoder.compile(optimizer='Adam', loss='mean_absolute_error')\n",
    "\n",
    "ac = autoencoder.fit(scaled_data_2y, scaled_data_1y,\n",
    "epochs=150,\n",
    "batch_size=20,\n",
    "shuffle=True)\n",
    "\n",
    "#print(ac.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(ac.history['loss'])\n",
    "#plt.plot(ac.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "#plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, 150, 0.0, 0.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"Autoencoder Input 2 year Output 1 year CT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Y CT\n",
      "(20, 148)\n"
     ]
    }
   ],
   "source": [
    "ct_sheet_2y = pd.ExcelFile(\"Data to be Interpolated.xlsx\") \n",
    "parsee = ct_sheet_2y.sheet_names[5]\n",
    "print(parsee)\n",
    "data = ct_sheet_2y.parse(parsee)\n",
    "data_features_ct2y = data.loc[:, data.columns] \n",
    "data_features_ct2y = data_features_ct2y.drop(['ROI',11142,12142], axis=1)\n",
    "scaled_data_ct2y = scaler2.transform(data_features_ct2y)\n",
    "print(scaled_data_ct2y.shape)\n",
    "\n",
    "predicted_1yr_ct = autoencoder.predict(scaled_data_ct2y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6332035   0.50006646  0.57114774 ...  0.46882164  0.46911532\n",
      "   0.4327111 ]\n",
      " [-0.34524107 -0.03065688  0.13512446 ... -0.19320163 -0.3701779\n",
      "   0.10696103]\n",
      " [-0.05960761  0.05314299  0.14814557 ... -0.05833349 -0.28801063\n",
      "   0.09480355]\n",
      " ...\n",
      " [ 0.01660283  0.16953766  0.20470393 ...  0.03244777 -0.18424323\n",
      "   0.16416128]\n",
      " [-0.15649265  0.14762788  0.24322906 ... -0.07000566 -0.20398378\n",
      "   0.1550608 ]\n",
      " [-0.12572294  0.10681565  0.12825173 ... -0.03611445 -0.20237513\n",
      "   0.17343535]]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_1yr_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predicted_1yr_ct)\n",
    "df.to_excel(\"Interpolated CT 1y.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.633204</td>\n",
       "      <td>0.500066</td>\n",
       "      <td>0.571148</td>\n",
       "      <td>0.653715</td>\n",
       "      <td>0.598459</td>\n",
       "      <td>0.755616</td>\n",
       "      <td>0.604603</td>\n",
       "      <td>0.533076</td>\n",
       "      <td>0.568695</td>\n",
       "      <td>0.570229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637455</td>\n",
       "      <td>0.524194</td>\n",
       "      <td>0.397115</td>\n",
       "      <td>0.471500</td>\n",
       "      <td>0.561303</td>\n",
       "      <td>0.804900</td>\n",
       "      <td>0.466915</td>\n",
       "      <td>0.468822</td>\n",
       "      <td>0.469115</td>\n",
       "      <td>0.432711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.345241</td>\n",
       "      <td>-0.030657</td>\n",
       "      <td>0.135124</td>\n",
       "      <td>-0.042443</td>\n",
       "      <td>-0.276815</td>\n",
       "      <td>0.248235</td>\n",
       "      <td>0.056493</td>\n",
       "      <td>-0.267335</td>\n",
       "      <td>-0.026539</td>\n",
       "      <td>-0.137934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059306</td>\n",
       "      <td>0.071699</td>\n",
       "      <td>-0.151146</td>\n",
       "      <td>-0.110233</td>\n",
       "      <td>0.148461</td>\n",
       "      <td>0.064440</td>\n",
       "      <td>-0.430663</td>\n",
       "      <td>-0.193202</td>\n",
       "      <td>-0.370178</td>\n",
       "      <td>0.106961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.059608</td>\n",
       "      <td>0.053143</td>\n",
       "      <td>0.148146</td>\n",
       "      <td>0.115841</td>\n",
       "      <td>-0.069659</td>\n",
       "      <td>0.325438</td>\n",
       "      <td>0.055484</td>\n",
       "      <td>-0.221650</td>\n",
       "      <td>0.045406</td>\n",
       "      <td>-0.075505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>0.077620</td>\n",
       "      <td>-0.122246</td>\n",
       "      <td>-0.042713</td>\n",
       "      <td>0.177038</td>\n",
       "      <td>0.333489</td>\n",
       "      <td>-0.376331</td>\n",
       "      <td>-0.058333</td>\n",
       "      <td>-0.288011</td>\n",
       "      <td>0.094804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.098709</td>\n",
       "      <td>0.121213</td>\n",
       "      <td>0.255222</td>\n",
       "      <td>0.206924</td>\n",
       "      <td>-0.104062</td>\n",
       "      <td>0.412454</td>\n",
       "      <td>0.207333</td>\n",
       "      <td>-0.018501</td>\n",
       "      <td>0.246705</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256870</td>\n",
       "      <td>0.358515</td>\n",
       "      <td>-0.026240</td>\n",
       "      <td>0.032454</td>\n",
       "      <td>0.248710</td>\n",
       "      <td>0.340618</td>\n",
       "      <td>-0.230151</td>\n",
       "      <td>-0.041986</td>\n",
       "      <td>-0.142446</td>\n",
       "      <td>0.205055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.196298</td>\n",
       "      <td>-0.048596</td>\n",
       "      <td>0.108206</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>-0.185726</td>\n",
       "      <td>0.279652</td>\n",
       "      <td>0.043221</td>\n",
       "      <td>-0.236393</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>-0.036828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041913</td>\n",
       "      <td>0.167597</td>\n",
       "      <td>-0.162967</td>\n",
       "      <td>-0.076082</td>\n",
       "      <td>0.162751</td>\n",
       "      <td>0.206135</td>\n",
       "      <td>-0.366942</td>\n",
       "      <td>-0.126038</td>\n",
       "      <td>-0.318888</td>\n",
       "      <td>0.088399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.214302</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>0.075802</td>\n",
       "      <td>0.037431</td>\n",
       "      <td>-0.218483</td>\n",
       "      <td>0.331024</td>\n",
       "      <td>0.097427</td>\n",
       "      <td>-0.237222</td>\n",
       "      <td>0.097479</td>\n",
       "      <td>0.064496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019833</td>\n",
       "      <td>0.241470</td>\n",
       "      <td>-0.157935</td>\n",
       "      <td>-0.075652</td>\n",
       "      <td>0.142014</td>\n",
       "      <td>0.196229</td>\n",
       "      <td>-0.340456</td>\n",
       "      <td>-0.108270</td>\n",
       "      <td>-0.302400</td>\n",
       "      <td>0.122740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-0.180532</td>\n",
       "      <td>0.067086</td>\n",
       "      <td>0.181357</td>\n",
       "      <td>0.142417</td>\n",
       "      <td>-0.183661</td>\n",
       "      <td>0.313881</td>\n",
       "      <td>0.120228</td>\n",
       "      <td>-0.201511</td>\n",
       "      <td>0.102114</td>\n",
       "      <td>0.083134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>0.211951</td>\n",
       "      <td>-0.074239</td>\n",
       "      <td>-0.024620</td>\n",
       "      <td>0.214816</td>\n",
       "      <td>0.183931</td>\n",
       "      <td>-0.295259</td>\n",
       "      <td>-0.071084</td>\n",
       "      <td>-0.213549</td>\n",
       "      <td>0.172659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-0.293331</td>\n",
       "      <td>0.017522</td>\n",
       "      <td>0.097288</td>\n",
       "      <td>-0.055954</td>\n",
       "      <td>-0.274845</td>\n",
       "      <td>0.250720</td>\n",
       "      <td>0.042443</td>\n",
       "      <td>-0.248596</td>\n",
       "      <td>0.049488</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046876</td>\n",
       "      <td>0.100378</td>\n",
       "      <td>-0.164210</td>\n",
       "      <td>-0.117768</td>\n",
       "      <td>0.115267</td>\n",
       "      <td>0.129506</td>\n",
       "      <td>-0.395353</td>\n",
       "      <td>-0.169608</td>\n",
       "      <td>-0.351799</td>\n",
       "      <td>0.068215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-0.222410</td>\n",
       "      <td>-0.057488</td>\n",
       "      <td>0.114284</td>\n",
       "      <td>0.056716</td>\n",
       "      <td>-0.213370</td>\n",
       "      <td>0.293207</td>\n",
       "      <td>0.089664</td>\n",
       "      <td>-0.240399</td>\n",
       "      <td>0.047521</td>\n",
       "      <td>0.025372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019973</td>\n",
       "      <td>0.173605</td>\n",
       "      <td>-0.160289</td>\n",
       "      <td>-0.074095</td>\n",
       "      <td>0.154086</td>\n",
       "      <td>0.184744</td>\n",
       "      <td>-0.370811</td>\n",
       "      <td>-0.132954</td>\n",
       "      <td>-0.277153</td>\n",
       "      <td>0.154341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-0.161700</td>\n",
       "      <td>0.089911</td>\n",
       "      <td>0.147831</td>\n",
       "      <td>0.089532</td>\n",
       "      <td>-0.161420</td>\n",
       "      <td>0.324618</td>\n",
       "      <td>0.130719</td>\n",
       "      <td>-0.192992</td>\n",
       "      <td>0.084728</td>\n",
       "      <td>0.068793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099094</td>\n",
       "      <td>0.185579</td>\n",
       "      <td>-0.105667</td>\n",
       "      <td>-0.024891</td>\n",
       "      <td>0.178059</td>\n",
       "      <td>0.239527</td>\n",
       "      <td>-0.339667</td>\n",
       "      <td>-0.083513</td>\n",
       "      <td>-0.232487</td>\n",
       "      <td>0.134911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>-0.075195</td>\n",
       "      <td>0.110223</td>\n",
       "      <td>0.172187</td>\n",
       "      <td>0.141127</td>\n",
       "      <td>-0.065785</td>\n",
       "      <td>0.376140</td>\n",
       "      <td>0.172203</td>\n",
       "      <td>-0.140014</td>\n",
       "      <td>0.114358</td>\n",
       "      <td>0.093978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189266</td>\n",
       "      <td>0.261567</td>\n",
       "      <td>-0.090899</td>\n",
       "      <td>0.019950</td>\n",
       "      <td>0.217401</td>\n",
       "      <td>0.337437</td>\n",
       "      <td>-0.317984</td>\n",
       "      <td>-0.035494</td>\n",
       "      <td>-0.187591</td>\n",
       "      <td>0.164074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>-0.204836</td>\n",
       "      <td>0.180875</td>\n",
       "      <td>0.236751</td>\n",
       "      <td>0.106072</td>\n",
       "      <td>-0.175420</td>\n",
       "      <td>0.309989</td>\n",
       "      <td>0.084276</td>\n",
       "      <td>-0.169228</td>\n",
       "      <td>0.076717</td>\n",
       "      <td>-0.014750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098217</td>\n",
       "      <td>0.078908</td>\n",
       "      <td>-0.052783</td>\n",
       "      <td>-0.046463</td>\n",
       "      <td>0.203116</td>\n",
       "      <td>0.229415</td>\n",
       "      <td>-0.325757</td>\n",
       "      <td>-0.101568</td>\n",
       "      <td>-0.255058</td>\n",
       "      <td>0.132165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>-0.213545</td>\n",
       "      <td>0.040618</td>\n",
       "      <td>0.116211</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>-0.184017</td>\n",
       "      <td>0.308759</td>\n",
       "      <td>0.128379</td>\n",
       "      <td>-0.202635</td>\n",
       "      <td>0.109735</td>\n",
       "      <td>0.012590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020989</td>\n",
       "      <td>0.278939</td>\n",
       "      <td>-0.125602</td>\n",
       "      <td>-0.031240</td>\n",
       "      <td>0.198747</td>\n",
       "      <td>0.181528</td>\n",
       "      <td>-0.327091</td>\n",
       "      <td>-0.089194</td>\n",
       "      <td>-0.281061</td>\n",
       "      <td>0.102249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>-0.153971</td>\n",
       "      <td>0.068336</td>\n",
       "      <td>0.246214</td>\n",
       "      <td>0.160143</td>\n",
       "      <td>-0.119187</td>\n",
       "      <td>0.324508</td>\n",
       "      <td>0.128932</td>\n",
       "      <td>-0.142372</td>\n",
       "      <td>0.109673</td>\n",
       "      <td>0.030762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.181553</td>\n",
       "      <td>-0.012210</td>\n",
       "      <td>0.040238</td>\n",
       "      <td>0.252740</td>\n",
       "      <td>0.215041</td>\n",
       "      <td>-0.302986</td>\n",
       "      <td>-0.043070</td>\n",
       "      <td>-0.225123</td>\n",
       "      <td>0.170476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>-0.054737</td>\n",
       "      <td>0.109644</td>\n",
       "      <td>0.296684</td>\n",
       "      <td>0.283644</td>\n",
       "      <td>-0.034746</td>\n",
       "      <td>0.406274</td>\n",
       "      <td>0.186109</td>\n",
       "      <td>-0.037383</td>\n",
       "      <td>0.187502</td>\n",
       "      <td>0.071020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053764</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.074464</td>\n",
       "      <td>0.278758</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>-0.273462</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>-0.173646</td>\n",
       "      <td>0.217075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>-0.259806</td>\n",
       "      <td>-0.002763</td>\n",
       "      <td>0.102413</td>\n",
       "      <td>-0.003768</td>\n",
       "      <td>-0.207459</td>\n",
       "      <td>0.263185</td>\n",
       "      <td>0.064206</td>\n",
       "      <td>-0.278860</td>\n",
       "      <td>-0.024457</td>\n",
       "      <td>-0.072656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008535</td>\n",
       "      <td>0.111051</td>\n",
       "      <td>-0.147036</td>\n",
       "      <td>-0.061767</td>\n",
       "      <td>0.156937</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>-0.426703</td>\n",
       "      <td>-0.139597</td>\n",
       "      <td>-0.315175</td>\n",
       "      <td>0.124316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>-0.121246</td>\n",
       "      <td>0.199485</td>\n",
       "      <td>0.225220</td>\n",
       "      <td>0.149140</td>\n",
       "      <td>-0.121984</td>\n",
       "      <td>0.411048</td>\n",
       "      <td>0.200990</td>\n",
       "      <td>-0.058317</td>\n",
       "      <td>0.258959</td>\n",
       "      <td>0.213857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174658</td>\n",
       "      <td>0.373180</td>\n",
       "      <td>-0.028646</td>\n",
       "      <td>0.029842</td>\n",
       "      <td>0.256671</td>\n",
       "      <td>0.293347</td>\n",
       "      <td>-0.181799</td>\n",
       "      <td>-0.019342</td>\n",
       "      <td>-0.181422</td>\n",
       "      <td>0.144823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.016603</td>\n",
       "      <td>0.169538</td>\n",
       "      <td>0.204704</td>\n",
       "      <td>0.213465</td>\n",
       "      <td>0.033281</td>\n",
       "      <td>0.428693</td>\n",
       "      <td>0.188951</td>\n",
       "      <td>-0.097513</td>\n",
       "      <td>0.149282</td>\n",
       "      <td>0.073045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118608</td>\n",
       "      <td>0.315718</td>\n",
       "      <td>-0.060501</td>\n",
       "      <td>0.056830</td>\n",
       "      <td>0.255669</td>\n",
       "      <td>0.392426</td>\n",
       "      <td>-0.297094</td>\n",
       "      <td>0.032448</td>\n",
       "      <td>-0.184243</td>\n",
       "      <td>0.164161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>-0.156493</td>\n",
       "      <td>0.147628</td>\n",
       "      <td>0.243229</td>\n",
       "      <td>0.150998</td>\n",
       "      <td>-0.133822</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.093660</td>\n",
       "      <td>-0.148010</td>\n",
       "      <td>0.107307</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061245</td>\n",
       "      <td>0.126724</td>\n",
       "      <td>-0.037867</td>\n",
       "      <td>-0.012379</td>\n",
       "      <td>0.232358</td>\n",
       "      <td>0.217223</td>\n",
       "      <td>-0.303958</td>\n",
       "      <td>-0.070006</td>\n",
       "      <td>-0.203984</td>\n",
       "      <td>0.155061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>-0.125723</td>\n",
       "      <td>0.106816</td>\n",
       "      <td>0.128252</td>\n",
       "      <td>0.137090</td>\n",
       "      <td>-0.128122</td>\n",
       "      <td>0.316143</td>\n",
       "      <td>0.116020</td>\n",
       "      <td>-0.184331</td>\n",
       "      <td>0.096365</td>\n",
       "      <td>0.018816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077845</td>\n",
       "      <td>0.211057</td>\n",
       "      <td>-0.105757</td>\n",
       "      <td>-0.009597</td>\n",
       "      <td>0.175736</td>\n",
       "      <td>0.219967</td>\n",
       "      <td>-0.325753</td>\n",
       "      <td>-0.036114</td>\n",
       "      <td>-0.202375</td>\n",
       "      <td>0.173435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "0   0.633204  0.500066  0.571148  0.653715  0.598459  0.755616  0.604603   \n",
       "1  -0.345241 -0.030657  0.135124 -0.042443 -0.276815  0.248235  0.056493   \n",
       "2  -0.059608  0.053143  0.148146  0.115841 -0.069659  0.325438  0.055484   \n",
       "3  -0.098709  0.121213  0.255222  0.206924 -0.104062  0.412454  0.207333   \n",
       "4  -0.196298 -0.048596  0.108206  0.005174 -0.185726  0.279652  0.043221   \n",
       "5  -0.214302  0.005120  0.075802  0.037431 -0.218483  0.331024  0.097427   \n",
       "6  -0.180532  0.067086  0.181357  0.142417 -0.183661  0.313881  0.120228   \n",
       "7  -0.293331  0.017522  0.097288 -0.055954 -0.274845  0.250720  0.042443   \n",
       "8  -0.222410 -0.057488  0.114284  0.056716 -0.213370  0.293207  0.089664   \n",
       "9  -0.161700  0.089911  0.147831  0.089532 -0.161420  0.324618  0.130719   \n",
       "10 -0.075195  0.110223  0.172187  0.141127 -0.065785  0.376140  0.172203   \n",
       "11 -0.204836  0.180875  0.236751  0.106072 -0.175420  0.309989  0.084276   \n",
       "12 -0.213545  0.040618  0.116211  0.002270 -0.184017  0.308759  0.128379   \n",
       "13 -0.153971  0.068336  0.246214  0.160143 -0.119187  0.324508  0.128932   \n",
       "14 -0.054737  0.109644  0.296684  0.283644 -0.034746  0.406274  0.186109   \n",
       "15 -0.259806 -0.002763  0.102413 -0.003768 -0.207459  0.263185  0.064206   \n",
       "16 -0.121246  0.199485  0.225220  0.149140 -0.121984  0.411048  0.200990   \n",
       "17  0.016603  0.169538  0.204704  0.213465  0.033281  0.428693  0.188951   \n",
       "18 -0.156493  0.147628  0.243229  0.150998 -0.133822  0.305085  0.093660   \n",
       "19 -0.125723  0.106816  0.128252  0.137090 -0.128122  0.316143  0.116020   \n",
       "\n",
       "         7         8         9    ...       138       139       140       141  \\\n",
       "0   0.533076  0.568695  0.570229  ...  0.637455  0.524194  0.397115  0.471500   \n",
       "1  -0.267335 -0.026539 -0.137934  ... -0.059306  0.071699 -0.151146 -0.110233   \n",
       "2  -0.221650  0.045406 -0.075505  ... -0.006122  0.077620 -0.122246 -0.042713   \n",
       "3  -0.018501  0.246705  0.180000  ...  0.256870  0.358515 -0.026240  0.032454   \n",
       "4  -0.236393  0.081146 -0.036828  ... -0.041913  0.167597 -0.162967 -0.076082   \n",
       "5  -0.237222  0.097479  0.064496  ...  0.019833  0.241470 -0.157935 -0.075652   \n",
       "6  -0.201511  0.102114  0.083134  ...  0.005705  0.211951 -0.074239 -0.024620   \n",
       "7  -0.248596  0.049488 -0.072084  ... -0.046876  0.100378 -0.164210 -0.117768   \n",
       "8  -0.240399  0.047521  0.025372  ...  0.019973  0.173605 -0.160289 -0.074095   \n",
       "9  -0.192992  0.084728  0.068793  ...  0.099094  0.185579 -0.105667 -0.024891   \n",
       "10 -0.140014  0.114358  0.093978  ...  0.189266  0.261567 -0.090899  0.019950   \n",
       "11 -0.169228  0.076717 -0.014750  ...  0.098217  0.078908 -0.052783 -0.046463   \n",
       "12 -0.202635  0.109735  0.012590  ...  0.020989  0.278939 -0.125602 -0.031240   \n",
       "13 -0.142372  0.109673  0.030762  ...  0.058700  0.181553 -0.012210  0.040238   \n",
       "14 -0.037383  0.187502  0.071020  ...  0.053764  0.278970  0.016966  0.074464   \n",
       "15 -0.278860 -0.024457 -0.072656  ... -0.008535  0.111051 -0.147036 -0.061767   \n",
       "16 -0.058317  0.258959  0.213857  ...  0.174658  0.373180 -0.028646  0.029842   \n",
       "17 -0.097513  0.149282  0.073045  ...  0.118608  0.315718 -0.060501  0.056830   \n",
       "18 -0.148010  0.107307  0.008507  ...  0.061245  0.126724 -0.037867 -0.012379   \n",
       "19 -0.184331  0.096365  0.018816  ...  0.077845  0.211057 -0.105757 -0.009597   \n",
       "\n",
       "         142       143       144       145       146       147  \n",
       "0   0.561303  0.804900  0.466915  0.468822  0.469115  0.432711  \n",
       "1   0.148461  0.064440 -0.430663 -0.193202 -0.370178  0.106961  \n",
       "2   0.177038  0.333489 -0.376331 -0.058333 -0.288011  0.094804  \n",
       "3   0.248710  0.340618 -0.230151 -0.041986 -0.142446  0.205055  \n",
       "4   0.162751  0.206135 -0.366942 -0.126038 -0.318888  0.088399  \n",
       "5   0.142014  0.196229 -0.340456 -0.108270 -0.302400  0.122740  \n",
       "6   0.214816  0.183931 -0.295259 -0.071084 -0.213549  0.172659  \n",
       "7   0.115267  0.129506 -0.395353 -0.169608 -0.351799  0.068215  \n",
       "8   0.154086  0.184744 -0.370811 -0.132954 -0.277153  0.154341  \n",
       "9   0.178059  0.239527 -0.339667 -0.083513 -0.232487  0.134911  \n",
       "10  0.217401  0.337437 -0.317984 -0.035494 -0.187591  0.164074  \n",
       "11  0.203116  0.229415 -0.325757 -0.101568 -0.255058  0.132165  \n",
       "12  0.198747  0.181528 -0.327091 -0.089194 -0.281061  0.102249  \n",
       "13  0.252740  0.215041 -0.302986 -0.043070 -0.225123  0.170476  \n",
       "14  0.278758  0.274255 -0.273462  0.003189 -0.173646  0.217075  \n",
       "15  0.156937  0.127200 -0.426703 -0.139597 -0.315175  0.124316  \n",
       "16  0.256671  0.293347 -0.181799 -0.019342 -0.181422  0.144823  \n",
       "17  0.255669  0.392426 -0.297094  0.032448 -0.184243  0.164161  \n",
       "18  0.232358  0.217223 -0.303958 -0.070006 -0.203984  0.155061  \n",
       "19  0.175736  0.219967 -0.325753 -0.036114 -0.202375  0.173435  \n",
       "\n",
       "[20 rows x 148 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT2y\n",
      "(188, 148)\n"
     ]
    }
   ],
   "source": [
    "#Now calculate MAE on the original Gilmore Dataset\n",
    "gilmore_sheet = pd.ExcelFile(\"Gilmore CT1y2y SA1y2y.xlsx\") \n",
    "parsee = gilmore_sheet.sheet_names[2] #ct2y\n",
    "print(parsee)\n",
    "data = gilmore_sheet.parse(parsee)\n",
    "data_features_ct2y = data.loc[:, data.columns] \n",
    "data_features_ct2y = data_features_ct2y.drop(['ROI'], axis=1)\n",
    "scaled_data_ct2y_gilmore = scaler2.transform(data_features_ct2y)\n",
    "print(scaled_data_ct2y_gilmore.shape)\n",
    "\n",
    "predicted_1yr_ct_gilmore = autoencoder.predict(scaled_data_ct2y_gilmore)\n",
    "df = pd.DataFrame(predicted_1yr_ct_gilmore)\n",
    "df.to_excel(\"Interpolated CT 1y Gilmore Scaled.xlsx\", index=False) #Don't necessarily need this sheet, but good to have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverse Transform the predicted data to calculate MAE\n",
    "unscaled_predicted_ct1y = scaler.inverse_transform(predicted_1yr_ct_gilmore)\n",
    "type(unscaled_predicted_ct1y)\n",
    "df = pd.DataFrame(unscaled_predicted_ct1y)\n",
    "df.to_excel(\"Interpolated CT 1y Gilmore.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
