{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261, 296)\n",
      "(64, 296)\n",
      "(325, 296)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "#Get base from IBIS Data to fit\n",
    "data = pd.ExcelFile(\"KNN Imputation.xlsx\") \n",
    "\n",
    "ibis_sa_sheet = data.sheet_names[0]\n",
    "\n",
    "sa_data = data.parse(ibis_sa_sheet)\n",
    "\n",
    "data_features_sa = sa_data.loc[:, sa_data.columns] \n",
    "data_features_sa = data_features_sa.drop(['ROI'], axis=1)\n",
    "#Already dropped '1SA-11142','1SA-12142','2SA-11142','2SA-12142'\n",
    "X_train, X_validation_truth = train_test_split(data_features_sa, test_size=0.10, random_state=42)\n",
    "\n",
    "#Now add in 50% gilmore data for training\n",
    "gilmore_sa_sheet = data.sheet_names[3]\n",
    "gilmore_sa_data = data.parse(gilmore_sa_sheet)\n",
    "gilmore_sa_data = gilmore_sa_data.loc[:, gilmore_sa_data.columns]\n",
    "gilmore_sa_data = gilmore_sa_data.drop(['ROI'], axis=1)\n",
    "\n",
    "X_train_Gilmore, X_test_Gilmore = train_test_split(gilmore_sa_data, test_size=0.50, random_state=42)\n",
    "\n",
    "print(X_train.shape) #261\n",
    "#print(gilmore_sa_data.shape) #129\n",
    "print(X_train_Gilmore.shape) #64\n",
    "#print(X_test_Gilmore.shape) #65\n",
    "\n",
    "X_train_full = pd.concat([X_train, X_train_Gilmore], ignore_index=True)\n",
    "print(X_train_full.shape) #354"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual data feature shapes\n",
      "(129, 296)\n",
      "(129, 296)\n",
      "X_validation_truth shape (29, 296)\n",
      "(29, 148)\n",
      "(29, 148)\n",
      "(29, 296)\n",
      "(29, 296)\n"
     ]
    }
   ],
   "source": [
    "#Get the Gilmore data we want imputed to calculate MAE\n",
    "#'1SA-11142','1SA-12142','2SA-11142','2SA-12142' Already dropped\n",
    "gilmore_sa_sheet_1yToImpute2y = data.sheet_names[1]\n",
    "gilmore_sa_sheet_2yToImpute1y = data.sheet_names[2]\n",
    "\n",
    "gilmore_sa1y_data = data.parse(gilmore_sa_sheet_1yToImpute2y)\n",
    "gilmore_data_features_sa1y = gilmore_sa1y_data.loc[:, gilmore_sa1y_data.columns]\n",
    "gilmore_data_features_sa1y = gilmore_data_features_sa1y.drop(['ROI'], axis=1)\n",
    "\n",
    "gilmore_sa2y_data = data.parse(gilmore_sa_sheet_2yToImpute1y)\n",
    "gilmore_data_features_sa2y = gilmore_sa2y_data.loc[:, gilmore_sa2y_data.columns]\n",
    "gilmore_data_features_sa2y = gilmore_data_features_sa2y.drop(['ROI'], axis=1)\n",
    "\n",
    "print(\"Individual data feature shapes\")\n",
    "print(gilmore_data_features_sa1y.shape)\n",
    "print(gilmore_data_features_sa2y.shape)\n",
    "\n",
    "X_train_Gilmore_1y, X_test_Gilmore_2y = train_test_split(gilmore_data_features_sa1y, test_size=0.50, random_state=42)\n",
    "X_train_Gilmore_2y, X_test_Gilmore_1y = train_test_split(gilmore_data_features_sa2y, test_size=0.50, random_state=42)\n",
    "\n",
    "#X_train_full already has all of the training IBIS and Gilmore data we want\n",
    "#X_train_Gilmore_1y has the training 1y data appearing in the set above -- Ignore\n",
    "#X_train_Gilmore2y has the training 2y data appearing in the set above -- Ignore\n",
    "#X_test_Gilmore1y has the testing 1y data that does not appear in the set above and is missing 2y data\n",
    "#X_test_Gilmore2y has the testing 2y data that does not appear in the set above and is missing 1y data\n",
    "\n",
    "print('X_validation_truth shape {}'.format(X_validation_truth.shape))\n",
    "X_validation_1y = X_validation_truth.loc[:, X_validation_truth.columns]\n",
    "X_validation_1y.drop(X_validation_1y.iloc[:, 0:148], axis=1, inplace=True) #Missing 1 yr\n",
    "X_validation_2y = X_validation_truth.loc[:, X_validation_truth.columns]\n",
    "X_validation_2y.drop(X_validation_2y.iloc[:, 148:296], axis=1, inplace=True) #Missing 2 yr\n",
    "print(X_validation_1y.shape)\n",
    "print(X_validation_2y.shape)\n",
    "#Add back NaNs\n",
    "for i in range(0,148):\n",
    "    X_validation_2y.insert(i+148,i+148, np.nan) #Add nans for missing 2yr\n",
    "    X_validation_1y.insert(i,i, np.nan) #Add nans for missing 1yr\n",
    "print(X_validation_1y.shape)\n",
    "print(X_validation_2y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 1y Validation KNN 0.050690232993067366 \n",
      "MAE 2y Validation KNN 0.0527292552594669 \n"
     ]
    }
   ],
   "source": [
    "sa_imputer = KNNImputer(n_neighbors=50)\n",
    "#Fit to IBIS Data\n",
    "sa_imputer.fit(X_train_full)\n",
    "\n",
    "imputed_validation_2y = sa_imputer.transform(X_validation_2y) #Predict 2yr\n",
    "imputed_validation_1y = sa_imputer.transform(X_validation_1y) #Predict 1yr\n",
    "\n",
    "#MAE Calculation\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE 1y Validation KNN {} '.format(mean_absolute_error(imputed_validation_1y, X_validation_truth.to_numpy())))\n",
    "print('MAE 2y Validation KNN {} '.format(mean_absolute_error(imputed_validation_2y, X_validation_truth.to_numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed Individual Shapes\n",
      "(65, 296)\n",
      "(65, 296)\n",
      "MAE 1y KNN 0.12542137299967474 \n",
      "MAE 2y KNN 0.12618903043571436 \n"
     ]
    }
   ],
   "source": [
    "#Predict Gilmore Data for MAE\n",
    "imputed_sa2y = sa_imputer.transform(X_test_Gilmore_2y)\n",
    "imputed_sa1y = sa_imputer.transform(X_test_Gilmore_1y)\n",
    "print(\"Imputed Individual Shapes\")\n",
    "print(imputed_sa2y.shape)\n",
    "print(imputed_sa1y.shape)\n",
    "\n",
    "#DFs for Individuals\n",
    "df_sa_2y = pd.DataFrame(imputed_sa2y)\n",
    "df_sa_1y = pd.DataFrame(imputed_sa1y)\n",
    "\n",
    "df_sa_2y.to_excel(\"Imputed SA 2y KNN with Gilmore in Training.xlsx\", index=False)\n",
    "df_sa_1y.to_excel(\"Imputed SA 1y KNN with Gilmore in Training.xlsx\", index=False)\n",
    "\n",
    "#Ground Truth\n",
    "#X_test_Gilmore_1y - Holds GT for 2y data\n",
    "#X_test_Gilmore_2y - Holds GT for 1y data\n",
    "\n",
    "#Imputed\n",
    "df_imputed_sa_1y_xlsx = pd.ExcelFile(\"Imputed SA 1y KNN with Gilmore in Training.xlsx\")\n",
    "imputed_sa_sheet = df_imputed_sa_1y_xlsx.sheet_names[0]\n",
    "imputed_sa_data = df_imputed_sa_1y_xlsx.parse(imputed_sa_sheet)\n",
    "imputed_data_features_sa1y = imputed_sa_data.loc[:, imputed_sa_data.columns]\n",
    "imputed_data_features_sa1y.drop(imputed_data_features_sa1y.iloc[:, 148:296], axis=1, inplace=True)\n",
    "#print(imputed_data_features_sa1y)\n",
    "\n",
    "df_imputed_sa_2y_xlsx = pd.ExcelFile(\"Imputed SA 2y KNN with Gilmore in Training.xlsx\")\n",
    "imputed_sa_sheet = df_imputed_sa_2y_xlsx.sheet_names[0]\n",
    "imputed_sa_data = df_imputed_sa_2y_xlsx.parse(imputed_sa_sheet)\n",
    "imputed_data_features_sa2y = imputed_sa_data.loc[:, imputed_sa_data.columns]\n",
    "imputed_data_features_sa2y.drop(imputed_data_features_sa2y.iloc[:, 0:148], axis=1, inplace=True)\n",
    "#print(imputed_data_features_sa2y)\n",
    "\n",
    "X_test_Gilmore_1y_148 = X_test_Gilmore_1y.loc[:, X_test_Gilmore_1y.columns]\n",
    "X_test_Gilmore_1y_148.drop(X_test_Gilmore_1y_148.iloc[:, 0:148], axis=1, inplace=True) #Missing 1 yr\n",
    "X_test_Gilmore_2y_148 = X_test_Gilmore_2y.loc[:, X_test_Gilmore_2y.columns]\n",
    "X_test_Gilmore_2y_148.drop(X_test_Gilmore_2y_148.iloc[:, 148:296], axis=1, inplace=True) #Missing 2 yr\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE 1y KNN {} '.format(mean_absolute_error(X_test_Gilmore_2y_148.to_numpy(), imputed_data_features_sa1y.to_numpy())))\n",
    "print('MAE 2y KNN {} '.format(mean_absolute_error(X_test_Gilmore_1y_148.to_numpy(), imputed_data_features_sa2y.to_numpy())))\n",
    "\n",
    "#Remove extra features for MAE calculation - Done\n",
    "#Find Optimal number of neighbors - todo\n",
    "#Create a validation set for KNN to see if the trend for AC having high MAE continues - todo\n",
    "#N = 2\n",
    "#MAE 1y KNN 0.16280582283255568 \n",
    "#MAE 2y KNN 0.16321320699559033 \n",
    "#N = 3\n",
    "#MAE 1y KNN 0.1577243075443826 \n",
    "#MAE 2y KNN 0.15720122874457262 \n",
    "#N = 4\n",
    "#MAE 1y KNN 0.15519481307686972 \n",
    "#MAE 2y KNN 0.15487959605664114 \n",
    "#N = 5\n",
    "#MAE 1y KNN 0.15356291288903134 \n",
    "#MAE 2y KNN 0.15294622209838285 \n",
    "#N = 10\n",
    "#MAE 1y KNN 0.15003403232716447 \n",
    "#MAE 2y KNN 0.14948200320277555 \n",
    "#N = 25\n",
    "#MAE 1y KNN 0.14792755622564427 \n",
    "#MAE 2y KNN 0.14750929111677524 \n",
    "#N = 50\n",
    "#MAE 1y KNN 0.14757113789488976 \n",
    "#MAE 2y KNN 0.1475000914221722 \n",
    "#N = 100\n",
    "#MAE 1y KNN 0.14826055109796843 \n",
    "#MAE 2y KNN 0.1483661596808016 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         148       149       150       151       152       153       154  \\\n",
      "0   0.396001  0.397246  0.343011  0.313636  0.332195  0.390709  0.360133   \n",
      "1   0.389542  0.436375  0.474733  0.374017  0.391385  0.525810  0.507901   \n",
      "2   0.309279  0.406053  0.479079  0.321853  0.369903  0.433040  0.416044   \n",
      "3   0.297995  0.399774  0.468808  0.291760  0.360219  0.407497  0.395010   \n",
      "4   0.299402  0.397265  0.499247  0.309854  0.344679  0.429097  0.439816   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "60  0.344096  0.380394  0.451422  0.326936  0.343845  0.420056  0.392495   \n",
      "61  0.315501  0.392317  0.445339  0.298543  0.341061  0.402917  0.407480   \n",
      "62  0.321159  0.434382  0.473962  0.344127  0.373336  0.462657  0.479178   \n",
      "63  0.349072  0.398529  0.401790  0.330062  0.358569  0.444004  0.430183   \n",
      "64  0.332941  0.429262  0.451497  0.346123  0.376922  0.484302  0.491031   \n",
      "\n",
      "         155       156       157  ...       286       287       288       289  \\\n",
      "0   0.299046  0.375824  0.231738  ...  0.378322  0.329665  0.338807  0.279684   \n",
      "1   0.346207  0.466619  0.280208  ...  0.409499  0.416733  0.461166  0.352048   \n",
      "2   0.296434  0.383738  0.262626  ...  0.333238  0.401857  0.393989  0.323422   \n",
      "3   0.269364  0.344522  0.251548  ...  0.313813  0.387794  0.364521  0.313426   \n",
      "4   0.295090  0.374697  0.268023  ...  0.320221  0.385333  0.411901  0.329074   \n",
      "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
      "60  0.295396  0.385952  0.257898  ...  0.322482  0.378343  0.400809  0.335746   \n",
      "61  0.274118  0.360958  0.247669  ...  0.322030  0.389475  0.342615  0.308382   \n",
      "62  0.315021  0.414557  0.275808  ...  0.344951  0.418711  0.428125  0.354033   \n",
      "63  0.302306  0.387596  0.245426  ...  0.358257  0.397399  0.378763  0.302323   \n",
      "64  0.316576  0.411574  0.279516  ...  0.379589  0.397044  0.398265  0.325986   \n",
      "\n",
      "         290       291       292       293       294       295  \n",
      "0   0.281169  0.254384  0.321608  0.205885  0.360245  0.344757  \n",
      "1   0.466945  0.340436  0.441108  0.211126  0.469997  0.452112  \n",
      "2   0.467942  0.275979  0.398233  0.193729  0.398806  0.390055  \n",
      "3   0.438333  0.275302  0.387918  0.178149  0.390752  0.396490  \n",
      "4   0.484829  0.287427  0.395891  0.189115  0.381986  0.397669  \n",
      "..       ...       ...       ...       ...       ...       ...  \n",
      "60  0.425634  0.273494  0.371518  0.210759  0.404603  0.385217  \n",
      "61  0.419702  0.275936  0.380347  0.172275  0.399668  0.386814  \n",
      "62  0.495956  0.322693  0.418991  0.220926  0.428210  0.409138  \n",
      "63  0.411131  0.262011  0.366234  0.209185  0.410361  0.398073  \n",
      "64  0.456519  0.339486  0.440588  0.210444  0.429805  0.406969  \n",
      "\n",
      "[65 rows x 148 columns]\n"
     ]
    }
   ],
   "source": [
    "print(imputed_data_features_sa2y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 296)\n",
      "(20, 296)\n"
     ]
    }
   ],
   "source": [
    "#Get the data we want imputed\n",
    "interpolate_data = pd.ExcelFile(\"Data to be Interpolated.xlsx\") \n",
    "sa1y = interpolate_data.sheet_names[4]\n",
    "sa2y = interpolate_data.sheet_names[9]\n",
    "\n",
    "sa1y_data = interpolate_data.parse(sa1y)\n",
    "data_features_sa1y = sa1y_data.loc[:, sa1y_data.columns] \n",
    "data_features_sa1y = data_features_sa1y.drop(['ROI'], axis=1)\n",
    "\n",
    "sa2y_data = interpolate_data.parse(sa2y)\n",
    "data_features_sa2y = sa2y_data.loc[:, sa2y_data.columns] \n",
    "data_features_sa2y = data_features_sa2y.drop(['ROI'], axis=1)\n",
    "\n",
    "print(data_features_sa1y.shape)\n",
    "print(data_features_sa2y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the data we want to impute here for the downstream task\n",
    "predicted_sa2y = sa_imputer.transform(data_features_sa1y)\n",
    "df_predicted_sa2y = pd.DataFrame(predicted_sa2y)\n",
    "df_predicted_sa2y.to_excel(\"Interpolated SA2y Downstream with Gilmore in Training.xlsx\", index=False)\n",
    "\n",
    "predicted_sa1y = sa_imputer.transform(data_features_sa2y)\n",
    "df_predicted_sa1y = pd.DataFrame(predicted_sa1y)\n",
    "df_predicted_sa1y.to_excel(\"Interpolated SA1y Downstream with Gilmore in Training.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
