{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.combine import SMOTETomek\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, precision_score, precision_recall_curve, average_precision_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, ReLU, Sigmoid, Module, BCELoss, BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "import time\n",
    "\n",
    "seed_value = 7\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import torch\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Data = pd.ExcelFile(\"Training Data with Mixed Imputation.xlsx\") #Training Data already pre-scaled to the IBIS Data set\n",
    "data = Training_Data.parse(Training_Data.sheet_names[0])\n",
    "label_data = Training_Data.parse(Training_Data.sheet_names[1])\n",
    "data_features = data.loc[:, data.columns]\n",
    "data_features = data_features.drop(['ROI','MATCH DEMOS','INDEX SEX','MATCH BASC2','INDEX GA', 'ATP', 'INDEX MEDU', 'MATCH DEMOS OLD', 'INDEX AGE'], axis=1)\n",
    "data_features = data_features.dropna()\n",
    "data_features = data_features.drop(['HYP'], axis=1)\n",
    "labels = label_data.loc[:, label_data.columns]\n",
    "labels = labels.drop(['ROI', 'ATP'], axis=1)\n",
    "labels = labels.dropna()\n",
    "print(data_features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_data = Training_Data.parse(Training_Data.sheet_names[6])\n",
    "interpolated_data_features = interpolated_data.loc[:, interpolated_data.columns]\n",
    "interpolated_data_features = interpolated_data_features.drop(['ROI','MATCH DEMOS','INDEX SEX','MATCH BASC2','INDEX GA', 'ATP', 'ATP Label', 'HYP Label', 'INDEX MEDU'], axis=1)\n",
    "interpolated_data_features = interpolated_data_features.dropna()\n",
    "interpolated_data_features = interpolated_data_features.drop(['HYP'], axis=1)\n",
    "\n",
    "interpolated_label_data = Training_Data.parse(Training_Data.sheet_names[14])\n",
    "interpolated_labels = interpolated_label_data.loc[:, interpolated_label_data.columns]\n",
    "interpolated_labels = interpolated_labels.drop(['ROI','ATP'], axis=1)\n",
    "interpolated_labels = interpolated_labels.dropna()\n",
    "\n",
    "print(interpolated_data_features.shape)\n",
    "print(interpolated_labels.shape)\n",
    "print(type(interpolated_data_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_data_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=8)\n",
    "skf.get_n_splits(data_features, labels)\n",
    "print(skf)\n",
    "\n",
    "training_indices_X = []\n",
    "testing_indices_X = []\n",
    "training_indices_Y = []\n",
    "testing_indices_Y = []\n",
    "\n",
    "for train_index, test_index in skf.split(data_features, labels):\n",
    "  \n",
    "    X_train, X_test = data_features.iloc[train_index], data_features.iloc[test_index]\n",
    "    Y_train, Y_test = labels.iloc[train_index], labels.iloc[test_index]\n",
    "   \n",
    "    sm = SMOTE(sampling_strategy = 'minority', random_state = seed_value, k_neighbors=2) \n",
    "    X_train_res, Y_train_res = sm.fit_sample(X_train, Y_train) #Only smote the training set.\n",
    "    print(X_train_res.shape)\n",
    "    training_indices_X.append(X_train_res)\n",
    "    testing_indices_X.append(X_test)\n",
    "    training_indices_Y.append(Y_train_res)\n",
    "    testing_indices_Y.append(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_indices_X[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in training_indices_X:\n",
    "    print(x.shape)\n",
    "    \n",
    "#Figure out how to loop this later. Wasn't working for the following code:\n",
    "#for x in training_indices_X:\n",
    "#    x = pd.concat([x,interpolated_data_features])\n",
    "\n",
    "training_indices_X[0] = pd.concat([training_indices_X[0],interpolated_data_features])\n",
    "training_indices_X[1] = pd.concat([training_indices_X[1],interpolated_data_features])\n",
    "training_indices_X[2] = pd.concat([training_indices_X[2],interpolated_data_features])\n",
    "training_indices_X[3] = pd.concat([training_indices_X[3],interpolated_data_features])\n",
    "training_indices_X[4] = pd.concat([training_indices_X[4],interpolated_data_features])\n",
    "training_indices_X[5] = pd.concat([training_indices_X[5],interpolated_data_features])\n",
    "training_indices_X[6] = pd.concat([training_indices_X[6],interpolated_data_features])\n",
    "training_indices_X[7] = pd.concat([training_indices_X[7],interpolated_data_features])\n",
    "\n",
    "print('----------')\n",
    "for x in training_indices_X:\n",
    "    print(x.shape)\n",
    "    \n",
    "print('Label shapes')\n",
    "    \n",
    "for y in training_indices_Y:\n",
    "    print(y.shape)\n",
    "\n",
    "training_indices_Y[0] = pd.concat([training_indices_Y[0],interpolated_labels])\n",
    "training_indices_Y[1] = pd.concat([training_indices_Y[1],interpolated_labels])\n",
    "training_indices_Y[2] = pd.concat([training_indices_Y[2],interpolated_labels])\n",
    "training_indices_Y[3] = pd.concat([training_indices_Y[3],interpolated_labels])\n",
    "training_indices_Y[4] = pd.concat([training_indices_Y[4],interpolated_labels])\n",
    "training_indices_Y[5] = pd.concat([training_indices_Y[5],interpolated_labels])\n",
    "training_indices_Y[6] = pd.concat([training_indices_Y[6],interpolated_labels])\n",
    "training_indices_Y[7] = pd.concat([training_indices_Y[7],interpolated_labels])\n",
    "\n",
    "print('----------')\n",
    "for y in training_indices_Y:\n",
    "    print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_indices_X[0] #8 Folds so 0 -> 7 Data type is a DataFrame currently.\n",
    "training_fold_X_0 = training_indices_X[0].to_numpy()\n",
    "training_fold_X_1 = training_indices_X[1].to_numpy()\n",
    "training_fold_X_2 = training_indices_X[2].to_numpy()\n",
    "training_fold_X_3 = training_indices_X[3].to_numpy()\n",
    "training_fold_X_4 = training_indices_X[4].to_numpy()\n",
    "training_fold_X_5 = training_indices_X[5].to_numpy()\n",
    "training_fold_X_6 = training_indices_X[6].to_numpy()\n",
    "training_fold_X_7 = training_indices_X[7].to_numpy()\n",
    "\n",
    "training_fold_Y_0 = training_indices_Y[0].to_numpy()\n",
    "training_fold_Y_1 = training_indices_Y[1].to_numpy()\n",
    "training_fold_Y_2 = training_indices_Y[2].to_numpy()\n",
    "training_fold_Y_3 = training_indices_Y[3].to_numpy()\n",
    "training_fold_Y_4 = training_indices_Y[4].to_numpy()\n",
    "training_fold_Y_5 = training_indices_Y[5].to_numpy()\n",
    "training_fold_Y_6 = training_indices_Y[6].to_numpy()\n",
    "training_fold_Y_7 = training_indices_Y[7].to_numpy()\n",
    "\n",
    "testing_fold_X_0 = testing_indices_X[0].to_numpy()\n",
    "testing_fold_X_1 = testing_indices_X[1].to_numpy()\n",
    "testing_fold_X_2 = testing_indices_X[2].to_numpy()\n",
    "testing_fold_X_3 = testing_indices_X[3].to_numpy()\n",
    "testing_fold_X_4 = testing_indices_X[4].to_numpy()\n",
    "testing_fold_X_5 = testing_indices_X[5].to_numpy()\n",
    "testing_fold_X_6 = testing_indices_X[6].to_numpy()\n",
    "testing_fold_X_7 = testing_indices_X[7].to_numpy()\n",
    "\n",
    "testing_fold_Y_0 = testing_indices_Y[0].to_numpy()\n",
    "testing_fold_Y_1 = testing_indices_Y[1].to_numpy()\n",
    "testing_fold_Y_2 = testing_indices_Y[2].to_numpy()\n",
    "testing_fold_Y_3 = testing_indices_Y[3].to_numpy()\n",
    "testing_fold_Y_4 = testing_indices_Y[4].to_numpy()\n",
    "testing_fold_Y_5 = testing_indices_Y[5].to_numpy()\n",
    "testing_fold_Y_6 = testing_indices_Y[6].to_numpy()\n",
    "testing_fold_Y_7 = testing_indices_Y[7].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_fold_Y_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some hyperparameters\n",
    "#D_in is input dimension; H is hidden dimension; D_out is output dimension. \n",
    "#Best: 0.621108 using {'batch_size': 20, 'dropout': 0.2, 'epochs': 25, 'layer1_size': 120, 'layer2_size': 20}\n",
    "D_in, H1, H2, D_out = 152, 120, 20, 1\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 20\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT_RATE = 0.20\n",
    "\n",
    "test_size = 19\n",
    "test_size1 = 18\n",
    "\n",
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data): #used to perform initializing operations such as reading data and preprocessing.\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index): #returns data (input and output) in batches.\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self): #returns the size of the input data.\n",
    "        return len(self.X_data)\n",
    "\n",
    "#A dataloader is then used on this dataset class to read the data in batches.\n",
    "train_data = trainData(torch.FloatTensor(training_fold_X_0), \n",
    "                       torch.FloatTensor(training_fold_Y_0))\n",
    "\n",
    "train_data1 = trainData(torch.FloatTensor(training_fold_X_1), \n",
    "                       torch.FloatTensor(training_fold_Y_1))\n",
    "\n",
    "train_data2 = trainData(torch.FloatTensor(training_fold_X_2), \n",
    "                       torch.FloatTensor(training_fold_Y_2))\n",
    "\n",
    "train_data3 = trainData(torch.FloatTensor(training_fold_X_3), \n",
    "                       torch.FloatTensor(training_fold_Y_3))\n",
    "\n",
    "train_data4 = trainData(torch.FloatTensor(training_fold_X_4), \n",
    "                       torch.FloatTensor(training_fold_Y_4))\n",
    "\n",
    "train_data5 = trainData(torch.FloatTensor(training_fold_X_5), \n",
    "                       torch.FloatTensor(training_fold_Y_5))\n",
    "\n",
    "train_data6 = trainData(torch.FloatTensor(training_fold_X_6), \n",
    "                       torch.FloatTensor(training_fold_Y_6))\n",
    "\n",
    "train_data7 = trainData(torch.FloatTensor(training_fold_X_7), \n",
    "                       torch.FloatTensor(training_fold_Y_7))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data): ##used to perform initializing operations such as reading data and preprocessing.\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index): #returns data (input and output) in batches.\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self): #returns the size of the input data.\n",
    "        return len(self.X_data)\n",
    "    \n",
    "#A dataloader is then used on this dataset class to read the data in batches.\n",
    "test_data = testData(torch.FloatTensor(testing_fold_X_0))\n",
    "test_data1 = testData(torch.FloatTensor(testing_fold_X_1))\n",
    "test_data2 = testData(torch.FloatTensor(testing_fold_X_2))\n",
    "test_data3 = testData(torch.FloatTensor(testing_fold_X_3))\n",
    "test_data4 = testData(torch.FloatTensor(testing_fold_X_4))\n",
    "test_data5 = testData(torch.FloatTensor(testing_fold_X_5))\n",
    "test_data6 = testData(torch.FloatTensor(testing_fold_X_6))\n",
    "test_data7 = testData(torch.FloatTensor(testing_fold_X_7))\n",
    "\n",
    "#Initialize DataLoaders\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=test_size) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader1 = DataLoader(dataset=train_data1, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader1 = DataLoader(dataset=test_data1, batch_size=test_size) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader2 = DataLoader(dataset=train_data2, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader2 = DataLoader(dataset=test_data2, batch_size=test_size) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader3 = DataLoader(dataset=train_data3, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader3 = DataLoader(dataset=test_data3, batch_size=test_size) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader4 = DataLoader(dataset=train_data4, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader4 = DataLoader(dataset=test_data4, batch_size=test_size1) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader5 = DataLoader(dataset=train_data5, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader5 = DataLoader(dataset=test_data5, batch_size=test_size1) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader6 = DataLoader(dataset=train_data6, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader6 = DataLoader(dataset=test_data6, batch_size=test_size1) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader7 = DataLoader(dataset=train_data7, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader7 = DataLoader(dataset=test_data7, batch_size=test_size1) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testing_fold_X_0.shape)\n",
    "print(testing_fold_X_1.shape)\n",
    "print(testing_fold_X_2.shape)\n",
    "print(testing_fold_X_3.shape)\n",
    "print(testing_fold_X_4.shape)\n",
    "print(testing_fold_X_5.shape)\n",
    "print(testing_fold_X_6.shape)\n",
    "print(testing_fold_X_7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 298.\n",
    "        self.layer_1 = nn.Linear(D_in, H1) #298 -> 100\n",
    "        self.layer_2 = nn.Linear(H1, H2) #100 -> 15\n",
    "        self.layer_out = nn.Linear(H2, D_out) #15 -> 1\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=DROPOUT_RATE)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(100)\n",
    "        #self.batchnorm2 = nn.BatchNorm1d(15)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs)) #ReLU on the 298?\n",
    "        #x = self.batchnorm1(x) #Normalize the 100\n",
    "        x = self.dropout(x) #Dropout 15%\n",
    "        x = self.relu(self.layer_2(x)) #ReLU on the 100?\n",
    "        #x = self.batchnorm2(x) #Normalize the 15\n",
    "        x = self.layer_out(x) #1\n",
    "        \n",
    "        return x\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#Should use the CPU since I don't have a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model = binaryClassification()\n",
    "model.load_state_dict(torch.load('./model_dict_hyp_sa_only.pth'))\n",
    "model.train()\n",
    "print(model)\n",
    "#weights = torch.FloatTensor([5]) #Class weights?\n",
    "#criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model1 = binaryClassification()\n",
    "model1.load_state_dict(torch.load('./model_dict_hyp_sa_only.pth'))\n",
    "model1.train()\n",
    "#print(model)\n",
    "#weights1 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion1 = nn.BCEWithLogitsLoss()\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model2 = binaryClassification()\n",
    "model2.load_state_dict(torch.load('./model_dict_hyp_sa_only.pth'))\n",
    "model2.train()\n",
    "#print(model)\n",
    "#weights2 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion2 = nn.BCEWithLogitsLoss()\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model3 = binaryClassification()\n",
    "model3.load_state_dict(torch.load('./model_dict_hyp_sa_only.pth'))\n",
    "model3.train()\n",
    "#print(model)\n",
    "#weights3 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion3 = nn.BCEWithLogitsLoss()\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model4 = binaryClassification()\n",
    "model4.load_state_dict(torch.load('./model_dict_hyp_sa_only.pth'))\n",
    "model4.train()\n",
    "#print(model)\n",
    "#weights4 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion4 = nn.BCEWithLogitsLoss()\n",
    "optimizer4 = optim.Adam(model4.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model5 = binaryClassification()\n",
    "model5.load_state_dict(torch.load('./model_dict_hyp_sa_only.pth'))\n",
    "model5.train()\n",
    "#print(model)\n",
    "#weights5 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion5 = nn.BCEWithLogitsLoss()\n",
    "optimizer5 = optim.Adam(model5.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model6 = binaryClassification()\n",
    "model6.load_state_dict(torch.load('./model_dict_hyp_sa_only.pth'))\n",
    "model6.train()\n",
    "#print(model)\n",
    "#weights6 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion6 = nn.BCEWithLogitsLoss()\n",
    "optimizer6 = optim.Adam(model6.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model7 = binaryClassification()\n",
    "model7.load_state_dict(torch.load('./model_dict_hyp_sa_only.pth'))\n",
    "model7.train()\n",
    "#print(model)\n",
    "#weights7 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion7 = nn.BCEWithLogitsLoss()\n",
    "optimizer7 = optim.Adam(model7.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to define accuracy. Should look to see if there is a prebuilt that I can use from sci-kit learn or something.\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "model.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc.append(epoch_acc/len(train_loader))\n",
    "    train_loss.append(epoch_loss/len(train_loader))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    #Validation metrics here\n",
    "    model.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_0))\n",
    "            val_loss.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_0), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_0, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_0, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc.append(accuracy*100)\n",
    "    model.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc1 = []\n",
    "train_acc1 = []\n",
    "train_loss1 = []\n",
    "val_loss1 = []\n",
    "\n",
    "model1.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer1.zero_grad()\n",
    "        \n",
    "        y_pred = model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc1.append(epoch_acc/len(train_loader1))\n",
    "    train_loss1.append(epoch_loss/len(train_loader1))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader1):.5f} | Acc: {epoch_acc/len(train_loader1):.3f}')\n",
    "    #Validation metrics here\n",
    "    model1.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader1 = DataLoader(dataset=test_data1, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader1:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model1(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_1))\n",
    "            val_loss1.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader = DataLoader(dataset=test_data1, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model1(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_1), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_1, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_1, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc1.append(accuracy*100)\n",
    "    model1.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc2 = []\n",
    "train_acc2 = []\n",
    "train_loss2 = []\n",
    "val_loss2 = []\n",
    "\n",
    "model2.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        y_pred = model2(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc2.append(epoch_acc/len(train_loader2))\n",
    "    train_loss2.append(epoch_loss/len(train_loader2))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader2):.5f} | Acc: {epoch_acc/len(train_loader2):.3f}')\n",
    "    #Validation metrics here\n",
    "    model2.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader2 = DataLoader(dataset=test_data2, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader2:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model2(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_2))\n",
    "            val_loss2.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader2 = DataLoader(dataset=test_data2, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader2:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model2(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_2), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_2, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_2, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc2.append(accuracy*100)\n",
    "    model2.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc3 = []\n",
    "train_acc3 = []\n",
    "train_loss3 = []\n",
    "val_loss3 = []\n",
    "\n",
    "model3.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader3:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer3.zero_grad()\n",
    "        \n",
    "        y_pred = model3(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer3.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc3.append(epoch_acc/len(train_loader3))\n",
    "    train_loss3.append(epoch_loss/len(train_loader3))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader3):.5f} | Acc: {epoch_acc/len(train_loader3):.3f}')\n",
    "    #Validation metrics here\n",
    "    model3.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader3 = DataLoader(dataset=test_data3, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader3:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model3(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_3))\n",
    "            val_loss3.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader3 = DataLoader(dataset=test_data3, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader3:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model3(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_3), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_3, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_3, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc3.append(accuracy*100)\n",
    "    model3.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc4 = []\n",
    "train_acc4 = []\n",
    "train_loss4 = []\n",
    "val_loss4 = []\n",
    "\n",
    "model4.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader4:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer4.zero_grad()\n",
    "        \n",
    "        y_pred = model4(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer4.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc4.append(epoch_acc/len(train_loader4))\n",
    "    train_loss4.append(epoch_loss/len(train_loader4))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader4):.5f} | Acc: {epoch_acc/len(train_loader4):.3f}')\n",
    "    #Validation metrics here\n",
    "    model4.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader4 = DataLoader(dataset=test_data4, batch_size=test_size1)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader4:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model4(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_4))\n",
    "            val_loss4.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader4 = DataLoader(dataset=test_data4, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader4:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model4(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_4), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_4, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_4, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc4.append(accuracy*100)\n",
    "    model4.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc5 = []\n",
    "train_acc5 = []\n",
    "train_loss5 = []\n",
    "val_loss5 = []\n",
    "\n",
    "model5.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader5:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer5.zero_grad()\n",
    "        \n",
    "        y_pred = model5(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer5.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc5.append(epoch_acc/len(train_loader5))\n",
    "    train_loss5.append(epoch_loss/len(train_loader5))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader5):.5f} | Acc: {epoch_acc/len(train_loader5):.3f}')\n",
    "    #Validation metrics here\n",
    "    model5.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader5 = DataLoader(dataset=test_data5, batch_size=test_size1)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader5:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model5(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_5))\n",
    "            val_loss5.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader5 = DataLoader(dataset=test_data5, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader5:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model5(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_5), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_5, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_5, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc5.append(accuracy*100)\n",
    "    model5.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc6 = []\n",
    "train_acc6 = []\n",
    "train_loss6 = []\n",
    "val_loss6 = []\n",
    "\n",
    "model6.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader6:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer6.zero_grad()\n",
    "        \n",
    "        y_pred = model6(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer6.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc6.append(epoch_acc/len(train_loader6))\n",
    "    train_loss6.append(epoch_loss/len(train_loader6))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader6):.5f} | Acc: {epoch_acc/len(train_loader6):.3f}')\n",
    "    #Validation metrics here\n",
    "    model6.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader6 = DataLoader(dataset=test_data6, batch_size=test_size1)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader6:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model6(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_6))\n",
    "            val_loss6.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader6 = DataLoader(dataset=test_data6, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader6:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model6(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_6), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_6, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_6, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc6.append(accuracy*100)\n",
    "    model6.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc7 = []\n",
    "train_acc7 = []\n",
    "train_loss7 = []\n",
    "val_loss7 = []\n",
    "\n",
    "model7.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader7:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer7.zero_grad()\n",
    "        \n",
    "        y_pred = model7(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer7.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc7.append(epoch_acc/len(train_loader7))\n",
    "    train_loss7.append(epoch_loss/len(train_loader7))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader7):.5f} | Acc: {epoch_acc/len(train_loader7):.3f}')\n",
    "    #Validation metrics here\n",
    "    model7.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader7 = DataLoader(dataset=test_data7, batch_size=test_size1)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader7:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model7(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_7))\n",
    "            val_loss7.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader7 = DataLoader(dataset=test_data7, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader7:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model7(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_7), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_7, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_7, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc7.append(accuracy*100)\n",
    "    model7.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting loss\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss1)\n",
    "plt.plot(val_loss1)\n",
    "plt.title('model1 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc1)\n",
    "plt.plot(val_acc1)\n",
    "plt.title('model1 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss2)\n",
    "plt.plot(val_loss2)\n",
    "plt.title('model2 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc2)\n",
    "plt.plot(val_acc2)\n",
    "plt.title('model2 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss3)\n",
    "plt.plot(val_loss3)\n",
    "plt.title('model3 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc3)\n",
    "plt.plot(val_acc3)\n",
    "plt.title('model3 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss4)\n",
    "plt.plot(val_loss4)\n",
    "plt.title('model4 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc4)\n",
    "plt.plot(val_acc4)\n",
    "plt.title('model4 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss5)\n",
    "plt.plot(val_loss5)\n",
    "plt.title('model5 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc5)\n",
    "plt.plot(val_acc5)\n",
    "plt.title('model5 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss6)\n",
    "plt.plot(val_loss6)\n",
    "plt.title('model6 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc6)\n",
    "plt.plot(val_acc6)\n",
    "plt.title('model6 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss7)\n",
    "plt.plot(val_loss7)\n",
    "plt.title('model7 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc7)\n",
    "plt.plot(val_acc7)\n",
    "plt.title('model7 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = []\n",
    "final_prediction_true = []\n",
    "\n",
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "model.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_0, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_0, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_0, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_0, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_0:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data1, batch_size=1)\n",
    "model1.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_1, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_1, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_1, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_1, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_1:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data2, batch_size=1)\n",
    "model2.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model2(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_2, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_2, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_2, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_2, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_2:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data3, batch_size=1)\n",
    "model3.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model3(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_3, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_3, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_3, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_3, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_3:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data4, batch_size=1)\n",
    "model4.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model4(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_4, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_4, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_4, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_4, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_4:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data5, batch_size=1)\n",
    "model5.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model5(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_5, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_5, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_5, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_5, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_5:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data6, batch_size=1)\n",
    "model6.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model6(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_6, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_6, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_6, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_6, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_6:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data7, batch_size=1)\n",
    "model7.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model7(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_7, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_7, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_7, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_7, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_7:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels = []\n",
    "true_labels = []\n",
    "\n",
    "for x in range(0,len(final_prediction_true)):\n",
    "    true_labels.append(final_prediction_true[x][0])\n",
    "    prediction_labels.append(final_prediction[x][0][0])\n",
    "\n",
    "prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(true_labels, prediction_labels)\n",
    "print(cf_matrix)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(true_labels, prediction_labels)\n",
    "recall = recall_score(true_labels, prediction_labels, average=None)\n",
    "prec_score = precision_score(true_labels, prediction_labels, average=None)\n",
    "print('Positive Predictive Value tp/(tp+fp): ',prec_score[1]) \n",
    "print('Accuracy Value (tp+tn)/(tp+fp+fn+tn): ',accuracy) \n",
    "print('Recall Value tp/(tp+fn): ',recall[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-latino",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
