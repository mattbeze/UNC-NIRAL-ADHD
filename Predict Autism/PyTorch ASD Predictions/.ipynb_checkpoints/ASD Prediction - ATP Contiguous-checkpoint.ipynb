{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intensive-executive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import comet_ml\\ncomet_ml.config.save(api_key=\"YarDlAXZLHepLKBFlSPyWbDPt\")\\nfrom comet_ml import Experiment\\nexperiment = Experiment(\\n    api_key=\"YarDlAXZLHepLKBFlSPyWbDPt\",\\n    project_name=\"asd-pytorch-atp-c\",\\n    workspace=\"mattbeze\",\\n    auto_metric_logging=True,\\n    auto_param_logging=True,\\n    auto_histogram_weight_logging=True,\\n    auto_histogram_gradient_logging=True,\\n    auto_histogram_activation_logging=True,\\n)\\nhyper_params = {\\n    \"input_size\": 298,\\n    \"hidden_size1\": 100,\\n    \"hidden_size2\": 15,\\n    \"num_layers\": 4,\\n    \"num_classes\": 2,\\n    \"batch_size\": 35,\\n    \"num_epochs\": 50,\\n    \"learning_rate\": 0.01\\n}\\nexperiment.log_parameters(hyper_params)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#COMET ML API KEY YarDlAXZLHepLKBFlSPyWbDPt\n",
    "'''import comet_ml\n",
    "comet_ml.config.save(api_key=\"YarDlAXZLHepLKBFlSPyWbDPt\")\n",
    "from comet_ml import Experiment\n",
    "experiment = Experiment(\n",
    "    api_key=\"YarDlAXZLHepLKBFlSPyWbDPt\",\n",
    "    project_name=\"asd-pytorch-atp-c\",\n",
    "    workspace=\"mattbeze\",\n",
    "    auto_metric_logging=True,\n",
    "    auto_param_logging=True,\n",
    "    auto_histogram_weight_logging=True,\n",
    "    auto_histogram_gradient_logging=True,\n",
    "    auto_histogram_activation_logging=True,\n",
    ")\n",
    "hyper_params = {\n",
    "    \"input_size\": 298,\n",
    "    \"hidden_size1\": 100,\n",
    "    \"hidden_size2\": 15,\n",
    "    \"num_layers\": 4,\n",
    "    \"num_classes\": 2,\n",
    "    \"batch_size\": 35,\n",
    "    \"num_epochs\": 50,\n",
    "    \"learning_rate\": 0.01\n",
    "}\n",
    "experiment.log_parameters(hyper_params)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foreign-airfare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29b0fca9a90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, multilabel_confusion_matrix, precision_score, precision_recall_curve, average_precision_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, ReLU, Sigmoid, Module, BCELoss, BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "import time\n",
    "\n",
    "seed_value = 7\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import torch\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cooked-scroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(325, 298)\n",
      "(325, 1)\n"
     ]
    }
   ],
   "source": [
    "Training_Data = pd.ExcelFile(\"Labels.xlsx\") #Training Data already pre-scaled to the IBIS Data set\n",
    "data = Training_Data.parse(Training_Data.sheet_names[1])\n",
    "label_data = Training_Data.parse(Training_Data.sheet_names[0])\n",
    "data_features = data.loc[:, data.columns]\n",
    "data_features = data_features.drop(['Case','Visit','MATCH','INDEX','ASD+','ASD-','Gender'], axis=1)\n",
    "data_features = data_features.dropna()\n",
    "data_features = data_features.drop(['Final Label'], axis=1)\n",
    "labels = label_data.loc[:, label_data.columns]\n",
    "labels = labels.drop(['CASE','MATCH','INDEX','ASD+','ASD-'], axis=1)\n",
    "labels = labels.dropna()\n",
    "print(data_features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "engaged-memorabilia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(484, 298)\n",
      "(484, 1)\n",
      "(33, 298)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data_features)\n",
    "\n",
    "scaled_data.shape\n",
    "labels.shape\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(scaled_data, labels, test_size=0.1, random_state=seed_value)\n",
    "sm = SMOTE(sampling_strategy = 'minority', random_state = seed_value, k_neighbors=2)\n",
    "\n",
    "#Imblearn has other SMOTE variants to look into.\n",
    "#ADASYN - creates synthetic data according to the data density. \n",
    "#The synthetic data generation would inversely proportional to the density of the minority class. It means more synthetic data are created in regions of the feature space where the density of minority examples is low, and fewer or none where the density is high.\n",
    "#In simpler terms, in an area where the minority class is less dense, the synthetic data are created more. Otherwise, the synthetic data is not made so much.\n",
    "\n",
    "#SMOTENC - Denote which features are categorical, and SMOTE would resample the categorical data instead of creating synthetic data.\n",
    "\n",
    "#Borderline SMOTE\n",
    "#K SMOTE\n",
    "\n",
    "#Should increase testing size. Play with testing/training split.\n",
    "X_train_smoted, Y_train_smoted = sm.fit_sample(X_train, Y_train) #Only smote the training set.\n",
    "\n",
    "for x in X_train_smoted: #Round sex to be categorical\n",
    "    x[297] = round(x[297]) \n",
    "\n",
    "print(X_train_smoted.shape)\n",
    "print(Y_train_smoted.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loved-salon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6    \\\n",
      "0    0.258705  0.438098  0.589216  0.576429  0.305759  0.731312  0.281998   \n",
      "1    0.676811  0.386962  0.869205  0.700846  0.592711  0.844316  0.555507   \n",
      "2    0.259988  0.599793  0.657592  0.609657  0.271939  0.623553  0.578996   \n",
      "3    0.301246  0.207873  0.523120  0.508736  0.395415  0.560070  0.181108   \n",
      "4    0.453272  0.289539  0.381162  0.626984  0.449094  0.613171  0.484941   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "479  0.246198  0.316535  0.366794  0.552902  0.375614  0.697511  0.753548   \n",
      "480  0.269994  0.610351  0.748144  0.624256  0.312674  0.656822  0.467333   \n",
      "481  0.473550  0.291992  0.482353  0.655797  0.453427  0.730532  0.446362   \n",
      "482  0.434639  0.713012  0.603793  0.797428  0.398962  0.778101  0.384269   \n",
      "483  0.288587  0.146858  0.301180  0.271368  0.358030  0.710700  0.385751   \n",
      "\n",
      "          7         8         9    ...       288       289       290  \\\n",
      "0    0.475210  0.416581  0.440725  ...  0.493642  0.326863  0.337629   \n",
      "1    0.719559  0.670943  0.688495  ...  0.177707  0.110675  0.262435   \n",
      "2    0.545181  0.421907  0.448909  ...  0.770331  0.497895  0.248455   \n",
      "3    0.046594  0.127788  0.416714  ...  0.103392  0.141287  0.217997   \n",
      "4    0.474950  0.640582  0.790487  ...  0.494643  0.257424  0.180958   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "479  0.954248  0.607127  0.550616  ...  0.604764  0.252862  0.219487   \n",
      "480  0.600007  0.741255  0.848010  ...  0.394781  0.211586  0.311358   \n",
      "481  0.324556  0.355787  0.500596  ...  0.307168  0.280647  0.208308   \n",
      "482  0.272052  0.479363  0.421486  ...  0.375415  0.414129  0.169883   \n",
      "483  0.290454  0.543450  0.500146  ...  0.419209  0.321013  0.171349   \n",
      "\n",
      "          291       292       293       294       295  296  297  \n",
      "0    0.440999  0.397850  0.401036  0.485546  0.177249  0.0  1.0  \n",
      "1    0.132851  0.342283  0.500764  0.109365  0.226558  0.0  0.0  \n",
      "2    0.668510  0.521945  0.378478  0.308959  0.096791  0.0  1.0  \n",
      "3    0.267829  0.614048  0.213031  0.173845  0.134848  0.0  0.0  \n",
      "4    0.164969  0.371697  0.133338  0.368773  0.287029  0.0  1.0  \n",
      "..        ...       ...       ...       ...       ...  ...  ...  \n",
      "479  0.164598  0.282927  0.372758  0.533885  0.199228  0.0  1.0  \n",
      "480  0.343813  0.548466  0.239800  0.376466  0.374317  0.0  1.0  \n",
      "481  0.131610  0.415278  0.256748  0.463796  0.797721  0.0  1.0  \n",
      "482  0.461277  0.396521  0.268435  0.478451  0.592548  0.0  1.0  \n",
      "483  0.393373  0.598087  0.439982  0.347846  0.431300  0.0  0.0  \n",
      "\n",
      "[484 rows x 298 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_df = pd.DataFrame(X_train_smoted)\n",
    "print(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "worthy-leadership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6    \\\n",
      "0    0.258705  0.438098  0.589216  0.576429  0.305759  0.731312  0.281998   \n",
      "1    0.676811  0.386962  0.869205  0.700846  0.592711  0.844316  0.555507   \n",
      "2    0.259988  0.599793  0.657592  0.609657  0.271939  0.623553  0.578996   \n",
      "3    0.301246  0.207873  0.523120  0.508736  0.395415  0.560070  0.181108   \n",
      "4    0.453272  0.289539  0.381162  0.626984  0.449094  0.613171  0.484941   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "479  0.246198  0.316535  0.366794  0.552902  0.375614  0.697511  0.753548   \n",
      "480  0.269994  0.610351  0.748144  0.624256  0.312674  0.656822  0.467333   \n",
      "481  0.473550  0.291992  0.482353  0.655797  0.453427  0.730532  0.446362   \n",
      "482  0.434639  0.713012  0.603793  0.797428  0.398962  0.778101  0.384269   \n",
      "483  0.288587  0.146858  0.301180  0.271368  0.358030  0.710700  0.385751   \n",
      "\n",
      "          7         8         9    ...       288       289       290  \\\n",
      "0    0.475210  0.416581  0.440725  ...  0.493642  0.326863  0.337629   \n",
      "1    0.719559  0.670943  0.688495  ...  0.177707  0.110675  0.262435   \n",
      "2    0.545181  0.421907  0.448909  ...  0.770331  0.497895  0.248455   \n",
      "3    0.046594  0.127788  0.416714  ...  0.103392  0.141287  0.217997   \n",
      "4    0.474950  0.640582  0.790487  ...  0.494643  0.257424  0.180958   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "479  0.954248  0.607127  0.550616  ...  0.604764  0.252862  0.219487   \n",
      "480  0.600007  0.741255  0.848010  ...  0.394781  0.211586  0.311358   \n",
      "481  0.324556  0.355787  0.500596  ...  0.307168  0.280647  0.208308   \n",
      "482  0.272052  0.479363  0.421486  ...  0.375415  0.414129  0.169883   \n",
      "483  0.290454  0.543450  0.500146  ...  0.419209  0.321013  0.171349   \n",
      "\n",
      "          291       292       293       294       295  296  297  \n",
      "0    0.440999  0.397850  0.401036  0.485546  0.177249  0.0  1.0  \n",
      "1    0.132851  0.342283  0.500764  0.109365  0.226558  0.0  0.0  \n",
      "2    0.668510  0.521945  0.378478  0.308959  0.096791  0.0  1.0  \n",
      "3    0.267829  0.614048  0.213031  0.173845  0.134848  0.0  0.0  \n",
      "4    0.164969  0.371697  0.133338  0.368773  0.287029  0.0  1.0  \n",
      "..        ...       ...       ...       ...       ...  ...  ...  \n",
      "479  0.164598  0.282927  0.372758  0.533885  0.199228  0.0  1.0  \n",
      "480  0.343813  0.548466  0.239800  0.376466  0.374317  0.0  1.0  \n",
      "481  0.131610  0.415278  0.256748  0.463796  0.797721  0.0  1.0  \n",
      "482  0.461277  0.396521  0.268435  0.478451  0.592548  0.0  1.0  \n",
      "483  0.393373  0.598087  0.439982  0.347846  0.431300  0.0  0.0  \n",
      "\n",
      "[484 rows x 298 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "consolidated-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some hyperparameters\n",
    "#D_in is input dimension; H is hidden dimension; D_out is output dimension. \n",
    "#Need to figure out how to get dropout\n",
    "D_in, H1, H2, D_out = 298, 100, 15, 1\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE = 35\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data): #used to perform initializing operations such as reading data and preprocessing.\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index): #returns data (input and output) in batches.\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self): #returns the size of the input data.\n",
    "        return len(self.X_data)\n",
    "\n",
    "#A dataloader is then used on this dataset class to read the data in batches.\n",
    "train_data = trainData(torch.FloatTensor(X_train_smoted), \n",
    "                       torch.FloatTensor(Y_train_smoted.values))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data): ##used to perform initializing operations such as reading data and preprocessing.\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index): #returns data (input and output) in batches.\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self): #returns the size of the input data.\n",
    "        return len(self.X_data)\n",
    "    \n",
    "#A dataloader is then used on this dataset class to read the data in batches.\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "#Initialize DataLoaders\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=33) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "addressed-python",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 298.\n",
    "        self.layer_1 = nn.Linear(D_in, H1) #298 -> 100\n",
    "        self.layer_2 = nn.Linear(H1, H2) #100 -> 15\n",
    "        self.layer_out = nn.Linear(H2, D_out) #15 -> 1\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.15)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(100)\n",
    "        #self.batchnorm2 = nn.BatchNorm1d(15)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs)) #ReLU on the 298?\n",
    "        #x = self.batchnorm1(x) #Normalize the 100\n",
    "        x = self.dropout(x) #Dropout 15%\n",
    "        x = self.relu(self.layer_2(x)) #ReLU on the 100?\n",
    "        #x = self.batchnorm2(x) #Normalize the 15\n",
    "        x = self.layer_out(x) #1\n",
    "        \n",
    "        return x\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#Should use the CPU since I don't have a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "utility-fairy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=298, out_features=100, bias=True)\n",
      "  (layer_2): Linear(in_features=100, out_features=15, bias=True)\n",
      "  (layer_out): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "weights = torch.FloatTensor([5]) #Class weights\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ignored-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to define accuracy. Should look to see if there is a prebuilt that I can use from sci-kit learn or something.\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-highland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 001: | Loss: 1.49497 | Acc: 48.643\n",
      "Validation Accuracy |  9.090909090909092  PPV |  [0.         0.09090909]  Recall |  [0. 1.]\n",
      "Training Epoch 002: | Loss: 1.34940 | Acc: 50.143\n",
      "Validation Accuracy |  9.090909090909092  PPV |  [0.         0.09090909]  Recall |  [0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 003: | Loss: 1.32733 | Acc: 50.071\n",
      "Validation Accuracy |  9.090909090909092  PPV |  [0.         0.09090909]  Recall |  [0. 1.]\n",
      "Training Epoch 004: | Loss: 1.31724 | Acc: 49.786\n",
      "Validation Accuracy |  9.090909090909092  PPV |  [0.         0.09090909]  Recall |  [0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 005: | Loss: 1.23526 | Acc: 49.857\n",
      "Validation Accuracy |  9.090909090909092  PPV |  [0.         0.09090909]  Recall |  [0. 1.]\n",
      "Training Epoch 006: | Loss: 1.13916 | Acc: 50.214\n",
      "Validation Accuracy |  9.090909090909092  PPV |  [0.         0.09090909]  Recall |  [0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 007: | Loss: 1.04209 | Acc: 54.786\n",
      "Validation Accuracy |  18.181818181818183  PPV |  [1.  0.1]  Recall |  [0.1 1. ]\n",
      "Training Epoch 008: | Loss: 0.89981 | Acc: 63.857\n",
      "Validation Accuracy |  51.515151515151516  PPV |  [1.         0.15789474]  Recall |  [0.46666667 1.        ]\n",
      "Training Epoch 009: | Loss: 0.87723 | Acc: 71.357\n",
      "Validation Accuracy |  18.181818181818183  PPV |  [1.  0.1]  Recall |  [0.1 1. ]\n",
      "Training Epoch 010: | Loss: 0.85223 | Acc: 70.286\n",
      "Validation Accuracy |  36.36363636363637  PPV |  [0.90909091 0.09090909]  Recall |  [0.33333333 0.66666667]\n",
      "Training Epoch 011: | Loss: 0.66134 | Acc: 77.714\n",
      "Validation Accuracy |  69.6969696969697  PPV |  [0.95454545 0.18181818]  Recall |  [0.7        0.66666667]\n",
      "Training Epoch 012: | Loss: 0.75087 | Acc: 75.929\n",
      "Validation Accuracy |  87.87878787878788  PPV |  [0.96428571 0.4       ]  Recall |  [0.9        0.66666667]\n",
      "Training Epoch 013: | Loss: 0.71665 | Acc: 77.000\n",
      "Validation Accuracy |  72.72727272727273  PPV |  [0.95652174 0.2       ]  Recall |  [0.73333333 0.66666667]\n",
      "Training Epoch 014: | Loss: 0.62917 | Acc: 80.929\n",
      "Validation Accuracy |  33.33333333333333  PPV |  [1.   0.12]  Recall |  [0.26666667 1.        ]\n",
      "Training Epoch 015: | Loss: 0.63405 | Acc: 81.143\n",
      "Validation Accuracy |  33.33333333333333  PPV |  [1.   0.12]  Recall |  [0.26666667 1.        ]\n",
      "Training Epoch 016: | Loss: 0.81070 | Acc: 72.714\n",
      "Validation Accuracy |  54.54545454545454  PPV |  [0.94117647 0.125     ]  Recall |  [0.53333333 0.66666667]\n",
      "Training Epoch 017: | Loss: 0.63201 | Acc: 81.571\n",
      "Validation Accuracy |  30.303030303030305  PPV |  [1.         0.11538462]  Recall |  [0.23333333 1.        ]\n",
      "Training Epoch 018: | Loss: 0.68908 | Acc: 77.786\n",
      "Validation Accuracy |  69.6969696969697  PPV |  [0.95454545 0.18181818]  Recall |  [0.7        0.66666667]\n",
      "Training Epoch 019: | Loss: 0.52049 | Acc: 86.571\n",
      "Validation Accuracy |  30.303030303030305  PPV |  [0.88888889 0.08333333]  Recall |  [0.26666667 0.66666667]\n",
      "Training Epoch 020: | Loss: 0.44679 | Acc: 87.071\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 021: | Loss: 0.45667 | Acc: 87.286\n",
      "Validation Accuracy |  78.78787878787878  PPV |  [0.96 0.25]  Recall |  [0.8        0.66666667]\n",
      "Training Epoch 022: | Loss: 0.44851 | Acc: 88.571\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 023: | Loss: 0.35892 | Acc: 91.357\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 024: | Loss: 0.33440 | Acc: 92.214\n",
      "Validation Accuracy |  69.6969696969697  PPV |  [0.95454545 0.18181818]  Recall |  [0.7        0.66666667]\n",
      "Training Epoch 025: | Loss: 0.42390 | Acc: 89.214\n",
      "Validation Accuracy |  69.6969696969697  PPV |  [0.95454545 0.18181818]  Recall |  [0.7        0.66666667]\n",
      "Training Epoch 026: | Loss: 0.55491 | Acc: 82.286\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.93103448 0.25      ]  Recall |  [0.9        0.33333333]\n",
      "Training Epoch 027: | Loss: 0.52633 | Acc: 87.357\n",
      "Validation Accuracy |  69.6969696969697  PPV |  [0.95454545 0.18181818]  Recall |  [0.7        0.66666667]\n",
      "Training Epoch 028: | Loss: 0.66069 | Acc: 77.429\n",
      "Validation Accuracy |  66.66666666666666  PPV |  [0.95238095 0.16666667]  Recall |  [0.66666667 0.66666667]\n",
      "Training Epoch 029: | Loss: 0.40254 | Acc: 90.143\n",
      "Validation Accuracy |  66.66666666666666  PPV |  [0.95238095 0.16666667]  Recall |  [0.66666667 0.66666667]\n",
      "Training Epoch 030: | Loss: 0.37561 | Acc: 91.357\n",
      "Validation Accuracy |  63.63636363636363  PPV |  [0.95       0.15384615]  Recall |  [0.63333333 0.66666667]\n",
      "Training Epoch 031: | Loss: 0.46049 | Acc: 88.214\n",
      "Validation Accuracy |  36.36363636363637  PPV |  [1.    0.125]  Recall |  [0.3 1. ]\n",
      "Training Epoch 032: | Loss: 0.38255 | Acc: 89.143\n",
      "Validation Accuracy |  69.6969696969697  PPV |  [0.95454545 0.18181818]  Recall |  [0.7        0.66666667]\n",
      "Training Epoch 033: | Loss: 0.30297 | Acc: 91.000\n",
      "Validation Accuracy |  75.75757575757575  PPV |  [0.95833333 0.22222222]  Recall |  [0.76666667 0.66666667]\n",
      "Training Epoch 034: | Loss: 0.20767 | Acc: 95.929\n",
      "Validation Accuracy |  78.78787878787878  PPV |  [0.92592593 0.16666667]  Recall |  [0.83333333 0.33333333]\n",
      "Training Epoch 035: | Loss: 0.18850 | Acc: 95.571\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 036: | Loss: 0.26872 | Acc: 94.143\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 037: | Loss: 0.31571 | Acc: 92.429\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.93103448 0.25      ]  Recall |  [0.9        0.33333333]\n",
      "Training Epoch 038: | Loss: 0.43312 | Acc: 90.643\n",
      "Validation Accuracy |  63.63636363636363  PPV |  [0.95       0.15384615]  Recall |  [0.63333333 0.66666667]\n",
      "Training Epoch 039: | Loss: 0.38141 | Acc: 92.143\n",
      "Validation Accuracy |  66.66666666666666  PPV |  [0.95238095 0.16666667]  Recall |  [0.66666667 0.66666667]\n",
      "Training Epoch 040: | Loss: 0.32240 | Acc: 92.286\n",
      "Validation Accuracy |  75.75757575757575  PPV |  [0.92307692 0.14285714]  Recall |  [0.8        0.33333333]\n",
      "Training Epoch 041: | Loss: 0.24072 | Acc: 93.643\n",
      "Validation Accuracy |  69.6969696969697  PPV |  [0.95454545 0.18181818]  Recall |  [0.7        0.66666667]\n",
      "Training Epoch 042: | Loss: 0.26985 | Acc: 92.357\n",
      "Validation Accuracy |  57.57575757575758  PPV |  [0.94444444 0.13333333]  Recall |  [0.56666667 0.66666667]\n",
      "Training Epoch 043: | Loss: 0.52156 | Acc: 88.929\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.93103448 0.25      ]  Recall |  [0.9        0.33333333]\n",
      "Training Epoch 044: | Loss: 0.78640 | Acc: 81.071\n",
      "Validation Accuracy |  72.72727272727273  PPV |  [0.95652174 0.2       ]  Recall |  [0.73333333 0.66666667]\n",
      "Training Epoch 045: | Loss: 0.59852 | Acc: 85.929\n",
      "Validation Accuracy |  39.39393939393939  PPV |  [0.91666667 0.0952381 ]  Recall |  [0.36666667 0.66666667]\n",
      "Training Epoch 046: | Loss: 0.43413 | Acc: 88.429\n",
      "Validation Accuracy |  57.57575757575758  PPV |  [0.94444444 0.13333333]  Recall |  [0.56666667 0.66666667]\n",
      "Training Epoch 047: | Loss: 0.58233 | Acc: 86.357\n",
      "Validation Accuracy |  69.6969696969697  PPV |  [0.95454545 0.18181818]  Recall |  [0.7        0.66666667]\n",
      "Training Epoch 048: | Loss: 0.52188 | Acc: 86.357\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 049: | Loss: 0.26182 | Acc: 95.286\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 050: | Loss: 0.31796 | Acc: 93.714\n",
      "Validation Accuracy |  78.78787878787878  PPV |  [0.96 0.25]  Recall |  [0.8        0.66666667]\n",
      "Training Epoch 051: | Loss: 0.28721 | Acc: 95.071\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.93103448 0.25      ]  Recall |  [0.9        0.33333333]\n",
      "Training Epoch 052: | Loss: 0.78044 | Acc: 81.071\n",
      "Validation Accuracy |  66.66666666666666  PPV |  [0.95238095 0.16666667]  Recall |  [0.66666667 0.66666667]\n",
      "Training Epoch 053: | Loss: 0.66736 | Acc: 82.357\n",
      "Validation Accuracy |  30.303030303030305  PPV |  [0.88888889 0.08333333]  Recall |  [0.26666667 0.66666667]\n",
      "Training Epoch 054: | Loss: 0.76298 | Acc: 74.929\n",
      "Validation Accuracy |  78.78787878787878  PPV |  [0.96 0.25]  Recall |  [0.8        0.66666667]\n",
      "Training Epoch 055: | Loss: 0.66737 | Acc: 88.143\n",
      "Validation Accuracy |  57.57575757575758  PPV |  [0.94444444 0.13333333]  Recall |  [0.56666667 0.66666667]\n",
      "Training Epoch 056: | Loss: 0.38483 | Acc: 91.214\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.93103448 0.25      ]  Recall |  [0.9        0.33333333]\n",
      "Training Epoch 057: | Loss: 0.35963 | Acc: 93.929\n",
      "Validation Accuracy |  72.72727272727273  PPV |  [0.95652174 0.2       ]  Recall |  [0.73333333 0.66666667]\n",
      "Training Epoch 058: | Loss: 0.26186 | Acc: 95.071\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.93103448 0.25      ]  Recall |  [0.9        0.33333333]\n",
      "Training Epoch 059: | Loss: 0.26304 | Acc: 96.000\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 060: | Loss: 0.46420 | Acc: 89.500\n",
      "Validation Accuracy |  60.60606060606061  PPV |  [0.94736842 0.14285714]  Recall |  [0.6        0.66666667]\n",
      "Training Epoch 061: | Loss: 0.54631 | Acc: 91.714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy |  84.84848484848484  PPV |  [0.96296296 0.33333333]  Recall |  [0.86666667 0.66666667]\n",
      "Training Epoch 062: | Loss: 0.43086 | Acc: 94.500\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 063: | Loss: 0.24860 | Acc: 96.000\n",
      "Validation Accuracy |  87.87878787878788  PPV |  [0.96428571 0.4       ]  Recall |  [0.9        0.66666667]\n",
      "Training Epoch 064: | Loss: 0.30179 | Acc: 95.500\n",
      "Validation Accuracy |  69.6969696969697  PPV |  [0.95454545 0.18181818]  Recall |  [0.7        0.66666667]\n",
      "Training Epoch 065: | Loss: 0.34705 | Acc: 94.929\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 066: | Loss: 0.45954 | Acc: 90.786\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.96296296 0.33333333]  Recall |  [0.86666667 0.66666667]\n",
      "Training Epoch 067: | Loss: 0.59716 | Acc: 90.357\n",
      "Validation Accuracy |  78.78787878787878  PPV |  [0.96 0.25]  Recall |  [0.8        0.66666667]\n",
      "Training Epoch 068: | Loss: 0.41745 | Acc: 95.786\n",
      "Validation Accuracy |  57.57575757575758  PPV |  [0.94444444 0.13333333]  Recall |  [0.56666667 0.66666667]\n",
      "Training Epoch 069: | Loss: 0.32950 | Acc: 95.143\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 070: | Loss: 0.32141 | Acc: 95.714\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.93103448 0.25      ]  Recall |  [0.9        0.33333333]\n",
      "Training Epoch 071: | Loss: 0.40805 | Acc: 92.286\n",
      "Validation Accuracy |  87.87878787878788  PPV |  [0.96428571 0.4       ]  Recall |  [0.9        0.66666667]\n",
      "Training Epoch 072: | Loss: 0.71677 | Acc: 86.357\n",
      "Validation Accuracy |  45.45454545454545  PPV |  [0.92857143 0.10526316]  Recall |  [0.43333333 0.66666667]\n",
      "Training Epoch 073: | Loss: 0.56585 | Acc: 88.357\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 074: | Loss: 0.43091 | Acc: 91.571\n",
      "Validation Accuracy |  48.484848484848484  PPV |  [0.93333333 0.11111111]  Recall |  [0.46666667 0.66666667]\n",
      "Training Epoch 075: | Loss: 0.45193 | Acc: 90.714\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.93103448 0.25      ]  Recall |  [0.9        0.33333333]\n",
      "Training Epoch 076: | Loss: 0.45009 | Acc: 92.786\n",
      "Validation Accuracy |  69.6969696969697  PPV |  [0.95454545 0.18181818]  Recall |  [0.7        0.66666667]\n",
      "Training Epoch 077: | Loss: 0.33653 | Acc: 93.000\n",
      "Validation Accuracy |  66.66666666666666  PPV |  [0.95238095 0.16666667]  Recall |  [0.66666667 0.66666667]\n",
      "Training Epoch 078: | Loss: 0.27802 | Acc: 95.000\n",
      "Validation Accuracy |  75.75757575757575  PPV |  [0.95833333 0.22222222]  Recall |  [0.76666667 0.66666667]\n",
      "Training Epoch 079: | Loss: 0.31904 | Acc: 96.071\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.96296296 0.33333333]  Recall |  [0.86666667 0.66666667]\n",
      "Training Epoch 080: | Loss: 0.29506 | Acc: 96.643\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 081: | Loss: 0.24413 | Acc: 97.357\n",
      "Validation Accuracy |  75.75757575757575  PPV |  [0.95833333 0.22222222]  Recall |  [0.76666667 0.66666667]\n",
      "Training Epoch 082: | Loss: 0.24310 | Acc: 98.000\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.96296296 0.33333333]  Recall |  [0.86666667 0.66666667]\n",
      "Training Epoch 083: | Loss: 0.35305 | Acc: 96.214\n",
      "Validation Accuracy |  87.87878787878788  PPV |  [0.96428571 0.4       ]  Recall |  [0.9        0.66666667]\n",
      "Training Epoch 084: | Loss: 0.22468 | Acc: 97.357\n",
      "Validation Accuracy |  87.87878787878788  PPV |  [0.96428571 0.4       ]  Recall |  [0.9        0.66666667]\n",
      "Training Epoch 085: | Loss: 0.23040 | Acc: 97.000\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.96296296 0.33333333]  Recall |  [0.86666667 0.66666667]\n",
      "Training Epoch 086: | Loss: 0.32983 | Acc: 96.357\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 087: | Loss: 0.33711 | Acc: 95.143\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.9 0. ]  Recall |  [0.9 0. ]\n",
      "Training Epoch 088: | Loss: 0.24645 | Acc: 97.000\n",
      "Validation Accuracy |  78.78787878787878  PPV |  [0.96 0.25]  Recall |  [0.8        0.66666667]\n",
      "Training Epoch 089: | Loss: 0.32334 | Acc: 94.786\n",
      "Validation Accuracy |  69.6969696969697  PPV |  [0.95454545 0.18181818]  Recall |  [0.7        0.66666667]\n",
      "Training Epoch 090: | Loss: 0.25252 | Acc: 97.643\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.96296296 0.33333333]  Recall |  [0.86666667 0.66666667]\n",
      "Training Epoch 091: | Loss: 0.27877 | Acc: 97.643\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 092: | Loss: 0.66300 | Acc: 88.857\n",
      "Validation Accuracy |  75.75757575757575  PPV |  [0.95833333 0.22222222]  Recall |  [0.76666667 0.66666667]\n",
      "Training Epoch 093: | Loss: 0.74192 | Acc: 90.214\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.96296296 0.33333333]  Recall |  [0.86666667 0.66666667]\n",
      "Training Epoch 094: | Loss: 0.76298 | Acc: 58.929\n",
      "Validation Accuracy |  9.090909090909092  PPV |  [0.         0.09090909]  Recall |  [0. 1.]\n",
      "Training Epoch 095: | Loss: 0.73218 | Acc: 49.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy |  12.121212121212121  PPV |  [1.      0.09375]  Recall |  [0.03333333 1.        ]\n",
      "Training Epoch 096: | Loss: 0.64314 | Acc: 88.286\n",
      "Validation Accuracy |  72.72727272727273  PPV |  [0.95652174 0.2       ]  Recall |  [0.73333333 0.66666667]\n",
      "Training Epoch 097: | Loss: 0.60063 | Acc: 91.500\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.93103448 0.25      ]  Recall |  [0.9        0.33333333]\n",
      "Training Epoch 098: | Loss: 0.64334 | Acc: 91.500\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 099: | Loss: 0.56411 | Acc: 92.286\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.93103448 0.25      ]  Recall |  [0.9        0.33333333]\n",
      "Training Epoch 100: | Loss: 0.60849 | Acc: 91.500\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.93103448 0.25      ]  Recall |  [0.9        0.33333333]\n",
      "Training Epoch 101: | Loss: 0.66393 | Acc: 90.429\n",
      "Validation Accuracy |  75.75757575757575  PPV |  [0.95833333 0.22222222]  Recall |  [0.76666667 0.66666667]\n",
      "Training Epoch 102: | Loss: 0.55750 | Acc: 93.000\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 103: | Loss: 0.62701 | Acc: 91.214\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 104: | Loss: 0.67460 | Acc: 90.286\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 105: | Loss: 0.65129 | Acc: 51.500\n",
      "Validation Accuracy |  12.121212121212121  PPV |  [1.      0.09375]  Recall |  [0.03333333 1.        ]\n",
      "Training Epoch 106: | Loss: 0.71156 | Acc: 85.714\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.93103448 0.25      ]  Recall |  [0.9        0.33333333]\n",
      "Training Epoch 107: | Loss: 0.62934 | Acc: 90.071\n",
      "Validation Accuracy |  78.78787878787878  PPV |  [0.96 0.25]  Recall |  [0.8        0.66666667]\n",
      "Training Epoch 108: | Loss: 0.66434 | Acc: 90.643\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 109: | Loss: 0.63285 | Acc: 91.071\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 110: | Loss: 0.56422 | Acc: 93.143\n",
      "Validation Accuracy |  75.75757575757575  PPV |  [0.95833333 0.22222222]  Recall |  [0.76666667 0.66666667]\n",
      "Training Epoch 111: | Loss: 0.61670 | Acc: 91.429\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.93103448 0.25      ]  Recall |  [0.9        0.33333333]\n",
      "Training Epoch 112: | Loss: 0.68010 | Acc: 90.000\n",
      "Validation Accuracy |  75.75757575757575  PPV |  [0.95833333 0.22222222]  Recall |  [0.76666667 0.66666667]\n",
      "Training Epoch 113: | Loss: 0.55650 | Acc: 92.857\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 114: | Loss: 0.58107 | Acc: 92.500\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.96296296 0.33333333]  Recall |  [0.86666667 0.66666667]\n",
      "Training Epoch 115: | Loss: 0.64683 | Acc: 91.571\n",
      "Validation Accuracy |  75.75757575757575  PPV |  [0.95833333 0.22222222]  Recall |  [0.76666667 0.66666667]\n",
      "Training Epoch 116: | Loss: 0.64611 | Acc: 91.214\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 117: | Loss: 0.64909 | Acc: 91.071\n",
      "Validation Accuracy |  75.75757575757575  PPV |  [0.95833333 0.22222222]  Recall |  [0.76666667 0.66666667]\n",
      "Training Epoch 118: | Loss: 0.66488 | Acc: 74.214\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 119: | Loss: 0.57759 | Acc: 92.929\n",
      "Validation Accuracy |  84.84848484848484  PPV |  [0.96296296 0.33333333]  Recall |  [0.86666667 0.66666667]\n",
      "Training Epoch 120: | Loss: 0.62911 | Acc: 91.500\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 121: | Loss: 0.53430 | Acc: 93.714\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 122: | Loss: 0.57163 | Acc: 92.929\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 123: | Loss: 0.60360 | Acc: 92.429\n",
      "Validation Accuracy |  78.78787878787878  PPV |  [0.96 0.25]  Recall |  [0.8        0.66666667]\n",
      "Training Epoch 124: | Loss: 0.62934 | Acc: 91.429\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 125: | Loss: 0.61279 | Acc: 92.357\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 126: | Loss: 0.60579 | Acc: 92.214\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 127: | Loss: 0.60585 | Acc: 92.143\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.92857143 0.2       ]  Recall |  [0.86666667 0.33333333]\n",
      "Training Epoch 128: | Loss: 0.70283 | Acc: 76.000\n",
      "Validation Accuracy |  9.090909090909092  PPV |  [0.         0.09090909]  Recall |  [0. 1.]\n",
      "Training Epoch 129: | Loss: 0.66883 | Acc: 61.071\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 130: | Loss: 0.60838 | Acc: 92.071\n",
      "Validation Accuracy |  75.75757575757575  PPV |  [0.95833333 0.22222222]  Recall |  [0.76666667 0.66666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 131: | Loss: 0.59418 | Acc: 92.286\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n",
      "Training Epoch 132: | Loss: 0.67123 | Acc: 73.786\n",
      "Validation Accuracy |  9.090909090909092  PPV |  [0.         0.09090909]  Recall |  [0. 1.]\n",
      "Training Epoch 133: | Loss: 0.58312 | Acc: 86.143\n",
      "Validation Accuracy |  78.78787878787878  PPV |  [0.92592593 0.16666667]  Recall |  [0.83333333 0.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 134: | Loss: 0.64505 | Acc: 91.357\n",
      "Validation Accuracy |  78.78787878787878  PPV |  [0.96 0.25]  Recall |  [0.8        0.66666667]\n",
      "Training Epoch 135: | Loss: 0.62418 | Acc: 91.786\n",
      "Validation Accuracy |  78.78787878787878  PPV |  [0.92592593 0.16666667]  Recall |  [0.83333333 0.33333333]\n",
      "Training Epoch 136: | Loss: 0.55399 | Acc: 93.357\n",
      "Validation Accuracy |  81.81818181818183  PPV |  [0.96153846 0.28571429]  Recall |  [0.83333333 0.66666667]\n"
     ]
    }
   ],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "model.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc.append(epoch_acc/len(train_loader))\n",
    "    train_loss.append(epoch_loss/len(train_loader))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    #Validation metrics here\n",
    "    model.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=33)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(Y_test.values))\n",
    "            val_loss.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(Y_test.values), y_pred_list)\n",
    "    ppv = precision_score(Y_test, y_pred_list, average=None)\n",
    "    recall = recall_score(Y_test, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc.append(accuracy*100)\n",
    "    model.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting loss\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "model.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(Y_test, y_pred_list)\n",
    "ppv = precision_score(Y_test, y_pred_list, average=None)\n",
    "recall = recall_score(Y_test, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(Y_test, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model once everything is all figured out\n",
    "\n",
    "#Models below were initially trained at 150 epochs. Re-trained for when accuracy was highest, without overtraining.\n",
    "'''\n",
    "10% Test - 27 03 ppv - 0.25 recall - 0.3333\n",
    "            2  1\n",
    "15% Test - 33 10 ppv - 0.09 recall - 0.17\n",
    "            5  1\n",
    "20% Test - 45 13 ppv - 0.07 recall - 0.14\n",
    "            6  1 \n",
    "25% Test - 54 19 ppv - 0.17 recall - 0.4444\n",
    "            5  4\n",
    "30% Test - 47 40 ppv - 0.11 recall - 0.45\n",
    "            6  5\n",
    "35% Test - 81 21 ppv - 0.125 recall - 0.25\n",
    "            9  3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-prince",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
