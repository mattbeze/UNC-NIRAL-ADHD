{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "simple-navigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16815842a10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.combine import SMOTETomek\n",
    "#from imblearn.under_sampling import TomekLinks\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, multilabel_confusion_matrix, precision_score, precision_recall_curve, average_precision_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, ReLU, Sigmoid, Module, BCELoss, BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "import time\n",
    "\n",
    "seed_value = 7\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import torch\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "independent-welding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148, 299)\n",
      "(148, 1)\n"
     ]
    }
   ],
   "source": [
    "Training_Data = pd.ExcelFile(\"Training Data.xlsx\") #Training Data already pre-scaled to the IBIS Data set\n",
    "Label_Data = pd.ExcelFile(\"Labels.xlsx\") #Labels\n",
    "data = Training_Data.parse(Training_Data.sheet_names[0])\n",
    "label_data = Label_Data.parse(Label_Data.sheet_names[0])\n",
    "data_features = data.loc[:, data.columns]\n",
    "data_features = data_features.drop(['ROI','MATCH DEMOS','INDEX SEX','INDEX GA', 'INDEX MEDU','HYP'], axis=1)\n",
    "data_features = data_features.dropna()\n",
    "data_features = data_features.drop(['ATP'], axis=1)\n",
    "labels = label_data.loc[:, label_data.columns]\n",
    "labels = labels.drop(['ROI','MATCH BASC2', 'INDEX ATP', 'INDEX HYP', 'HYP'], axis=1)\n",
    "labels = labels.dropna()\n",
    "print(data_features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "settled-opportunity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 299)\n",
      "(34, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "interpolated_data = Training_Data.parse(Training_Data.sheet_names[1])\n",
    "interpolated_data_features = interpolated_data.loc[:, interpolated_data.columns]\n",
    "interpolated_data_features = interpolated_data_features.drop(['ROI','MATCH','INDEX','MATCH2','INDEX2', 'ATP t-score', 'HYP t-score', 'ATP Middle', 'HYP Middle', 'HYP', 'INDEX3'], axis=1)\n",
    "interpolated_data_features = interpolated_data_features.dropna()\n",
    "interpolated_data_features = interpolated_data_features.drop(['ATP'], axis=1)\n",
    "\n",
    "interpolated_label_data = Label_Data.parse(Label_Data.sheet_names[1])\n",
    "interpolated_labels = interpolated_label_data.loc[:, interpolated_label_data.columns]\n",
    "interpolated_labels = interpolated_labels.drop(['ROI','HYP'], axis=1)\n",
    "interpolated_labels = interpolated_labels.dropna()\n",
    "\n",
    "print(interpolated_data_features.shape)\n",
    "print(interpolated_labels.shape)\n",
    "print(type(interpolated_data_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "defined-monroe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=8, random_state=None, shuffle=False)\n",
      "(218, 299)\n",
      "(218, 299)\n",
      "(218, 299)\n",
      "(218, 299)\n",
      "(218, 299)\n",
      "(220, 299)\n",
      "(220, 299)\n",
      "(220, 299)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=8)\n",
    "skf.get_n_splits(data_features, labels)\n",
    "print(skf)\n",
    "\n",
    "training_indices_X = []\n",
    "testing_indices_X = []\n",
    "training_indices_Y = []\n",
    "testing_indices_Y = []\n",
    "\n",
    "for train_index, test_index in skf.split(data_features, labels):\n",
    "  \n",
    "    X_train, X_test = data_features.iloc[train_index], data_features.iloc[test_index]\n",
    "    Y_train, Y_test = labels.iloc[train_index], labels.iloc[test_index]\n",
    "   \n",
    "    sm = SMOTE(sampling_strategy = 'minority', random_state = seed_value, k_neighbors=2) \n",
    "    X_train_res, Y_train_res = sm.fit_sample(X_train, Y_train) #Only smote the training set.\n",
    "    print(X_train_res.shape)\n",
    "    training_indices_X.append(X_train_res)\n",
    "    testing_indices_X.append(X_test)\n",
    "    training_indices_Y.append(Y_train_res)\n",
    "    testing_indices_Y.append(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proper-weekend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218, 299)\n",
      "(218, 299)\n",
      "(218, 299)\n",
      "(218, 299)\n",
      "(218, 299)\n",
      "(220, 299)\n",
      "(220, 299)\n",
      "(220, 299)\n",
      "----------\n",
      "(252, 596)\n",
      "(252, 596)\n",
      "(252, 596)\n",
      "(252, 596)\n",
      "(252, 596)\n",
      "(254, 596)\n",
      "(254, 596)\n",
      "(254, 596)\n",
      "Label shapes\n",
      "(218, 1)\n",
      "(218, 1)\n",
      "(218, 1)\n",
      "(218, 1)\n",
      "(218, 1)\n",
      "(220, 1)\n",
      "(220, 1)\n",
      "(220, 1)\n",
      "----------\n",
      "(252, 1)\n",
      "(252, 1)\n",
      "(252, 1)\n",
      "(252, 1)\n",
      "(252, 1)\n",
      "(254, 1)\n",
      "(254, 1)\n",
      "(254, 1)\n"
     ]
    }
   ],
   "source": [
    "for x in training_indices_X:\n",
    "    print(x.shape)\n",
    "    \n",
    "#Figure out how to loop this later. Wasn't working for the following code:\n",
    "#for x in training_indices_X:\n",
    "#    x = pd.concat([x,interpolated_data_features])\n",
    "\n",
    "training_indices_X[0] = pd.concat([training_indices_X[0],interpolated_data_features])\n",
    "training_indices_X[1] = pd.concat([training_indices_X[1],interpolated_data_features])\n",
    "training_indices_X[2] = pd.concat([training_indices_X[2],interpolated_data_features])\n",
    "training_indices_X[3] = pd.concat([training_indices_X[3],interpolated_data_features])\n",
    "training_indices_X[4] = pd.concat([training_indices_X[4],interpolated_data_features])\n",
    "training_indices_X[5] = pd.concat([training_indices_X[5],interpolated_data_features])\n",
    "training_indices_X[6] = pd.concat([training_indices_X[6],interpolated_data_features])\n",
    "training_indices_X[7] = pd.concat([training_indices_X[7],interpolated_data_features])\n",
    "\n",
    "print('----------')\n",
    "for x in training_indices_X:\n",
    "    print(x.shape)\n",
    "    \n",
    "print('Label shapes')\n",
    "    \n",
    "for y in training_indices_Y:\n",
    "    print(y.shape)\n",
    "\n",
    "training_indices_Y[0] = pd.concat([training_indices_Y[0],interpolated_labels])\n",
    "training_indices_Y[1] = pd.concat([training_indices_Y[1],interpolated_labels])\n",
    "training_indices_Y[2] = pd.concat([training_indices_Y[2],interpolated_labels])\n",
    "training_indices_Y[3] = pd.concat([training_indices_Y[3],interpolated_labels])\n",
    "training_indices_Y[4] = pd.concat([training_indices_Y[4],interpolated_labels])\n",
    "training_indices_Y[5] = pd.concat([training_indices_Y[5],interpolated_labels])\n",
    "training_indices_Y[6] = pd.concat([training_indices_Y[6],interpolated_labels])\n",
    "training_indices_Y[7] = pd.concat([training_indices_Y[7],interpolated_labels])\n",
    "\n",
    "print('----------')\n",
    "for y in training_indices_Y:\n",
    "    print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conventional-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_indices_X[0] #8 Folds so 0 -> 7 Data type is a DataFrame currently.\n",
    "training_fold_X_0 = training_indices_X[0].to_numpy()\n",
    "training_fold_X_1 = training_indices_X[1].to_numpy()\n",
    "training_fold_X_2 = training_indices_X[2].to_numpy()\n",
    "training_fold_X_3 = training_indices_X[3].to_numpy()\n",
    "training_fold_X_4 = training_indices_X[4].to_numpy()\n",
    "training_fold_X_5 = training_indices_X[5].to_numpy()\n",
    "training_fold_X_6 = training_indices_X[6].to_numpy()\n",
    "training_fold_X_7 = training_indices_X[7].to_numpy()\n",
    "\n",
    "training_fold_Y_0 = training_indices_Y[0].to_numpy()\n",
    "training_fold_Y_1 = training_indices_Y[1].to_numpy()\n",
    "training_fold_Y_2 = training_indices_Y[2].to_numpy()\n",
    "training_fold_Y_3 = training_indices_Y[3].to_numpy()\n",
    "training_fold_Y_4 = training_indices_Y[4].to_numpy()\n",
    "training_fold_Y_5 = training_indices_Y[5].to_numpy()\n",
    "training_fold_Y_6 = training_indices_Y[6].to_numpy()\n",
    "training_fold_Y_7 = training_indices_Y[7].to_numpy()\n",
    "\n",
    "testing_fold_X_0 = testing_indices_X[0].to_numpy()\n",
    "testing_fold_X_1 = testing_indices_X[1].to_numpy()\n",
    "testing_fold_X_2 = testing_indices_X[2].to_numpy()\n",
    "testing_fold_X_3 = testing_indices_X[3].to_numpy()\n",
    "testing_fold_X_4 = testing_indices_X[4].to_numpy()\n",
    "testing_fold_X_5 = testing_indices_X[5].to_numpy()\n",
    "testing_fold_X_6 = testing_indices_X[6].to_numpy()\n",
    "testing_fold_X_7 = testing_indices_X[7].to_numpy()\n",
    "\n",
    "testing_fold_Y_0 = testing_indices_Y[0].to_numpy()\n",
    "testing_fold_Y_1 = testing_indices_Y[1].to_numpy()\n",
    "testing_fold_Y_2 = testing_indices_Y[2].to_numpy()\n",
    "testing_fold_Y_3 = testing_indices_Y[3].to_numpy()\n",
    "testing_fold_Y_4 = testing_indices_Y[4].to_numpy()\n",
    "testing_fold_Y_5 = testing_indices_Y[5].to_numpy()\n",
    "testing_fold_Y_6 = testing_indices_Y[6].to_numpy()\n",
    "testing_fold_Y_7 = testing_indices_Y[7].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "creative-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some hyperparameters\n",
    "#D_in is input dimension; H is hidden dimension; D_out is output dimension. \n",
    "\n",
    "#Best: 0.508814 using {'batch_size': 35, 'dropout': 0.15, 'epochs': 35, 'layer1_size': 100, 'layer2_size': 15}\n",
    "D_in, H1, H2, D_out = 299, 100, 15, 1\n",
    "EPOCHS = 35\n",
    "BATCH_SIZE = 35\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT_RATE = 0.15\n",
    "\n",
    "test_size = 19\n",
    "test_size1 = 18\n",
    "\n",
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data): #used to perform initializing operations such as reading data and preprocessing.\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index): #returns data (input and output) in batches.\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self): #returns the size of the input data.\n",
    "        return len(self.X_data)\n",
    "\n",
    "#A dataloader is then used on this dataset class to read the data in batches.\n",
    "train_data = trainData(torch.FloatTensor(training_fold_X_0), \n",
    "                       torch.FloatTensor(training_fold_Y_0))\n",
    "\n",
    "train_data1 = trainData(torch.FloatTensor(training_fold_X_1), \n",
    "                       torch.FloatTensor(training_fold_Y_1))\n",
    "\n",
    "train_data2 = trainData(torch.FloatTensor(training_fold_X_2), \n",
    "                       torch.FloatTensor(training_fold_Y_2))\n",
    "\n",
    "train_data3 = trainData(torch.FloatTensor(training_fold_X_3), \n",
    "                       torch.FloatTensor(training_fold_Y_3))\n",
    "\n",
    "train_data4 = trainData(torch.FloatTensor(training_fold_X_4), \n",
    "                       torch.FloatTensor(training_fold_Y_4))\n",
    "\n",
    "train_data5 = trainData(torch.FloatTensor(training_fold_X_5), \n",
    "                       torch.FloatTensor(training_fold_Y_5))\n",
    "\n",
    "train_data6 = trainData(torch.FloatTensor(training_fold_X_6), \n",
    "                       torch.FloatTensor(training_fold_Y_6))\n",
    "\n",
    "train_data7 = trainData(torch.FloatTensor(training_fold_X_7), \n",
    "                       torch.FloatTensor(training_fold_Y_7))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data): ##used to perform initializing operations such as reading data and preprocessing.\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index): #returns data (input and output) in batches.\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self): #returns the size of the input data.\n",
    "        return len(self.X_data)\n",
    "    \n",
    "#A dataloader is then used on this dataset class to read the data in batches.\n",
    "test_data = testData(torch.FloatTensor(testing_fold_X_0))\n",
    "test_data1 = testData(torch.FloatTensor(testing_fold_X_1))\n",
    "test_data2 = testData(torch.FloatTensor(testing_fold_X_2))\n",
    "test_data3 = testData(torch.FloatTensor(testing_fold_X_3))\n",
    "test_data4 = testData(torch.FloatTensor(testing_fold_X_4))\n",
    "test_data5 = testData(torch.FloatTensor(testing_fold_X_5))\n",
    "test_data6 = testData(torch.FloatTensor(testing_fold_X_6))\n",
    "test_data7 = testData(torch.FloatTensor(testing_fold_X_7))\n",
    "\n",
    "#Initialize DataLoaders\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=test_size) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader1 = DataLoader(dataset=train_data1, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader1 = DataLoader(dataset=test_data1, batch_size=test_size) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader2 = DataLoader(dataset=train_data2, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader2 = DataLoader(dataset=test_data2, batch_size=test_size) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader3 = DataLoader(dataset=train_data3, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader3 = DataLoader(dataset=test_data3, batch_size=test_size) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader4 = DataLoader(dataset=train_data4, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader4 = DataLoader(dataset=test_data4, batch_size=test_size1) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader5 = DataLoader(dataset=train_data5, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader5 = DataLoader(dataset=test_data5, batch_size=test_size1) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader6 = DataLoader(dataset=train_data6, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader6 = DataLoader(dataset=test_data6, batch_size=test_size1) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader7 = DataLoader(dataset=train_data7, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader7 = DataLoader(dataset=test_data7, batch_size=test_size1) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cardiac-chess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 299)\n",
      "(19, 299)\n",
      "(19, 299)\n",
      "(19, 299)\n",
      "(18, 299)\n",
      "(18, 299)\n",
      "(18, 299)\n",
      "(18, 299)\n"
     ]
    }
   ],
   "source": [
    "print(testing_fold_X_0.shape)\n",
    "print(testing_fold_X_1.shape)\n",
    "print(testing_fold_X_2.shape)\n",
    "print(testing_fold_X_3.shape)\n",
    "print(testing_fold_X_4.shape)\n",
    "print(testing_fold_X_5.shape)\n",
    "print(testing_fold_X_6.shape)\n",
    "print(testing_fold_X_7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "excited-account",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 298.\n",
    "        self.layer_1 = nn.Linear(D_in, H1) #298 -> 100\n",
    "        self.layer_2 = nn.Linear(H1, H2) #100 -> 15\n",
    "        self.layer_out = nn.Linear(H2, D_out) #15 -> 1\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=DROPOUT_RATE)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(100)\n",
    "        #self.batchnorm2 = nn.BatchNorm1d(15)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs)) #ReLU on the 298?\n",
    "        #x = self.batchnorm1(x) #Normalize the 100\n",
    "        x = self.dropout(x) #Dropout 15%\n",
    "        x = self.relu(self.layer_2(x)) #ReLU on the 100?\n",
    "        #x = self.batchnorm2(x) #Normalize the 15\n",
    "        x = self.layer_out(x) #1\n",
    "        \n",
    "        return x\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#Should use the CPU since I don't have a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "visible-potter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=299, out_features=100, bias=True)\n",
      "  (layer_2): Linear(in_features=100, out_features=15, bias=True)\n",
      "  (layer_out): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      ")\n",
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=299, out_features=100, bias=True)\n",
      "  (layer_2): Linear(in_features=100, out_features=15, bias=True)\n",
      "  (layer_out): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      ")\n",
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=299, out_features=100, bias=True)\n",
      "  (layer_2): Linear(in_features=100, out_features=15, bias=True)\n",
      "  (layer_out): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      ")\n",
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=299, out_features=100, bias=True)\n",
      "  (layer_2): Linear(in_features=100, out_features=15, bias=True)\n",
      "  (layer_out): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      ")\n",
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=299, out_features=100, bias=True)\n",
      "  (layer_2): Linear(in_features=100, out_features=15, bias=True)\n",
      "  (layer_out): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      ")\n",
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=299, out_features=100, bias=True)\n",
      "  (layer_2): Linear(in_features=100, out_features=15, bias=True)\n",
      "  (layer_out): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      ")\n",
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=299, out_features=100, bias=True)\n",
      "  (layer_2): Linear(in_features=100, out_features=15, bias=True)\n",
      "  (layer_out): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      ")\n",
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=299, out_features=100, bias=True)\n",
      "  (layer_2): Linear(in_features=100, out_features=15, bias=True)\n",
      "  (layer_out): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "weights = torch.FloatTensor([5]) #Class weights\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model1's actual architecture can be viewed in the forward function above.\n",
    "model1 = binaryClassification()\n",
    "model1.to(device)\n",
    "print(model1)\n",
    "weights = torch.FloatTensor([5]) #Class weights\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "optimizer = optim.Adam(model1.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model2's actual architecture can be viewed in the forward function above.\n",
    "model2 = binaryClassification()\n",
    "model2.to(device)\n",
    "print(model2)\n",
    "weights = torch.FloatTensor([5]) #Class weights\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "optimizer = optim.Adam(model2.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model3's actual architecture can be viewed in the forward function above.\n",
    "model3 = binaryClassification()\n",
    "model3.to(device)\n",
    "print(model3)\n",
    "weights = torch.FloatTensor([5]) #Class weights\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "optimizer = optim.Adam(model3.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model4's actual architecture can be viewed in the forward function above.\n",
    "model4 = binaryClassification()\n",
    "model4.to(device)\n",
    "print(model4)\n",
    "weights = torch.FloatTensor([5]) #Class weights\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "optimizer = optim.Adam(model4.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model5's actual architecture can be viewed in the forward function above.\n",
    "model5 = binaryClassification()\n",
    "model5.to(device)\n",
    "print(model5)\n",
    "weights = torch.FloatTensor([5]) #Class weights\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "optimizer = optim.Adam(model5.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model6's actual architecture can be viewed in the forward function above.\n",
    "model6 = binaryClassification()\n",
    "model6.to(device)\n",
    "print(model6)\n",
    "weights = torch.FloatTensor([5]) #Class weights\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "optimizer = optim.Adam(model6.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model7's actual architecture can be viewed in the forward function above.\n",
    "model7 = binaryClassification()\n",
    "model7.to(device)\n",
    "print(model7)\n",
    "weights = torch.FloatTensor([5]) #Class weights\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "optimizer = optim.Adam(model7.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "assumed-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to define accuracy. Should look to see if there is a prebuilt that I can use from sci-kit learn or something.\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "developed-enlargement",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (35x596 and 299x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-49183e440513>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-dcff38044f5f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#ReLU on the 298?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;31m#x = self.batchnorm1(x) #Normalize the 100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Dropout 15%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (35x596 and 299x100)"
     ]
    }
   ],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "model.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc.append(epoch_acc/len(train_loader))\n",
    "    train_loss.append(epoch_loss/len(train_loader))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    #Validation metrics here\n",
    "    model.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=33)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(Y_test.values))\n",
    "            val_loss.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(Y_test.values), y_pred_list)\n",
    "    ppv = precision_score(Y_test, y_pred_list, average=None)\n",
    "    recall = recall_score(Y_test, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc.append(accuracy*100)\n",
    "    model.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc1 = []\n",
    "train_acc1 = []\n",
    "train_loss1 = []\n",
    "val_loss1 = []\n",
    "\n",
    "model1.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer1.zero_grad()\n",
    "        \n",
    "        y_pred = model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc1.append(epoch_acc/len(train_loader1))\n",
    "    train_loss1.append(epoch_loss/len(train_loader1))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader1):.5f} | Acc: {epoch_acc/len(train_loader1):.3f}')\n",
    "    #Validation metrics here\n",
    "    model1.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader1 = DataLoader(dataset=test_data1, batch_size=test_size1)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader1:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model1(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_1))\n",
    "            val_loss1.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader = DataLoader(dataset=test_data1, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model1(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_1), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_1, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_1, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc1.append(accuracy*100)\n",
    "    model1.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc2 = []\n",
    "train_acc2 = []\n",
    "train_loss2 = []\n",
    "val_loss2 = []\n",
    "\n",
    "model2.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        y_pred = model2(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc2.append(epoch_acc/len(train_loader2))\n",
    "    train_loss2.append(epoch_loss/len(train_loader2))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader2):.5f} | Acc: {epoch_acc/len(train_loader2):.3f}')\n",
    "    #Validation metrics here\n",
    "    model2.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader2 = DataLoader(dataset=test_data2, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader2:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model2(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_2))\n",
    "            val_loss2.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader2 = DataLoader(dataset=test_data2, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader2:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model2(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_2), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_2, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_2, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc2.append(accuracy*100)\n",
    "    model2.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc3 = []\n",
    "train_acc3 = []\n",
    "train_loss3 = []\n",
    "val_loss3 = []\n",
    "\n",
    "model3.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader3:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer3.zero_grad()\n",
    "        \n",
    "        y_pred = model3(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer3.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc3.append(epoch_acc/len(train_loader3))\n",
    "    train_loss3.append(epoch_loss/len(train_loader3))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader3):.5f} | Acc: {epoch_acc/len(train_loader3):.3f}')\n",
    "    #Validation metrics here\n",
    "    model3.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader3 = DataLoader(dataset=test_data3, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader3:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model3(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_3))\n",
    "            val_loss3.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader3 = DataLoader(dataset=test_data3, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader3:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model3(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_3), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_3, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_3, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc3.append(accuracy*100)\n",
    "    model3.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc4 = []\n",
    "train_acc4 = []\n",
    "train_loss4 = []\n",
    "val_loss4 = []\n",
    "\n",
    "model4.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader4:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer4.zero_grad()\n",
    "        \n",
    "        y_pred = model4(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer4.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc4.append(epoch_acc/len(train_loader4))\n",
    "    train_loss4.append(epoch_loss/len(train_loader4))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader4):.5f} | Acc: {epoch_acc/len(train_loader4):.3f}')\n",
    "    #Validation metrics here\n",
    "    model4.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader4 = DataLoader(dataset=test_data4, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader4:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model4(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_4))\n",
    "            val_loss4.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader4 = DataLoader(dataset=test_data4, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader4:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model4(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_4), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_4, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_4, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc4.append(accuracy*100)\n",
    "    model4.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc5 = []\n",
    "train_acc5 = []\n",
    "train_loss5 = []\n",
    "val_loss5 = []\n",
    "\n",
    "model5.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader5:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer5.zero_grad()\n",
    "        \n",
    "        y_pred = model5(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer5.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc5.append(epoch_acc/len(train_loader5))\n",
    "    train_loss5.append(epoch_loss/len(train_loader5))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader5):.5f} | Acc: {epoch_acc/len(train_loader5):.3f}')\n",
    "    #Validation metrics here\n",
    "    model5.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader5 = DataLoader(dataset=test_data5, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader5:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model5(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_5))\n",
    "            val_loss5.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader5 = DataLoader(dataset=test_data5, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader5:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model5(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_5), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_5, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_5, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc5.append(accuracy*100)\n",
    "    model5.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc6 = []\n",
    "train_acc6 = []\n",
    "train_loss6 = []\n",
    "val_loss6 = []\n",
    "\n",
    "model6.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader6:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer6.zero_grad()\n",
    "        \n",
    "        y_pred = model6(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer6.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc6.append(epoch_acc/len(train_loader6))\n",
    "    train_loss6.append(epoch_loss/len(train_loader6))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader6):.5f} | Acc: {epoch_acc/len(train_loader6):.3f}')\n",
    "    #Validation metrics here\n",
    "    model6.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader6 = DataLoader(dataset=test_data6, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader6:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model6(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_6))\n",
    "            val_loss6.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader6 = DataLoader(dataset=test_data6, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader6:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model6(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_6), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_6, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_6, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc6.append(accuracy*100)\n",
    "    model6.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that you’re in training mode.\n",
    "#Similarly, we’ll call model.eval() when we test our model. We’ll see that below.\n",
    "'''If you’re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you don’t explicitly have to write that. But it’s good practice.'''\n",
    "val_acc7 = []\n",
    "train_acc7 = []\n",
    "train_loss7 = []\n",
    "val_loss7 = []\n",
    "\n",
    "model7.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader7:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer7.zero_grad()\n",
    "        \n",
    "        y_pred = model7(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer7.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc7.append(epoch_acc/len(train_loader7))\n",
    "    train_loss7.append(epoch_loss/len(train_loader7))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader7):.5f} | Acc: {epoch_acc/len(train_loader7):.3f}')\n",
    "    #Validation metrics here\n",
    "    model7.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader7 = DataLoader(dataset=test_data7, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader7:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model7(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_7))\n",
    "            val_loss7.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader7 = DataLoader(dataset=test_data7, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader7:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model7(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_7), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_7, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_7, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc7.append(accuracy*100)\n",
    "    model7.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting loss\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss1)\n",
    "plt.plot(val_loss1)\n",
    "plt.title('model1 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc1)\n",
    "plt.plot(val_acc1)\n",
    "plt.title('model1 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss2)\n",
    "plt.plot(val_loss2)\n",
    "plt.title('model2 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc2)\n",
    "plt.plot(val_acc2)\n",
    "plt.title('model2 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss3)\n",
    "plt.plot(val_loss3)\n",
    "plt.title('model3 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc3)\n",
    "plt.plot(val_acc3)\n",
    "plt.title('model3 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss4)\n",
    "plt.plot(val_loss4)\n",
    "plt.title('model4 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc4)\n",
    "plt.plot(val_acc4)\n",
    "plt.title('model4 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss5)\n",
    "plt.plot(val_loss5)\n",
    "plt.title('model5 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc5)\n",
    "plt.plot(val_acc5)\n",
    "plt.title('model5 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss6)\n",
    "plt.plot(val_loss6)\n",
    "plt.title('model6 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc6)\n",
    "plt.plot(val_acc6)\n",
    "plt.title('model6 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss7)\n",
    "plt.plot(val_loss7)\n",
    "plt.title('model7 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc7)\n",
    "plt.plot(val_acc7)\n",
    "plt.title('model7 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = []\n",
    "final_prediction_true = []\n",
    "\n",
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "model.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_0, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_0, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_0, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_0, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_0:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data1, batch_size=1)\n",
    "model1.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_1, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_1, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_1, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_1, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_1:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data2, batch_size=1)\n",
    "model2.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model2(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_2, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_2, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_2, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_2, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_2:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data3, batch_size=1)\n",
    "model3.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model3(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_3, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_3, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_3, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_3, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_3:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data4, batch_size=1)\n",
    "model4.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model4(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_4, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_4, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_4, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_4, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_4:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data5, batch_size=1)\n",
    "model5.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model5(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_5, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_5, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_5, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_5, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_5:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data6, batch_size=1)\n",
    "model6.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model6(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_6, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_6, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_6, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_6, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_6:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data7, batch_size=1)\n",
    "model7.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model7(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_7, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_7, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_7, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_7, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_7:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels = []\n",
    "true_labels = []\n",
    "\n",
    "for x in range(0,len(final_prediction_true)):\n",
    "    true_labels.append(final_prediction_true[x][0])\n",
    "    prediction_labels.append(final_prediction[x][0][0])\n",
    "\n",
    "prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(true_labels, prediction_labels)\n",
    "print(cf_matrix)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(true_labels, prediction_labels)\n",
    "recall = recall_score(true_labels, prediction_labels, average=None)\n",
    "prec_score = precision_score(true_labels, prediction_labels, average=None)\n",
    "print('Positive Predictive Value tp/(tp+fp): ',prec_score[1]) \n",
    "print('Accuracy Value (tp+tn)/(tp+fp+fn+tn): ',accuracy) \n",
    "print('Recall Value tp/(tp+fn): ',recall[1]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
