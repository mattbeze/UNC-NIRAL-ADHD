{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras import losses\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "\n",
    "ct_sheet = pd.ExcelFile(\"All CTSA 2-1yr.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(585, 148)\n",
      "(585, 148)\n",
      "Tensor(\"input_1:0\", shape=(None, 148), dtype=float32)\n",
      "Train on 526 samples, validate on 59 samples\n",
      "Epoch 1/150\n",
      "526/526 [==============================] - 1s 2ms/step - loss: 0.1762 - val_loss: 0.0945\n",
      "Epoch 2/150\n",
      "526/526 [==============================] - 0s 134us/step - loss: 0.1059 - val_loss: 0.0851\n",
      "Epoch 3/150\n",
      "526/526 [==============================] - 0s 143us/step - loss: 0.0939 - val_loss: 0.0755\n",
      "Epoch 4/150\n",
      "526/526 [==============================] - 0s 142us/step - loss: 0.0876 - val_loss: 0.0742\n",
      "Epoch 5/150\n",
      "526/526 [==============================] - 0s 156us/step - loss: 0.0860 - val_loss: 0.0731\n",
      "Epoch 6/150\n",
      "526/526 [==============================] - 0s 139us/step - loss: 0.0831 - val_loss: 0.0725\n",
      "Epoch 7/150\n",
      "526/526 [==============================] - 0s 144us/step - loss: 0.0829 - val_loss: 0.0723\n",
      "Epoch 8/150\n",
      "526/526 [==============================] - 0s 143us/step - loss: 0.0807 - val_loss: 0.0742\n",
      "Epoch 9/150\n",
      "526/526 [==============================] - 0s 143us/step - loss: 0.0801 - val_loss: 0.0723\n",
      "Epoch 10/150\n",
      "526/526 [==============================] - 0s 144us/step - loss: 0.0807 - val_loss: 0.0739\n",
      "Epoch 11/150\n",
      "526/526 [==============================] - 0s 139us/step - loss: 0.0797 - val_loss: 0.0729\n",
      "Epoch 12/150\n",
      "526/526 [==============================] - 0s 146us/step - loss: 0.0779 - val_loss: 0.0720\n",
      "Epoch 13/150\n",
      "526/526 [==============================] - 0s 240us/step - loss: 0.0782 - val_loss: 0.0715\n",
      "Epoch 14/150\n",
      "526/526 [==============================] - 0s 183us/step - loss: 0.0778 - val_loss: 0.0720\n",
      "Epoch 15/150\n",
      "526/526 [==============================] - 0s 156us/step - loss: 0.0772 - val_loss: 0.0721\n",
      "Epoch 16/150\n",
      "526/526 [==============================] - 0s 156us/step - loss: 0.0772 - val_loss: 0.0719\n",
      "Epoch 17/150\n",
      "526/526 [==============================] - 0s 156us/step - loss: 0.0768 - val_loss: 0.0714\n",
      "Epoch 18/150\n",
      "526/526 [==============================] - 0s 168us/step - loss: 0.0771 - val_loss: 0.0715\n",
      "Epoch 19/150\n",
      "526/526 [==============================] - 0s 168us/step - loss: 0.0770 - val_loss: 0.0719\n",
      "Epoch 20/150\n",
      "526/526 [==============================] - 0s 252us/step - loss: 0.0772 - val_loss: 0.0702\n",
      "Epoch 21/150\n",
      "526/526 [==============================] - 0s 167us/step - loss: 0.0754 - val_loss: 0.0718\n",
      "Epoch 22/150\n",
      "526/526 [==============================] - 0s 169us/step - loss: 0.0766 - val_loss: 0.0705\n",
      "Epoch 23/150\n",
      "526/526 [==============================] - 0s 150us/step - loss: 0.0754 - val_loss: 0.0741\n",
      "Epoch 24/150\n",
      "526/526 [==============================] - 0s 141us/step - loss: 0.0756 - val_loss: 0.0699\n",
      "Epoch 25/150\n",
      "526/526 [==============================] - 0s 126us/step - loss: 0.0754 - val_loss: 0.0714\n",
      "Epoch 26/150\n",
      "526/526 [==============================] - 0s 166us/step - loss: 0.0750 - val_loss: 0.0736\n",
      "Epoch 27/150\n",
      "526/526 [==============================] - 0s 145us/step - loss: 0.0751 - val_loss: 0.0712\n",
      "Epoch 28/150\n",
      "526/526 [==============================] - 0s 145us/step - loss: 0.0742 - val_loss: 0.0741\n",
      "Epoch 29/150\n",
      "526/526 [==============================] - 0s 144us/step - loss: 0.0759 - val_loss: 0.0700\n",
      "Epoch 30/150\n",
      "526/526 [==============================] - 0s 141us/step - loss: 0.0747 - val_loss: 0.0718\n",
      "Epoch 31/150\n",
      "526/526 [==============================] - 0s 152us/step - loss: 0.0750 - val_loss: 0.0719\n",
      "Epoch 32/150\n",
      "526/526 [==============================] - 0s 224us/step - loss: 0.0748 - val_loss: 0.0697\n",
      "Epoch 33/150\n",
      "526/526 [==============================] - 0s 249us/step - loss: 0.0744 - val_loss: 0.0693\n",
      "Epoch 34/150\n",
      "526/526 [==============================] - 0s 150us/step - loss: 0.0741 - val_loss: 0.0705\n",
      "Epoch 35/150\n",
      "526/526 [==============================] - 0s 154us/step - loss: 0.0741 - val_loss: 0.0689\n",
      "Epoch 36/150\n",
      "526/526 [==============================] - 0s 141us/step - loss: 0.0741 - val_loss: 0.0695\n",
      "Epoch 37/150\n",
      "526/526 [==============================] - 0s 147us/step - loss: 0.0743 - val_loss: 0.0688\n",
      "Epoch 38/150\n",
      "526/526 [==============================] - 0s 140us/step - loss: 0.0744 - val_loss: 0.0709\n",
      "Epoch 39/150\n",
      "526/526 [==============================] - 0s 237us/step - loss: 0.0742 - val_loss: 0.0691\n",
      "Epoch 40/150\n",
      "526/526 [==============================] - 0s 158us/step - loss: 0.0740 - val_loss: 0.0705\n",
      "Epoch 41/150\n",
      "526/526 [==============================] - 0s 157us/step - loss: 0.0740 - val_loss: 0.0695\n",
      "Epoch 42/150\n",
      "526/526 [==============================] - 0s 144us/step - loss: 0.0729 - val_loss: 0.0685\n",
      "Epoch 43/150\n",
      "526/526 [==============================] - 0s 146us/step - loss: 0.0728 - val_loss: 0.0690\n",
      "Epoch 44/150\n",
      "526/526 [==============================] - 0s 121us/step - loss: 0.0727 - val_loss: 0.0689\n",
      "Epoch 45/150\n",
      "526/526 [==============================] - 0s 163us/step - loss: 0.0734 - val_loss: 0.0694\n",
      "Epoch 46/150\n",
      "526/526 [==============================] - 0s 138us/step - loss: 0.0737 - val_loss: 0.0702\n",
      "Epoch 47/150\n",
      "526/526 [==============================] - 0s 139us/step - loss: 0.0736 - val_loss: 0.0702\n",
      "Epoch 48/150\n",
      "526/526 [==============================] - 0s 263us/step - loss: 0.0731 - val_loss: 0.0689\n",
      "Epoch 49/150\n",
      "526/526 [==============================] - 0s 175us/step - loss: 0.0721 - val_loss: 0.0686\n",
      "Epoch 50/150\n",
      "526/526 [==============================] - 0s 158us/step - loss: 0.0724 - val_loss: 0.0701\n",
      "Epoch 51/150\n",
      "526/526 [==============================] - 0s 141us/step - loss: 0.0729 - val_loss: 0.0687\n",
      "Epoch 52/150\n",
      "526/526 [==============================] - 0s 154us/step - loss: 0.0726 - val_loss: 0.0683\n",
      "Epoch 53/150\n",
      "526/526 [==============================] - 0s 124us/step - loss: 0.0722 - val_loss: 0.0685\n",
      "Epoch 54/150\n",
      "526/526 [==============================] - 0s 144us/step - loss: 0.0734 - val_loss: 0.0683\n",
      "Epoch 55/150\n",
      "526/526 [==============================] - 0s 277us/step - loss: 0.0725 - val_loss: 0.0698\n",
      "Epoch 56/150\n",
      "526/526 [==============================] - 0s 171us/step - loss: 0.0713 - val_loss: 0.0710\n",
      "Epoch 57/150\n",
      "526/526 [==============================] - 0s 141us/step - loss: 0.0724 - val_loss: 0.0686\n",
      "Epoch 58/150\n",
      "526/526 [==============================] - 0s 141us/step - loss: 0.0720 - val_loss: 0.0708\n",
      "Epoch 59/150\n",
      "526/526 [==============================] - 0s 139us/step - loss: 0.0719 - val_loss: 0.0700\n",
      "Epoch 60/150\n",
      "526/526 [==============================] - 0s 126us/step - loss: 0.0721 - val_loss: 0.0685\n",
      "Epoch 61/150\n",
      "526/526 [==============================] - 0s 151us/step - loss: 0.0728 - val_loss: 0.0708\n",
      "Epoch 62/150\n",
      "526/526 [==============================] - 0s 138us/step - loss: 0.0727 - val_loss: 0.0701\n",
      "Epoch 63/150\n",
      "526/526 [==============================] - 0s 139us/step - loss: 0.0716 - val_loss: 0.0680\n",
      "Epoch 64/150\n",
      "526/526 [==============================] - 0s 148us/step - loss: 0.0719 - val_loss: 0.0684\n",
      "Epoch 65/150\n",
      "526/526 [==============================] - 0s 130us/step - loss: 0.0728 - val_loss: 0.0687\n",
      "Epoch 66/150\n",
      "526/526 [==============================] - 0s 208us/step - loss: 0.0713 - val_loss: 0.0706\n",
      "Epoch 67/150\n",
      "526/526 [==============================] - 0s 201us/step - loss: 0.0720 - val_loss: 0.0724\n",
      "Epoch 68/150\n",
      "526/526 [==============================] - 0s 148us/step - loss: 0.0724 - val_loss: 0.0687\n",
      "Epoch 69/150\n",
      "526/526 [==============================] - 0s 143us/step - loss: 0.0727 - val_loss: 0.0708\n",
      "Epoch 70/150\n",
      "526/526 [==============================] - 0s 120us/step - loss: 0.0719 - val_loss: 0.0690\n",
      "Epoch 71/150\n",
      "526/526 [==============================] - 0s 152us/step - loss: 0.0710 - val_loss: 0.0685\n",
      "Epoch 72/150\n",
      "526/526 [==============================] - ETA: 0s - loss: 0.071 - 0s 171us/step - loss: 0.0714 - val_loss: 0.0680\n",
      "Epoch 73/150\n",
      "526/526 [==============================] - 0s 154us/step - loss: 0.0715 - val_loss: 0.0689\n",
      "Epoch 74/150\n",
      "526/526 [==============================] - 0s 116us/step - loss: 0.0709 - val_loss: 0.0681\n",
      "Epoch 75/150\n",
      "526/526 [==============================] - 0s 157us/step - loss: 0.0719 - val_loss: 0.0679\n",
      "Epoch 76/150\n",
      "526/526 [==============================] - 0s 186us/step - loss: 0.0725 - val_loss: 0.0695\n",
      "Epoch 77/150\n",
      "526/526 [==============================] - 0s 190us/step - loss: 0.0712 - val_loss: 0.0682\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526/526 [==============================] - 0s 144us/step - loss: 0.0715 - val_loss: 0.0694\n",
      "Epoch 79/150\n",
      "526/526 [==============================] - 0s 146us/step - loss: 0.0705 - val_loss: 0.0698\n",
      "Epoch 80/150\n",
      "526/526 [==============================] - 0s 146us/step - loss: 0.0708 - val_loss: 0.0700\n",
      "Epoch 81/150\n",
      "526/526 [==============================] - 0s 150us/step - loss: 0.0711 - val_loss: 0.0704\n",
      "Epoch 82/150\n",
      "526/526 [==============================] - 0s 170us/step - loss: 0.0709 - val_loss: 0.0688\n",
      "Epoch 83/150\n",
      "526/526 [==============================] - 0s 221us/step - loss: 0.0708 - val_loss: 0.0684\n",
      "Epoch 84/150\n",
      "526/526 [==============================] - 0s 249us/step - loss: 0.0715 - val_loss: 0.0706\n",
      "Epoch 85/150\n",
      "526/526 [==============================] - 0s 179us/step - loss: 0.0717 - val_loss: 0.0698\n",
      "Epoch 86/150\n",
      "526/526 [==============================] - 0s 143us/step - loss: 0.0712 - val_loss: 0.0680\n",
      "Epoch 87/150\n",
      "526/526 [==============================] - 0s 154us/step - loss: 0.0708 - val_loss: 0.0692\n",
      "Epoch 88/150\n",
      "526/526 [==============================] - 0s 152us/step - loss: 0.0705 - val_loss: 0.0682\n",
      "Epoch 89/150\n",
      "526/526 [==============================] - 0s 152us/step - loss: 0.0705 - val_loss: 0.0701\n",
      "Epoch 90/150\n",
      "526/526 [==============================] - 0s 154us/step - loss: 0.0709 - val_loss: 0.0689\n",
      "Epoch 91/150\n",
      "526/526 [==============================] - 0s 156us/step - loss: 0.0706 - val_loss: 0.0687\n",
      "Epoch 92/150\n",
      "526/526 [==============================] - 0s 151us/step - loss: 0.0707 - val_loss: 0.0720\n",
      "Epoch 93/150\n",
      "526/526 [==============================] - 0s 156us/step - loss: 0.0709 - val_loss: 0.0685\n",
      "Epoch 94/150\n",
      "526/526 [==============================] - 0s 154us/step - loss: 0.0703 - val_loss: 0.0687\n",
      "Epoch 95/150\n",
      "526/526 [==============================] - 0s 173us/step - loss: 0.0705 - val_loss: 0.0714\n",
      "Epoch 96/150\n",
      "526/526 [==============================] - 0s 196us/step - loss: 0.0713 - val_loss: 0.0685\n",
      "Epoch 97/150\n",
      "526/526 [==============================] - 0s 134us/step - loss: 0.0705 - val_loss: 0.0700\n",
      "Epoch 98/150\n",
      "526/526 [==============================] - 0s 207us/step - loss: 0.0701 - val_loss: 0.0701\n",
      "Epoch 99/150\n",
      "526/526 [==============================] - 0s 154us/step - loss: 0.0706 - val_loss: 0.0701\n",
      "Epoch 100/150\n",
      "526/526 [==============================] - 0s 119us/step - loss: 0.0707 - val_loss: 0.0686\n",
      "Epoch 101/150\n",
      "526/526 [==============================] - 0s 126us/step - loss: 0.0706 - val_loss: 0.0694\n",
      "Epoch 102/150\n",
      "526/526 [==============================] - 0s 191us/step - loss: 0.0698 - val_loss: 0.0680\n",
      "Epoch 103/150\n",
      "526/526 [==============================] - 0s 160us/step - loss: 0.0703 - val_loss: 0.0687\n",
      "Epoch 104/150\n",
      "526/526 [==============================] - 0s 156us/step - loss: 0.0701 - val_loss: 0.0691\n",
      "Epoch 105/150\n",
      "526/526 [==============================] - 0s 158us/step - loss: 0.0699 - val_loss: 0.0695\n",
      "Epoch 106/150\n",
      "526/526 [==============================] - 0s 158us/step - loss: 0.0698 - val_loss: 0.0694\n",
      "Epoch 107/150\n",
      "526/526 [==============================] - 0s 150us/step - loss: 0.0697 - val_loss: 0.0684\n",
      "Epoch 108/150\n",
      "526/526 [==============================] - 0s 152us/step - loss: 0.0709 - val_loss: 0.0695\n",
      "Epoch 109/150\n",
      "526/526 [==============================] - 0s 182us/step - loss: 0.0705 - val_loss: 0.0693\n",
      "Epoch 110/150\n",
      "526/526 [==============================] - 0s 230us/step - loss: 0.0700 - val_loss: 0.0693\n",
      "Epoch 111/150\n",
      "526/526 [==============================] - 0s 300us/step - loss: 0.0692 - val_loss: 0.0696\n",
      "Epoch 112/150\n",
      "526/526 [==============================] - 0s 177us/step - loss: 0.0696 - val_loss: 0.0684\n",
      "Epoch 113/150\n",
      "526/526 [==============================] - 0s 164us/step - loss: 0.0701 - val_loss: 0.0692\n",
      "Epoch 114/150\n",
      "526/526 [==============================] - 0s 152us/step - loss: 0.0699 - val_loss: 0.0687\n",
      "Epoch 115/150\n",
      "526/526 [==============================] - 0s 152us/step - loss: 0.0694 - val_loss: 0.0707\n",
      "Epoch 116/150\n",
      "526/526 [==============================] - 0s 152us/step - loss: 0.0701 - val_loss: 0.0684\n",
      "Epoch 117/150\n",
      "526/526 [==============================] - 0s 275us/step - loss: 0.0701 - val_loss: 0.0694\n",
      "Epoch 118/150\n",
      "526/526 [==============================] - 0s 279us/step - loss: 0.0696 - val_loss: 0.0694\n",
      "Epoch 119/150\n",
      "526/526 [==============================] - 0s 166us/step - loss: 0.0689 - val_loss: 0.0705\n",
      "Epoch 120/150\n",
      "526/526 [==============================] - 0s 149us/step - loss: 0.0694 - val_loss: 0.0707\n",
      "Epoch 121/150\n",
      "526/526 [==============================] - 0s 150us/step - loss: 0.0697 - val_loss: 0.0710\n",
      "Epoch 122/150\n",
      "526/526 [==============================] - 0s 149us/step - loss: 0.0703 - val_loss: 0.0685\n",
      "Epoch 123/150\n",
      "526/526 [==============================] - 0s 149us/step - loss: 0.0707 - val_loss: 0.0687\n",
      "Epoch 124/150\n",
      "526/526 [==============================] - 0s 149us/step - loss: 0.0697 - val_loss: 0.0678\n",
      "Epoch 125/150\n",
      "526/526 [==============================] - 0s 149us/step - loss: 0.0698 - val_loss: 0.0708\n",
      "Epoch 126/150\n",
      "526/526 [==============================] - 0s 149us/step - loss: 0.0691 - val_loss: 0.0704\n",
      "Epoch 127/150\n",
      "526/526 [==============================] - 0s 157us/step - loss: 0.0702 - val_loss: 0.0703\n",
      "Epoch 128/150\n",
      "526/526 [==============================] - 0s 178us/step - loss: 0.0696 - val_loss: 0.0686\n",
      "Epoch 129/150\n",
      "526/526 [==============================] - 0s 178us/step - loss: 0.0707 - val_loss: 0.0688\n",
      "Epoch 130/150\n",
      "526/526 [==============================] - 0s 149us/step - loss: 0.0698 - val_loss: 0.0700\n",
      "Epoch 131/150\n",
      "526/526 [==============================] - 0s 149us/step - loss: 0.0697 - val_loss: 0.0696\n",
      "Epoch 132/150\n",
      "526/526 [==============================] - 0s 178us/step - loss: 0.0693 - val_loss: 0.0700\n",
      "Epoch 133/150\n",
      "526/526 [==============================] - 0s 163us/step - loss: 0.0694 - val_loss: 0.0704\n",
      "Epoch 134/150\n",
      "526/526 [==============================] - 0s 149us/step - loss: 0.0702 - val_loss: 0.0696\n",
      "Epoch 135/150\n",
      "526/526 [==============================] - 0s 178us/step - loss: 0.0699 - val_loss: 0.0678\n",
      "Epoch 136/150\n",
      "526/526 [==============================] - 0s 146us/step - loss: 0.0690 - val_loss: 0.0686\n",
      "Epoch 137/150\n",
      "526/526 [==============================] - 0s 170us/step - loss: 0.0693 - val_loss: 0.0697\n",
      "Epoch 138/150\n",
      "526/526 [==============================] - ETA: 0s - loss: 0.068 - 0s 177us/step - loss: 0.0692 - val_loss: 0.0715\n",
      "Epoch 139/150\n",
      "526/526 [==============================] - 0s 191us/step - loss: 0.0694 - val_loss: 0.0694\n",
      "Epoch 140/150\n",
      "526/526 [==============================] - 0s 136us/step - loss: 0.0694 - val_loss: 0.0697\n",
      "Epoch 141/150\n",
      "526/526 [==============================] - 0s 139us/step - loss: 0.0694 - val_loss: 0.0679\n",
      "Epoch 142/150\n",
      "526/526 [==============================] - 0s 152us/step - loss: 0.0700 - val_loss: 0.0693\n",
      "Epoch 143/150\n",
      "526/526 [==============================] - 0s 172us/step - loss: 0.0689 - val_loss: 0.0701\n",
      "Epoch 144/150\n",
      "526/526 [==============================] - 0s 140us/step - loss: 0.0687 - val_loss: 0.0716\n",
      "Epoch 145/150\n",
      "526/526 [==============================] - 0s 178us/step - loss: 0.0689 - val_loss: 0.0701\n",
      "Epoch 146/150\n",
      "526/526 [==============================] - 0s 165us/step - loss: 0.0687 - val_loss: 0.0696\n",
      "Epoch 147/150\n",
      "526/526 [==============================] - 0s 170us/step - loss: 0.0687 - val_loss: 0.0693\n",
      "Epoch 148/150\n",
      "526/526 [==============================] - 0s 168us/step - loss: 0.0687 - val_loss: 0.0718\n",
      "Epoch 149/150\n",
      "526/526 [==============================] - 0s 198us/step - loss: 0.0688 - val_loss: 0.0699\n",
      "Epoch 150/150\n",
      "526/526 [==============================] - 0s 263us/step - loss: 0.0693 - val_loss: 0.0707\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parsee = ct_sheet.sheet_names[0]\n",
    "data = ct_sheet.parse(parsee)\n",
    "data_features = data.loc[:, data.columns] \n",
    "data_features = data_features.drop(['ROI',11142,12142], axis=1)  \n",
    "\n",
    "parsee2 = ct_sheet.sheet_names[1]\n",
    "data2 = ct_sheet.parse(parsee2)\n",
    "data_labels = data2.loc[:, data2.columns] \n",
    "data_labels = data_labels.drop(['ROI',11142,12142], axis=1)  \n",
    "#Get rid of subject names to only have features now. #Need to remove ROIs. They don't convert to floats.\n",
    "#Get rid of ctx_rh_Medial_wall and ctx_lh_Medial_wall, not needed for analysis.\n",
    "#Have to standardize data. Scikit learn here. Need to create stratified K folds to avoid uneven distribution of risk groups.pcaCT1Y = PCA(n_components=150) #150 Features\n",
    "scaler_filename = \"IBIS_scaledCT1y.save\"\n",
    "scaler = joblib.load(scaler_filename)\n",
    "scaled_data = scaler.transform(data_features)\n",
    "\n",
    "scaler_filename2 = \"IBIS_scaledCT2y.save\"\n",
    "scaler2 = joblib.load(scaler_filename2)\n",
    "scaled_labels = scaler.transform(data_labels)\n",
    "print(scaled_data.shape)\n",
    "print(scaled_labels.shape)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(scaled_data, scaled_labels, test_size=0.10, random_state=20)\n",
    "\n",
    "#Size of encoded representation\n",
    "#{'batch_size': 20, 'dropout': 0.2, 'encoded_layer_size': 25, 'epochs': 150, 'layer1_size': 100, 'layer2_size': 25}\n",
    "input_size = 148\n",
    "hidden_size = 100\n",
    "hidden_size_2 = 25\n",
    "encoding_dim = 25\n",
    "dropout = 0.2\n",
    "\n",
    "# Input Placeholder\n",
    "input_data = Input(shape=(input_size,))\n",
    "print(input_data)\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "hidden_e_1 = Dense(hidden_size, activation='tanh')(input_data) \n",
    "hidden_e_2 = Dense(hidden_size_2, activation='tanh')(hidden_e_1)\n",
    "dropout_layer = Dropout(dropout)(hidden_e_2)\n",
    "encoded = Dense(encoding_dim, activation='tanh')(dropout_layer)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "hidden_d_1 = Dense(hidden_size, activation='tanh')(encoded)\n",
    "dropout_layer_d = Dropout(dropout)(hidden_d_1)\n",
    "hidden_d_2 = Dense(hidden_size, activation='tanh')(dropout_layer_d)\n",
    "decoded = Dense(input_size, activation='tanh')(hidden_d_2) \n",
    "# this model maps an input to its prediction\n",
    "autoencoder = Model(input_data, decoded)\n",
    "# configure our model to use mean_absolute_error loss function, and the Adam optimizer:\n",
    "autoencoder.compile(optimizer='Adam', loss='mean_absolute_error')\n",
    "\n",
    "ac = autoencoder.fit(X_train, Y_train,\n",
    "epochs=150,\n",
    "batch_size=20,\n",
    "shuffle=True,\n",
    "validation_data=(X_test, Y_test))\n",
    "\n",
    "#print(ac.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(ac.history['loss'])\n",
    "plt.plot(ac.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, 150, 0.0, 0.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
