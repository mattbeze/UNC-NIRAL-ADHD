{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "simple-navigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c546994a30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.combine import SMOTETomek\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, precision_score, precision_recall_curve, average_precision_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, ReLU, Sigmoid, Module, BCELoss, BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "import time\n",
    "\n",
    "seed_value = 7\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import torch\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "independent-welding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 300)\n",
      "(127, 1)\n"
     ]
    }
   ],
   "source": [
    "Training_Data = pd.ExcelFile(\"Training Data.xlsx\") #Training Data already pre-scaled to the IBIS Data set\n",
    "Label_Data = pd.ExcelFile(\"Labels.xlsx\") #Labels\n",
    "data = Training_Data.parse(Training_Data.sheet_names[1])\n",
    "label_data = Label_Data.parse(Label_Data.sheet_names[1])\n",
    "data_features = data.loc[:, data.columns]\n",
    "data_features = data_features.drop(['ROI','MATCH DEMOS','INDEX SEX','MATCH BASC2','INDEX GA', 'HYP', 'INDEX MEDU', 'MATCH DEMOS OLD', 'INDEX AGE'], axis=1)\n",
    "data_features = data_features.dropna()\n",
    "data_features = data_features.drop(['ATP'], axis=1)\n",
    "labels = label_data.loc[:, label_data.columns]\n",
    "labels = labels.drop(['ROI','MATCH BASC2', 'INDEX ATP', 'INDEX HYP', 'HYP'], axis=1)\n",
    "labels = labels.dropna()\n",
    "print(data_features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defined-monroe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=8, random_state=None, shuffle=False)\n",
      "(190, 300)\n",
      "(190, 300)\n",
      "(190, 300)\n",
      "(190, 300)\n",
      "(190, 300)\n",
      "(192, 300)\n",
      "(192, 300)\n",
      "(192, 300)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=8)\n",
    "skf.get_n_splits(data_features, labels)\n",
    "print(skf)\n",
    "\n",
    "training_indices_X = []\n",
    "testing_indices_X = []\n",
    "training_indices_Y = []\n",
    "testing_indices_Y = []\n",
    "\n",
    "for train_index, test_index in skf.split(data_features, labels):\n",
    "  \n",
    "    X_train, X_test = data_features.iloc[train_index], data_features.iloc[test_index]\n",
    "    Y_train, Y_test = labels.iloc[train_index], labels.iloc[test_index]\n",
    "   \n",
    "    sm = SMOTE(sampling_strategy = 'minority', random_state = seed_value, k_neighbors=2) \n",
    "    X_train_res, Y_train_res = sm.fit_sample(X_train, Y_train) #Only smote the training set.\n",
    "    print(X_train_res.shape)\n",
    "    training_indices_X.append(X_train_res)\n",
    "    testing_indices_X.append(X_test)\n",
    "    training_indices_Y.append(Y_train_res)\n",
    "    testing_indices_Y.append(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "informed-hawaii",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>SEX</th>\n",
       "      <th>Gestational Age</th>\n",
       "      <th>Maternal Education MEDU</th>\n",
       "      <th>Age at MRI 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.293787</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.025914</td>\n",
       "      <td>0.167209</td>\n",
       "      <td>-0.327508</td>\n",
       "      <td>-0.292465</td>\n",
       "      <td>-0.348738</td>\n",
       "      <td>-0.218615</td>\n",
       "      <td>-0.078855</td>\n",
       "      <td>-0.086240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334543</td>\n",
       "      <td>0.743217</td>\n",
       "      <td>0.229896</td>\n",
       "      <td>0.115003</td>\n",
       "      <td>0.613862</td>\n",
       "      <td>0.419573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.161644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.134314</td>\n",
       "      <td>0.048638</td>\n",
       "      <td>0.157068</td>\n",
       "      <td>-0.118706</td>\n",
       "      <td>-0.098239</td>\n",
       "      <td>-0.109438</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>-0.336313</td>\n",
       "      <td>0.074765</td>\n",
       "      <td>0.071769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216634</td>\n",
       "      <td>0.271318</td>\n",
       "      <td>0.347661</td>\n",
       "      <td>0.134042</td>\n",
       "      <td>0.413723</td>\n",
       "      <td>0.255445</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.024658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.163454</td>\n",
       "      <td>0.075192</td>\n",
       "      <td>-0.022291</td>\n",
       "      <td>-0.138708</td>\n",
       "      <td>-0.049811</td>\n",
       "      <td>0.057390</td>\n",
       "      <td>-0.165016</td>\n",
       "      <td>-0.404240</td>\n",
       "      <td>-0.087664</td>\n",
       "      <td>-0.077308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226022</td>\n",
       "      <td>0.419697</td>\n",
       "      <td>0.351481</td>\n",
       "      <td>0.487143</td>\n",
       "      <td>0.186957</td>\n",
       "      <td>0.223046</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.972603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.173784</td>\n",
       "      <td>-0.086895</td>\n",
       "      <td>-0.044482</td>\n",
       "      <td>-0.140339</td>\n",
       "      <td>-0.132705</td>\n",
       "      <td>-0.341187</td>\n",
       "      <td>-0.244494</td>\n",
       "      <td>-0.364035</td>\n",
       "      <td>-0.062480</td>\n",
       "      <td>-0.095222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109657</td>\n",
       "      <td>0.128430</td>\n",
       "      <td>0.526648</td>\n",
       "      <td>0.083436</td>\n",
       "      <td>0.535189</td>\n",
       "      <td>0.444251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.008219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.384659</td>\n",
       "      <td>0.110031</td>\n",
       "      <td>0.069220</td>\n",
       "      <td>-0.116755</td>\n",
       "      <td>-0.405043</td>\n",
       "      <td>-0.095715</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>-0.253376</td>\n",
       "      <td>-0.013787</td>\n",
       "      <td>0.106184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144029</td>\n",
       "      <td>0.241537</td>\n",
       "      <td>0.264994</td>\n",
       "      <td>0.284063</td>\n",
       "      <td>0.312178</td>\n",
       "      <td>0.391243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.015068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.293787  0.003139  0.025914  0.167209 -0.327508 -0.292465 -0.348738   \n",
       "1 -0.134314  0.048638  0.157068 -0.118706 -0.098239 -0.109438  0.014594   \n",
       "2 -0.163454  0.075192 -0.022291 -0.138708 -0.049811  0.057390 -0.165016   \n",
       "3 -0.173784 -0.086895 -0.044482 -0.140339 -0.132705 -0.341187 -0.244494   \n",
       "4 -0.384659  0.110031  0.069220 -0.116755 -0.405043 -0.095715  0.008814   \n",
       "\n",
       "          7         8         9  ...       290       291       292       293  \\\n",
       "0 -0.218615 -0.078855 -0.086240  ...  0.334543  0.743217  0.229896  0.115003   \n",
       "1 -0.336313  0.074765  0.071769  ...  0.216634  0.271318  0.347661  0.134042   \n",
       "2 -0.404240 -0.087664 -0.077308  ...  0.226022  0.419697  0.351481  0.487143   \n",
       "3 -0.364035 -0.062480 -0.095222  ...  0.109657  0.128430  0.526648  0.083436   \n",
       "4 -0.253376 -0.013787  0.106184  ...  0.144029  0.241537  0.264994  0.284063   \n",
       "\n",
       "        294       295  SEX  Gestational Age  Maternal Education MEDU  \\\n",
       "0  0.613862  0.419573  0.0         0.916667                     14.0   \n",
       "1  0.413723  0.255445  1.0         0.750000                      9.0   \n",
       "2  0.186957  0.223046  1.0         0.833333                     10.0   \n",
       "3  0.535189  0.444251  0.0         0.500000                     14.0   \n",
       "4  0.312178  0.391243  0.0         0.666667                     19.0   \n",
       "\n",
       "   Age at MRI 2  \n",
       "0      1.161644  \n",
       "1      1.024658  \n",
       "2      0.972603  \n",
       "3      1.008219  \n",
       "4      1.015068  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_indices_X[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conventional-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_indices_X[0] #8 Folds so 0 -> 7 Data type is a DataFrame currently.\n",
    "training_fold_X_0 = training_indices_X[0].to_numpy()\n",
    "training_fold_X_1 = training_indices_X[1].to_numpy()\n",
    "training_fold_X_2 = training_indices_X[2].to_numpy()\n",
    "training_fold_X_3 = training_indices_X[3].to_numpy()\n",
    "training_fold_X_4 = training_indices_X[4].to_numpy()\n",
    "training_fold_X_5 = training_indices_X[5].to_numpy()\n",
    "training_fold_X_6 = training_indices_X[6].to_numpy()\n",
    "training_fold_X_7 = training_indices_X[7].to_numpy()\n",
    "\n",
    "training_fold_Y_0 = training_indices_Y[0].to_numpy()\n",
    "training_fold_Y_1 = training_indices_Y[1].to_numpy()\n",
    "training_fold_Y_2 = training_indices_Y[2].to_numpy()\n",
    "training_fold_Y_3 = training_indices_Y[3].to_numpy()\n",
    "training_fold_Y_4 = training_indices_Y[4].to_numpy()\n",
    "training_fold_Y_5 = training_indices_Y[5].to_numpy()\n",
    "training_fold_Y_6 = training_indices_Y[6].to_numpy()\n",
    "training_fold_Y_7 = training_indices_Y[7].to_numpy()\n",
    "\n",
    "testing_fold_X_0 = testing_indices_X[0].to_numpy()\n",
    "testing_fold_X_1 = testing_indices_X[1].to_numpy()\n",
    "testing_fold_X_2 = testing_indices_X[2].to_numpy()\n",
    "testing_fold_X_3 = testing_indices_X[3].to_numpy()\n",
    "testing_fold_X_4 = testing_indices_X[4].to_numpy()\n",
    "testing_fold_X_5 = testing_indices_X[5].to_numpy()\n",
    "testing_fold_X_6 = testing_indices_X[6].to_numpy()\n",
    "testing_fold_X_7 = testing_indices_X[7].to_numpy()\n",
    "\n",
    "testing_fold_Y_0 = testing_indices_Y[0].to_numpy()\n",
    "testing_fold_Y_1 = testing_indices_Y[1].to_numpy()\n",
    "testing_fold_Y_2 = testing_indices_Y[2].to_numpy()\n",
    "testing_fold_Y_3 = testing_indices_Y[3].to_numpy()\n",
    "testing_fold_Y_4 = testing_indices_Y[4].to_numpy()\n",
    "testing_fold_Y_5 = testing_indices_Y[5].to_numpy()\n",
    "testing_fold_Y_6 = testing_indices_Y[6].to_numpy()\n",
    "testing_fold_Y_7 = testing_indices_Y[7].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conditional-cowboy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_fold_Y_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "creative-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some hyperparameters\n",
    "#D_in is input dimension; H is hidden dimension; D_out is output dimension. \n",
    "#Best: 0.691927 using {'batch_size': 30, 'dropout': 0.3, 'epochs': 25, 'layer1_size': 130, 'layer2_size': 30}\n",
    "D_in, H1, H2, D_out = 300, 130, 30, 1\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 30\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT_RATE = 0.30\n",
    "DROPOUT_RATE = 0.15\n",
    "\n",
    "test_size = 19\n",
    "test_size1 = 18\n",
    "\n",
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data): #used to perform initializing operations such as reading data and preprocessing.\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index): #returns data (input and output) in batches.\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self): #returns the size of the input data.\n",
    "        return len(self.X_data)\n",
    "\n",
    "#A dataloader is then used on this dataset class to read the data in batches.\n",
    "train_data = trainData(torch.FloatTensor(training_fold_X_0), \n",
    "                       torch.FloatTensor(training_fold_Y_0))\n",
    "\n",
    "train_data1 = trainData(torch.FloatTensor(training_fold_X_1), \n",
    "                       torch.FloatTensor(training_fold_Y_1))\n",
    "\n",
    "train_data2 = trainData(torch.FloatTensor(training_fold_X_2), \n",
    "                       torch.FloatTensor(training_fold_Y_2))\n",
    "\n",
    "train_data3 = trainData(torch.FloatTensor(training_fold_X_3), \n",
    "                       torch.FloatTensor(training_fold_Y_3))\n",
    "\n",
    "train_data4 = trainData(torch.FloatTensor(training_fold_X_4), \n",
    "                       torch.FloatTensor(training_fold_Y_4))\n",
    "\n",
    "train_data5 = trainData(torch.FloatTensor(training_fold_X_5), \n",
    "                       torch.FloatTensor(training_fold_Y_5))\n",
    "\n",
    "train_data6 = trainData(torch.FloatTensor(training_fold_X_6), \n",
    "                       torch.FloatTensor(training_fold_Y_6))\n",
    "\n",
    "train_data7 = trainData(torch.FloatTensor(training_fold_X_7), \n",
    "                       torch.FloatTensor(training_fold_Y_7))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data): ##used to perform initializing operations such as reading data and preprocessing.\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index): #returns data (input and output) in batches.\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self): #returns the size of the input data.\n",
    "        return len(self.X_data)\n",
    "    \n",
    "#A dataloader is then used on this dataset class to read the data in batches.\n",
    "test_data = testData(torch.FloatTensor(testing_fold_X_0))\n",
    "test_data1 = testData(torch.FloatTensor(testing_fold_X_1))\n",
    "test_data2 = testData(torch.FloatTensor(testing_fold_X_2))\n",
    "test_data3 = testData(torch.FloatTensor(testing_fold_X_3))\n",
    "test_data4 = testData(torch.FloatTensor(testing_fold_X_4))\n",
    "test_data5 = testData(torch.FloatTensor(testing_fold_X_5))\n",
    "test_data6 = testData(torch.FloatTensor(testing_fold_X_6))\n",
    "test_data7 = testData(torch.FloatTensor(testing_fold_X_7))\n",
    "\n",
    "#Initialize DataLoaders\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=test_size) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader1 = DataLoader(dataset=train_data1, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader1 = DataLoader(dataset=test_data1, batch_size=test_size) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader2 = DataLoader(dataset=train_data2, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader2 = DataLoader(dataset=test_data2, batch_size=test_size) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader3 = DataLoader(dataset=train_data3, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader3 = DataLoader(dataset=test_data3, batch_size=test_size) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader4 = DataLoader(dataset=train_data4, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader4 = DataLoader(dataset=test_data4, batch_size=test_size1) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader5 = DataLoader(dataset=train_data5, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader5 = DataLoader(dataset=test_data5, batch_size=test_size1) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader6 = DataLoader(dataset=train_data6, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader6 = DataLoader(dataset=test_data6, batch_size=test_size1) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial.\n",
    "\n",
    "train_loader7 = DataLoader(dataset=train_data7, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader7 = DataLoader(dataset=test_data7, batch_size=test_size1) #Batch size of the validation set. Need 1 at a time for how it was setup in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cardiac-chess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 300)\n",
      "(16, 300)\n",
      "(16, 300)\n",
      "(16, 300)\n",
      "(16, 300)\n",
      "(16, 300)\n",
      "(16, 300)\n",
      "(15, 300)\n"
     ]
    }
   ],
   "source": [
    "print(testing_fold_X_0.shape)\n",
    "print(testing_fold_X_1.shape)\n",
    "print(testing_fold_X_2.shape)\n",
    "print(testing_fold_X_3.shape)\n",
    "print(testing_fold_X_4.shape)\n",
    "print(testing_fold_X_5.shape)\n",
    "print(testing_fold_X_6.shape)\n",
    "print(testing_fold_X_7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "excited-account",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 298.\n",
    "        self.layer_1 = nn.Linear(D_in, H1) #298 -> 100\n",
    "        self.layer_2 = nn.Linear(H1, H2) #100 -> 15\n",
    "        self.layer_out = nn.Linear(H2, D_out) #15 -> 1\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=DROPOUT_RATE)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(100)\n",
    "        #self.batchnorm2 = nn.BatchNorm1d(15)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs)) #ReLU on the 298?\n",
    "        #x = self.batchnorm1(x) #Normalize the 100\n",
    "        x = self.dropout(x) #Dropout 15%\n",
    "        x = self.relu(self.layer_2(x)) #ReLU on the 100?\n",
    "        #x = self.batchnorm2(x) #Normalize the 15\n",
    "        x = self.layer_out(x) #1\n",
    "        \n",
    "        return x\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#Should use the CPU since I don't have a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "visible-potter",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for binaryClassification:\n\tsize mismatch for layer_1.weight: copying a param with shape torch.Size([100, 300]) from checkpoint, the shape in current model is torch.Size([130, 300]).\n\tsize mismatch for layer_1.bias: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([130]).\n\tsize mismatch for layer_2.weight: copying a param with shape torch.Size([15, 100]) from checkpoint, the shape in current model is torch.Size([30, 130]).\n\tsize mismatch for layer_2.bias: copying a param with shape torch.Size([15]) from checkpoint, the shape in current model is torch.Size([30]).\n\tsize mismatch for layer_out.weight: copying a param with shape torch.Size([1, 15]) from checkpoint, the shape in current model is torch.Size([1, 30]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5efffa244598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinaryClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model_dict_atp.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1052\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1053\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for binaryClassification:\n\tsize mismatch for layer_1.weight: copying a param with shape torch.Size([100, 300]) from checkpoint, the shape in current model is torch.Size([130, 300]).\n\tsize mismatch for layer_1.bias: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([130]).\n\tsize mismatch for layer_2.weight: copying a param with shape torch.Size([15, 100]) from checkpoint, the shape in current model is torch.Size([30, 130]).\n\tsize mismatch for layer_2.bias: copying a param with shape torch.Size([15]) from checkpoint, the shape in current model is torch.Size([30]).\n\tsize mismatch for layer_out.weight: copying a param with shape torch.Size([1, 15]) from checkpoint, the shape in current model is torch.Size([1, 30])."
     ]
    }
   ],
   "source": [
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model = binaryClassification()\n",
    "model.load_state_dict(torch.load('./model_dict_atp_2yr.pth'))\n",
    "model.train()\n",
    "print(model)\n",
    "weights = torch.FloatTensor([5]) #Class weights?\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model1 = binaryClassification()\n",
    "model1.load_state_dict(torch.load('./model_dict_atp_2yr.pth'))\n",
    "model1.train()\n",
    "#print(model)\n",
    "weights1 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion1 = nn.BCEWithLogitsLoss(pos_weight=weights1)\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model2 = binaryClassification()\n",
    "model2.load_state_dict(torch.load('./model_dict_atp_2yr.pth'))\n",
    "model2.train()\n",
    "#print(model)\n",
    "weights2 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion2 = nn.BCEWithLogitsLoss(pos_weight=weights2)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model3 = binaryClassification()\n",
    "model3.load_state_dict(torch.load('./model_dict_atp_2yr.pth'))\n",
    "model3.train()\n",
    "#print(model)\n",
    "weights3 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion3 = nn.BCEWithLogitsLoss(pos_weight=weights3)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model4 = binaryClassification()\n",
    "model4.load_state_dict(torch.load('./model_dict_atp_2yr.pth'))\n",
    "model4.train()\n",
    "#print(model)\n",
    "weights4 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion4 = nn.BCEWithLogitsLoss(pos_weight=weights4)\n",
    "optimizer4 = optim.Adam(model4.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model5 = binaryClassification()\n",
    "model5.load_state_dict(torch.load('./model_dict_atp_2yr.pth'))\n",
    "model5.train()\n",
    "#print(model)\n",
    "weights5 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion5 = nn.BCEWithLogitsLoss(pos_weight=weights5)\n",
    "optimizer5 = optim.Adam(model5.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model6 = binaryClassification()\n",
    "model6.load_state_dict(torch.load('./model_dict_atp_2yr.pth'))\n",
    "model6.train()\n",
    "#print(model)\n",
    "weights6 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion6 = nn.BCEWithLogitsLoss(pos_weight=weights6)\n",
    "optimizer6 = optim.Adam(model6.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Model initialization and information on layers. The model's actual architecture can be viewed in the forward function above.\n",
    "model7 = binaryClassification()\n",
    "model7.load_state_dict(torch.load('./model_dict_atp_2yr.pth'))\n",
    "model7.train()\n",
    "#print(model)\n",
    "weights7 = torch.FloatTensor([5]) #Class weights?\n",
    "criterion7 = nn.BCEWithLogitsLoss(pos_weight=weights7)\n",
    "optimizer7 = optim.Adam(model7.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to define accuracy. Should look to see if there is a prebuilt that I can use from sci-kit learn or something.\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that youâ€™re in training mode.\n",
    "#Similarly, weâ€™ll call model.eval() when we test our model. Weâ€™ll see that below.\n",
    "'''If youâ€™re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you donâ€™t explicitly have to write that. But itâ€™s good practice.'''\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "model.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc.append(epoch_acc/len(train_loader))\n",
    "    train_loss.append(epoch_loss/len(train_loader))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    #Validation metrics here\n",
    "    model.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_0))\n",
    "            val_loss.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_0), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_0, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_0, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc.append(accuracy*100)\n",
    "    model.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that youâ€™re in training mode.\n",
    "#Similarly, weâ€™ll call model.eval() when we test our model. Weâ€™ll see that below.\n",
    "'''If youâ€™re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you donâ€™t explicitly have to write that. But itâ€™s good practice.'''\n",
    "val_acc1 = []\n",
    "train_acc1 = []\n",
    "train_loss1 = []\n",
    "val_loss1 = []\n",
    "\n",
    "model1.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer1.zero_grad()\n",
    "        \n",
    "        y_pred = model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc1.append(epoch_acc/len(train_loader1))\n",
    "    train_loss1.append(epoch_loss/len(train_loader1))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader1):.5f} | Acc: {epoch_acc/len(train_loader1):.3f}')\n",
    "    #Validation metrics here\n",
    "    model1.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader1 = DataLoader(dataset=test_data1, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader1:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model1(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_1))\n",
    "            val_loss1.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader = DataLoader(dataset=test_data1, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model1(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_1), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_1, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_1, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc1.append(accuracy*100)\n",
    "    model1.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that youâ€™re in training mode.\n",
    "#Similarly, weâ€™ll call model.eval() when we test our model. Weâ€™ll see that below.\n",
    "'''If youâ€™re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you donâ€™t explicitly have to write that. But itâ€™s good practice.'''\n",
    "val_acc2 = []\n",
    "train_acc2 = []\n",
    "train_loss2 = []\n",
    "val_loss2 = []\n",
    "\n",
    "model2.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        y_pred = model2(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc2.append(epoch_acc/len(train_loader2))\n",
    "    train_loss2.append(epoch_loss/len(train_loader2))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader2):.5f} | Acc: {epoch_acc/len(train_loader2):.3f}')\n",
    "    #Validation metrics here\n",
    "    model2.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader2 = DataLoader(dataset=test_data2, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader2:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model2(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_2))\n",
    "            val_loss2.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader2 = DataLoader(dataset=test_data2, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader2:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model2(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_2), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_2, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_2, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc2.append(accuracy*100)\n",
    "    model2.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that youâ€™re in training mode.\n",
    "#Similarly, weâ€™ll call model.eval() when we test our model. Weâ€™ll see that below.\n",
    "'''If youâ€™re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you donâ€™t explicitly have to write that. But itâ€™s good practice.'''\n",
    "val_acc3 = []\n",
    "train_acc3 = []\n",
    "train_loss3 = []\n",
    "val_loss3 = []\n",
    "\n",
    "model3.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader3:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer3.zero_grad()\n",
    "        \n",
    "        y_pred = model3(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer3.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc3.append(epoch_acc/len(train_loader3))\n",
    "    train_loss3.append(epoch_loss/len(train_loader3))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader3):.5f} | Acc: {epoch_acc/len(train_loader3):.3f}')\n",
    "    #Validation metrics here\n",
    "    model3.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader3 = DataLoader(dataset=test_data3, batch_size=test_size)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader3:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model3(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_3))\n",
    "            val_loss3.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader3 = DataLoader(dataset=test_data3, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader3:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model3(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_3), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_3, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_3, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc3.append(accuracy*100)\n",
    "    model3.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that youâ€™re in training mode.\n",
    "#Similarly, weâ€™ll call model.eval() when we test our model. Weâ€™ll see that below.\n",
    "'''If youâ€™re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you donâ€™t explicitly have to write that. But itâ€™s good practice.'''\n",
    "val_acc4 = []\n",
    "train_acc4 = []\n",
    "train_loss4 = []\n",
    "val_loss4 = []\n",
    "\n",
    "model4.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader4:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer4.zero_grad()\n",
    "        \n",
    "        y_pred = model4(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer4.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc4.append(epoch_acc/len(train_loader4))\n",
    "    train_loss4.append(epoch_loss/len(train_loader4))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader4):.5f} | Acc: {epoch_acc/len(train_loader4):.3f}')\n",
    "    #Validation metrics here\n",
    "    model4.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader4 = DataLoader(dataset=test_data4, batch_size=test_size1)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader4:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model4(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_4))\n",
    "            val_loss4.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader4 = DataLoader(dataset=test_data4, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader4:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model4(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_4), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_4, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_4, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc4.append(accuracy*100)\n",
    "    model4.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that youâ€™re in training mode.\n",
    "#Similarly, weâ€™ll call model.eval() when we test our model. Weâ€™ll see that below.\n",
    "'''If youâ€™re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you donâ€™t explicitly have to write that. But itâ€™s good practice.'''\n",
    "val_acc5 = []\n",
    "train_acc5 = []\n",
    "train_loss5 = []\n",
    "val_loss5 = []\n",
    "\n",
    "model5.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader5:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer5.zero_grad()\n",
    "        \n",
    "        y_pred = model5(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer5.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc5.append(epoch_acc/len(train_loader5))\n",
    "    train_loss5.append(epoch_loss/len(train_loader5))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader5):.5f} | Acc: {epoch_acc/len(train_loader5):.3f}')\n",
    "    #Validation metrics here\n",
    "    model5.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader5 = DataLoader(dataset=test_data5, batch_size=test_size1)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader5:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model5(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_5))\n",
    "            val_loss5.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader5 = DataLoader(dataset=test_data5, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader5:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model5(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_5), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_5, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_5, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc5.append(accuracy*100)\n",
    "    model5.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that youâ€™re in training mode.\n",
    "#Similarly, weâ€™ll call model.eval() when we test our model. Weâ€™ll see that below.\n",
    "'''If youâ€™re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you donâ€™t explicitly have to write that. But itâ€™s good practice.'''\n",
    "val_acc6 = []\n",
    "train_acc6 = []\n",
    "train_loss6 = []\n",
    "val_loss6 = []\n",
    "\n",
    "model6.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader6:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer6.zero_grad()\n",
    "        \n",
    "        y_pred = model6(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer6.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc6.append(epoch_acc/len(train_loader6))\n",
    "    train_loss6.append(epoch_loss/len(train_loader6))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader6):.5f} | Acc: {epoch_acc/len(train_loader6):.3f}')\n",
    "    #Validation metrics here\n",
    "    model6.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader6 = DataLoader(dataset=test_data6, batch_size=test_size1)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader6:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model6(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_6))\n",
    "            val_loss6.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader6 = DataLoader(dataset=test_data6, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader6:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model6(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_6), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_6, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_6, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc6.append(accuracy*100)\n",
    "    model6.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() tells PyTorch that youâ€™re in training mode.\n",
    "#Similarly, weâ€™ll call model.eval() when we test our model. Weâ€™ll see that below.\n",
    "'''If youâ€™re using layers such as Dropout or BatchNorm which behave differently during training and evaluation, \n",
    "you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, \n",
    "so, you donâ€™t explicitly have to write that. But itâ€™s good practice.'''\n",
    "val_acc7 = []\n",
    "train_acc7 = []\n",
    "train_loss7 = []\n",
    "val_loss7 = []\n",
    "\n",
    "model7.train() #Initial training mode\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader7:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer7.zero_grad()\n",
    "        \n",
    "        y_pred = model7(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer7.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    train_acc7.append(epoch_acc/len(train_loader7))\n",
    "    train_loss7.append(epoch_loss/len(train_loader7))\n",
    "    print(f'Training Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader7):.5f} | Acc: {epoch_acc/len(train_loader7):.3f}')\n",
    "    #Validation metrics here\n",
    "    model7.eval()\n",
    "    #print(\"Evaluation mode\")\n",
    "    y_pred_list = []\n",
    "    test_loader7 = DataLoader(dataset=test_data7, batch_size=test_size1)\n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for X_batch in test_loader7:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model7(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            loss = criterion(y_test_pred,torch.FloatTensor(testing_fold_Y_7))\n",
    "            val_loss7.append(loss)\n",
    "            counter+=1\n",
    "            \n",
    "    y_pred_list = []\n",
    "    test_loader7 = DataLoader(dataset=test_data7, batch_size=1)\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader7:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model7(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    y_loss_df = pd.DataFrame(y_pred_list)\n",
    "    accuracy = accuracy_score(torch.FloatTensor(testing_fold_Y_7), y_pred_list)\n",
    "    ppv = precision_score(testing_fold_Y_7, y_pred_list, average=None)\n",
    "    recall = recall_score(testing_fold_Y_7, y_pred_list, average=None)\n",
    "    print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "    val_acc7.append(accuracy*100)\n",
    "    model7.train()\n",
    "    #print(\"Return to training mode\")\n",
    "    \n",
    "    #Need to get validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting loss\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss1)\n",
    "plt.plot(val_loss1)\n",
    "plt.title('model1 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc1)\n",
    "plt.plot(val_acc1)\n",
    "plt.title('model1 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss2)\n",
    "plt.plot(val_loss2)\n",
    "plt.title('model2 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc2)\n",
    "plt.plot(val_acc2)\n",
    "plt.title('model2 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss3)\n",
    "plt.plot(val_loss3)\n",
    "plt.title('model3 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc3)\n",
    "plt.plot(val_acc3)\n",
    "plt.title('model3 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss4)\n",
    "plt.plot(val_loss4)\n",
    "plt.title('model4 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc4)\n",
    "plt.plot(val_acc4)\n",
    "plt.title('model4 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss5)\n",
    "plt.plot(val_loss5)\n",
    "plt.title('model5 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc5)\n",
    "plt.plot(val_acc5)\n",
    "plt.title('model5 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss6)\n",
    "plt.plot(val_loss6)\n",
    "plt.title('model6 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc6)\n",
    "plt.plot(val_acc6)\n",
    "plt.title('model6 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()\n",
    "\n",
    "#Plotting loss\n",
    "plt.plot(train_loss7)\n",
    "plt.plot(val_loss7)\n",
    "plt.title('model7 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 1.5])\n",
    "plt.show()\n",
    "\n",
    "#Plotting Accuracy\n",
    "plt.plot(train_acc7)\n",
    "plt.plot(val_acc7)\n",
    "plt.title('model7 accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "plt.axis([0, EPOCHS-1, 0.0, 105])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = []\n",
    "final_prediction_true = []\n",
    "\n",
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "model.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_0, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_0, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_0, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_0, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_0:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data1, batch_size=1)\n",
    "model1.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_1, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_1, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_1, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_1, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_1:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data2, batch_size=1)\n",
    "model2.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model2(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_2, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_2, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_2, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_2, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_2:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data3, batch_size=1)\n",
    "model3.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model3(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_3, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_3, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_3, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_3, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_3:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data4, batch_size=1)\n",
    "model4.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model4(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_4, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_4, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_4, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_4, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_4:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data5, batch_size=1)\n",
    "model5.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model5(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_5, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_5, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_5, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_5, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_5:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data6, batch_size=1)\n",
    "model6.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model6(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_6, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_6, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_6, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_6, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_6:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "test_loader = DataLoader(dataset=test_data7, batch_size=1)\n",
    "model7.eval() #Model evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model7(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        final_prediction.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "accuracy = accuracy_score(testing_fold_Y_7, y_pred_list)\n",
    "ppv = precision_score(testing_fold_Y_7, y_pred_list, average=None)\n",
    "recall = recall_score(testing_fold_Y_7, y_pred_list, average=None)\n",
    "print(\"Validation Accuracy | \",accuracy*100,\" PPV | \",ppv,\" Recall | \",recall)\n",
    "cf_matrix = confusion_matrix(testing_fold_Y_7, y_pred_list)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "for y in testing_fold_Y_7:\n",
    "    final_prediction_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels = []\n",
    "true_labels = []\n",
    "\n",
    "for x in range(0,len(final_prediction_true)):\n",
    "    true_labels.append(final_prediction_true[x][0])\n",
    "    prediction_labels.append(final_prediction[x][0][0])\n",
    "\n",
    "prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(true_labels, prediction_labels)\n",
    "print(cf_matrix)\n",
    "sn.heatmap(cf_matrix, annot=True)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(true_labels, prediction_labels)\n",
    "recall = recall_score(true_labels, prediction_labels, average=None)\n",
    "prec_score = precision_score(true_labels, prediction_labels, average=None)\n",
    "print('Positive Predictive Value tp/(tp+fp): ',prec_score[1]) \n",
    "print('Accuracy Value (tp+tn)/(tp+fp+fn+tn): ',accuracy) \n",
    "print('Recall Value tp/(tp+fn): ',recall[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-nashville",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
