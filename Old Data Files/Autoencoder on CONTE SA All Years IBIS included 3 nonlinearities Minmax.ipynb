{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import losses\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "\n",
    "\n",
    "\n",
    "#Bring in all data for all years. This notebook contains Joseph's classifiers from 0-3 for risk groups. Col 151 is risk groups.\n",
    "ct_sheet = pd.ExcelFile(\"SA_and_CT_AALandfROI_08272019.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destrieux_SA\n"
     ]
    }
   ],
   "source": [
    "print(ct_sheet.sheet_names[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1122 10:33:51.334289 19860 deprecation_wrapper.py:119] From C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1122 10:33:51.371660 19860 deprecation_wrapper.py:119] From C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1122 10:33:51.380637 19860 deprecation_wrapper.py:119] From C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1889, 148)\n",
      "Tensor(\"input_1:0\", shape=(?, 148), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1122 10:33:51.566565 19860 deprecation_wrapper.py:119] From C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1122 10:33:51.764798 19860 deprecation_wrapper.py:119] From C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W1122 10:33:52.156803 19860 deprecation_wrapper.py:119] From C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1700 samples, validate on 189 samples\n",
      "Epoch 1/1500\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.1146 - val_loss: 0.0867\n",
      "Epoch 2/1500\n",
      "1700/1700 [==============================] - 1s 423us/step - loss: 0.0859 - val_loss: 0.0841\n",
      "Epoch 3/1500\n",
      "1700/1700 [==============================] - 1s 417us/step - loss: 0.0836 - val_loss: 0.0833\n",
      "Epoch 4/1500\n",
      "1700/1700 [==============================] - 1s 416us/step - loss: 0.0811 - val_loss: 0.0812\n",
      "Epoch 5/1500\n",
      "1700/1700 [==============================] - 1s 392us/step - loss: 0.0800 - val_loss: 0.0785\n",
      "Epoch 6/1500\n",
      "1700/1700 [==============================] - 1s 531us/step - loss: 0.0780 - val_loss: 0.0786\n",
      "Epoch 7/1500\n",
      "1700/1700 [==============================] - 1s 386us/step - loss: 0.0763 - val_loss: 0.0753\n",
      "Epoch 8/1500\n",
      "1700/1700 [==============================] - 1s 396us/step - loss: 0.0751 - val_loss: 0.0752\n",
      "Epoch 9/1500\n",
      "1700/1700 [==============================] - 1s 460us/step - loss: 0.0743 - val_loss: 0.0752\n",
      "Epoch 10/1500\n",
      "1700/1700 [==============================] - 1s 440us/step - loss: 0.0732 - val_loss: 0.0746\n",
      "Epoch 11/1500\n",
      "1700/1700 [==============================] - 1s 422us/step - loss: 0.0731 - val_loss: 0.0729\n",
      "Epoch 12/1500\n",
      "1700/1700 [==============================] - 1s 416us/step - loss: 0.0718 - val_loss: 0.0724\n",
      "Epoch 13/1500\n",
      "1700/1700 [==============================] - 1s 525us/step - loss: 0.0715 - val_loss: 0.0717\n",
      "Epoch 14/1500\n",
      "1700/1700 [==============================] - 1s 488us/step - loss: 0.0713 - val_loss: 0.0711\n",
      "Epoch 15/1500\n",
      "1700/1700 [==============================] - 1s 459us/step - loss: 0.0704 - val_loss: 0.0713\n",
      "Epoch 16/1500\n",
      "1700/1700 [==============================] - 1s 432us/step - loss: 0.0700 - val_loss: 0.0752\n",
      "Epoch 17/1500\n",
      "1700/1700 [==============================] - 1s 441us/step - loss: 0.0694 - val_loss: 0.0713\n",
      "Epoch 18/1500\n",
      "1700/1700 [==============================] - 1s 430us/step - loss: 0.0702 - val_loss: 0.0724\n",
      "Epoch 19/1500\n",
      "1700/1700 [==============================] - 1s 617us/step - loss: 0.0690 - val_loss: 0.0705\n",
      "Epoch 20/1500\n",
      "1700/1700 [==============================] - 1s 621us/step - loss: 0.0686 - val_loss: 0.0697\n",
      "Epoch 21/1500\n",
      "1700/1700 [==============================] - 1s 427us/step - loss: 0.0683 - val_loss: 0.0698\n",
      "Epoch 22/1500\n",
      "1700/1700 [==============================] - 1s 454us/step - loss: 0.0684 - val_loss: 0.0712\n",
      "Epoch 23/1500\n",
      "1700/1700 [==============================] - 1s 422us/step - loss: 0.0680 - val_loss: 0.0692\n",
      "Epoch 24/1500\n",
      "1700/1700 [==============================] - 1s 445us/step - loss: 0.0683 - val_loss: 0.0699\n",
      "Epoch 25/1500\n",
      "1700/1700 [==============================] - 1s 513us/step - loss: 0.0678 - val_loss: 0.0692\n",
      "Epoch 26/1500\n",
      "1700/1700 [==============================] - 1s 448us/step - loss: 0.0679 - val_loss: 0.0685\n",
      "Epoch 27/1500\n",
      "1700/1700 [==============================] - 1s 451us/step - loss: 0.0674 - val_loss: 0.0695\n",
      "Epoch 28/1500\n",
      "1700/1700 [==============================] - 1s 419us/step - loss: 0.0674 - val_loss: 0.0689\n",
      "Epoch 29/1500\n",
      "1700/1700 [==============================] - 1s 446us/step - loss: 0.0674 - val_loss: 0.0686\n",
      "Epoch 30/1500\n",
      "1700/1700 [==============================] - 1s 427us/step - loss: 0.0671 - val_loss: 0.0681\n",
      "Epoch 31/1500\n",
      "1700/1700 [==============================] - 1s 442us/step - loss: 0.0668 - val_loss: 0.0684\n",
      "Epoch 32/1500\n",
      "1700/1700 [==============================] - 1s 523us/step - loss: 0.0669 - val_loss: 0.0695\n",
      "Epoch 33/1500\n",
      "1700/1700 [==============================] - 1s 474us/step - loss: 0.0668 - val_loss: 0.0688\n",
      "Epoch 34/1500\n",
      "1700/1700 [==============================] - 1s 444us/step - loss: 0.0667 - val_loss: 0.0680\n",
      "Epoch 35/1500\n",
      "1700/1700 [==============================] - 1s 466us/step - loss: 0.0664 - val_loss: 0.0684\n",
      "Epoch 36/1500\n",
      "1700/1700 [==============================] - 1s 450us/step - loss: 0.0670 - val_loss: 0.0681\n",
      "Epoch 37/1500\n",
      "1700/1700 [==============================] - 1s 610us/step - loss: 0.0663 - val_loss: 0.0690\n",
      "Epoch 38/1500\n",
      "1700/1700 [==============================] - 1s 616us/step - loss: 0.0664 - val_loss: 0.0679\n",
      "Epoch 39/1500\n",
      "1700/1700 [==============================] - 1s 736us/step - loss: 0.0661 - val_loss: 0.0680\n",
      "Epoch 40/1500\n",
      "1700/1700 [==============================] - 1s 467us/step - loss: 0.0667 - val_loss: 0.0686\n",
      "Epoch 41/1500\n",
      "1700/1700 [==============================] - 1s 446us/step - loss: 0.0663 - val_loss: 0.0674\n",
      "Epoch 42/1500\n",
      "1700/1700 [==============================] - 1s 477us/step - loss: 0.0662 - val_loss: 0.0699\n",
      "Epoch 43/1500\n",
      "1700/1700 [==============================] - 1s 434us/step - loss: 0.0660 - val_loss: 0.0679\n",
      "Epoch 44/1500\n",
      "1700/1700 [==============================] - 1s 542us/step - loss: 0.0658 - val_loss: 0.0677\n",
      "Epoch 45/1500\n",
      "1700/1700 [==============================] - 1s 448us/step - loss: 0.0658 - val_loss: 0.0679\n",
      "Epoch 46/1500\n",
      "1700/1700 [==============================] - 1s 437us/step - loss: 0.0658 - val_loss: 0.0680\n",
      "Epoch 47/1500\n",
      "1700/1700 [==============================] - 1s 460us/step - loss: 0.0660 - val_loss: 0.0673\n",
      "Epoch 48/1500\n",
      "1700/1700 [==============================] - 1s 444us/step - loss: 0.0659 - val_loss: 0.0672\n",
      "Epoch 49/1500\n",
      "1700/1700 [==============================] - 1s 471us/step - loss: 0.0659 - val_loss: 0.0674\n",
      "Epoch 50/1500\n",
      "1700/1700 [==============================] - 1s 543us/step - loss: 0.0656 - val_loss: 0.0694\n",
      "Epoch 51/1500\n",
      "1700/1700 [==============================] - 1s 481us/step - loss: 0.0658 - val_loss: 0.0682\n",
      "Epoch 52/1500\n",
      "1700/1700 [==============================] - 1s 486us/step - loss: 0.0658 - val_loss: 0.0685\n",
      "Epoch 53/1500\n",
      "1700/1700 [==============================] - 1s 433us/step - loss: 0.0658 - val_loss: 0.0678\n",
      "Epoch 54/1500\n",
      "1700/1700 [==============================] - 1s 443us/step - loss: 0.0656 - val_loss: 0.0682\n",
      "Epoch 55/1500\n",
      "1700/1700 [==============================] - 1s 428us/step - loss: 0.0658 - val_loss: 0.0670\n",
      "Epoch 56/1500\n",
      "1700/1700 [==============================] - 1s 479us/step - loss: 0.0652 - val_loss: 0.0667\n",
      "Epoch 57/1500\n",
      "1700/1700 [==============================] - 1s 549us/step - loss: 0.0653 - val_loss: 0.0681\n",
      "Epoch 58/1500\n",
      "1700/1700 [==============================] - 1s 803us/step - loss: 0.0654 - val_loss: 0.0667\n",
      "Epoch 59/1500\n",
      "1700/1700 [==============================] - 1s 440us/step - loss: 0.0658 - val_loss: 0.0670\n",
      "Epoch 60/1500\n",
      "1700/1700 [==============================] - 1s 431us/step - loss: 0.0656 - val_loss: 0.0681\n",
      "Epoch 61/1500\n",
      "1700/1700 [==============================] - 1s 477us/step - loss: 0.0653 - val_loss: 0.0675\n",
      "Epoch 62/1500\n",
      "1700/1700 [==============================] - 1s 538us/step - loss: 0.0652 - val_loss: 0.0669\n",
      "Epoch 63/1500\n",
      "1700/1700 [==============================] - 1s 479us/step - loss: 0.0650 - val_loss: 0.0675\n",
      "Epoch 64/1500\n",
      "1700/1700 [==============================] - 1s 452us/step - loss: 0.0652 - val_loss: 0.0669\n",
      "Epoch 65/1500\n",
      "1700/1700 [==============================] - 1s 471us/step - loss: 0.0659 - val_loss: 0.0686\n",
      "Epoch 66/1500\n",
      "1700/1700 [==============================] - 1s 453us/step - loss: 0.0653 - val_loss: 0.0666\n",
      "Epoch 67/1500\n",
      "1700/1700 [==============================] - 1s 544us/step - loss: 0.0657 - val_loss: 0.0670\n",
      "Epoch 68/1500\n",
      "1700/1700 [==============================] - 1s 476us/step - loss: 0.0653 - val_loss: 0.0673\n",
      "Epoch 69/1500\n",
      "1700/1700 [==============================] - 1s 536us/step - loss: 0.0649 - val_loss: 0.0676\n",
      "Epoch 70/1500\n",
      "1700/1700 [==============================] - 1s 489us/step - loss: 0.0653 - val_loss: 0.0672\n",
      "Epoch 71/1500\n",
      "1700/1700 [==============================] - 1s 456us/step - loss: 0.0651 - val_loss: 0.0667\n",
      "Epoch 72/1500\n",
      "1700/1700 [==============================] - 1s 463us/step - loss: 0.0649 - val_loss: 0.0667\n",
      "Epoch 73/1500\n",
      "1700/1700 [==============================] - 1s 485us/step - loss: 0.0652 - val_loss: 0.0666\n",
      "Epoch 74/1500\n",
      "1700/1700 [==============================] - 1s 481us/step - loss: 0.0652 - val_loss: 0.0672\n",
      "Epoch 75/1500\n",
      "1700/1700 [==============================] - 1s 527us/step - loss: 0.0656 - val_loss: 0.0692\n",
      "Epoch 76/1500\n",
      "1700/1700 [==============================] - 1s 606us/step - loss: 0.0652 - val_loss: 0.0671\n",
      "Epoch 77/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 1s 609us/step - loss: 0.0650 - val_loss: 0.0671\n",
      "Epoch 78/1500\n",
      "1700/1700 [==============================] - 1s 406us/step - loss: 0.0650 - val_loss: 0.0671\n",
      "Epoch 79/1500\n",
      "1700/1700 [==============================] - 1s 399us/step - loss: 0.0650 - val_loss: 0.0666\n",
      "Epoch 80/1500\n",
      "1700/1700 [==============================] - 1s 398us/step - loss: 0.0649 - val_loss: 0.0679\n",
      "Epoch 81/1500\n",
      "1700/1700 [==============================] - 1s 467us/step - loss: 0.0653 - val_loss: 0.0674\n",
      "Epoch 82/1500\n",
      "1700/1700 [==============================] - 1s 406us/step - loss: 0.0649 - val_loss: 0.0667\n",
      "Epoch 83/1500\n",
      "1700/1700 [==============================] - 1s 417us/step - loss: 0.0649 - val_loss: 0.0672\n",
      "Epoch 84/1500\n",
      "1700/1700 [==============================] - 1s 393us/step - loss: 0.0649 - val_loss: 0.0669\n",
      "Epoch 85/1500\n",
      "1700/1700 [==============================] - 1s 400us/step - loss: 0.0648 - val_loss: 0.0667\n",
      "Epoch 86/1500\n",
      "1700/1700 [==============================] - 1s 492us/step - loss: 0.0651 - val_loss: 0.0675\n",
      "Epoch 87/1500\n",
      "1700/1700 [==============================] - 1s 451us/step - loss: 0.0647 - val_loss: 0.0663\n",
      "Epoch 88/1500\n",
      "1700/1700 [==============================] - 1s 527us/step - loss: 0.0650 - val_loss: 0.0671\n",
      "Epoch 89/1500\n",
      "1700/1700 [==============================] - 1s 406us/step - loss: 0.0655 - val_loss: 0.0662\n",
      "Epoch 90/1500\n",
      "1700/1700 [==============================] - 1s 396us/step - loss: 0.0649 - val_loss: 0.0671\n",
      "Epoch 91/1500\n",
      "1700/1700 [==============================] - 1s 400us/step - loss: 0.0649 - val_loss: 0.0667\n",
      "Epoch 92/1500\n",
      "1700/1700 [==============================] - 1s 374us/step - loss: 0.0645 - val_loss: 0.0665\n",
      "Epoch 93/1500\n",
      "1700/1700 [==============================] - 1s 393us/step - loss: 0.0648 - val_loss: 0.0666\n",
      "Epoch 94/1500\n",
      "1700/1700 [==============================] - 1s 420us/step - loss: 0.0651 - val_loss: 0.0667\n",
      "Epoch 95/1500\n",
      "1700/1700 [==============================] - 1s 596us/step - loss: 0.0647 - val_loss: 0.0690\n",
      "Epoch 96/1500\n",
      "1700/1700 [==============================] - 1s 420us/step - loss: 0.0651 - val_loss: 0.0663\n",
      "Epoch 97/1500\n",
      "1700/1700 [==============================] - 1s 576us/step - loss: 0.0645 - val_loss: 0.0664\n",
      "Epoch 98/1500\n",
      "1700/1700 [==============================] - 1s 670us/step - loss: 0.0645 - val_loss: 0.0661\n",
      "Epoch 99/1500\n",
      "1700/1700 [==============================] - 1s 459us/step - loss: 0.0645 - val_loss: 0.0667\n",
      "Epoch 100/1500\n",
      "1700/1700 [==============================] - 1s 426us/step - loss: 0.0647 - val_loss: 0.0664\n",
      "Epoch 101/1500\n",
      "1700/1700 [==============================] - 1s 479us/step - loss: 0.0650 - val_loss: 0.0666\n",
      "Epoch 102/1500\n",
      "1700/1700 [==============================] - 1s 445us/step - loss: 0.0646 - val_loss: 0.0661\n",
      "Epoch 103/1500\n",
      "1700/1700 [==============================] - 1s 404us/step - loss: 0.0645 - val_loss: 0.0665\n",
      "Epoch 104/1500\n",
      "1700/1700 [==============================] - 1s 393us/step - loss: 0.0647 - val_loss: 0.0667\n",
      "Epoch 105/1500\n",
      "1700/1700 [==============================] - 1s 460us/step - loss: 0.0644 - val_loss: 0.0667\n",
      "Epoch 106/1500\n",
      "1700/1700 [==============================] - 1s 461us/step - loss: 0.0650 - val_loss: 0.0668\n",
      "Epoch 107/1500\n",
      "1700/1700 [==============================] - 1s 396us/step - loss: 0.0648 - val_loss: 0.0666\n",
      "Epoch 108/1500\n",
      "1700/1700 [==============================] - 1s 476us/step - loss: 0.0649 - val_loss: 0.0670\n",
      "Epoch 109/1500\n",
      "1700/1700 [==============================] - 1s 403us/step - loss: 0.0648 - val_loss: 0.0668\n",
      "Epoch 110/1500\n",
      "1700/1700 [==============================] - 1s 412us/step - loss: 0.0647 - val_loss: 0.0673\n",
      "Epoch 111/1500\n",
      "1700/1700 [==============================] - 1s 398us/step - loss: 0.0648 - val_loss: 0.0672\n",
      "Epoch 112/1500\n",
      "1700/1700 [==============================] - 1s 420us/step - loss: 0.0649 - val_loss: 0.0664\n",
      "Epoch 113/1500\n",
      "1700/1700 [==============================] - 1s 412us/step - loss: 0.0645 - val_loss: 0.0664\n",
      "Epoch 114/1500\n",
      "1700/1700 [==============================] - 1s 418us/step - loss: 0.0647 - val_loss: 0.0666\n",
      "Epoch 115/1500\n",
      "1700/1700 [==============================] - 1s 399us/step - loss: 0.0646 - val_loss: 0.0663\n",
      "Epoch 116/1500\n",
      "1700/1700 [==============================] - 1s 501us/step - loss: 0.0644 - val_loss: 0.0666\n",
      "Epoch 117/1500\n",
      "1700/1700 [==============================] - 1s 388us/step - loss: 0.0643 - val_loss: 0.0662\n",
      "Epoch 118/1500\n",
      "1700/1700 [==============================] - 1s 597us/step - loss: 0.0643 - val_loss: 0.0660\n",
      "Epoch 119/1500\n",
      "1700/1700 [==============================] - 1s 586us/step - loss: 0.0645 - val_loss: 0.0663\n",
      "Epoch 120/1500\n",
      "1700/1700 [==============================] - 1s 409us/step - loss: 0.0644 - val_loss: 0.0664\n",
      "Epoch 121/1500\n",
      "1700/1700 [==============================] - 1s 419us/step - loss: 0.0648 - val_loss: 0.0669\n",
      "Epoch 122/1500\n",
      "1700/1700 [==============================] - 1s 488us/step - loss: 0.0653 - val_loss: 0.0670\n",
      "Epoch 123/1500\n",
      "1700/1700 [==============================] - 1s 419us/step - loss: 0.0645 - val_loss: 0.0662\n",
      "Epoch 124/1500\n",
      "1700/1700 [==============================] - 1s 411us/step - loss: 0.0642 - val_loss: 0.0659\n",
      "Epoch 125/1500\n",
      "1700/1700 [==============================] - 1s 448us/step - loss: 0.0644 - val_loss: 0.0666\n",
      "Epoch 126/1500\n",
      "1700/1700 [==============================] - 1s 425us/step - loss: 0.0645 - val_loss: 0.0664\n",
      "Epoch 127/1500\n",
      "1700/1700 [==============================] - 1s 436us/step - loss: 0.0643 - val_loss: 0.0663\n",
      "Epoch 128/1500\n",
      "1700/1700 [==============================] - 1s 443us/step - loss: 0.0644 - val_loss: 0.0662\n",
      "Epoch 129/1500\n",
      "1700/1700 [==============================] - 1s 485us/step - loss: 0.0644 - val_loss: 0.0661\n",
      "Epoch 130/1500\n",
      "1700/1700 [==============================] - 1s 416us/step - loss: 0.0643 - val_loss: 0.0663\n",
      "Epoch 131/1500\n",
      "1700/1700 [==============================] - 1s 411us/step - loss: 0.0642 - val_loss: 0.0666\n",
      "Epoch 132/1500\n",
      "1700/1700 [==============================] - 1s 408us/step - loss: 0.0643 - val_loss: 0.0666\n",
      "Epoch 133/1500\n",
      "1700/1700 [==============================] - 1s 423us/step - loss: 0.0647 - val_loss: 0.0666\n",
      "Epoch 134/1500\n",
      "1700/1700 [==============================] - 1s 399us/step - loss: 0.0647 - val_loss: 0.0675\n",
      "Epoch 135/1500\n",
      "1700/1700 [==============================] - 1s 424us/step - loss: 0.0645 - val_loss: 0.0663\n",
      "Epoch 136/1500\n",
      "1700/1700 [==============================] - 1s 489us/step - loss: 0.0643 - val_loss: 0.0664\n",
      "Epoch 137/1500\n",
      "1700/1700 [==============================] - 1s 452us/step - loss: 0.0643 - val_loss: 0.0667\n",
      "Epoch 138/1500\n",
      "1700/1700 [==============================] - 1s 409us/step - loss: 0.0646 - val_loss: 0.0662\n",
      "Epoch 139/1500\n",
      "1700/1700 [==============================] - 1s 741us/step - loss: 0.0643 - val_loss: 0.0663\n",
      "Epoch 140/1500\n",
      "1700/1700 [==============================] - 1s 453us/step - loss: 0.0643 - val_loss: 0.0665\n",
      "Epoch 141/1500\n",
      "1700/1700 [==============================] - 1s 387us/step - loss: 0.0641 - val_loss: 0.0662\n",
      "Epoch 142/1500\n",
      "1700/1700 [==============================] - 1s 498us/step - loss: 0.0642 - val_loss: 0.0660\n",
      "Epoch 143/1500\n",
      "1700/1700 [==============================] - 1s 419us/step - loss: 0.0642 - val_loss: 0.0665\n",
      "Epoch 144/1500\n",
      "1700/1700 [==============================] - ETA: 0s - loss: 0.0642- ETA: 0s - l - 1s 499us/step - loss: 0.0643 - val_loss: 0.0663\n",
      "Epoch 145/1500\n",
      "1700/1700 [==============================] - 1s 461us/step - loss: 0.0643 - val_loss: 0.0662\n",
      "Epoch 146/1500\n",
      "1700/1700 [==============================] - 1s 428us/step - loss: 0.0644 - val_loss: 0.0670\n",
      "Epoch 147/1500\n",
      "1700/1700 [==============================] - 1s 421us/step - loss: 0.0642 - val_loss: 0.0659\n",
      "Epoch 148/1500\n",
      "1700/1700 [==============================] - 1s 417us/step - loss: 0.0641 - val_loss: 0.0661\n",
      "Epoch 149/1500\n",
      "1700/1700 [==============================] - 1s 489us/step - loss: 0.0640 - val_loss: 0.0659\n",
      "Epoch 150/1500\n",
      "1700/1700 [==============================] - 1s 423us/step - loss: 0.0643 - val_loss: 0.0666\n",
      "Epoch 151/1500\n",
      "1700/1700 [==============================] - 1s 444us/step - loss: 0.0643 - val_loss: 0.0664\n",
      "Epoch 152/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 1s 396us/step - loss: 0.0641 - val_loss: 0.0657\n",
      "Epoch 153/1500\n",
      "1700/1700 [==============================] - ETA: 0s - loss: 0.063 - 1s 382us/step - loss: 0.0640 - val_loss: 0.0655\n",
      "Epoch 154/1500\n",
      "1700/1700 [==============================] - 1s 404us/step - loss: 0.0641 - val_loss: 0.0681\n",
      "Epoch 155/1500\n",
      "1700/1700 [==============================] - 1s 406us/step - loss: 0.0650 - val_loss: 0.0661\n",
      "Epoch 156/1500\n",
      "1700/1700 [==============================] - 1s 448us/step - loss: 0.0642 - val_loss: 0.0662\n",
      "Epoch 157/1500\n",
      "1700/1700 [==============================] - 1s 413us/step - loss: 0.0645 - val_loss: 0.0659\n",
      "Epoch 158/1500\n",
      "1700/1700 [==============================] - 1s 384us/step - loss: 0.0639 - val_loss: 0.0656\n",
      "Epoch 159/1500\n",
      "1700/1700 [==============================] - 1s 483us/step - loss: 0.0639 - val_loss: 0.0657\n",
      "Epoch 160/1500\n",
      "1700/1700 [==============================] - 1s 746us/step - loss: 0.0641 - val_loss: 0.0663\n",
      "Epoch 161/1500\n",
      "1700/1700 [==============================] - 2s 954us/step - loss: 0.0640 - val_loss: 0.0668\n",
      "Epoch 162/1500\n",
      "1700/1700 [==============================] - 1s 637us/step - loss: 0.0644 - val_loss: 0.0663\n",
      "Epoch 163/1500\n",
      "1700/1700 [==============================] - 1s 734us/step - loss: 0.0645 - val_loss: 0.0675\n",
      "Epoch 164/1500\n",
      "1700/1700 [==============================] - 1s 521us/step - loss: 0.0640 - val_loss: 0.0663\n",
      "Epoch 165/1500\n",
      "1700/1700 [==============================] - 1s 592us/step - loss: 0.0641 - val_loss: 0.0661\n",
      "Epoch 166/1500\n",
      "1700/1700 [==============================] - 1s 539us/step - loss: 0.0640 - val_loss: 0.0661\n",
      "Epoch 167/1500\n",
      "1700/1700 [==============================] - 1s 564us/step - loss: 0.0640 - val_loss: 0.0661\n",
      "Epoch 168/1500\n",
      "1700/1700 [==============================] - 1s 717us/step - loss: 0.0639 - val_loss: 0.0664\n",
      "Epoch 169/1500\n",
      "1700/1700 [==============================] - 1s 713us/step - loss: 0.0640 - val_loss: 0.0659\n",
      "Epoch 170/1500\n",
      "1700/1700 [==============================] - 1s 568us/step - loss: 0.0638 - val_loss: 0.0659\n",
      "Epoch 171/1500\n",
      "1700/1700 [==============================] - 1s 811us/step - loss: 0.0639 - val_loss: 0.0659\n",
      "Epoch 172/1500\n",
      "1700/1700 [==============================] - 1s 636us/step - loss: 0.0640 - val_loss: 0.0662\n",
      "Epoch 173/1500\n",
      "1700/1700 [==============================] - ETA: 0s - loss: 0.064 - 1s 759us/step - loss: 0.0642 - val_loss: 0.0662\n",
      "Epoch 174/1500\n",
      "1700/1700 [==============================] - 1s 831us/step - loss: 0.0640 - val_loss: 0.0660\n",
      "Epoch 175/1500\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.0641 - val_loss: 0.0659\n",
      "Epoch 176/1500\n",
      "1700/1700 [==============================] - 1s 643us/step - loss: 0.0640 - val_loss: 0.0659\n",
      "Epoch 177/1500\n",
      "1700/1700 [==============================] - 1s 644us/step - loss: 0.0642 - val_loss: 0.0658\n",
      "Epoch 178/1500\n",
      "1700/1700 [==============================] - 1s 531us/step - loss: 0.0638 - val_loss: 0.0663\n",
      "Epoch 179/1500\n",
      "1700/1700 [==============================] - 1s 532us/step - loss: 0.0642 - val_loss: 0.0659\n",
      "Epoch 180/1500\n",
      "1700/1700 [==============================] - 1s 450us/step - loss: 0.0639 - val_loss: 0.0662\n",
      "Epoch 181/1500\n",
      "1700/1700 [==============================] - 1s 425us/step - loss: 0.0638 - val_loss: 0.0663\n",
      "Epoch 182/1500\n",
      "1700/1700 [==============================] - 1s 398us/step - loss: 0.0640 - val_loss: 0.0659\n",
      "Epoch 183/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0638 - val_loss: 0.0657\n",
      "Epoch 184/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0642 - val_loss: 0.0664\n",
      "Epoch 185/1500\n",
      "1700/1700 [==============================] - 1s 362us/step - loss: 0.0640 - val_loss: 0.0662\n",
      "Epoch 186/1500\n",
      "1700/1700 [==============================] - 1s 355us/step - loss: 0.0640 - val_loss: 0.0667\n",
      "Epoch 187/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0639 - val_loss: 0.0659\n",
      "Epoch 188/1500\n",
      "1700/1700 [==============================] - 1s 413us/step - loss: 0.0638 - val_loss: 0.0665\n",
      "Epoch 189/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0639 - val_loss: 0.0661\n",
      "Epoch 190/1500\n",
      "1700/1700 [==============================] - 1s 358us/step - loss: 0.0638 - val_loss: 0.0668\n",
      "Epoch 191/1500\n",
      "1700/1700 [==============================] - 1s 653us/step - loss: 0.0642 - val_loss: 0.0661\n",
      "Epoch 192/1500\n",
      "1700/1700 [==============================] - 3s 2ms/step - loss: 0.0640 - val_loss: 0.0665\n",
      "Epoch 193/1500\n",
      "1700/1700 [==============================] - 1s 615us/step - loss: 0.0639 - val_loss: 0.0665\n",
      "Epoch 194/1500\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.0639 - val_loss: 0.0660\n",
      "Epoch 195/1500\n",
      "1700/1700 [==============================] - 3s 2ms/step - loss: 0.0637 - val_loss: 0.0659\n",
      "Epoch 196/1500\n",
      "1700/1700 [==============================] - 2s 993us/step - loss: 0.0638 - val_loss: 0.0662\n",
      "Epoch 197/1500\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.0638 - val_loss: 0.0659\n",
      "Epoch 198/1500\n",
      "1700/1700 [==============================] - 1s 586us/step - loss: 0.0638 - val_loss: 0.0658\n",
      "Epoch 199/1500\n",
      "1700/1700 [==============================] - 1s 373us/step - loss: 0.0638 - val_loss: 0.0662\n",
      "Epoch 200/1500\n",
      "1700/1700 [==============================] - 1s 850us/step - loss: 0.0640 - val_loss: 0.0664\n",
      "Epoch 201/1500\n",
      "1700/1700 [==============================] - 1s 632us/step - loss: 0.0638 - val_loss: 0.0658\n",
      "Epoch 202/1500\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.0637 - val_loss: 0.0664\n",
      "Epoch 203/1500\n",
      "1700/1700 [==============================] - 1s 665us/step - loss: 0.0639 - val_loss: 0.0660\n",
      "Epoch 204/1500\n",
      "1700/1700 [==============================] - 3s 2ms/step - loss: 0.0637 - val_loss: 0.0662\n",
      "Epoch 205/1500\n",
      "1700/1700 [==============================] - 4s 2ms/step - loss: 0.0638 - val_loss: 0.0656\n",
      "Epoch 206/1500\n",
      "1700/1700 [==============================] - 3s 1ms/step - loss: 0.0637 - val_loss: 0.0660\n",
      "Epoch 207/1500\n",
      "1700/1700 [==============================] - 1s 788us/step - loss: 0.0639 - val_loss: 0.0667\n",
      "Epoch 208/1500\n",
      "1700/1700 [==============================] - 1s 539us/step - loss: 0.0641 - val_loss: 0.0662\n",
      "Epoch 209/1500\n",
      "1700/1700 [==============================] - 1s 724us/step - loss: 0.0638 - val_loss: 0.0658\n",
      "Epoch 210/1500\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.0639 - val_loss: 0.0661\n",
      "Epoch 211/1500\n",
      "1700/1700 [==============================] - 1s 802us/step - loss: 0.0637 - val_loss: 0.0660\n",
      "Epoch 212/1500\n",
      "1700/1700 [==============================] - 1s 403us/step - loss: 0.0641 - val_loss: 0.0658\n",
      "Epoch 213/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0636 - val_loss: 0.0660\n",
      "Epoch 214/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0637 - val_loss: 0.0660\n",
      "Epoch 215/1500\n",
      "1700/1700 [==============================] - 1s 313us/step - loss: 0.0636 - val_loss: 0.0659\n",
      "Epoch 216/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0637 - val_loss: 0.0657\n",
      "Epoch 217/1500\n",
      "1700/1700 [==============================] - 1s 394us/step - loss: 0.0637 - val_loss: 0.0668\n",
      "Epoch 218/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0638 - val_loss: 0.0657\n",
      "Epoch 219/1500\n",
      "1700/1700 [==============================] - 1s 368us/step - loss: 0.0637 - val_loss: 0.0662\n",
      "Epoch 220/1500\n",
      "1700/1700 [==============================] - 1s 310us/step - loss: 0.0636 - val_loss: 0.0657\n",
      "Epoch 221/1500\n",
      "1700/1700 [==============================] - 1s 531us/step - loss: 0.0637 - val_loss: 0.0657\n",
      "Epoch 222/1500\n",
      "1700/1700 [==============================] - 1s 416us/step - loss: 0.0638 - val_loss: 0.0666\n",
      "Epoch 223/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0643 - val_loss: 0.0662\n",
      "Epoch 224/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0636 - val_loss: 0.0657\n",
      "Epoch 225/1500\n",
      "1700/1700 [==============================] - 1s 381us/step - loss: 0.0637 - val_loss: 0.0662\n",
      "Epoch 226/1500\n",
      "1700/1700 [==============================] - 1s 343us/step - loss: 0.0639 - val_loss: 0.0659\n",
      "Epoch 227/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 1s 376us/step - loss: 0.0636 - val_loss: 0.0657\n",
      "Epoch 228/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0638 - val_loss: 0.0657\n",
      "Epoch 229/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0636 - val_loss: 0.0660\n",
      "Epoch 230/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0635 - val_loss: 0.0675\n",
      "Epoch 231/1500\n",
      "1700/1700 [==============================] - 1s 308us/step - loss: 0.0636 - val_loss: 0.0659\n",
      "Epoch 232/1500\n",
      "1700/1700 [==============================] - 1s 580us/step - loss: 0.0636 - val_loss: 0.0660\n",
      "Epoch 233/1500\n",
      "1700/1700 [==============================] - 1s 422us/step - loss: 0.0636 - val_loss: 0.0664\n",
      "Epoch 234/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0637 - val_loss: 0.0656\n",
      "Epoch 235/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0636 - val_loss: 0.0660\n",
      "Epoch 236/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0638 - val_loss: 0.0663\n",
      "Epoch 237/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0640 - val_loss: 0.0660\n",
      "Epoch 238/1500\n",
      "1700/1700 [==============================] - 1s 385us/step - loss: 0.0636 - val_loss: 0.0662\n",
      "Epoch 239/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0635 - val_loss: 0.0660\n",
      "Epoch 240/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0635 - val_loss: 0.0656\n",
      "Epoch 241/1500\n",
      "1700/1700 [==============================] - 1s 406us/step - loss: 0.0637 - val_loss: 0.0657\n",
      "Epoch 242/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0637 - val_loss: 0.0657\n",
      "Epoch 243/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0636 - val_loss: 0.0656\n",
      "Epoch 244/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0635 - val_loss: 0.0660\n",
      "Epoch 245/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0638 - val_loss: 0.0662\n",
      "Epoch 246/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0636 - val_loss: 0.0660\n",
      "Epoch 247/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0636 - val_loss: 0.0657\n",
      "Epoch 248/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0636 - val_loss: 0.0658\n",
      "Epoch 249/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0637 - val_loss: 0.0659\n",
      "Epoch 250/1500\n",
      "1700/1700 [==============================] - 1s 380us/step - loss: 0.0636 - val_loss: 0.0660\n",
      "Epoch 251/1500\n",
      "1700/1700 [==============================] - 1s 325us/step - loss: 0.0636 - val_loss: 0.0659\n",
      "Epoch 252/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0637 - val_loss: 0.0664\n",
      "Epoch 253/1500\n",
      "1700/1700 [==============================] - 1s 346us/step - loss: 0.0637 - val_loss: 0.0656\n",
      "Epoch 254/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0634 - val_loss: 0.0657\n",
      "Epoch 255/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0635 - val_loss: 0.0660\n",
      "Epoch 256/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0637 - val_loss: 0.0660\n",
      "Epoch 257/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0635 - val_loss: 0.0661\n",
      "Epoch 258/1500\n",
      "1700/1700 [==============================] - 1s 413us/step - loss: 0.0636 - val_loss: 0.0661\n",
      "Epoch 259/1500\n",
      "1700/1700 [==============================] - 1s 591us/step - loss: 0.0636 - val_loss: 0.0660\n",
      "Epoch 260/1500\n",
      "1700/1700 [==============================] - 1s 324us/step - loss: 0.0635 - val_loss: 0.0658\n",
      "Epoch 261/1500\n",
      "1700/1700 [==============================] - 1s 351us/step - loss: 0.0634 - val_loss: 0.0661\n",
      "Epoch 262/1500\n",
      "1700/1700 [==============================] - 1s 339us/step - loss: 0.0635 - val_loss: 0.0663\n",
      "Epoch 263/1500\n",
      "1700/1700 [==============================] - 1s 340us/step - loss: 0.0636 - val_loss: 0.0659\n",
      "Epoch 264/1500\n",
      "1700/1700 [==============================] - 1s 352us/step - loss: 0.0634 - val_loss: 0.0659\n",
      "Epoch 265/1500\n",
      "1700/1700 [==============================] - 1s 319us/step - loss: 0.0636 - val_loss: 0.0657\n",
      "Epoch 266/1500\n",
      "1700/1700 [==============================] - ETA: 0s - loss: 0.063 - 1s 336us/step - loss: 0.0635 - val_loss: 0.0662\n",
      "Epoch 267/1500\n",
      "1700/1700 [==============================] - 1s 381us/step - loss: 0.0637 - val_loss: 0.0661\n",
      "Epoch 268/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0634 - val_loss: 0.0656\n",
      "Epoch 269/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0637 - val_loss: 0.0654\n",
      "Epoch 270/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0635 - val_loss: 0.0658\n",
      "Epoch 271/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0634 - val_loss: 0.0663\n",
      "Epoch 272/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0634 - val_loss: 0.0662\n",
      "Epoch 273/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0636 - val_loss: 0.0663\n",
      "Epoch 274/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0639 - val_loss: 0.0663\n",
      "Epoch 275/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0634 - val_loss: 0.0659\n",
      "Epoch 276/1500\n",
      "1700/1700 [==============================] - 1s 385us/step - loss: 0.0634 - val_loss: 0.0658\n",
      "Epoch 277/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0635 - val_loss: 0.0659\n",
      "Epoch 278/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0634 - val_loss: 0.0662\n",
      "Epoch 279/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0636 - val_loss: 0.0660\n",
      "Epoch 280/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0636 - val_loss: 0.0659\n",
      "Epoch 281/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0634 - val_loss: 0.0659\n",
      "Epoch 282/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0633 - val_loss: 0.0660\n",
      "Epoch 283/1500\n",
      "1700/1700 [==============================] - 1s 343us/step - loss: 0.0634 - val_loss: 0.0657\n",
      "Epoch 284/1500\n",
      "1700/1700 [==============================] - 1s 404us/step - loss: 0.0635 - val_loss: 0.0659\n",
      "Epoch 285/1500\n",
      "1700/1700 [==============================] - 1s 639us/step - loss: 0.0634 - val_loss: 0.0669\n",
      "Epoch 286/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0637 - val_loss: 0.0658\n",
      "Epoch 287/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0636 - val_loss: 0.0658\n",
      "Epoch 288/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0633 - val_loss: 0.0661\n",
      "Epoch 289/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0636 - val_loss: 0.0660\n",
      "Epoch 290/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0634 - val_loss: 0.0660\n",
      "Epoch 291/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0633 - val_loss: 0.0657\n",
      "Epoch 292/1500\n",
      "1700/1700 [==============================] - 1s 403us/step - loss: 0.0633 - val_loss: 0.0657\n",
      "Epoch 293/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0636 - val_loss: 0.0659\n",
      "Epoch 294/1500\n",
      "1700/1700 [==============================] - 1s 313us/step - loss: 0.0634 - val_loss: 0.0665\n",
      "Epoch 295/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0635 - val_loss: 0.0659\n",
      "Epoch 296/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0635 - val_loss: 0.0659\n",
      "Epoch 297/1500\n",
      "1700/1700 [==============================] - 1s 358us/step - loss: 0.0634 - val_loss: 0.0660\n",
      "Epoch 298/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0633 - val_loss: 0.0656\n",
      "Epoch 299/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0634 - val_loss: 0.0657\n",
      "Epoch 300/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0634 - val_loss: 0.0659\n",
      "Epoch 301/1500\n",
      "1700/1700 [==============================] - 1s 390us/step - loss: 0.0635 - val_loss: 0.0656\n",
      "Epoch 302/1500\n",
      "1700/1700 [==============================] - 1s 337us/step - loss: 0.0634 - val_loss: 0.0666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/1500\n",
      "1700/1700 [==============================] - 1s 321us/step - loss: 0.0633 - val_loss: 0.0657\n",
      "Epoch 304/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0633 - val_loss: 0.0660\n",
      "Epoch 305/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0634 - val_loss: 0.0659\n",
      "Epoch 306/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0634 - val_loss: 0.0662\n",
      "Epoch 307/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0634 - val_loss: 0.0658\n",
      "Epoch 308/1500\n",
      "1700/1700 [==============================] - 1s 304us/step - loss: 0.0636 - val_loss: 0.0659\n",
      "Epoch 309/1500\n",
      "1700/1700 [==============================] - 1s 334us/step - loss: 0.0636 - val_loss: 0.0656\n",
      "Epoch 310/1500\n",
      "1700/1700 [==============================] - 1s 431us/step - loss: 0.0631 - val_loss: 0.0659\n",
      "Epoch 311/1500\n",
      "1700/1700 [==============================] - 1s 628us/step - loss: 0.0632 - val_loss: 0.0658\n",
      "Epoch 312/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0635 - val_loss: 0.0662\n",
      "Epoch 313/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0634 - val_loss: 0.0663\n",
      "Epoch 314/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0631 - val_loss: 0.0655\n",
      "Epoch 315/1500\n",
      "1700/1700 [==============================] - 1s 311us/step - loss: 0.0635 - val_loss: 0.0659\n",
      "Epoch 316/1500\n",
      "1700/1700 [==============================] - 1s 337us/step - loss: 0.0632 - val_loss: 0.0659\n",
      "Epoch 317/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0633 - val_loss: 0.0658\n",
      "Epoch 318/1500\n",
      "1700/1700 [==============================] - 1s 381us/step - loss: 0.0632 - val_loss: 0.0657\n",
      "Epoch 319/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0633 - val_loss: 0.0660\n",
      "Epoch 320/1500\n",
      "1700/1700 [==============================] - 1s 348us/step - loss: 0.0633 - val_loss: 0.0660\n",
      "Epoch 321/1500\n",
      "1700/1700 [==============================] - 1s 368us/step - loss: 0.0634 - val_loss: 0.0658\n",
      "Epoch 322/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0634 - val_loss: 0.0661\n",
      "Epoch 323/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0634 - val_loss: 0.0661\n",
      "Epoch 324/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0632 - val_loss: 0.0658\n",
      "Epoch 325/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0633 - val_loss: 0.0656\n",
      "Epoch 326/1500\n",
      "1700/1700 [==============================] - 1s 408us/step - loss: 0.0636 - val_loss: 0.0658\n",
      "Epoch 327/1500\n",
      "1700/1700 [==============================] - 1s 367us/step - loss: 0.0633 - val_loss: 0.0660\n",
      "Epoch 328/1500\n",
      "1700/1700 [==============================] - 1s 350us/step - loss: 0.0632 - val_loss: 0.0661\n",
      "Epoch 329/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0631 - val_loss: 0.0657\n",
      "Epoch 330/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0635 - val_loss: 0.0662\n",
      "Epoch 331/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0637 - val_loss: 0.0669\n",
      "Epoch 332/1500\n",
      "1700/1700 [==============================] - 1s 385us/step - loss: 0.0637 - val_loss: 0.0658\n",
      "Epoch 333/1500\n",
      "1700/1700 [==============================] - 1s 313us/step - loss: 0.0632 - val_loss: 0.0664\n",
      "Epoch 334/1500\n",
      "1700/1700 [==============================] - 1s 431us/step - loss: 0.0633 - val_loss: 0.0662\n",
      "Epoch 335/1500\n",
      "1700/1700 [==============================] - 1s 385us/step - loss: 0.0633 - val_loss: 0.0662\n",
      "Epoch 336/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0632 - val_loss: 0.0657\n",
      "Epoch 337/1500\n",
      "1700/1700 [==============================] - 1s 648us/step - loss: 0.0634 - val_loss: 0.0661\n",
      "Epoch 338/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0633 - val_loss: 0.0659\n",
      "Epoch 339/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0633 - val_loss: 0.0659\n",
      "Epoch 340/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0632 - val_loss: 0.0659\n",
      "Epoch 341/1500\n",
      "1700/1700 [==============================] - 1s 340us/step - loss: 0.0631 - val_loss: 0.0657\n",
      "Epoch 342/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0632 - val_loss: 0.0659\n",
      "Epoch 343/1500\n",
      "1700/1700 [==============================] - 1s 403us/step - loss: 0.0634 - val_loss: 0.0661\n",
      "Epoch 344/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0634 - val_loss: 0.0659\n",
      "Epoch 345/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0631 - val_loss: 0.0660\n",
      "Epoch 346/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0630 - val_loss: 0.0657\n",
      "Epoch 347/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0631 - val_loss: 0.0656\n",
      "Epoch 348/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0631 - val_loss: 0.0658\n",
      "Epoch 349/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0633 - val_loss: 0.0663\n",
      "Epoch 350/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0634 - val_loss: 0.0659\n",
      "Epoch 351/1500\n",
      "1700/1700 [==============================] - 1s 394us/step - loss: 0.0631 - val_loss: 0.0657\n",
      "Epoch 352/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0631 - val_loss: 0.0659\n",
      "Epoch 353/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0632 - val_loss: 0.0661\n",
      "Epoch 354/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0631 - val_loss: 0.0655\n",
      "Epoch 355/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0632 - val_loss: 0.0656\n",
      "Epoch 356/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0632 - val_loss: 0.0658\n",
      "Epoch 357/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0630 - val_loss: 0.0658\n",
      "Epoch 358/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0631 - val_loss: 0.0657\n",
      "Epoch 359/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0633 - val_loss: 0.0665\n",
      "Epoch 360/1500\n",
      "1700/1700 [==============================] - 1s 437us/step - loss: 0.0634 - val_loss: 0.0662\n",
      "Epoch 361/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0631 - val_loss: 0.0660\n",
      "Epoch 362/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0632 - val_loss: 0.0659\n",
      "Epoch 363/1500\n",
      "1700/1700 [==============================] - 1s 685us/step - loss: 0.0632 - val_loss: 0.0659\n",
      "Epoch 364/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0631 - val_loss: 0.0659\n",
      "Epoch 365/1500\n",
      "1700/1700 [==============================] - 1s 338us/step - loss: 0.0631 - val_loss: 0.0664\n",
      "Epoch 366/1500\n",
      "1700/1700 [==============================] - 1s 324us/step - loss: 0.0633 - val_loss: 0.0659\n",
      "Epoch 367/1500\n",
      "1700/1700 [==============================] - 1s 331us/step - loss: 0.0631 - val_loss: 0.0659\n",
      "Epoch 368/1500\n",
      "1700/1700 [==============================] - 1s 403us/step - loss: 0.0632 - val_loss: 0.0654\n",
      "Epoch 369/1500\n",
      "1700/1700 [==============================] - 1s 375us/step - loss: 0.0632 - val_loss: 0.0657\n",
      "Epoch 370/1500\n",
      "1700/1700 [==============================] - 1s 369us/step - loss: 0.0632 - val_loss: 0.0657\n",
      "Epoch 371/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0633 - val_loss: 0.0658\n",
      "Epoch 372/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0630 - val_loss: 0.0656\n",
      "Epoch 373/1500\n",
      "1700/1700 [==============================] - 1s 304us/step - loss: 0.0632 - val_loss: 0.0656\n",
      "Epoch 374/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0630 - val_loss: 0.0659\n",
      "Epoch 375/1500\n",
      "1700/1700 [==============================] - 1s 337us/step - loss: 0.0630 - val_loss: 0.0661\n",
      "Epoch 376/1500\n",
      "1700/1700 [==============================] - 1s 311us/step - loss: 0.0630 - val_loss: 0.0658\n",
      "Epoch 377/1500\n",
      "1700/1700 [==============================] - 1s 395us/step - loss: 0.0631 - val_loss: 0.0659\n",
      "Epoch 378/1500\n",
      "1700/1700 [==============================] - 1s 336us/step - loss: 0.0631 - val_loss: 0.0662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0633 - val_loss: 0.0661\n",
      "Epoch 380/1500\n",
      "1700/1700 [==============================] - 1s 334us/step - loss: 0.0630 - val_loss: 0.0658\n",
      "Epoch 381/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0631 - val_loss: 0.0658\n",
      "Epoch 382/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0631 - val_loss: 0.0657\n",
      "Epoch 383/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0631 - val_loss: 0.0662\n",
      "Epoch 384/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0632 - val_loss: 0.0659\n",
      "Epoch 385/1500\n",
      "1700/1700 [==============================] - 1s 431us/step - loss: 0.0630 - val_loss: 0.0659\n",
      "Epoch 386/1500\n",
      "1700/1700 [==============================] - 1s 358us/step - loss: 0.0631 - val_loss: 0.0662\n",
      "Epoch 387/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0631 - val_loss: 0.0662\n",
      "Epoch 388/1500\n",
      "1700/1700 [==============================] - 1s 385us/step - loss: 0.0631 - val_loss: 0.0661\n",
      "Epoch 389/1500\n",
      "1700/1700 [==============================] - 1s 586us/step - loss: 0.0632 - val_loss: 0.0655\n",
      "Epoch 390/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0629 - val_loss: 0.0659\n",
      "Epoch 391/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0630 - val_loss: 0.0660\n",
      "Epoch 392/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0630 - val_loss: 0.0657\n",
      "Epoch 393/1500\n",
      "1700/1700 [==============================] - 1s 391us/step - loss: 0.0630 - val_loss: 0.0656\n",
      "Epoch 394/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0632 - val_loss: 0.0655\n",
      "Epoch 395/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0630 - val_loss: 0.0663\n",
      "Epoch 396/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0631 - val_loss: 0.0670\n",
      "Epoch 397/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0632 - val_loss: 0.0660\n",
      "Epoch 398/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0630 - val_loss: 0.0658\n",
      "Epoch 399/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0631 - val_loss: 0.0659\n",
      "Epoch 400/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0630 - val_loss: 0.0661\n",
      "Epoch 401/1500\n",
      "1700/1700 [==============================] - 1s 349us/step - loss: 0.0630 - val_loss: 0.0661\n",
      "Epoch 402/1500\n",
      "1700/1700 [==============================] - 1s 413us/step - loss: 0.0631 - val_loss: 0.0658\n",
      "Epoch 403/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0630 - val_loss: 0.0660\n",
      "Epoch 404/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0631 - val_loss: 0.0667\n",
      "Epoch 405/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0634 - val_loss: 0.0661\n",
      "Epoch 406/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0630 - val_loss: 0.0662\n",
      "Epoch 407/1500\n",
      "1700/1700 [==============================] - 1s 343us/step - loss: 0.0630 - val_loss: 0.0655\n",
      "Epoch 408/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0630 - val_loss: 0.0658\n",
      "Epoch 409/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0630 - val_loss: 0.0657\n",
      "Epoch 410/1500\n",
      "1700/1700 [==============================] - 1s 459us/step - loss: 0.0630 - val_loss: 0.0665\n",
      "Epoch 411/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0632 - val_loss: 0.0659\n",
      "Epoch 412/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0630 - val_loss: 0.0660\n",
      "Epoch 413/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0630 - val_loss: 0.0657\n",
      "Epoch 414/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0631 - val_loss: 0.0658\n",
      "Epoch 415/1500\n",
      "1700/1700 [==============================] - 1s 649us/step - loss: 0.0629 - val_loss: 0.0657\n",
      "Epoch 416/1500\n",
      "1700/1700 [==============================] - 1s 422us/step - loss: 0.0630 - val_loss: 0.0660\n",
      "Epoch 417/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0630 - val_loss: 0.0657\n",
      "Epoch 418/1500\n",
      "1700/1700 [==============================] - 1s 385us/step - loss: 0.0628 - val_loss: 0.0663\n",
      "Epoch 419/1500\n",
      "1700/1700 [==============================] - 1s 403us/step - loss: 0.0632 - val_loss: 0.0658\n",
      "Epoch 420/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0629 - val_loss: 0.0659\n",
      "Epoch 421/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0632 - val_loss: 0.0661\n",
      "Epoch 422/1500\n",
      "1700/1700 [==============================] - 1s 336us/step - loss: 0.0632 - val_loss: 0.0662\n",
      "Epoch 423/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0629 - val_loss: 0.0656\n",
      "Epoch 424/1500\n",
      "1700/1700 [==============================] - 1s 313us/step - loss: 0.0628 - val_loss: 0.0656\n",
      "Epoch 425/1500\n",
      "1700/1700 [==============================] - 1s 334us/step - loss: 0.0630 - val_loss: 0.0659\n",
      "Epoch 426/1500\n",
      "1700/1700 [==============================] - 1s 373us/step - loss: 0.0629 - val_loss: 0.0658\n",
      "Epoch 427/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0631 - val_loss: 0.0662\n",
      "Epoch 428/1500\n",
      "1700/1700 [==============================] - 1s 313us/step - loss: 0.0629 - val_loss: 0.0658\n",
      "Epoch 429/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0631 - val_loss: 0.0662\n",
      "Epoch 430/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0631 - val_loss: 0.0660\n",
      "Epoch 431/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0629 - val_loss: 0.0658\n",
      "Epoch 432/1500\n",
      "1700/1700 [==============================] - 1s 336us/step - loss: 0.0630 - val_loss: 0.0659\n",
      "Epoch 433/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0629 - val_loss: 0.0659\n",
      "Epoch 434/1500\n",
      "1700/1700 [==============================] - 1s 376us/step - loss: 0.0629 - val_loss: 0.0656\n",
      "Epoch 435/1500\n",
      "1700/1700 [==============================] - 1s 419us/step - loss: 0.0628 - val_loss: 0.0661\n",
      "Epoch 436/1500\n",
      "1700/1700 [==============================] - 1s 323us/step - loss: 0.0630 - val_loss: 0.0661\n",
      "Epoch 437/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0630 - val_loss: 0.0656\n",
      "Epoch 438/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0628 - val_loss: 0.0659\n",
      "Epoch 439/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0630 - val_loss: 0.0661\n",
      "Epoch 440/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0629 - val_loss: 0.0659\n",
      "Epoch 441/1500\n",
      "1700/1700 [==============================] - 1s 590us/step - loss: 0.0628 - val_loss: 0.0657\n",
      "Epoch 442/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0628 - val_loss: 0.0658\n",
      "Epoch 443/1500\n",
      "1700/1700 [==============================] - 1s 413us/step - loss: 0.0631 - val_loss: 0.0660\n",
      "Epoch 444/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0631 - val_loss: 0.0661\n",
      "Epoch 445/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0630 - val_loss: 0.0657\n",
      "Epoch 446/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0628 - val_loss: 0.0659\n",
      "Epoch 447/1500\n",
      "1700/1700 [==============================] - 1s 314us/step - loss: 0.0628 - val_loss: 0.0657\n",
      "Epoch 448/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0628 - val_loss: 0.0654\n",
      "Epoch 449/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0631 - val_loss: 0.0658\n",
      "Epoch 450/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0629 - val_loss: 0.0657\n",
      "Epoch 451/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0628 - val_loss: 0.0657\n",
      "Epoch 452/1500\n",
      "1700/1700 [==============================] - 1s 403us/step - loss: 0.0630 - val_loss: 0.0662\n",
      "Epoch 453/1500\n",
      "1700/1700 [==============================] - 1s 308us/step - loss: 0.0628 - val_loss: 0.0659\n",
      "Epoch 454/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0629 - val_loss: 0.0658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0630 - val_loss: 0.0661\n",
      "Epoch 456/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0629 - val_loss: 0.0658\n",
      "Epoch 457/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0628 - val_loss: 0.0656\n",
      "Epoch 458/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0630 - val_loss: 0.0658\n",
      "Epoch 459/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0628 - val_loss: 0.0660\n",
      "Epoch 460/1500\n",
      "1700/1700 [==============================] - 1s 378us/step - loss: 0.0628 - val_loss: 0.0658\n",
      "Epoch 461/1500\n",
      "1700/1700 [==============================] - 1s 391us/step - loss: 0.0629 - val_loss: 0.0658\n",
      "Epoch 462/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0629 - val_loss: 0.0658\n",
      "Epoch 463/1500\n",
      "1700/1700 [==============================] - 1s 313us/step - loss: 0.0630 - val_loss: 0.0659\n",
      "Epoch 464/1500\n",
      "1700/1700 [==============================] - 1s 308us/step - loss: 0.0631 - val_loss: 0.0659\n",
      "Epoch 465/1500\n",
      "1700/1700 [==============================] - 1s 338us/step - loss: 0.0628 - val_loss: 0.0665\n",
      "Epoch 466/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0629 - val_loss: 0.0658\n",
      "Epoch 467/1500\n",
      "1700/1700 [==============================] - 1s 630us/step - loss: 0.0628 - val_loss: 0.0658\n",
      "Epoch 468/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0628 - val_loss: 0.0657\n",
      "Epoch 469/1500\n",
      "1700/1700 [==============================] - 1s 394us/step - loss: 0.0628 - val_loss: 0.0660\n",
      "Epoch 470/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0630 - val_loss: 0.0658\n",
      "Epoch 471/1500\n",
      "1700/1700 [==============================] - 1s 357us/step - loss: 0.0627 - val_loss: 0.0655\n",
      "Epoch 472/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0627 - val_loss: 0.0657\n",
      "Epoch 473/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0628 - val_loss: 0.0659\n",
      "Epoch 474/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0628 - val_loss: 0.0658\n",
      "Epoch 475/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0628 - val_loss: 0.0656\n",
      "Epoch 476/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0627 - val_loss: 0.0656\n",
      "Epoch 477/1500\n",
      "1700/1700 [==============================] - 1s 313us/step - loss: 0.0629 - val_loss: 0.0659\n",
      "Epoch 478/1500\n",
      "1700/1700 [==============================] - 1s 394us/step - loss: 0.0628 - val_loss: 0.0660\n",
      "Epoch 479/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0629 - val_loss: 0.0661\n",
      "Epoch 480/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0630 - val_loss: 0.0659\n",
      "Epoch 481/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0628 - val_loss: 0.0660\n",
      "Epoch 482/1500\n",
      "1700/1700 [==============================] - 1s 357us/step - loss: 0.0628 - val_loss: 0.0659\n",
      "Epoch 483/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0629 - val_loss: 0.0659\n",
      "Epoch 484/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0628 - val_loss: 0.0662\n",
      "Epoch 485/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0630 - val_loss: 0.0658\n",
      "Epoch 486/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0628 - val_loss: 0.0659\n",
      "Epoch 487/1500\n",
      "1700/1700 [==============================] - 1s 394us/step - loss: 0.0631 - val_loss: 0.0664\n",
      "Epoch 488/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0630 - val_loss: 0.0661\n",
      "Epoch 489/1500\n",
      "1700/1700 [==============================] - 1s 314us/step - loss: 0.0628 - val_loss: 0.0656\n",
      "Epoch 490/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0627 - val_loss: 0.0657\n",
      "Epoch 491/1500\n",
      "1700/1700 [==============================] - 1s 304us/step - loss: 0.0628 - val_loss: 0.0657\n",
      "Epoch 492/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0629 - val_loss: 0.0658\n",
      "Epoch 493/1500\n",
      "1700/1700 [==============================] - 1s 404us/step - loss: 0.0628 - val_loss: 0.0659\n",
      "Epoch 494/1500\n",
      "1700/1700 [==============================] - 1s 591us/step - loss: 0.0627 - val_loss: 0.0660\n",
      "Epoch 495/1500\n",
      "1700/1700 [==============================] - 1s 426us/step - loss: 0.0628 - val_loss: 0.0657\n",
      "Epoch 496/1500\n",
      "1700/1700 [==============================] - 1s 366us/step - loss: 0.0626 - val_loss: 0.0658\n",
      "Epoch 497/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0629 - val_loss: 0.0659\n",
      "Epoch 498/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0629 - val_loss: 0.0663\n",
      "Epoch 499/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0630 - val_loss: 0.0657\n",
      "Epoch 500/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0627 - val_loss: 0.0656\n",
      "Epoch 501/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0627 - val_loss: 0.0657\n",
      "Epoch 502/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0628 - val_loss: 0.0658\n",
      "Epoch 503/1500\n",
      "1700/1700 [==============================] - 1s 394us/step - loss: 0.0627 - val_loss: 0.0658\n",
      "Epoch 504/1500\n",
      "1700/1700 [==============================] - 1s 325us/step - loss: 0.0628 - val_loss: 0.0659\n",
      "Epoch 505/1500\n",
      "1700/1700 [==============================] - 1s 324us/step - loss: 0.0628 - val_loss: 0.0656\n",
      "Epoch 506/1500\n",
      "1700/1700 [==============================] - 1s 304us/step - loss: 0.0627 - val_loss: 0.0661\n",
      "Epoch 507/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0626 - val_loss: 0.0657\n",
      "Epoch 508/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0627 - val_loss: 0.0657\n",
      "Epoch 509/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0626 - val_loss: 0.0659\n",
      "Epoch 510/1500\n",
      "1700/1700 [==============================] - 1s 368us/step - loss: 0.0627 - val_loss: 0.0658\n",
      "Epoch 511/1500\n",
      "1700/1700 [==============================] - 1s 342us/step - loss: 0.0628 - val_loss: 0.0663\n",
      "Epoch 512/1500\n",
      "1700/1700 [==============================] - 1s 501us/step - loss: 0.0629 - val_loss: 0.0657\n",
      "Epoch 513/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0627 - val_loss: 0.0656\n",
      "Epoch 514/1500\n",
      "1700/1700 [==============================] - 1s 319us/step - loss: 0.0628 - val_loss: 0.0656\n",
      "Epoch 515/1500\n",
      "1700/1700 [==============================] - 1s 347us/step - loss: 0.0628 - val_loss: 0.0662\n",
      "Epoch 516/1500\n",
      "1700/1700 [==============================] - 1s 358us/step - loss: 0.0629 - val_loss: 0.0664\n",
      "Epoch 517/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0628 - val_loss: 0.0656\n",
      "Epoch 518/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0625 - val_loss: 0.0660\n",
      "Epoch 519/1500\n",
      "1700/1700 [==============================] - 1s 422us/step - loss: 0.0627 - val_loss: 0.0661\n",
      "Epoch 520/1500\n",
      "1700/1700 [==============================] - 1s 619us/step - loss: 0.0629 - val_loss: 0.0658\n",
      "Epoch 521/1500\n",
      "1700/1700 [==============================] - 1s 352us/step - loss: 0.0628 - val_loss: 0.0658\n",
      "Epoch 522/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0628 - val_loss: 0.0658\n",
      "Epoch 523/1500\n",
      "1700/1700 [==============================] - 1s 384us/step - loss: 0.0627 - val_loss: 0.0662\n",
      "Epoch 524/1500\n",
      "1700/1700 [==============================] - 1s 346us/step - loss: 0.0626 - val_loss: 0.0664\n",
      "Epoch 525/1500\n",
      "1700/1700 [==============================] - 1s 404us/step - loss: 0.0630 - val_loss: 0.0659\n",
      "Epoch 526/1500\n",
      "1700/1700 [==============================] - 1s 409us/step - loss: 0.0626 - val_loss: 0.0657\n",
      "Epoch 527/1500\n",
      "1700/1700 [==============================] - 1s 358us/step - loss: 0.0626 - val_loss: 0.0657\n",
      "Epoch 528/1500\n",
      "1700/1700 [==============================] - 1s 481us/step - loss: 0.0626 - val_loss: 0.0658\n",
      "Epoch 529/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0631 - val_loss: 0.0658\n",
      "Epoch 530/1500\n",
      "1700/1700 [==============================] - 1s 333us/step - loss: 0.0627 - val_loss: 0.0659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531/1500\n",
      "1700/1700 [==============================] - 1s 376us/step - loss: 0.0627 - val_loss: 0.0660\n",
      "Epoch 532/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0628 - val_loss: 0.0659\n",
      "Epoch 533/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0628 - val_loss: 0.0661\n",
      "Epoch 534/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0626 - val_loss: 0.0656\n",
      "Epoch 535/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0626 - val_loss: 0.0657\n",
      "Epoch 536/1500\n",
      "1700/1700 [==============================] - 1s 394us/step - loss: 0.0629 - val_loss: 0.0661\n",
      "Epoch 537/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0628 - val_loss: 0.0657\n",
      "Epoch 538/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0626 - val_loss: 0.0659\n",
      "Epoch 539/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0626 - val_loss: 0.0657\n",
      "Epoch 540/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0626 - val_loss: 0.0658\n",
      "Epoch 541/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0630 - val_loss: 0.0661\n",
      "Epoch 542/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0629 - val_loss: 0.0658\n",
      "Epoch 543/1500\n",
      "1700/1700 [==============================] - 1s 336us/step - loss: 0.0627 - val_loss: 0.0659\n",
      "Epoch 544/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0627 - val_loss: 0.0658\n",
      "Epoch 545/1500\n",
      "1700/1700 [==============================] - 1s 649us/step - loss: 0.0626 - val_loss: 0.0659\n",
      "Epoch 546/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0626 - val_loss: 0.0658\n",
      "Epoch 547/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0629 - val_loss: 0.0660\n",
      "Epoch 548/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0626 - val_loss: 0.0659\n",
      "Epoch 549/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0628 - val_loss: 0.0658\n",
      "Epoch 550/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0627 - val_loss: 0.0658\n",
      "Epoch 551/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0626 - val_loss: 0.0657\n",
      "Epoch 552/1500\n",
      "1700/1700 [==============================] - 1s 304us/step - loss: 0.0628 - val_loss: 0.0656\n",
      "Epoch 553/1500\n",
      "1700/1700 [==============================] - 1s 414us/step - loss: 0.0625 - val_loss: 0.0657\n",
      "Epoch 554/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0626 - val_loss: 0.0657\n",
      "Epoch 555/1500\n",
      "1700/1700 [==============================] - 1s 467us/step - loss: 0.0626 - val_loss: 0.0661\n",
      "Epoch 556/1500\n",
      "1700/1700 [==============================] - 1s 346us/step - loss: 0.0629 - val_loss: 0.0656\n",
      "Epoch 557/1500\n",
      "1700/1700 [==============================] - 1s 353us/step - loss: 0.0626 - val_loss: 0.0657\n",
      "Epoch 558/1500\n",
      "1700/1700 [==============================] - ETA: 0s - loss: 0.062 - 1s 345us/step - loss: 0.0626 - val_loss: 0.0658\n",
      "Epoch 559/1500\n",
      "1700/1700 [==============================] - 1s 369us/step - loss: 0.0626 - val_loss: 0.0660\n",
      "Epoch 560/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0626 - val_loss: 0.0658\n",
      "Epoch 561/1500\n",
      "1700/1700 [==============================] - 1s 387us/step - loss: 0.0626 - val_loss: 0.0655\n",
      "Epoch 562/1500\n",
      "1700/1700 [==============================] - 1s 313us/step - loss: 0.0627 - val_loss: 0.0661\n",
      "Epoch 563/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0628 - val_loss: 0.0659\n",
      "Epoch 564/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0628 - val_loss: 0.0661\n",
      "Epoch 565/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0628 - val_loss: 0.0660\n",
      "Epoch 566/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0626 - val_loss: 0.0661\n",
      "Epoch 567/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0627 - val_loss: 0.0662\n",
      "Epoch 568/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0626 - val_loss: 0.0659\n",
      "Epoch 569/1500\n",
      "1700/1700 [==============================] - 1s 404us/step - loss: 0.0627 - val_loss: 0.0657\n",
      "Epoch 570/1500\n",
      "1700/1700 [==============================] - 1s 734us/step - loss: 0.0625 - val_loss: 0.0658\n",
      "Epoch 571/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0625 - val_loss: 0.0660\n",
      "Epoch 572/1500\n",
      "1700/1700 [==============================] - 1s 404us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 573/1500\n",
      "1700/1700 [==============================] - 1s 362us/step - loss: 0.0626 - val_loss: 0.0658\n",
      "Epoch 574/1500\n",
      "1700/1700 [==============================] - 1s 355us/step - loss: 0.0627 - val_loss: 0.0661\n",
      "Epoch 575/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0627 - val_loss: 0.0661\n",
      "Epoch 576/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0626 - val_loss: 0.0657\n",
      "Epoch 577/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0625 - val_loss: 0.0658\n",
      "Epoch 578/1500\n",
      "1700/1700 [==============================] - 1s 372us/step - loss: 0.0627 - val_loss: 0.0663\n",
      "Epoch 579/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0626 - val_loss: 0.0664\n",
      "Epoch 580/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0629 - val_loss: 0.0665\n",
      "Epoch 581/1500\n",
      "1700/1700 [==============================] - 1s 304us/step - loss: 0.0625 - val_loss: 0.0657\n",
      "Epoch 582/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0627 - val_loss: 0.0656\n",
      "Epoch 583/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0626 - val_loss: 0.0657\n",
      "Epoch 584/1500\n",
      "1700/1700 [==============================] - 1s 311us/step - loss: 0.0624 - val_loss: 0.0657\n",
      "Epoch 585/1500\n",
      "1700/1700 [==============================] - 1s 338us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 586/1500\n",
      "1700/1700 [==============================] - 1s 400us/step - loss: 0.0626 - val_loss: 0.0660\n",
      "Epoch 587/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0626 - val_loss: 0.0658\n",
      "Epoch 588/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0625 - val_loss: 0.0654\n",
      "Epoch 589/1500\n",
      "1700/1700 [==============================] - 1s 358us/step - loss: 0.0625 - val_loss: 0.0658\n",
      "Epoch 590/1500\n",
      "1700/1700 [==============================] - 1s 329us/step - loss: 0.0625 - val_loss: 0.0658\n",
      "Epoch 591/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0627 - val_loss: 0.0659\n",
      "Epoch 592/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0626 - val_loss: 0.0664\n",
      "Epoch 593/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0629 - val_loss: 0.0660\n",
      "Epoch 594/1500\n",
      "1700/1700 [==============================] - 1s 313us/step - loss: 0.0626 - val_loss: 0.0661\n",
      "Epoch 595/1500\n",
      "1700/1700 [==============================] - 1s 413us/step - loss: 0.0626 - val_loss: 0.0656\n",
      "Epoch 596/1500\n",
      "1700/1700 [==============================] - 1s 612us/step - loss: 0.0625 - val_loss: 0.0666\n",
      "Epoch 597/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0627 - val_loss: 0.0663\n",
      "Epoch 598/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0626 - val_loss: 0.0660\n",
      "Epoch 599/1500\n",
      "1700/1700 [==============================] - 1s 331us/step - loss: 0.0625 - val_loss: 0.0658\n",
      "Epoch 600/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0627 - val_loss: 0.0658\n",
      "Epoch 601/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 602/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0625 - val_loss: 0.0661\n",
      "Epoch 603/1500\n",
      "1700/1700 [==============================] - 1s 391us/step - loss: 0.0626 - val_loss: 0.0659\n",
      "Epoch 604/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0628 - val_loss: 0.0660\n",
      "Epoch 605/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0625 - val_loss: 0.0657\n",
      "Epoch 606/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0626 - val_loss: 0.0659\n",
      "Epoch 607/1500\n",
      "1700/1700 [==============================] - 1s 337us/step - loss: 0.0627 - val_loss: 0.0661\n",
      "Epoch 608/1500\n",
      "1700/1700 [==============================] - 1s 357us/step - loss: 0.0626 - val_loss: 0.0659\n",
      "Epoch 609/1500\n",
      "1700/1700 [==============================] - 1s 373us/step - loss: 0.0626 - val_loss: 0.0661\n",
      "Epoch 610/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0626 - val_loss: 0.0658\n",
      "Epoch 611/1500\n",
      "1700/1700 [==============================] - 1s 417us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 612/1500\n",
      "1700/1700 [==============================] - 1s 413us/step - loss: 0.0626 - val_loss: 0.0657\n",
      "Epoch 613/1500\n",
      "1700/1700 [==============================] - 1s 350us/step - loss: 0.0624 - val_loss: 0.0657\n",
      "Epoch 614/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0625 - val_loss: 0.0660\n",
      "Epoch 615/1500\n",
      "1700/1700 [==============================] - 1s 360us/step - loss: 0.0626 - val_loss: 0.0660\n",
      "Epoch 616/1500\n",
      "1700/1700 [==============================] - 1s 320us/step - loss: 0.0627 - val_loss: 0.0663\n",
      "Epoch 617/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 618/1500\n",
      "1700/1700 [==============================] - 1s 350us/step - loss: 0.0626 - val_loss: 0.0658\n",
      "Epoch 619/1500\n",
      "1700/1700 [==============================] - 1s 313us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 620/1500\n",
      "1700/1700 [==============================] - 1s 416us/step - loss: 0.0625 - val_loss: 0.0661\n",
      "Epoch 621/1500\n",
      "1700/1700 [==============================] - 1s 310us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 622/1500\n",
      "1700/1700 [==============================] - 1s 630us/step - loss: 0.0627 - val_loss: 0.0659\n",
      "Epoch 623/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0626 - val_loss: 0.0657\n",
      "Epoch 624/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 625/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0626 - val_loss: 0.0659\n",
      "Epoch 626/1500\n",
      "1700/1700 [==============================] - 1s 367us/step - loss: 0.0626 - val_loss: 0.0658\n",
      "Epoch 627/1500\n",
      "1700/1700 [==============================] - 1s 325us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 628/1500\n",
      "1700/1700 [==============================] - 1s 435us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 629/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0625 - val_loss: 0.0657\n",
      "Epoch 630/1500\n",
      "1700/1700 [==============================] - 1s 331us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 631/1500\n",
      "1700/1700 [==============================] - 1s 346us/step - loss: 0.0627 - val_loss: 0.0657\n",
      "Epoch 632/1500\n",
      "1700/1700 [==============================] - 1s 343us/step - loss: 0.0624 - val_loss: 0.0662\n",
      "Epoch 633/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0626 - val_loss: 0.0658\n",
      "Epoch 634/1500\n",
      "1700/1700 [==============================] - 1s 373us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 635/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0626 - val_loss: 0.0660\n",
      "Epoch 636/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0628 - val_loss: 0.0664\n",
      "Epoch 637/1500\n",
      "1700/1700 [==============================] - 1s 453us/step - loss: 0.0626 - val_loss: 0.0659\n",
      "Epoch 638/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 639/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 640/1500\n",
      "1700/1700 [==============================] - 1s 304us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 641/1500\n",
      "1700/1700 [==============================] - 1s 337us/step - loss: 0.0625 - val_loss: 0.0656\n",
      "Epoch 642/1500\n",
      "1700/1700 [==============================] - 1s 343us/step - loss: 0.0624 - val_loss: 0.0656\n",
      "Epoch 643/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0626 - val_loss: 0.0658\n",
      "Epoch 644/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0625 - val_loss: 0.0666\n",
      "Epoch 645/1500\n",
      "1700/1700 [==============================] - 1s 412us/step - loss: 0.0625 - val_loss: 0.0663\n",
      "Epoch 646/1500\n",
      "1700/1700 [==============================] - 1s 362us/step - loss: 0.0625 - val_loss: 0.0658\n",
      "Epoch 647/1500\n",
      "1700/1700 [==============================] - 1s 318us/step - loss: 0.0624 - val_loss: 0.0657\n",
      "Epoch 648/1500\n",
      "1700/1700 [==============================] - 1s 630us/step - loss: 0.0624 - val_loss: 0.0662\n",
      "Epoch 649/1500\n",
      "1700/1700 [==============================] - 1s 340us/step - loss: 0.0625 - val_loss: 0.0660\n",
      "Epoch 650/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0625 - val_loss: 0.0661\n",
      "Epoch 651/1500\n",
      "1700/1700 [==============================] - 1s 381us/step - loss: 0.0627 - val_loss: 0.0661\n",
      "Epoch 652/1500\n",
      "1700/1700 [==============================] - 1s 327us/step - loss: 0.0625 - val_loss: 0.0661\n",
      "Epoch 653/1500\n",
      "1700/1700 [==============================] - 1s 371us/step - loss: 0.0627 - val_loss: 0.0661\n",
      "Epoch 654/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0625 - val_loss: 0.0660\n",
      "Epoch 655/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0624 - val_loss: 0.0657\n",
      "Epoch 656/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 657/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0624 - val_loss: 0.0658\n",
      "Epoch 658/1500\n",
      "1700/1700 [==============================] - 1s 351us/step - loss: 0.0624 - val_loss: 0.0658\n",
      "Epoch 659/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0625 - val_loss: 0.0663\n",
      "Epoch 660/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 661/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 662/1500\n",
      "1700/1700 [==============================] - 1s 390us/step - loss: 0.0624 - val_loss: 0.0662\n",
      "Epoch 663/1500\n",
      "1700/1700 [==============================] - 1s 325us/step - loss: 0.0626 - val_loss: 0.0662\n",
      "Epoch 664/1500\n",
      "1700/1700 [==============================] - 1s 380us/step - loss: 0.0625 - val_loss: 0.0657\n",
      "Epoch 665/1500\n",
      "1700/1700 [==============================] - 1s 644us/step - loss: 0.0624 - val_loss: 0.0658\n",
      "Epoch 666/1500\n",
      "1700/1700 [==============================] - 1s 657us/step - loss: 0.0625 - val_loss: 0.0658\n",
      "Epoch 667/1500\n",
      "1700/1700 [==============================] - 1s 625us/step - loss: 0.0628 - val_loss: 0.0659\n",
      "Epoch 668/1500\n",
      "1700/1700 [==============================] - 1s 756us/step - loss: 0.0624 - val_loss: 0.0658\n",
      "Epoch 669/1500\n",
      "1700/1700 [==============================] - 1s 462us/step - loss: 0.0624 - val_loss: 0.0658\n",
      "Epoch 670/1500\n",
      "1700/1700 [==============================] - 2s 884us/step - loss: 0.0624 - val_loss: 0.0658\n",
      "Epoch 671/1500\n",
      "1700/1700 [==============================] - 1s 684us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 672/1500\n",
      "1700/1700 [==============================] - 1s 549us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 673/1500\n",
      "1700/1700 [==============================] - 1s 414us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 674/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0627 - val_loss: 0.0659\n",
      "Epoch 675/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0625 - val_loss: 0.0661\n",
      "Epoch 676/1500\n",
      "1700/1700 [==============================] - 1s 329us/step - loss: 0.0624 - val_loss: 0.0658\n",
      "Epoch 677/1500\n",
      "1700/1700 [==============================] - 1s 331us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 678/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 679/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 680/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 681/1500\n",
      "1700/1700 [==============================] - 1s 413us/step - loss: 0.0624 - val_loss: 0.0660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 682/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 683/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 684/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0624 - val_loss: 0.0662\n",
      "Epoch 685/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0624 - val_loss: 0.0661\n",
      "Epoch 686/1500\n",
      "1700/1700 [==============================] - 1s 331us/step - loss: 0.0625 - val_loss: 0.0660\n",
      "Epoch 687/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0627 - val_loss: 0.0657\n",
      "Epoch 688/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0625 - val_loss: 0.0660\n",
      "Epoch 689/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0625 - val_loss: 0.0658\n",
      "Epoch 690/1500\n",
      "1700/1700 [==============================] - 1s 400us/step - loss: 0.0625 - val_loss: 0.0661\n",
      "Epoch 691/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0626 - val_loss: 0.0660\n",
      "Epoch 692/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0624 - val_loss: 0.0657\n",
      "Epoch 693/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 694/1500\n",
      "1700/1700 [==============================] - 1s 804us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 695/1500\n",
      "1700/1700 [==============================] - 1s 414us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 696/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 697/1500\n",
      "1700/1700 [==============================] - 1s 381us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 698/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 699/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 700/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0624 - val_loss: 0.0658\n",
      "Epoch 701/1500\n",
      "1700/1700 [==============================] - 1s 392us/step - loss: 0.0624 - val_loss: 0.0663\n",
      "Epoch 702/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0628 - val_loss: 0.0660\n",
      "Epoch 703/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0626 - val_loss: 0.0663\n",
      "Epoch 704/1500\n",
      "1700/1700 [==============================] - 1s 337us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 705/1500\n",
      "1700/1700 [==============================] - 1s 311us/step - loss: 0.0623 - val_loss: 0.0658\n",
      "Epoch 706/1500\n",
      "1700/1700 [==============================] - 1s 403us/step - loss: 0.0623 - val_loss: 0.0661\n",
      "Epoch 707/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 708/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 709/1500\n",
      "1700/1700 [==============================] - 1s 334us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 710/1500\n",
      "1700/1700 [==============================] - 1s 331us/step - loss: 0.0625 - val_loss: 0.0660\n",
      "Epoch 711/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 712/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0624 - val_loss: 0.0661\n",
      "Epoch 713/1500\n",
      "1700/1700 [==============================] - 1s 331us/step - loss: 0.0625 - val_loss: 0.0671\n",
      "Epoch 714/1500\n",
      "1700/1700 [==============================] - 1s 295us/step - loss: 0.0625 - val_loss: 0.0662\n",
      "Epoch 715/1500\n",
      "1700/1700 [==============================] - 1s 412us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 716/1500\n",
      "1700/1700 [==============================] - 1s 422us/step - loss: 0.0625 - val_loss: 0.0660\n",
      "Epoch 717/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 718/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 719/1500\n",
      "1700/1700 [==============================] - 1s 571us/step - loss: 0.0623 - val_loss: 0.0657\n",
      "Epoch 720/1500\n",
      "1700/1700 [==============================] - 1s 422us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 721/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0623 - val_loss: 0.0657\n",
      "Epoch 722/1500\n",
      "1700/1700 [==============================] - 1s 391us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 723/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 724/1500\n",
      "1700/1700 [==============================] - 1s 353us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 725/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 726/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0624 - val_loss: 0.0657\n",
      "Epoch 727/1500\n",
      "1700/1700 [==============================] - 1s 336us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 728/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 729/1500\n",
      "1700/1700 [==============================] - 1s 359us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 730/1500\n",
      "1700/1700 [==============================] - 1s 330us/step - loss: 0.0623 - val_loss: 0.0666\n",
      "Epoch 731/1500\n",
      "1700/1700 [==============================] - 1s 391us/step - loss: 0.0624 - val_loss: 0.0661\n",
      "Epoch 732/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 733/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 734/1500\n",
      "1700/1700 [==============================] - 1s 344us/step - loss: 0.0625 - val_loss: 0.0662\n",
      "Epoch 735/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 736/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0623 - val_loss: 0.0661\n",
      "Epoch 737/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 738/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 739/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0624 - val_loss: 0.0663\n",
      "Epoch 740/1500\n",
      "1700/1700 [==============================] - 1s 385us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 741/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0623 - val_loss: 0.0661\n",
      "Epoch 742/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0626 - val_loss: 0.0659\n",
      "Epoch 743/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 744/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0622 - val_loss: 0.0658\n",
      "Epoch 745/1500\n",
      "1700/1700 [==============================] - 1s 398us/step - loss: 0.0623 - val_loss: 0.0658\n",
      "Epoch 746/1500\n",
      "1700/1700 [==============================] - 1s 600us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 747/1500\n",
      "1700/1700 [==============================] - 1s 397us/step - loss: 0.0624 - val_loss: 0.0658\n",
      "Epoch 748/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 749/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0623 - val_loss: 0.0664\n",
      "Epoch 750/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 751/1500\n",
      "1700/1700 [==============================] - 1s 347us/step - loss: 0.0623 - val_loss: 0.0657\n",
      "Epoch 752/1500\n",
      "1700/1700 [==============================] - 1s 354us/step - loss: 0.0623 - val_loss: 0.0658\n",
      "Epoch 753/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0623 - val_loss: 0.0657\n",
      "Epoch 754/1500\n",
      "1700/1700 [==============================] - 1s 304us/step - loss: 0.0622 - val_loss: 0.0659\n",
      "Epoch 755/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0624 - val_loss: 0.0666\n",
      "Epoch 756/1500\n",
      "1700/1700 [==============================] - 1s 376us/step - loss: 0.0624 - val_loss: 0.0664\n",
      "Epoch 757/1500\n",
      "1700/1700 [==============================] - 1s 331us/step - loss: 0.0623 - val_loss: 0.0660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 758/1500\n",
      "1700/1700 [==============================] - 1s 331us/step - loss: 0.0626 - val_loss: 0.0662\n",
      "Epoch 759/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0623 - val_loss: 0.0664\n",
      "Epoch 760/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0626 - val_loss: 0.0659\n",
      "Epoch 761/1500\n",
      "1700/1700 [==============================] - 1s 372us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 762/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0624 - val_loss: 0.0661\n",
      "Epoch 763/1500\n",
      "1700/1700 [==============================] - 1s 324us/step - loss: 0.0623 - val_loss: 0.0658\n",
      "Epoch 764/1500\n",
      "1700/1700 [==============================] - 1s 342us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 765/1500\n",
      "1700/1700 [==============================] - 1s 404us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 766/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0622 - val_loss: 0.0659\n",
      "Epoch 767/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0623 - val_loss: 0.0662\n",
      "Epoch 768/1500\n",
      "1700/1700 [==============================] - 1s 350us/step - loss: 0.0625 - val_loss: 0.0659\n",
      "Epoch 769/1500\n",
      "1700/1700 [==============================] - 1s 321us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 770/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0622 - val_loss: 0.0659\n",
      "Epoch 771/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 772/1500\n",
      "1700/1700 [==============================] - 1s 649us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 773/1500\n",
      "1700/1700 [==============================] - 1s 422us/step - loss: 0.0625 - val_loss: 0.0662\n",
      "Epoch 774/1500\n",
      "1700/1700 [==============================] - 1s 363us/step - loss: 0.0626 - val_loss: 0.0662\n",
      "Epoch 775/1500\n",
      "1700/1700 [==============================] - 1s 335us/step - loss: 0.0623 - val_loss: 0.0661\n",
      "Epoch 776/1500\n",
      "1700/1700 [==============================] - 1s 732us/step - loss: 0.0623 - val_loss: 0.0658\n",
      "Epoch 777/1500\n",
      "1700/1700 [==============================] - 2s 969us/step - loss: 0.0622 - val_loss: 0.0658\n",
      "Epoch 778/1500\n",
      "1700/1700 [==============================] - 1s 726us/step - loss: 0.0625 - val_loss: 0.0663\n",
      "Epoch 779/1500\n",
      "1700/1700 [==============================] - 1s 670us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 780/1500\n",
      "1700/1700 [==============================] - 1s 561us/step - loss: 0.0624 - val_loss: 0.0658\n",
      "Epoch 781/1500\n",
      "1700/1700 [==============================] - 1s 632us/step - loss: 0.0622 - val_loss: 0.0659\n",
      "Epoch 782/1500\n",
      "1700/1700 [==============================] - ETA: 0s - loss: 0.062 - 1s 761us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 783/1500\n",
      "1700/1700 [==============================] - 1s 424us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 784/1500\n",
      "1700/1700 [==============================] - 1s 783us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 785/1500\n",
      "1700/1700 [==============================] - 1s 533us/step - loss: 0.0624 - val_loss: 0.0658\n",
      "Epoch 786/1500\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 787/1500\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.0621 - val_loss: 0.0659\n",
      "Epoch 788/1500\n",
      "1700/1700 [==============================] - 1s 776us/step - loss: 0.0622 - val_loss: 0.0663\n",
      "Epoch 789/1500\n",
      "1700/1700 [==============================] - 1s 583us/step - loss: 0.0624 - val_loss: 0.0665\n",
      "Epoch 790/1500\n",
      "1700/1700 [==============================] - 1s 716us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 791/1500\n",
      "1700/1700 [==============================] - 1s 586us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 792/1500\n",
      "1700/1700 [==============================] - 1s 614us/step - loss: 0.0625 - val_loss: 0.0663\n",
      "Epoch 793/1500\n",
      "1700/1700 [==============================] - 1s 716us/step - loss: 0.0624 - val_loss: 0.0662\n",
      "Epoch 794/1500\n",
      "1700/1700 [==============================] - 1s 667us/step - loss: 0.0624 - val_loss: 0.0659\n",
      "Epoch 795/1500\n",
      "1700/1700 [==============================] - 1s 738us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 796/1500\n",
      "1700/1700 [==============================] - 1s 581us/step - loss: 0.0623 - val_loss: 0.0662\n",
      "Epoch 797/1500\n",
      "1700/1700 [==============================] - 1s 656us/step - loss: 0.0621 - val_loss: 0.0659\n",
      "Epoch 798/1500\n",
      "1700/1700 [==============================] - 1s 689us/step - loss: 0.0622 - val_loss: 0.0659\n",
      "Epoch 799/1500\n",
      "1700/1700 [==============================] - 2s 905us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 800/1500\n",
      "1700/1700 [==============================] - 1s 652us/step - loss: 0.0622 - val_loss: 0.0664\n",
      "Epoch 801/1500\n",
      "1700/1700 [==============================] - 1s 637us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 802/1500\n",
      "1700/1700 [==============================] - 1s 615us/step - loss: 0.0623 - val_loss: 0.0667\n",
      "Epoch 803/1500\n",
      "1700/1700 [==============================] - 1s 669us/step - loss: 0.0623 - val_loss: 0.0658\n",
      "Epoch 804/1500\n",
      "1700/1700 [==============================] - 1s 774us/step - loss: 0.0623 - val_loss: 0.0663\n",
      "Epoch 805/1500\n",
      "1700/1700 [==============================] - 1s 610us/step - loss: 0.0623 - val_loss: 0.0661\n",
      "Epoch 806/1500\n",
      "1700/1700 [==============================] - 1s 640us/step - loss: 0.0624 - val_loss: 0.0665\n",
      "Epoch 807/1500\n",
      "1700/1700 [==============================] - 1s 611us/step - loss: 0.0624 - val_loss: 0.0662\n",
      "Epoch 808/1500\n",
      "1700/1700 [==============================] - 1s 820us/step - loss: 0.0624 - val_loss: 0.0666\n",
      "Epoch 809/1500\n",
      "1700/1700 [==============================] - 1s 575us/step - loss: 0.0625 - val_loss: 0.0658\n",
      "Epoch 810/1500\n",
      "1700/1700 [==============================] - 1s 629us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 811/1500\n",
      "1700/1700 [==============================] - 1s 586us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 812/1500\n",
      "1700/1700 [==============================] - 1s 635us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 813/1500\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.0622 - val_loss: 0.0659\n",
      "Epoch 814/1500\n",
      "1700/1700 [==============================] - 1s 614us/step - loss: 0.0622 - val_loss: 0.0658\n",
      "Epoch 815/1500\n",
      "1700/1700 [==============================] - 1s 581us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 816/1500\n",
      "1700/1700 [==============================] - 1s 716us/step - loss: 0.0622 - val_loss: 0.0659\n",
      "Epoch 817/1500\n",
      "1700/1700 [==============================] - 1s 659us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 818/1500\n",
      "1700/1700 [==============================] - 1s 645us/step - loss: 0.0623 - val_loss: 0.0665\n",
      "Epoch 819/1500\n",
      "1700/1700 [==============================] - 1s 664us/step - loss: 0.0624 - val_loss: 0.0661\n",
      "Epoch 820/1500\n",
      "1700/1700 [==============================] - 1s 592us/step - loss: 0.0622 - val_loss: 0.0663\n",
      "Epoch 821/1500\n",
      "1700/1700 [==============================] - 1s 643us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 822/1500\n",
      "1700/1700 [==============================] - 1s 689us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 823/1500\n",
      "1700/1700 [==============================] - 1s 612us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 824/1500\n",
      "1700/1700 [==============================] - 1s 576us/step - loss: 0.0623 - val_loss: 0.0661\n",
      "Epoch 825/1500\n",
      "1700/1700 [==============================] - 1s 595us/step - loss: 0.0625 - val_loss: 0.0662\n",
      "Epoch 826/1500\n",
      "1700/1700 [==============================] - 1s 617us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 827/1500\n",
      "1700/1700 [==============================] - 2s 906us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 828/1500\n",
      "1700/1700 [==============================] - 1s 648us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 829/1500\n",
      "1700/1700 [==============================] - 1s 616us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 830/1500\n",
      "1700/1700 [==============================] - 1s 580us/step - loss: 0.0623 - val_loss: 0.0661\n",
      "Epoch 831/1500\n",
      "1700/1700 [==============================] - 1s 619us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 832/1500\n",
      "1700/1700 [==============================] - 1s 643us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 833/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 1s 593us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 834/1500\n",
      "1700/1700 [==============================] - 1s 623us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 835/1500\n",
      "1700/1700 [==============================] - 1s 616us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 836/1500\n",
      "1700/1700 [==============================] - 1s 696us/step - loss: 0.0624 - val_loss: 0.0662\n",
      "Epoch 837/1500\n",
      "1700/1700 [==============================] - 1s 707us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 838/1500\n",
      "1700/1700 [==============================] - 1s 603us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 839/1500\n",
      "1700/1700 [==============================] - 1s 617us/step - loss: 0.0621 - val_loss: 0.0660\n",
      "Epoch 840/1500\n",
      "1700/1700 [==============================] - 1s 681us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 841/1500\n",
      "1700/1700 [==============================] - 1s 710us/step - loss: 0.0623 - val_loss: 0.0661\n",
      "Epoch 842/1500\n",
      "1700/1700 [==============================] - 2s 957us/step - loss: 0.0624 - val_loss: 0.0660\n",
      "Epoch 843/1500\n",
      "1700/1700 [==============================] - 1s 645us/step - loss: 0.0626 - val_loss: 0.0663\n",
      "Epoch 844/1500\n",
      "1700/1700 [==============================] - 1s 598us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 845/1500\n",
      "1700/1700 [==============================] - 1s 674us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 846/1500\n",
      "1700/1700 [==============================] - 1s 696us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 847/1500\n",
      "1700/1700 [==============================] - 1s 714us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 848/1500\n",
      "1700/1700 [==============================] - 1s 674us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 849/1500\n",
      "1700/1700 [==============================] - 1s 717us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 850/1500\n",
      "1700/1700 [==============================] - 1s 669us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 851/1500\n",
      "1700/1700 [==============================] - 1s 682us/step - loss: 0.0622 - val_loss: 0.0664\n",
      "Epoch 852/1500\n",
      "1700/1700 [==============================] - 1s 599us/step - loss: 0.0623 - val_loss: 0.0662\n",
      "Epoch 853/1500\n",
      "1700/1700 [==============================] - 1s 625us/step - loss: 0.0623 - val_loss: 0.0659\n",
      "Epoch 854/1500\n",
      "1700/1700 [==============================] - 1s 647us/step - loss: 0.0622 - val_loss: 0.0659\n",
      "Epoch 855/1500\n",
      "1700/1700 [==============================] - 1s 843us/step - loss: 0.0621 - val_loss: 0.0660\n",
      "Epoch 856/1500\n",
      "1700/1700 [==============================] - 1s 666us/step - loss: 0.0621 - val_loss: 0.0666\n",
      "Epoch 857/1500\n",
      "1700/1700 [==============================] - 1s 675us/step - loss: 0.0624 - val_loss: 0.0661\n",
      "Epoch 858/1500\n",
      "1700/1700 [==============================] - 1s 690us/step - loss: 0.0622 - val_loss: 0.0659\n",
      "Epoch 859/1500\n",
      "1700/1700 [==============================] - 1s 621us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 860/1500\n",
      "1700/1700 [==============================] - 1s 658us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 861/1500\n",
      "1700/1700 [==============================] - 1s 654us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 862/1500\n",
      "1700/1700 [==============================] - 1s 659us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 863/1500\n",
      "1700/1700 [==============================] - 1s 687us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 864/1500\n",
      "1700/1700 [==============================] - 1s 670us/step - loss: 0.0623 - val_loss: 0.0662\n",
      "Epoch 865/1500\n",
      "1700/1700 [==============================] - 1s 576us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 866/1500\n",
      "1700/1700 [==============================] - 1s 658us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 867/1500\n",
      "1700/1700 [==============================] - 1s 708us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 868/1500\n",
      "1700/1700 [==============================] - 1s 693us/step - loss: 0.0623 - val_loss: 0.0661\n",
      "Epoch 869/1500\n",
      "1700/1700 [==============================] - 2s 940us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 870/1500\n",
      "1700/1700 [==============================] - 1s 664us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 871/1500\n",
      "1700/1700 [==============================] - 1s 608us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 872/1500\n",
      "1700/1700 [==============================] - 1s 760us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 873/1500\n",
      "1700/1700 [==============================] - 1s 619us/step - loss: 0.0623 - val_loss: 0.0661\n",
      "Epoch 874/1500\n",
      "1700/1700 [==============================] - 1s 652us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 875/1500\n",
      "1700/1700 [==============================] - 1s 622us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 876/1500\n",
      "1700/1700 [==============================] - 1s 668us/step - loss: 0.0623 - val_loss: 0.0666\n",
      "Epoch 877/1500\n",
      "1700/1700 [==============================] - 1s 608us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 878/1500\n",
      "1700/1700 [==============================] - 1s 637us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 879/1500\n",
      "1700/1700 [==============================] - 1s 611us/step - loss: 0.0622 - val_loss: 0.0667\n",
      "Epoch 880/1500\n",
      "1700/1700 [==============================] - 1s 674us/step - loss: 0.0627 - val_loss: 0.0662\n",
      "Epoch 881/1500\n",
      "1700/1700 [==============================] - 1s 673us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 882/1500\n",
      "1700/1700 [==============================] - 1s 675us/step - loss: 0.0621 - val_loss: 0.0660\n",
      "Epoch 883/1500\n",
      "1700/1700 [==============================] - 2s 963us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 884/1500\n",
      "1700/1700 [==============================] - 1s 647us/step - loss: 0.0622 - val_loss: 0.0667\n",
      "Epoch 885/1500\n",
      "1700/1700 [==============================] - 1s 700us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 886/1500\n",
      "1700/1700 [==============================] - 1s 640us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 887/1500\n",
      "1700/1700 [==============================] - 1s 563us/step - loss: 0.0623 - val_loss: 0.0666\n",
      "Epoch 888/1500\n",
      "1700/1700 [==============================] - 1s 588us/step - loss: 0.0623 - val_loss: 0.0660\n",
      "Epoch 889/1500\n",
      "1700/1700 [==============================] - 1s 617us/step - loss: 0.0620 - val_loss: 0.0660\n",
      "Epoch 890/1500\n",
      "1700/1700 [==============================] - 1s 675us/step - loss: 0.0620 - val_loss: 0.0659\n",
      "Epoch 891/1500\n",
      "1700/1700 [==============================] - 1s 781us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 892/1500\n",
      "1700/1700 [==============================] - 1s 629us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 893/1500\n",
      "1700/1700 [==============================] - 1s 605us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 894/1500\n",
      "1700/1700 [==============================] - 1s 634us/step - loss: 0.0623 - val_loss: 0.0662\n",
      "Epoch 895/1500\n",
      "1700/1700 [==============================] - 1s 716us/step - loss: 0.0623 - val_loss: 0.0661\n",
      "Epoch 896/1500\n",
      "1700/1700 [==============================] - 1s 622us/step - loss: 0.0623 - val_loss: 0.0662\n",
      "Epoch 897/1500\n",
      "1700/1700 [==============================] - 2s 970us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 898/1500\n",
      "1700/1700 [==============================] - 1s 619us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 899/1500\n",
      "1700/1700 [==============================] - 1s 735us/step - loss: 0.0621 - val_loss: 0.0659\n",
      "Epoch 900/1500\n",
      "1700/1700 [==============================] - 1s 651us/step - loss: 0.0620 - val_loss: 0.0660\n",
      "Epoch 901/1500\n",
      "1700/1700 [==============================] - 1s 628us/step - loss: 0.0622 - val_loss: 0.0664\n",
      "Epoch 902/1500\n",
      "1700/1700 [==============================] - 1s 593us/step - loss: 0.0622 - val_loss: 0.0663\n",
      "Epoch 903/1500\n",
      "1700/1700 [==============================] - 1s 624us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 904/1500\n",
      "1700/1700 [==============================] - 1s 756us/step - loss: 0.0620 - val_loss: 0.0661\n",
      "Epoch 905/1500\n",
      "1700/1700 [==============================] - 1s 608us/step - loss: 0.0625 - val_loss: 0.0670\n",
      "Epoch 906/1500\n",
      "1700/1700 [==============================] - 1s 630us/step - loss: 0.0624 - val_loss: 0.0661\n",
      "Epoch 907/1500\n",
      "1700/1700 [==============================] - 1s 644us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 908/1500\n",
      "1700/1700 [==============================] - 1s 673us/step - loss: 0.0621 - val_loss: 0.0659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 909/1500\n",
      "1700/1700 [==============================] - 1s 624us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 910/1500\n",
      "1700/1700 [==============================] - ETA: 0s - loss: 0.062 - 1s 669us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 911/1500\n",
      "1700/1700 [==============================] - 1s 852us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 912/1500\n",
      "1700/1700 [==============================] - 1s 633us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 913/1500\n",
      "1700/1700 [==============================] - 1s 638us/step - loss: 0.0621 - val_loss: 0.0660\n",
      "Epoch 914/1500\n",
      "1700/1700 [==============================] - 1s 605us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 915/1500\n",
      "1700/1700 [==============================] - 1s 571us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 916/1500\n",
      "1700/1700 [==============================] - 1s 618us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 917/1500\n",
      "1700/1700 [==============================] - 1s 693us/step - loss: 0.0622 - val_loss: 0.0665\n",
      "Epoch 918/1500\n",
      "1700/1700 [==============================] - 1s 681us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 919/1500\n",
      "1700/1700 [==============================] - 1s 651us/step - loss: 0.0622 - val_loss: 0.0659\n",
      "Epoch 920/1500\n",
      "1700/1700 [==============================] - 1s 671us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 921/1500\n",
      "1700/1700 [==============================] - 1s 674us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 922/1500\n",
      "1700/1700 [==============================] - 1s 735us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 923/1500\n",
      "1700/1700 [==============================] - 1s 675us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 924/1500\n",
      "1700/1700 [==============================] - 1s 759us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 925/1500\n",
      "1700/1700 [==============================] - 1s 859us/step - loss: 0.0622 - val_loss: 0.0665\n",
      "Epoch 926/1500\n",
      "1700/1700 [==============================] - 1s 706us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 927/1500\n",
      "1700/1700 [==============================] - 1s 634us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 928/1500\n",
      "1700/1700 [==============================] - 1s 641us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 929/1500\n",
      "1700/1700 [==============================] - 1s 640us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 930/1500\n",
      "1700/1700 [==============================] - 1s 628us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 931/1500\n",
      "1700/1700 [==============================] - 1s 693us/step - loss: 0.0621 - val_loss: 0.0660\n",
      "Epoch 932/1500\n",
      "1700/1700 [==============================] - 1s 752us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 933/1500\n",
      "1700/1700 [==============================] - 1s 623us/step - loss: 0.0623 - val_loss: 0.0663\n",
      "Epoch 934/1500\n",
      "1700/1700 [==============================] - 1s 653us/step - loss: 0.0622 - val_loss: 0.0665\n",
      "Epoch 935/1500\n",
      "1700/1700 [==============================] - 1s 735us/step - loss: 0.0623 - val_loss: 0.0664\n",
      "Epoch 936/1500\n",
      "1700/1700 [==============================] - 1s 611us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 937/1500\n",
      "1700/1700 [==============================] - 1s 663us/step - loss: 0.0621 - val_loss: 0.0660\n",
      "Epoch 938/1500\n",
      "1700/1700 [==============================] - 1s 681us/step - loss: 0.0622 - val_loss: 0.0663\n",
      "Epoch 939/1500\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 940/1500\n",
      "1700/1700 [==============================] - 1s 707us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 941/1500\n",
      "1700/1700 [==============================] - 1s 600us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 942/1500\n",
      "1700/1700 [==============================] - 1s 631us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 943/1500\n",
      "1700/1700 [==============================] - 1s 594us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 944/1500\n",
      "1700/1700 [==============================] - 1s 733us/step - loss: 0.0620 - val_loss: 0.0661\n",
      "Epoch 945/1500\n",
      "1700/1700 [==============================] - 1s 627us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 946/1500\n",
      "1700/1700 [==============================] - 1s 695us/step - loss: 0.0621 - val_loss: 0.0660\n",
      "Epoch 947/1500\n",
      "1700/1700 [==============================] - 1s 627us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 948/1500\n",
      "1700/1700 [==============================] - 1s 723us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 949/1500\n",
      "1700/1700 [==============================] - 1s 673us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 950/1500\n",
      "1700/1700 [==============================] - 1s 660us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 951/1500\n",
      "1700/1700 [==============================] - 1s 717us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 952/1500\n",
      "1700/1700 [==============================] - 2s 919us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 953/1500\n",
      "1700/1700 [==============================] - 1s 728us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 954/1500\n",
      "1700/1700 [==============================] - 1s 687us/step - loss: 0.0621 - val_loss: 0.0660\n",
      "Epoch 955/1500\n",
      "1700/1700 [==============================] - 1s 648us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 956/1500\n",
      "1700/1700 [==============================] - 1s 586us/step - loss: 0.0622 - val_loss: 0.0663\n",
      "Epoch 957/1500\n",
      "1700/1700 [==============================] - 1s 759us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 958/1500\n",
      "1700/1700 [==============================] - 1s 606us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 959/1500\n",
      "1700/1700 [==============================] - 1s 628us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 960/1500\n",
      "1700/1700 [==============================] - 1s 600us/step - loss: 0.0622 - val_loss: 0.0670\n",
      "Epoch 961/1500\n",
      "1700/1700 [==============================] - 1s 656us/step - loss: 0.0622 - val_loss: 0.0660\n",
      "Epoch 962/1500\n",
      "1700/1700 [==============================] - 1s 633us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 963/1500\n",
      "1700/1700 [==============================] - 1s 633us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 964/1500\n",
      "1700/1700 [==============================] - 1s 677us/step - loss: 0.0623 - val_loss: 0.0664\n",
      "Epoch 965/1500\n",
      "1700/1700 [==============================] - 1s 618us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 966/1500\n",
      "1700/1700 [==============================] - 1s 857us/step - loss: 0.0624 - val_loss: 0.0663\n",
      "Epoch 967/1500\n",
      "1700/1700 [==============================] - 1s 716us/step - loss: 0.0621 - val_loss: 0.0659\n",
      "Epoch 968/1500\n",
      "1700/1700 [==============================] - 1s 587us/step - loss: 0.0619 - val_loss: 0.0660\n",
      "Epoch 969/1500\n",
      "1700/1700 [==============================] - 1s 607us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 970/1500\n",
      "1700/1700 [==============================] - 1s 649us/step - loss: 0.0620 - val_loss: 0.0661\n",
      "Epoch 971/1500\n",
      "1700/1700 [==============================] - 1s 634us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 972/1500\n",
      "1700/1700 [==============================] - 1s 657us/step - loss: 0.0620 - val_loss: 0.0665\n",
      "Epoch 973/1500\n",
      "1700/1700 [==============================] - 1s 648us/step - loss: 0.0620 - val_loss: 0.0661\n",
      "Epoch 974/1500\n",
      "1700/1700 [==============================] - 1s 633us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 975/1500\n",
      "1700/1700 [==============================] - 1s 617us/step - loss: 0.0622 - val_loss: 0.0663\n",
      "Epoch 976/1500\n",
      "1700/1700 [==============================] - 1s 693us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 977/1500\n",
      "1700/1700 [==============================] - 1s 622us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 978/1500\n",
      "1700/1700 [==============================] - 1s 640us/step - loss: 0.0620 - val_loss: 0.0660\n",
      "Epoch 979/1500\n",
      "1700/1700 [==============================] - 1s 611us/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 980/1500\n",
      "1700/1700 [==============================] - 1s 603us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 981/1500\n",
      "1700/1700 [==============================] - 2s 959us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 982/1500\n",
      "1700/1700 [==============================] - 1s 687us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 983/1500\n",
      "1700/1700 [==============================] - 1s 747us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 984/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 1s 750us/step - loss: 0.0620 - val_loss: 0.0661\n",
      "Epoch 985/1500\n",
      "1700/1700 [==============================] - 1s 730us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 986/1500\n",
      "1700/1700 [==============================] - 1s 611us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 987/1500\n",
      "1700/1700 [==============================] - 1s 646us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 988/1500\n",
      "1700/1700 [==============================] - 1s 605us/step - loss: 0.0622 - val_loss: 0.0659\n",
      "Epoch 989/1500\n",
      "1700/1700 [==============================] - 1s 669us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 990/1500\n",
      "1700/1700 [==============================] - 1s 669us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 991/1500\n",
      "1700/1700 [==============================] - 1s 661us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 992/1500\n",
      "1700/1700 [==============================] - 1s 671us/step - loss: 0.0619 - val_loss: 0.0660\n",
      "Epoch 993/1500\n",
      "1700/1700 [==============================] - 1s 593us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 994/1500\n",
      "1700/1700 [==============================] - 2s 988us/step - loss: 0.0621 - val_loss: 0.0664\n",
      "Epoch 995/1500\n",
      "1700/1700 [==============================] - 1s 721us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 996/1500\n",
      "1700/1700 [==============================] - 1s 670us/step - loss: 0.0621 - val_loss: 0.0665\n",
      "Epoch 997/1500\n",
      "1700/1700 [==============================] - 1s 619us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 998/1500\n",
      "1700/1700 [==============================] - 1s 713us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 999/1500\n",
      "1700/1700 [==============================] - 1s 688us/step - loss: 0.0622 - val_loss: 0.0664\n",
      "Epoch 1000/1500\n",
      "1700/1700 [==============================] - 1s 715us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 1001/1500\n",
      "1700/1700 [==============================] - 1s 793us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1002/1500\n",
      "1700/1700 [==============================] - 1s 700us/step - loss: 0.0621 - val_loss: 0.0660\n",
      "Epoch 1003/1500\n",
      "1700/1700 [==============================] - 1s 647us/step - loss: 0.0619 - val_loss: 0.0661\n",
      "Epoch 1004/1500\n",
      "1700/1700 [==============================] - 1s 658us/step - loss: 0.0622 - val_loss: 0.0664\n",
      "Epoch 1005/1500\n",
      "1700/1700 [==============================] - 1s 646us/step - loss: 0.0621 - val_loss: 0.0661\n",
      "Epoch 1006/1500\n",
      "1700/1700 [==============================] - 1s 597us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1007/1500\n",
      "1700/1700 [==============================] - 1s 372us/step - loss: 0.0620 - val_loss: 0.0661\n",
      "Epoch 1008/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 1009/1500\n",
      "1700/1700 [==============================] - 1s 621us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 1010/1500\n",
      "1700/1700 [==============================] - 1s 295us/step - loss: 0.0620 - val_loss: 0.0661\n",
      "Epoch 1011/1500\n",
      "1700/1700 [==============================] - 1s 313us/step - loss: 0.0619 - val_loss: 0.0661\n",
      "Epoch 1012/1500\n",
      "1700/1700 [==============================] - 1s 455us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 1013/1500\n",
      "1700/1700 [==============================] - 1s 339us/step - loss: 0.0621 - val_loss: 0.0665\n",
      "Epoch 1014/1500\n",
      "1700/1700 [==============================] - 1s 295us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1015/1500\n",
      "1700/1700 [==============================] - 1s 424us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 1016/1500\n",
      "1700/1700 [==============================] - 1s 316us/step - loss: 0.0620 - val_loss: 0.0661\n",
      "Epoch 1017/1500\n",
      "1700/1700 [==============================] - 1s 466us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 1018/1500\n",
      "1700/1700 [==============================] - 0s 215us/step - loss: 0.0619 - val_loss: 0.0661\n",
      "Epoch 1019/1500\n",
      "1700/1700 [==============================] - 0s 199us/step - loss: 0.0620 - val_loss: 0.0661\n",
      "Epoch 1020/1500\n",
      "1700/1700 [==============================] - 0s 217us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 1021/1500\n",
      "1700/1700 [==============================] - 0s 205us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 1022/1500\n",
      "1700/1700 [==============================] - 0s 195us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 1023/1500\n",
      "1700/1700 [==============================] - 0s 218us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1024/1500\n",
      "1700/1700 [==============================] - 0s 204us/step - loss: 0.0620 - val_loss: 0.0659\n",
      "Epoch 1025/1500\n",
      "1700/1700 [==============================] - 0s 199us/step - loss: 0.0620 - val_loss: 0.0661\n",
      "Epoch 1026/1500\n",
      "1700/1700 [==============================] - 0s 217us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 1027/1500\n",
      "1700/1700 [==============================] - 0s 282us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 1028/1500\n",
      "1700/1700 [==============================] - 0s 208us/step - loss: 0.0621 - val_loss: 0.0660\n",
      "Epoch 1029/1500\n",
      "1700/1700 [==============================] - 0s 217us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 1030/1500\n",
      "1700/1700 [==============================] - 0s 244us/step - loss: 0.0621 - val_loss: 0.0666\n",
      "Epoch 1031/1500\n",
      "1700/1700 [==============================] - 1s 297us/step - loss: 0.0620 - val_loss: 0.0660\n",
      "Epoch 1032/1500\n",
      "1700/1700 [==============================] - 0s 293us/step - loss: 0.0620 - val_loss: 0.0665\n",
      "Epoch 1033/1500\n",
      "1700/1700 [==============================] - 1s 394us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1034/1500\n",
      "1700/1700 [==============================] - 1s 358us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1035/1500\n",
      "1700/1700 [==============================] - 1s 341us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 1036/1500\n",
      "1700/1700 [==============================] - 1s 329us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 1037/1500\n",
      "1700/1700 [==============================] - 1s 467us/step - loss: 0.0619 - val_loss: 0.0661\n",
      "Epoch 1038/1500\n",
      "1700/1700 [==============================] - 0s 265us/step - loss: 0.0619 - val_loss: 0.0661\n",
      "Epoch 1039/1500\n",
      "1700/1700 [==============================] - 1s 306us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 1040/1500\n",
      "1700/1700 [==============================] - 1s 805us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 1041/1500\n",
      "1700/1700 [==============================] - 1s 481us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1042/1500\n",
      "1700/1700 [==============================] - 1s 459us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1043/1500\n",
      "1700/1700 [==============================] - 1s 480us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 1044/1500\n",
      "1700/1700 [==============================] - 1s 556us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 1045/1500\n",
      "1700/1700 [==============================] - 1s 493us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1046/1500\n",
      "1700/1700 [==============================] - 1s 423us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1047/1500\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 1048/1500\n",
      "1700/1700 [==============================] - 2s 931us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1049/1500\n",
      "1700/1700 [==============================] - 0s 267us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1050/1500\n",
      "1700/1700 [==============================] - 0s 211us/step - loss: 0.0620 - val_loss: 0.0661\n",
      "Epoch 1051/1500\n",
      "1700/1700 [==============================] - 0s 201us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1052/1500\n",
      "1700/1700 [==============================] - 0s 261us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 1053/1500\n",
      "1700/1700 [==============================] - 0s 285us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 1054/1500\n",
      "1700/1700 [==============================] - 1s 296us/step - loss: 0.0619 - val_loss: 0.0660\n",
      "Epoch 1055/1500\n",
      "1700/1700 [==============================] - 1s 554us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1056/1500\n",
      "1700/1700 [==============================] - 1s 382us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1057/1500\n",
      "1700/1700 [==============================] - 1s 336us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1058/1500\n",
      "1700/1700 [==============================] - 1s 340us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 1059/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 1s 837us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1060/1500\n",
      "1700/1700 [==============================] - 1s 456us/step - loss: 0.0622 - val_loss: 0.0665\n",
      "Epoch 1061/1500\n",
      "1700/1700 [==============================] - 1s 471us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 1062/1500\n",
      "1700/1700 [==============================] - 1s 347us/step - loss: 0.0619 - val_loss: 0.0660\n",
      "Epoch 1063/1500\n",
      "1700/1700 [==============================] - 1s 311us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1064/1500\n",
      "1700/1700 [==============================] - 0s 227us/step - loss: 0.0619 - val_loss: 0.0666\n",
      "Epoch 1065/1500\n",
      "1700/1700 [==============================] - 0s 197us/step - loss: 0.0619 - val_loss: 0.0665\n",
      "Epoch 1066/1500\n",
      "1700/1700 [==============================] - 0s 168us/step - loss: 0.0620 - val_loss: 0.0670\n",
      "Epoch 1067/1500\n",
      "1700/1700 [==============================] - 0s 270us/step - loss: 0.0621 - val_loss: 0.0663\n",
      "Epoch 1068/1500\n",
      "1700/1700 [==============================] - 0s 292us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1069/1500\n",
      "1700/1700 [==============================] - 1s 308us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1070/1500\n",
      "1700/1700 [==============================] - 1s 303us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1071/1500\n",
      "1700/1700 [==============================] - 1s 297us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1072/1500\n",
      "1700/1700 [==============================] - 0s 273us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1073/1500\n",
      "1700/1700 [==============================] - 0s 290us/step - loss: 0.0621 - val_loss: 0.0664\n",
      "Epoch 1074/1500\n",
      "1700/1700 [==============================] - 1s 356us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1075/1500\n",
      "1700/1700 [==============================] - 0s 273us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1076/1500\n",
      "1700/1700 [==============================] - 0s 288us/step - loss: 0.0619 - val_loss: 0.0665\n",
      "Epoch 1077/1500\n",
      "1700/1700 [==============================] - 0s 249us/step - loss: 0.0624 - val_loss: 0.0665\n",
      "Epoch 1078/1500\n",
      "1700/1700 [==============================] - 0s 253us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 1079/1500\n",
      "1700/1700 [==============================] - 0s 252us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1080/1500\n",
      "1700/1700 [==============================] - 0s 247us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1081/1500\n",
      "1700/1700 [==============================] - 0s 255us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1082/1500\n",
      "1700/1700 [==============================] - 0s 238us/step - loss: 0.0619 - val_loss: 0.0661\n",
      "Epoch 1083/1500\n",
      "1700/1700 [==============================] - 0s 261us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1084/1500\n",
      "1700/1700 [==============================] - 0s 244us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1085/1500\n",
      "1700/1700 [==============================] - 0s 268us/step - loss: 0.0620 - val_loss: 0.0660\n",
      "Epoch 1086/1500\n",
      "1700/1700 [==============================] - 1s 370us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 1087/1500\n",
      "1700/1700 [==============================] - 0s 243us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1088/1500\n",
      "1700/1700 [==============================] - 0s 251us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 1089/1500\n",
      "1700/1700 [==============================] - 0s 250us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1090/1500\n",
      "1700/1700 [==============================] - 1s 324us/step - loss: 0.0621 - val_loss: 0.0664\n",
      "Epoch 1091/1500\n",
      "1700/1700 [==============================] - 1s 739us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1092/1500\n",
      "1700/1700 [==============================] - 0s 266us/step - loss: 0.0619 - val_loss: 0.0666\n",
      "Epoch 1093/1500\n",
      "1700/1700 [==============================] - 1s 334us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1094/1500\n",
      "1700/1700 [==============================] - 1s 364us/step - loss: 0.0619 - val_loss: 0.0667\n",
      "Epoch 1095/1500\n",
      "1700/1700 [==============================] - 1s 424us/step - loss: 0.0620 - val_loss: 0.0666\n",
      "Epoch 1096/1500\n",
      "1700/1700 [==============================] - 0s 263us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1097/1500\n",
      "1700/1700 [==============================] - 0s 257us/step - loss: 0.0618 - val_loss: 0.0661\n",
      "Epoch 1098/1500\n",
      "1700/1700 [==============================] - 0s 273us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1099/1500\n",
      "1700/1700 [==============================] - 1s 479us/step - loss: 0.0620 - val_loss: 0.0661\n",
      "Epoch 1100/1500\n",
      "1700/1700 [==============================] - 1s 530us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1101/1500\n",
      "1700/1700 [==============================] - 1s 517us/step - loss: 0.0620 - val_loss: 0.0665\n",
      "Epoch 1102/1500\n",
      "1700/1700 [==============================] - 1s 462us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 1103/1500\n",
      "1700/1700 [==============================] - 1s 486us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1104/1500\n",
      "1700/1700 [==============================] - 1s 371us/step - loss: 0.0618 - val_loss: 0.0661\n",
      "Epoch 1105/1500\n",
      "1700/1700 [==============================] - 1s 307us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1106/1500\n",
      "1700/1700 [==============================] - 1s 465us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1107/1500\n",
      "1700/1700 [==============================] - 1s 523us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1108/1500\n",
      "1700/1700 [==============================] - 1s 522us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1109/1500\n",
      "1700/1700 [==============================] - 1s 483us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1110/1500\n",
      "1700/1700 [==============================] - 0s 260us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1111/1500\n",
      "1700/1700 [==============================] - 0s 285us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1112/1500\n",
      "1700/1700 [==============================] - 0s 287us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1113/1500\n",
      "1700/1700 [==============================] - 0s 289us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1114/1500\n",
      "1700/1700 [==============================] - 1s 655us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1115/1500\n",
      "1700/1700 [==============================] - 0s 253us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1116/1500\n",
      "1700/1700 [==============================] - 0s 248us/step - loss: 0.0618 - val_loss: 0.0666\n",
      "Epoch 1117/1500\n",
      "1700/1700 [==============================] - 1s 300us/step - loss: 0.0620 - val_loss: 0.0665\n",
      "Epoch 1118/1500\n",
      "1700/1700 [==============================] - 1s 301us/step - loss: 0.0621 - val_loss: 0.0662\n",
      "Epoch 1119/1500\n",
      "1700/1700 [==============================] - 1s 318us/step - loss: 0.0618 - val_loss: 0.0662\n",
      "Epoch 1120/1500\n",
      "1700/1700 [==============================] - 1s 508us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1121/1500\n",
      "1700/1700 [==============================] - 1s 511us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1122/1500\n",
      "1700/1700 [==============================] - 1s 526us/step - loss: 0.0622 - val_loss: 0.0662\n",
      "Epoch 1123/1500\n",
      "1700/1700 [==============================] - 1s 503us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1124/1500\n",
      "1700/1700 [==============================] - 1s 510us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1125/1500\n",
      "1700/1700 [==============================] - 1s 628us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1126/1500\n",
      "1700/1700 [==============================] - 1s 473us/step - loss: 0.0620 - val_loss: 0.0667\n",
      "Epoch 1127/1500\n",
      "1700/1700 [==============================] - 1s 575us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1128/1500\n",
      "1700/1700 [==============================] - 1s 439us/step - loss: 0.0619 - val_loss: 0.0666\n",
      "Epoch 1129/1500\n",
      "1700/1700 [==============================] - 0s 293us/step - loss: 0.0621 - val_loss: 0.0666\n",
      "Epoch 1130/1500\n",
      "1700/1700 [==============================] - 1s 306us/step - loss: 0.0620 - val_loss: 0.0665\n",
      "Epoch 1131/1500\n",
      "1700/1700 [==============================] - 0s 260us/step - loss: 0.0619 - val_loss: 0.0665\n",
      "Epoch 1132/1500\n",
      "1700/1700 [==============================] - 1s 349us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1133/1500\n",
      "1700/1700 [==============================] - 1s 401us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1134/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 0s 270us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1135/1500\n",
      "1700/1700 [==============================] - 0s 258us/step - loss: 0.0618 - val_loss: 0.0662\n",
      "Epoch 1136/1500\n",
      "1700/1700 [==============================] - 0s 261us/step - loss: 0.0618 - val_loss: 0.0666\n",
      "Epoch 1137/1500\n",
      "1700/1700 [==============================] - 0s 253us/step - loss: 0.0618 - val_loss: 0.0662\n",
      "Epoch 1138/1500\n",
      "1700/1700 [==============================] - 1s 662us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1139/1500\n",
      "1700/1700 [==============================] - 0s 274us/step - loss: 0.0619 - val_loss: 0.0665\n",
      "Epoch 1140/1500\n",
      "1700/1700 [==============================] - 1s 367us/step - loss: 0.0619 - val_loss: 0.0660\n",
      "Epoch 1141/1500\n",
      "1700/1700 [==============================] - 1s 397us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1142/1500\n",
      "1700/1700 [==============================] - 1s 302us/step - loss: 0.0619 - val_loss: 0.0667\n",
      "Epoch 1143/1500\n",
      "1700/1700 [==============================] - 1s 312us/step - loss: 0.0620 - val_loss: 0.0665\n",
      "Epoch 1144/1500\n",
      "1700/1700 [==============================] - 1s 307us/step - loss: 0.0622 - val_loss: 0.0665\n",
      "Epoch 1145/1500\n",
      "1700/1700 [==============================] - 1s 388us/step - loss: 0.0619 - val_loss: 0.0665\n",
      "Epoch 1146/1500\n",
      "1700/1700 [==============================] - 1s 331us/step - loss: 0.0621 - val_loss: 0.0666\n",
      "Epoch 1147/1500\n",
      "1700/1700 [==============================] - 0s 220us/step - loss: 0.0619 - val_loss: 0.0665\n",
      "Epoch 1148/1500\n",
      "1700/1700 [==============================] - 0s 208us/step - loss: 0.0619 - val_loss: 0.0666\n",
      "Epoch 1149/1500\n",
      "1700/1700 [==============================] - 1s 304us/step - loss: 0.0621 - val_loss: 0.0664\n",
      "Epoch 1150/1500\n",
      "1700/1700 [==============================] - 0s 237us/step - loss: 0.0619 - val_loss: 0.0667\n",
      "Epoch 1151/1500\n",
      "1700/1700 [==============================] - 1s 353us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1152/1500\n",
      "1700/1700 [==============================] - 1s 304us/step - loss: 0.0620 - val_loss: 0.0666\n",
      "Epoch 1153/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0619 - val_loss: 0.0666\n",
      "Epoch 1154/1500\n",
      "1700/1700 [==============================] - 1s 304us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1155/1500\n",
      "1700/1700 [==============================] - 1s 332us/step - loss: 0.0618 - val_loss: 0.0666\n",
      "Epoch 1156/1500\n",
      "1700/1700 [==============================] - 1s 304us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1157/1500\n",
      "1700/1700 [==============================] - 1s 326us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1158/1500\n",
      "1700/1700 [==============================] - 1s 313us/step - loss: 0.0619 - val_loss: 0.0665\n",
      "Epoch 1159/1500\n",
      "1700/1700 [==============================] - 1s 330us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1160/1500\n",
      "1700/1700 [==============================] - 0s 259us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1161/1500\n",
      "1700/1700 [==============================] - 0s 284us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1162/1500\n",
      "1700/1700 [==============================] - 0s 228us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1163/1500\n",
      "1700/1700 [==============================] - 0s 205us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1164/1500\n",
      "1700/1700 [==============================] - 0s 241us/step - loss: 0.0619 - val_loss: 0.0667\n",
      "Epoch 1165/1500\n",
      "1700/1700 [==============================] - 0s 270us/step - loss: 0.0619 - val_loss: 0.0661\n",
      "Epoch 1166/1500\n",
      "1700/1700 [==============================] - 0s 254us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1167/1500\n",
      "1700/1700 [==============================] - 0s 223us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1168/1500\n",
      "1700/1700 [==============================] - 0s 189us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1169/1500\n",
      "1700/1700 [==============================] - 1s 435us/step - loss: 0.0619 - val_loss: 0.0668\n",
      "Epoch 1170/1500\n",
      "1700/1700 [==============================] - 0s 286us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1171/1500\n",
      "1700/1700 [==============================] - 1s 327us/step - loss: 0.0619 - val_loss: 0.0661\n",
      "Epoch 1172/1500\n",
      "1700/1700 [==============================] - 1s 322us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1173/1500\n",
      "1700/1700 [==============================] - 0s 158us/step - loss: 0.0618 - val_loss: 0.0662\n",
      "Epoch 1174/1500\n",
      "1700/1700 [==============================] - 0s 173us/step - loss: 0.0618 - val_loss: 0.0662\n",
      "Epoch 1175/1500\n",
      "1700/1700 [==============================] - 0s 168us/step - loss: 0.0620 - val_loss: 0.0662\n",
      "Epoch 1176/1500\n",
      "1700/1700 [==============================] - 0s 168us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1177/1500\n",
      "1700/1700 [==============================] - 0s 177us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1178/1500\n",
      "1700/1700 [==============================] - 1s 372us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1179/1500\n",
      "1700/1700 [==============================] - 1s 347us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1180/1500\n",
      "1700/1700 [==============================] - 1s 296us/step - loss: 0.0620 - val_loss: 0.0665\n",
      "Epoch 1181/1500\n",
      "1700/1700 [==============================] - 0s 242us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1182/1500\n",
      "1700/1700 [==============================] - 0s 253us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1183/1500\n",
      "1700/1700 [==============================] - 0s 198us/step - loss: 0.0619 - val_loss: 0.0666\n",
      "Epoch 1184/1500\n",
      "1700/1700 [==============================] - 0s 200us/step - loss: 0.0622 - val_loss: 0.0669\n",
      "Epoch 1185/1500\n",
      "1700/1700 [==============================] - 1s 309us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1186/1500\n",
      "1700/1700 [==============================] - 1s 361us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1187/1500\n",
      "1700/1700 [==============================] - 1s 441us/step - loss: 0.0618 - val_loss: 0.0661\n",
      "Epoch 1188/1500\n",
      "1700/1700 [==============================] - 1s 517us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1189/1500\n",
      "1700/1700 [==============================] - 1s 433us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1190/1500\n",
      "1700/1700 [==============================] - 1s 424us/step - loss: 0.0618 - val_loss: 0.0666\n",
      "Epoch 1191/1500\n",
      "1700/1700 [==============================] - 1s 423us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1192/1500\n",
      "1700/1700 [==============================] - 1s 303us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1193/1500\n",
      "1700/1700 [==============================] - 1s 459us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1194/1500\n",
      "1700/1700 [==============================] - 0s 269us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1195/1500\n",
      "1700/1700 [==============================] - 1s 315us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1196/1500\n",
      "1700/1700 [==============================] - 1s 377us/step - loss: 0.0619 - val_loss: 0.0666\n",
      "Epoch 1197/1500\n",
      "1700/1700 [==============================] - 1s 314us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1198/1500\n",
      "1700/1700 [==============================] - 1s 402us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1199/1500\n",
      "1700/1700 [==============================] - 1s 653us/step - loss: 0.0619 - val_loss: 0.0665\n",
      "Epoch 1200/1500\n",
      "1700/1700 [==============================] - 1s 402us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1201/1500\n",
      "1700/1700 [==============================] - 0s 220us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1202/1500\n",
      "1700/1700 [==============================] - 1s 534us/step - loss: 0.0619 - val_loss: 0.0667\n",
      "Epoch 1203/1500\n",
      "1700/1700 [==============================] - 0s 247us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1204/1500\n",
      "1700/1700 [==============================] - 0s 264us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1205/1500\n",
      "1700/1700 [==============================] - 0s 208us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1206/1500\n",
      "1700/1700 [==============================] - 0s 210us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1207/1500\n",
      "1700/1700 [==============================] - 1s 421us/step - loss: 0.0618 - val_loss: 0.0666\n",
      "Epoch 1208/1500\n",
      "1700/1700 [==============================] - 0s 193us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1209/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 0s 205us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1210/1500\n",
      "1700/1700 [==============================] - 0s 267us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1211/1500\n",
      "1700/1700 [==============================] - 1s 454us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1212/1500\n",
      "1700/1700 [==============================] - 0s 278us/step - loss: 0.0621 - val_loss: 0.0665\n",
      "Epoch 1213/1500\n",
      "1700/1700 [==============================] - 0s 287us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1214/1500\n",
      "1700/1700 [==============================] - 0s 244us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1215/1500\n",
      "1700/1700 [==============================] - 0s 291us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1216/1500\n",
      "1700/1700 [==============================] - 0s 237us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1217/1500\n",
      "1700/1700 [==============================] - 0s 235us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1218/1500\n",
      "1700/1700 [==============================] - 0s 221us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1219/1500\n",
      "1700/1700 [==============================] - 0s 225us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1220/1500\n",
      "1700/1700 [==============================] - 0s 265us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1221/1500\n",
      "1700/1700 [==============================] - 2s 909us/step - loss: 0.0619 - val_loss: 0.0661\n",
      "Epoch 1222/1500\n",
      "1700/1700 [==============================] - 1s 767us/step - loss: 0.0618 - val_loss: 0.0667\n",
      "Epoch 1223/1500\n",
      "1700/1700 [==============================] - 1s 422us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1224/1500\n",
      "1700/1700 [==============================] - 0s 283us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1225/1500\n",
      "1700/1700 [==============================] - 0s 184us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1226/1500\n",
      "1700/1700 [==============================] - 1s 390us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1227/1500\n",
      "1700/1700 [==============================] - 2s 885us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1228/1500\n",
      "1700/1700 [==============================] - 1s 330us/step - loss: 0.0620 - val_loss: 0.0665\n",
      "Epoch 1229/1500\n",
      "1700/1700 [==============================] - 1s 316us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1230/1500\n",
      "1700/1700 [==============================] - 0s 281us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1231/1500\n",
      "1700/1700 [==============================] - 1s 302us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1232/1500\n",
      "1700/1700 [==============================] - 1s 755us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1233/1500\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1234/1500\n",
      "1700/1700 [==============================] - 1s 847us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1235/1500\n",
      "1700/1700 [==============================] - 1s 347us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1236/1500\n",
      "1700/1700 [==============================] - 0s 282us/step - loss: 0.0619 - val_loss: 0.0666\n",
      "Epoch 1237/1500\n",
      "1700/1700 [==============================] - 1s 313us/step - loss: 0.0619 - val_loss: 0.0665\n",
      "Epoch 1238/1500\n",
      "1700/1700 [==============================] - 0s 273us/step - loss: 0.0618 - val_loss: 0.0666\n",
      "Epoch 1239/1500\n",
      "1700/1700 [==============================] - 0s 258us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1240/1500\n",
      "1700/1700 [==============================] - 1s 318us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1241/1500\n",
      "1700/1700 [==============================] - 0s 249us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1242/1500\n",
      "1700/1700 [==============================] - 0s 199us/step - loss: 0.0618 - val_loss: 0.0666\n",
      "Epoch 1243/1500\n",
      "1700/1700 [==============================] - 0s 261us/step - loss: 0.0619 - val_loss: 0.0667\n",
      "Epoch 1244/1500\n",
      "1700/1700 [==============================] - 0s 236us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1245/1500\n",
      "1700/1700 [==============================] - 0s 199us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1246/1500\n",
      "1700/1700 [==============================] - 0s 215us/step - loss: 0.0619 - val_loss: 0.0666\n",
      "Epoch 1247/1500\n",
      "1700/1700 [==============================] - 1s 296us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1248/1500\n",
      "1700/1700 [==============================] - 1s 366us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1249/1500\n",
      "1700/1700 [==============================] - 1s 400us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1250/1500\n",
      "1700/1700 [==============================] - 1s 869us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1251/1500\n",
      "1700/1700 [==============================] - 1s 648us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1252/1500\n",
      "1700/1700 [==============================] - 1s 491us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1253/1500\n",
      "1700/1700 [==============================] - 1s 470us/step - loss: 0.0617 - val_loss: 0.0661\n",
      "Epoch 1254/1500\n",
      "1700/1700 [==============================] - 1s 504us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1255/1500\n",
      "1700/1700 [==============================] - 1s 472us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1256/1500\n",
      "1700/1700 [==============================] - 1s 567us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1257/1500\n",
      "1700/1700 [==============================] - 1s 327us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1258/1500\n",
      "1700/1700 [==============================] - 1s 423us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1259/1500\n",
      "1700/1700 [==============================] - 1s 370us/step - loss: 0.0619 - val_loss: 0.0667\n",
      "Epoch 1260/1500\n",
      "1700/1700 [==============================] - 0s 253us/step - loss: 0.0617 - val_loss: 0.0662\n",
      "Epoch 1261/1500\n",
      "1700/1700 [==============================] - 1s 378us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1262/1500\n",
      "1700/1700 [==============================] - 1s 392us/step - loss: 0.0620 - val_loss: 0.0666\n",
      "Epoch 1263/1500\n",
      "1700/1700 [==============================] - 0s 270us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1264/1500\n",
      "1700/1700 [==============================] - 1s 408us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1265/1500\n",
      "1700/1700 [==============================] - 0s 291us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1266/1500\n",
      "1700/1700 [==============================] - 1s 333us/step - loss: 0.0617 - val_loss: 0.0662\n",
      "Epoch 1267/1500\n",
      "1700/1700 [==============================] - 1s 368us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1268/1500\n",
      "1700/1700 [==============================] - 0s 289us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1269/1500\n",
      "1700/1700 [==============================] - 0s 278us/step - loss: 0.0618 - val_loss: 0.0666\n",
      "Epoch 1270/1500\n",
      "1700/1700 [==============================] - 0s 238us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1271/1500\n",
      "1700/1700 [==============================] - 0s 243us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1272/1500\n",
      "1700/1700 [==============================] - 1s 357us/step - loss: 0.0618 - val_loss: 0.0666\n",
      "Epoch 1273/1500\n",
      "1700/1700 [==============================] - 1s 597us/step - loss: 0.0618 - val_loss: 0.0662\n",
      "Epoch 1274/1500\n",
      "1700/1700 [==============================] - 0s 177us/step - loss: 0.0618 - val_loss: 0.0667\n",
      "Epoch 1275/1500\n",
      "1700/1700 [==============================] - 0s 177us/step - loss: 0.0620 - val_loss: 0.0663\n",
      "Epoch 1276/1500\n",
      "1700/1700 [==============================] - 0s 177us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1277/1500\n",
      "1700/1700 [==============================] - 0s 178us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1278/1500\n",
      "1700/1700 [==============================] - 0s 175us/step - loss: 0.0617 - val_loss: 0.0669\n",
      "Epoch 1279/1500\n",
      "1700/1700 [==============================] - 0s 177us/step - loss: 0.0619 - val_loss: 0.0662\n",
      "Epoch 1280/1500\n",
      "1700/1700 [==============================] - 0s 188us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1281/1500\n",
      "1700/1700 [==============================] - 0s 165us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1282/1500\n",
      "1700/1700 [==============================] - 0s 190us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1283/1500\n",
      "1700/1700 [==============================] - 1s 295us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1284/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 1s 331us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1285/1500\n",
      "1700/1700 [==============================] - ETA: 0s - loss: 0.061 - 1s 329us/step - loss: 0.0616 - val_loss: 0.0661\n",
      "Epoch 1286/1500\n",
      "1700/1700 [==============================] - 1s 342us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1287/1500\n",
      "1700/1700 [==============================] - 1s 299us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1288/1500\n",
      "1700/1700 [==============================] - 1s 388us/step - loss: 0.0616 - val_loss: 0.0663\n",
      "Epoch 1289/1500\n",
      "1700/1700 [==============================] - 1s 428us/step - loss: 0.0617 - val_loss: 0.0667\n",
      "Epoch 1290/1500\n",
      "1700/1700 [==============================] - 1s 490us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1291/1500\n",
      "1700/1700 [==============================] - 1s 490us/step - loss: 0.0619 - val_loss: 0.0668\n",
      "Epoch 1292/1500\n",
      "1700/1700 [==============================] - 1s 439us/step - loss: 0.0620 - val_loss: 0.0666\n",
      "Epoch 1293/1500\n",
      "1700/1700 [==============================] - 1s 466us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1294/1500\n",
      "1700/1700 [==============================] - 1s 377us/step - loss: 0.0617 - val_loss: 0.0667\n",
      "Epoch 1295/1500\n",
      "1700/1700 [==============================] - 1s 373us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1296/1500\n",
      "1700/1700 [==============================] - 1s 445us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1297/1500\n",
      "1700/1700 [==============================] - 1s 494us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1298/1500\n",
      "1700/1700 [==============================] - 1s 427us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1299/1500\n",
      "1700/1700 [==============================] - 1s 329us/step - loss: 0.0619 - val_loss: 0.0670\n",
      "Epoch 1300/1500\n",
      "1700/1700 [==============================] - 0s 244us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1301/1500\n",
      "1700/1700 [==============================] - 1s 716us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1302/1500\n",
      "1700/1700 [==============================] - 1s 504us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1303/1500\n",
      "1700/1700 [==============================] - 1s 412us/step - loss: 0.0619 - val_loss: 0.0666\n",
      "Epoch 1304/1500\n",
      "1700/1700 [==============================] - 1s 428us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1305/1500\n",
      "1700/1700 [==============================] - 1s 389us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1306/1500\n",
      "1700/1700 [==============================] - 1s 401us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1307/1500\n",
      "1700/1700 [==============================] - 1s 475us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1308/1500\n",
      "1700/1700 [==============================] - 1s 470us/step - loss: 0.0619 - val_loss: 0.0666\n",
      "Epoch 1309/1500\n",
      "1700/1700 [==============================] - 0s 206us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1310/1500\n",
      "1700/1700 [==============================] - 0s 273us/step - loss: 0.0616 - val_loss: 0.0663\n",
      "Epoch 1311/1500\n",
      "1700/1700 [==============================] - 1s 383us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1312/1500\n",
      "1700/1700 [==============================] - 0s 292us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1313/1500\n",
      "1700/1700 [==============================] - 1s 327us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1314/1500\n",
      "1700/1700 [==============================] - 1s 316us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1315/1500\n",
      "1700/1700 [==============================] - 1s 490us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1316/1500\n",
      "1700/1700 [==============================] - 7s 4ms/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1317/1500\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1318/1500\n",
      "1700/1700 [==============================] - 1s 865us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1319/1500\n",
      "1700/1700 [==============================] - 1s 509us/step - loss: 0.0620 - val_loss: 0.0665\n",
      "Epoch 1320/1500\n",
      "1700/1700 [==============================] - 1s 490us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1321/1500\n",
      "1700/1700 [==============================] - 1s 405us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1322/1500\n",
      "1700/1700 [==============================] - 0s 202us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1323/1500\n",
      "1700/1700 [==============================] - 0s 259us/step - loss: 0.0616 - val_loss: 0.0663\n",
      "Epoch 1324/1500\n",
      "1700/1700 [==============================] - 0s 264us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1325/1500\n",
      "1700/1700 [==============================] - 0s 197us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1326/1500\n",
      "1700/1700 [==============================] - 1s 320us/step - loss: 0.0619 - val_loss: 0.0663\n",
      "Epoch 1327/1500\n",
      "1700/1700 [==============================] - 0s 286us/step - loss: 0.0616 - val_loss: 0.0664\n",
      "Epoch 1328/1500\n",
      "1700/1700 [==============================] - 1s 337us/step - loss: 0.0618 - val_loss: 0.0672\n",
      "Epoch 1329/1500\n",
      "1700/1700 [==============================] - 1s 620us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1330/1500\n",
      "1700/1700 [==============================] - 0s 242us/step - loss: 0.0616 - val_loss: 0.0664\n",
      "Epoch 1331/1500\n",
      "1700/1700 [==============================] - 0s 293us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1332/1500\n",
      "1700/1700 [==============================] - 0s 168us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1333/1500\n",
      "1700/1700 [==============================] - 1s 372us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1334/1500\n",
      "1700/1700 [==============================] - 1s 348us/step - loss: 0.0619 - val_loss: 0.0666\n",
      "Epoch 1335/1500\n",
      "1700/1700 [==============================] - 1s 517us/step - loss: 0.0618 - val_loss: 0.0662\n",
      "Epoch 1336/1500\n",
      "1700/1700 [==============================] - 1s 479us/step - loss: 0.0616 - val_loss: 0.0664\n",
      "Epoch 1337/1500\n",
      "1700/1700 [==============================] - 1s 625us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1338/1500\n",
      "1700/1700 [==============================] - 1s 581us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1339/1500\n",
      "1700/1700 [==============================] - 0s 283us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1340/1500\n",
      "1700/1700 [==============================] - 0s 293us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1341/1500\n",
      "1700/1700 [==============================] - 1s 298us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1342/1500\n",
      "1700/1700 [==============================] - 1s 333us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1343/1500\n",
      "1700/1700 [==============================] - 0s 293us/step - loss: 0.0618 - val_loss: 0.0670\n",
      "Epoch 1344/1500\n",
      "1700/1700 [==============================] - 1s 466us/step - loss: 0.0619 - val_loss: 0.0668\n",
      "Epoch 1345/1500\n",
      "1700/1700 [==============================] - 1s 592us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1346/1500\n",
      "1700/1700 [==============================] - 1s 536us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1347/1500\n",
      "1700/1700 [==============================] - 1s 535us/step - loss: 0.0616 - val_loss: 0.0665\n",
      "Epoch 1348/1500\n",
      "1700/1700 [==============================] - 1s 517us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1349/1500\n",
      "1700/1700 [==============================] - 1s 564us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1350/1500\n",
      "1700/1700 [==============================] - 1s 486us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1351/1500\n",
      "1700/1700 [==============================] - 1s 554us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1352/1500\n",
      "1700/1700 [==============================] - 1s 361us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1353/1500\n",
      "1700/1700 [==============================] - 1s 338us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1354/1500\n",
      "1700/1700 [==============================] - 0s 230us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1355/1500\n",
      "1700/1700 [==============================] - 1s 367us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1356/1500\n",
      "1700/1700 [==============================] - 1s 513us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1357/1500\n",
      "1700/1700 [==============================] - 1s 538us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1358/1500\n",
      "1700/1700 [==============================] - 2s 948us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1359/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 1s 729us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1360/1500\n",
      "1700/1700 [==============================] - 1s 451us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1361/1500\n",
      "1700/1700 [==============================] - 1s 457us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1362/1500\n",
      "1700/1700 [==============================] - 1s 428us/step - loss: 0.0620 - val_loss: 0.0665\n",
      "Epoch 1363/1500\n",
      "1700/1700 [==============================] - 1s 551us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1364/1500\n",
      "1700/1700 [==============================] - 1s 706us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1365/1500\n",
      "1700/1700 [==============================] - 0s 201us/step - loss: 0.0617 - val_loss: 0.0669\n",
      "Epoch 1366/1500\n",
      "1700/1700 [==============================] - 0s 268us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1367/1500\n",
      "1700/1700 [==============================] - 1s 425us/step - loss: 0.0616 - val_loss: 0.0664\n",
      "Epoch 1368/1500\n",
      "1700/1700 [==============================] - 1s 463us/step - loss: 0.0618 - val_loss: 0.0666\n",
      "Epoch 1369/1500\n",
      "1700/1700 [==============================] - 1s 502us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1370/1500\n",
      "1700/1700 [==============================] - 1s 327us/step - loss: 0.0616 - val_loss: 0.0664\n",
      "Epoch 1371/1500\n",
      "1700/1700 [==============================] - 1s 445us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1372/1500\n",
      "1700/1700 [==============================] - 1s 377us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1373/1500\n",
      "1700/1700 [==============================] - 0s 200us/step - loss: 0.0620 - val_loss: 0.0664\n",
      "Epoch 1374/1500\n",
      "1700/1700 [==============================] - 1s 667us/step - loss: 0.0621 - val_loss: 0.0665\n",
      "Epoch 1375/1500\n",
      "1700/1700 [==============================] - 1s 310us/step - loss: 0.0616 - val_loss: 0.0664\n",
      "Epoch 1376/1500\n",
      "1700/1700 [==============================] - 1s 631us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1377/1500\n",
      "1700/1700 [==============================] - 1s 383us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1378/1500\n",
      "1700/1700 [==============================] - 1s 387us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1379/1500\n",
      "1700/1700 [==============================] - 1s 671us/step - loss: 0.0619 - val_loss: 0.0665\n",
      "Epoch 1380/1500\n",
      "1700/1700 [==============================] - 0s 241us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1381/1500\n",
      "1700/1700 [==============================] - 0s 271us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1382/1500\n",
      "1700/1700 [==============================] - 0s 283us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1383/1500\n",
      "1700/1700 [==============================] - 0s 280us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1384/1500\n",
      "1700/1700 [==============================] - 0s 247us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1385/1500\n",
      "1700/1700 [==============================] - 1s 488us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1386/1500\n",
      "1700/1700 [==============================] - 1s 463us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1387/1500\n",
      "1700/1700 [==============================] - 0s 184us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1388/1500\n",
      "1700/1700 [==============================] - 1s 424us/step - loss: 0.0616 - val_loss: 0.0668\n",
      "Epoch 1389/1500\n",
      "1700/1700 [==============================] - 1s 508us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1390/1500\n",
      "1700/1700 [==============================] - 1s 306us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1391/1500\n",
      "1700/1700 [==============================] - 1s 424us/step - loss: 0.0619 - val_loss: 0.0667\n",
      "Epoch 1392/1500\n",
      "1700/1700 [==============================] - 0s 280us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1393/1500\n",
      "1700/1700 [==============================] - 1s 472us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1394/1500\n",
      "1700/1700 [==============================] - 1s 556us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1395/1500\n",
      "1700/1700 [==============================] - 1s 457us/step - loss: 0.0616 - val_loss: 0.0665\n",
      "Epoch 1396/1500\n",
      "1700/1700 [==============================] - 1s 456us/step - loss: 0.0619 - val_loss: 0.0668\n",
      "Epoch 1397/1500\n",
      "1700/1700 [==============================] - 1s 438us/step - loss: 0.0619 - val_loss: 0.0665\n",
      "Epoch 1398/1500\n",
      "1700/1700 [==============================] - 1s 441us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1399/1500\n",
      "1700/1700 [==============================] - 1s 333us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1400/1500\n",
      "1700/1700 [==============================] - 0s 185us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1401/1500\n",
      "1700/1700 [==============================] - 0s 286us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1402/1500\n",
      "1700/1700 [==============================] - 1s 580us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1403/1500\n",
      "1700/1700 [==============================] - 1s 843us/step - loss: 0.0617 - val_loss: 0.0670\n",
      "Epoch 1404/1500\n",
      "1700/1700 [==============================] - 1s 537us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1405/1500\n",
      "1700/1700 [==============================] - 1s 598us/step - loss: 0.0616 - val_loss: 0.0667\n",
      "Epoch 1406/1500\n",
      "1700/1700 [==============================] - ETA: 0s - loss: 0.061 - 1s 570us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1407/1500\n",
      "1700/1700 [==============================] - 1s 604us/step - loss: 0.0618 - val_loss: 0.0667\n",
      "Epoch 1408/1500\n",
      "1700/1700 [==============================] - 1s 507us/step - loss: 0.0618 - val_loss: 0.0668\n",
      "Epoch 1409/1500\n",
      "1700/1700 [==============================] - 1s 501us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1410/1500\n",
      "1700/1700 [==============================] - 1s 611us/step - loss: 0.0618 - val_loss: 0.0665\n",
      "Epoch 1411/1500\n",
      "1700/1700 [==============================] - 1s 523us/step - loss: 0.0616 - val_loss: 0.0664\n",
      "Epoch 1412/1500\n",
      "1700/1700 [==============================] - 1s 491us/step - loss: 0.0616 - val_loss: 0.0665\n",
      "Epoch 1413/1500\n",
      "1700/1700 [==============================] - 1s 581us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1414/1500\n",
      "1700/1700 [==============================] - 1s 455us/step - loss: 0.0619 - val_loss: 0.0670\n",
      "Epoch 1415/1500\n",
      "1700/1700 [==============================] - 0s 270us/step - loss: 0.0618 - val_loss: 0.0666\n",
      "Epoch 1416/1500\n",
      "1700/1700 [==============================] - 1s 295us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1417/1500\n",
      "1700/1700 [==============================] - 1s 388us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1418/1500\n",
      "1700/1700 [==============================] - 1s 371us/step - loss: 0.0616 - val_loss: 0.0663\n",
      "Epoch 1419/1500\n",
      "1700/1700 [==============================] - 1s 375us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1420/1500\n",
      "1700/1700 [==============================] - 1s 485us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1421/1500\n",
      "1700/1700 [==============================] - 1s 455us/step - loss: 0.0616 - val_loss: 0.0665\n",
      "Epoch 1422/1500\n",
      "1700/1700 [==============================] - 1s 781us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1423/1500\n",
      "1700/1700 [==============================] - 1s 362us/step - loss: 0.0616 - val_loss: 0.0665\n",
      "Epoch 1424/1500\n",
      "1700/1700 [==============================] - 1s 439us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1425/1500\n",
      "1700/1700 [==============================] - 1s 371us/step - loss: 0.0618 - val_loss: 0.0667\n",
      "Epoch 1426/1500\n",
      "1700/1700 [==============================] - 1s 483us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1427/1500\n",
      "1700/1700 [==============================] - 1s 441us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1428/1500\n",
      "1700/1700 [==============================] - 1s 329us/step - loss: 0.0618 - val_loss: 0.0664\n",
      "Epoch 1429/1500\n",
      "1700/1700 [==============================] - 1s 424us/step - loss: 0.0618 - val_loss: 0.0668\n",
      "Epoch 1430/1500\n",
      "1700/1700 [==============================] - 1s 489us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1431/1500\n",
      "1700/1700 [==============================] - 1s 434us/step - loss: 0.0618 - val_loss: 0.0668\n",
      "Epoch 1432/1500\n",
      "1700/1700 [==============================] - 1s 415us/step - loss: 0.0623 - val_loss: 0.0667\n",
      "Epoch 1433/1500\n",
      "1700/1700 [==============================] - 1s 480us/step - loss: 0.0619 - val_loss: 0.0664\n",
      "Epoch 1434/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 1s 451us/step - loss: 0.0616 - val_loss: 0.0665\n",
      "Epoch 1435/1500\n",
      "1700/1700 [==============================] - 1s 331us/step - loss: 0.0616 - val_loss: 0.0667\n",
      "Epoch 1436/1500\n",
      "1700/1700 [==============================] - 0s 244us/step - loss: 0.0619 - val_loss: 0.0667\n",
      "Epoch 1437/1500\n",
      "1700/1700 [==============================] - 0s 216us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1438/1500\n",
      "1700/1700 [==============================] - 1s 397us/step - loss: 0.0615 - val_loss: 0.0667\n",
      "Epoch 1439/1500\n",
      "1700/1700 [==============================] - 1s 568us/step - loss: 0.0616 - val_loss: 0.0664\n",
      "Epoch 1440/1500\n",
      "1700/1700 [==============================] - 0s 273us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1441/1500\n",
      "1700/1700 [==============================] - 1s 331us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1442/1500\n",
      "1700/1700 [==============================] - 1s 546us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1443/1500\n",
      "1700/1700 [==============================] - 1s 384us/step - loss: 0.0617 - val_loss: 0.0668\n",
      "Epoch 1444/1500\n",
      "1700/1700 [==============================] - 1s 376us/step - loss: 0.0616 - val_loss: 0.0667\n",
      "Epoch 1445/1500\n",
      "1700/1700 [==============================] - 1s 709us/step - loss: 0.0616 - val_loss: 0.0667\n",
      "Epoch 1446/1500\n",
      "1700/1700 [==============================] - 1s 480us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1447/1500\n",
      "1700/1700 [==============================] - 0s 241us/step - loss: 0.0618 - val_loss: 0.0667\n",
      "Epoch 1448/1500\n",
      "1700/1700 [==============================] - 0s 294us/step - loss: 0.0616 - val_loss: 0.0664\n",
      "Epoch 1449/1500\n",
      "1700/1700 [==============================] - 1s 432us/step - loss: 0.0617 - val_loss: 0.0667\n",
      "Epoch 1450/1500\n",
      "1700/1700 [==============================] - 1s 310us/step - loss: 0.0617 - val_loss: 0.0667\n",
      "Epoch 1451/1500\n",
      "1700/1700 [==============================] - 0s 169us/step - loss: 0.0616 - val_loss: 0.0663\n",
      "Epoch 1452/1500\n",
      "1700/1700 [==============================] - 0s 187us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1453/1500\n",
      "1700/1700 [==============================] - 1s 314us/step - loss: 0.0617 - val_loss: 0.0667\n",
      "Epoch 1454/1500\n",
      "1700/1700 [==============================] - 1s 349us/step - loss: 0.0617 - val_loss: 0.0668\n",
      "Epoch 1455/1500\n",
      "1700/1700 [==============================] - 1s 330us/step - loss: 0.0616 - val_loss: 0.0665\n",
      "Epoch 1456/1500\n",
      "1700/1700 [==============================] - 1s 320us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1457/1500\n",
      "1700/1700 [==============================] - 0s 267us/step - loss: 0.0615 - val_loss: 0.0666\n",
      "Epoch 1458/1500\n",
      "1700/1700 [==============================] - 1s 314us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1459/1500\n",
      "1700/1700 [==============================] - 1s 372us/step - loss: 0.0619 - val_loss: 0.0667\n",
      "Epoch 1460/1500\n",
      "1700/1700 [==============================] - 1s 400us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1461/1500\n",
      "1700/1700 [==============================] - 0s 279us/step - loss: 0.0616 - val_loss: 0.0667\n",
      "Epoch 1462/1500\n",
      "1700/1700 [==============================] - 0s 238us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1463/1500\n",
      "1700/1700 [==============================] - 0s 253us/step - loss: 0.0618 - val_loss: 0.0668\n",
      "Epoch 1464/1500\n",
      "1700/1700 [==============================] - 0s 243us/step - loss: 0.0617 - val_loss: 0.0663\n",
      "Epoch 1465/1500\n",
      "1700/1700 [==============================] - 0s 256us/step - loss: 0.0617 - val_loss: 0.0668\n",
      "Epoch 1466/1500\n",
      "1700/1700 [==============================] - 0s 269us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1467/1500\n",
      "1700/1700 [==============================] - 1s 350us/step - loss: 0.0616 - val_loss: 0.0664\n",
      "Epoch 1468/1500\n",
      "1700/1700 [==============================] - 1s 563us/step - loss: 0.0617 - val_loss: 0.0669\n",
      "Epoch 1469/1500\n",
      "1700/1700 [==============================] - 1s 351us/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 1470/1500\n",
      "1700/1700 [==============================] - 1s 336us/step - loss: 0.0615 - val_loss: 0.0666\n",
      "Epoch 1471/1500\n",
      "1700/1700 [==============================] - 0s 250us/step - loss: 0.0616 - val_loss: 0.0667\n",
      "Epoch 1472/1500\n",
      "1700/1700 [==============================] - 0s 222us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1473/1500\n",
      "1700/1700 [==============================] - 1s 611us/step - loss: 0.0615 - val_loss: 0.0664\n",
      "Epoch 1474/1500\n",
      "1700/1700 [==============================] - 0s 280us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1475/1500\n",
      "1700/1700 [==============================] - 0s 171us/step - loss: 0.0617 - val_loss: 0.0664\n",
      "Epoch 1476/1500\n",
      "1700/1700 [==============================] - 0s 168us/step - loss: 0.0617 - val_loss: 0.0667\n",
      "Epoch 1477/1500\n",
      "1700/1700 [==============================] - 0s 177us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1478/1500\n",
      "1700/1700 [==============================] - 0s 204us/step - loss: 0.0617 - val_loss: 0.0665\n",
      "Epoch 1479/1500\n",
      "1700/1700 [==============================] - 0s 168us/step - loss: 0.0617 - val_loss: 0.0667\n",
      "Epoch 1480/1500\n",
      "1700/1700 [==============================] - 0s 190us/step - loss: 0.0616 - val_loss: 0.0664\n",
      "Epoch 1481/1500\n",
      "1700/1700 [==============================] - 0s 168us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1482/1500\n",
      "1700/1700 [==============================] - 0s 236us/step - loss: 0.0615 - val_loss: 0.0666\n",
      "Epoch 1483/1500\n",
      "1700/1700 [==============================] - 0s 186us/step - loss: 0.0616 - val_loss: 0.0665\n",
      "Epoch 1484/1500\n",
      "1700/1700 [==============================] - 0s 176us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1485/1500\n",
      "1700/1700 [==============================] - 0s 204us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1486/1500\n",
      "1700/1700 [==============================] - 0s 235us/step - loss: 0.0616 - val_loss: 0.0665\n",
      "Epoch 1487/1500\n",
      "1700/1700 [==============================] - 0s 169us/step - loss: 0.0616 - val_loss: 0.0664\n",
      "Epoch 1488/1500\n",
      "1700/1700 [==============================] - 0s 234us/step - loss: 0.0616 - val_loss: 0.0673\n",
      "Epoch 1489/1500\n",
      "1700/1700 [==============================] - 1s 296us/step - loss: 0.0621 - val_loss: 0.0666\n",
      "Epoch 1490/1500\n",
      "1700/1700 [==============================] - 1s 317us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1491/1500\n",
      "1700/1700 [==============================] - 1s 304us/step - loss: 0.0615 - val_loss: 0.0664\n",
      "Epoch 1492/1500\n",
      "1700/1700 [==============================] - 1s 345us/step - loss: 0.0616 - val_loss: 0.0664\n",
      "Epoch 1493/1500\n",
      "1700/1700 [==============================] - 0s 176us/step - loss: 0.0615 - val_loss: 0.0666\n",
      "Epoch 1494/1500\n",
      "1700/1700 [==============================] - 0s 177us/step - loss: 0.0619 - val_loss: 0.0668\n",
      "Epoch 1495/1500\n",
      "1700/1700 [==============================] - 0s 255us/step - loss: 0.0617 - val_loss: 0.0666\n",
      "Epoch 1496/1500\n",
      "1700/1700 [==============================] - 0s 168us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1497/1500\n",
      "1700/1700 [==============================] - 0s 167us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1498/1500\n",
      "1700/1700 [==============================] - 0s 168us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1499/1500\n",
      "1700/1700 [==============================] - 0s 209us/step - loss: 0.0616 - val_loss: 0.0666\n",
      "Epoch 1500/1500\n",
      "1700/1700 [==============================] - 1s 316us/step - loss: 0.0617 - val_loss: 0.0666\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Will create a large function to apply to the 4 CT Scans for each year.\n",
    "parsee = ct_sheet.sheet_names[10]\n",
    "data = ct_sheet.parse(parsee)\n",
    "data_features = data.loc[:, data.columns] \n",
    "data_features = data_features.drop(['Case','Visit','ROI42','ROI117'], axis=1)  \n",
    "#Get rid of subject names to only have features now. #Need to remove ROIs. They don't convert to floats.\n",
    "#Get rid of ctx_rh_Medial_wall and ctx_lh_Medial_wall, not needed for analysis.\n",
    "#Have to standardize data. Scikit learn here. Need to create stratified K folds to avoid uneven distribution of risk groups.pcaCT1Y = PCA(n_components=150) #150 Features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data_features)\n",
    "\n",
    "ct_sheet = pd.ExcelFile(\"SAAutoEncoder.xlsx\") \n",
    "parsee = ct_sheet.sheet_names[0]\n",
    "data = ct_sheet.parse(parsee)\n",
    "data_features = data.loc[:, data.columns] \n",
    "data_features = data_features.drop(['ROI',11142,12142], axis=1)  \n",
    "scaled_data = scaler.transform(data_features)\n",
    "\n",
    "print(scaled_data.shape)\n",
    "X_train, X_test = train_test_split(scaled_data, test_size=0.10, random_state=20)\n",
    "\n",
    "#Size of encoded representation\n",
    "input_size = 148\n",
    "hidden_size3 = 119\n",
    "hidden_size2 = 88\n",
    "hidden_size1 = 57\n",
    "encoding_dim = 27 # 13 floats -> compression of factor ~11.5, assuming the input is 150 floats\n",
    "\n",
    "# Input Placeholder\n",
    "input_data = Input(shape=(input_size,))\n",
    "print(input_data)\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "hidden_e_3 = Dense(hidden_size3, activation='tanh')(input_data)\n",
    "hidden_e_2 = Dense(hidden_size2, activation='tanh')(hidden_e_3)\n",
    "hidden_e_1 = Dense(hidden_size1, activation='tanh')(hidden_e_2) \n",
    "encoded = Dense(encoding_dim, activation='tanh')(hidden_e_1)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "hidden_d_1 = Dense(hidden_size1, activation='tanh')(encoded)\n",
    "hidden_d_2 = Dense(hidden_size2, activation='tanh')(hidden_d_1)\n",
    "hidden_d_3 = Dense(hidden_size3, activation='tanh')(hidden_d_2)\n",
    "decoded = Dense(input_size, activation='tanh')(hidden_d_3) #Decoded layers and activation function. Needs to return to 151.\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_data, decoded)\n",
    "# configure our model to use mean_absolute_error loss function, and the Adam optimizer:\n",
    "autoencoder.compile(optimizer='Adam', loss='mean_absolute_error')\n",
    "\n",
    "ac = autoencoder.fit(X_train, X_train,\n",
    "epochs=1500,\n",
    "batch_size=15,\n",
    "shuffle=True,\n",
    "validation_data=(X_test, X_test))\n",
    "\n",
    "#print(ac.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(ac.history['loss'])\n",
    "plt.plot(ac.history['val_loss'])\n",
    "#plt.set(xlim=(0, 50), ylim=(0.0, 1.0))\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, 1500, 0.0, 0.15])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.2634 - val_loss: 0.1353\n",
      "Epoch 2/1500\n",
      "603/603 [==============================] - 0s 384us/step - loss: 0.1150 - val_loss: 0.1029\n",
      "Epoch 3/1500\n",
      "603/603 [==============================] - 0s 472us/step - loss: 0.0962 - val_loss: 0.0933\n",
      "Epoch 4/1500\n",
      "603/603 [==============================] - 0s 444us/step - loss: 0.0887 - val_loss: 0.0872\n",
      "Epoch 5/1500\n",
      "603/603 [==============================] - 0s 433us/step - loss: 0.0843 - val_loss: 0.0847\n",
      "Epoch 6/1500\n",
      "603/603 [==============================] - 0s 515us/step - loss: 0.0810 - val_loss: 0.0817\n",
      "Epoch 7/1500\n",
      "603/603 [==============================] - 0s 532us/step - loss: 0.0785 - val_loss: 0.0797\n",
      "Epoch 8/1500\n",
      "603/603 [==============================] - 0s 641us/step - loss: 0.0769 - val_loss: 0.0788\n",
      "Epoch 9/1500\n",
      "603/603 [==============================] - 0s 609us/step - loss: 0.0756 - val_loss: 0.0777\n",
      "Epoch 10/1500\n",
      "603/603 [==============================] - 0s 490us/step - loss: 0.0747 - val_loss: 0.0764\n",
      "Epoch 11/1500\n",
      "603/603 [==============================] - 0s 815us/step - loss: 0.0737 - val_loss: 0.0759\n",
      "Epoch 12/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0729 - val_loss: 0.0755\n",
      "Epoch 13/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0724 - val_loss: 0.0750\n",
      "Epoch 14/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0722 - val_loss: 0.0747\n",
      "Epoch 15/1500\n",
      "603/603 [==============================] - 1s 908us/step - loss: 0.0717 - val_loss: 0.0740\n",
      "Epoch 16/1500\n",
      "603/603 [==============================] - 0s 562us/step - loss: 0.0713 - val_loss: 0.0744\n",
      "Epoch 17/1500\n",
      "603/603 [==============================] - 0s 463us/step - loss: 0.0712 - val_loss: 0.0735\n",
      "Epoch 18/1500\n",
      "603/603 [==============================] - 0s 672us/step - loss: 0.0712 - val_loss: 0.0740\n",
      "Epoch 19/1500\n",
      "603/603 [==============================] - 1s 940us/step - loss: 0.0710 - val_loss: 0.0734\n",
      "Epoch 20/1500\n",
      "603/603 [==============================] - 1s 967us/step - loss: 0.0711 - val_loss: 0.0733\n",
      "Epoch 21/1500\n",
      "603/603 [==============================] - 0s 547us/step - loss: 0.0707 - val_loss: 0.0733\n",
      "Epoch 22/1500\n",
      "603/603 [==============================] - 0s 625us/step - loss: 0.0705 - val_loss: 0.0734\n",
      "Epoch 23/1500\n",
      "603/603 [==============================] - 1s 922us/step - loss: 0.0706 - val_loss: 0.0732\n",
      "Epoch 24/1500\n",
      "603/603 [==============================] - 0s 527us/step - loss: 0.0705 - val_loss: 0.0731\n",
      "Epoch 25/1500\n",
      "603/603 [==============================] - 0s 769us/step - loss: 0.0705 - val_loss: 0.0733\n",
      "Epoch 26/1500\n",
      "603/603 [==============================] - 0s 517us/step - loss: 0.0703 - val_loss: 0.0729\n",
      "Epoch 27/1500\n",
      "603/603 [==============================] - 0s 520us/step - loss: 0.0703 - val_loss: 0.0733\n",
      "Epoch 28/1500\n",
      "603/603 [==============================] - 0s 542us/step - loss: 0.0706 - val_loss: 0.0729\n",
      "Epoch 29/1500\n",
      "603/603 [==============================] - 0s 509us/step - loss: 0.0702 - val_loss: 0.0736\n",
      "Epoch 30/1500\n",
      "603/603 [==============================] - 0s 536us/step - loss: 0.0703 - val_loss: 0.0728\n",
      "Epoch 31/1500\n",
      "603/603 [==============================] - 0s 659us/step - loss: 0.0700 - val_loss: 0.0727\n",
      "Epoch 32/1500\n",
      "603/603 [==============================] - 0s 448us/step - loss: 0.0700 - val_loss: 0.0729\n",
      "Epoch 33/1500\n",
      "603/603 [==============================] - 0s 507us/step - loss: 0.0701 - val_loss: 0.0731\n",
      "Epoch 34/1500\n",
      "603/603 [==============================] - 0s 539us/step - loss: 0.0702 - val_loss: 0.0733\n",
      "Epoch 35/1500\n",
      "603/603 [==============================] - 0s 566us/step - loss: 0.0702 - val_loss: 0.0727\n",
      "Epoch 36/1500\n",
      "603/603 [==============================] - 0s 643us/step - loss: 0.0701 - val_loss: 0.0731\n",
      "Epoch 37/1500\n",
      "603/603 [==============================] - 0s 522us/step - loss: 0.0701 - val_loss: 0.0727\n",
      "Epoch 38/1500\n",
      "603/603 [==============================] - 0s 704us/step - loss: 0.0699 - val_loss: 0.0727\n",
      "Epoch 39/1500\n",
      "603/603 [==============================] - 0s 709us/step - loss: 0.0702 - val_loss: 0.0730\n",
      "Epoch 40/1500\n",
      "603/603 [==============================] - 0s 478us/step - loss: 0.0701 - val_loss: 0.0729\n",
      "Epoch 41/1500\n",
      "603/603 [==============================] - 0s 739us/step - loss: 0.0703 - val_loss: 0.0726\n",
      "Epoch 42/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0700 - val_loss: 0.0729\n",
      "Epoch 43/1500\n",
      "603/603 [==============================] - 0s 803us/step - loss: 0.0699 - val_loss: 0.0724\n",
      "Epoch 44/1500\n",
      "603/603 [==============================] - 0s 629us/step - loss: 0.0699 - val_loss: 0.0727\n",
      "Epoch 45/1500\n",
      "603/603 [==============================] - 0s 772us/step - loss: 0.0700 - val_loss: 0.0727\n",
      "Epoch 46/1500\n",
      "603/603 [==============================] - 1s 832us/step - loss: 0.0700 - val_loss: 0.0728\n",
      "Epoch 47/1500\n",
      "603/603 [==============================] - 1s 989us/step - loss: 0.0698 - val_loss: 0.0728\n",
      "Epoch 48/1500\n",
      "603/603 [==============================] - 1s 946us/step - loss: 0.0698 - val_loss: 0.0725\n",
      "Epoch 49/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0697 - val_loss: 0.0726\n",
      "Epoch 50/1500\n",
      "603/603 [==============================] - 0s 769us/step - loss: 0.0697 - val_loss: 0.0731\n",
      "Epoch 51/1500\n",
      "603/603 [==============================] - 0s 607us/step - loss: 0.0701 - val_loss: 0.0731\n",
      "Epoch 52/1500\n",
      "603/603 [==============================] - 1s 878us/step - loss: 0.0698 - val_loss: 0.0726\n",
      "Epoch 53/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0699 - val_loss: 0.0728\n",
      "Epoch 54/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0728\n",
      "Epoch 55/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0697 - val_loss: 0.0727\n",
      "Epoch 56/1500\n",
      "603/603 [==============================] - 0s 750us/step - loss: 0.0697 - val_loss: 0.0729\n",
      "Epoch 57/1500\n",
      "603/603 [==============================] - 0s 603us/step - loss: 0.0698 - val_loss: 0.0730\n",
      "Epoch 58/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0698 - val_loss: 0.0725\n",
      "Epoch 59/1500\n",
      "603/603 [==============================] - 0s 565us/step - loss: 0.0697 - val_loss: 0.0726\n",
      "Epoch 60/1500\n",
      "603/603 [==============================] - 1s 872us/step - loss: 0.0698 - val_loss: 0.0725\n",
      "Epoch 61/1500\n",
      "603/603 [==============================] - 1s 969us/step - loss: 0.0696 - val_loss: 0.0728\n",
      "Epoch 62/1500\n",
      "603/603 [==============================] - 1s 954us/step - loss: 0.0696 - val_loss: 0.0725\n",
      "Epoch 63/1500\n",
      "603/603 [==============================] - 0s 651us/step - loss: 0.0697 - val_loss: 0.0725\n",
      "Epoch 64/1500\n",
      "603/603 [==============================] - 1s 858us/step - loss: 0.0696 - val_loss: 0.0728\n",
      "Epoch 65/1500\n",
      "603/603 [==============================] - 1s 873us/step - loss: 0.0696 - val_loss: 0.0723\n",
      "Epoch 66/1500\n",
      "603/603 [==============================] - 1s 839us/step - loss: 0.0696 - val_loss: 0.0725\n",
      "Epoch 67/1500\n",
      "603/603 [==============================] - 0s 737us/step - loss: 0.0698 - val_loss: 0.0725\n",
      "Epoch 68/1500\n",
      "603/603 [==============================] - 1s 991us/step - loss: 0.0696 - val_loss: 0.0722\n",
      "Epoch 69/1500\n",
      "603/603 [==============================] - 1s 954us/step - loss: 0.0695 - val_loss: 0.0721\n",
      "Epoch 70/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0725\n",
      "Epoch 71/1500\n",
      "603/603 [==============================] - 0s 752us/step - loss: 0.0696 - val_loss: 0.0723\n",
      "Epoch 72/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0696 - val_loss: 0.0724\n",
      "Epoch 73/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0726\n",
      "Epoch 74/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0726\n",
      "Epoch 75/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0697 - val_loss: 0.0725\n",
      "Epoch 76/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0695 - val_loss: 0.0728\n",
      "Epoch 77/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0730\n",
      "Epoch 78/1500\n",
      "603/603 [==============================] - 0s 736us/step - loss: 0.0695 - val_loss: 0.0726\n",
      "Epoch 79/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0723\n",
      "Epoch 80/1500\n",
      "603/603 [==============================] - 0s 518us/step - loss: 0.0694 - val_loss: 0.0725\n",
      "Epoch 81/1500\n",
      "603/603 [==============================] - 0s 778us/step - loss: 0.0694 - val_loss: 0.0722\n",
      "Epoch 82/1500\n",
      "603/603 [==============================] - 0s 619us/step - loss: 0.0693 - val_loss: 0.0725\n",
      "Epoch 83/1500\n",
      "603/603 [==============================] - 0s 635us/step - loss: 0.0694 - val_loss: 0.0722\n",
      "Epoch 84/1500\n",
      "603/603 [==============================] - 0s 795us/step - loss: 0.0693 - val_loss: 0.0724\n",
      "Epoch 85/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0724\n",
      "Epoch 86/1500\n",
      "603/603 [==============================] - 1s 885us/step - loss: 0.0694 - val_loss: 0.0724\n",
      "Epoch 87/1500\n",
      "603/603 [==============================] - 0s 642us/step - loss: 0.0694 - val_loss: 0.0724\n",
      "Epoch 88/1500\n",
      "603/603 [==============================] - 0s 334us/step - loss: 0.0695 - val_loss: 0.0723\n",
      "Epoch 89/1500\n",
      "603/603 [==============================] - 0s 560us/step - loss: 0.0694 - val_loss: 0.0724\n",
      "Epoch 90/1500\n",
      "603/603 [==============================] - 0s 523us/step - loss: 0.0694 - val_loss: 0.0730\n",
      "Epoch 91/1500\n",
      "603/603 [==============================] - 0s 530us/step - loss: 0.0694 - val_loss: 0.0724\n",
      "Epoch 92/1500\n",
      "603/603 [==============================] - 0s 397us/step - loss: 0.0694 - val_loss: 0.0723\n",
      "Epoch 93/1500\n",
      "603/603 [==============================] - 0s 475us/step - loss: 0.0694 - val_loss: 0.0724\n",
      "Epoch 94/1500\n",
      "603/603 [==============================] - 0s 707us/step - loss: 0.0693 - val_loss: 0.0727\n",
      "Epoch 95/1500\n",
      "603/603 [==============================] - 0s 488us/step - loss: 0.0694 - val_loss: 0.0724\n",
      "Epoch 96/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0694 - val_loss: 0.0724\n",
      "Epoch 97/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0693 - val_loss: 0.0722 - ETA: 0s - loss:\n",
      "Epoch 98/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0692 - val_loss: 0.0721\n",
      "Epoch 99/1500\n",
      "603/603 [==============================] - 1s 830us/step - loss: 0.0692 - val_loss: 0.0718\n",
      "Epoch 100/1500\n",
      "603/603 [==============================] - 0s 607us/step - loss: 0.0693 - val_loss: 0.0722\n",
      "Epoch 101/1500\n",
      "603/603 [==============================] - 0s 554us/step - loss: 0.0693 - val_loss: 0.0722\n",
      "Epoch 102/1500\n",
      "603/603 [==============================] - 0s 531us/step - loss: 0.0694 - val_loss: 0.0724\n",
      "Epoch 103/1500\n",
      "603/603 [==============================] - 0s 715us/step - loss: 0.0692 - val_loss: 0.0722\n",
      "Epoch 104/1500\n",
      "603/603 [==============================] - 1s 900us/step - loss: 0.0692 - val_loss: 0.0725\n",
      "Epoch 105/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0722\n",
      "Epoch 106/1500\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.069 - 1s 958us/step - loss: 0.0692 - val_loss: 0.0721\n",
      "Epoch 107/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0692 - val_loss: 0.0722\n",
      "Epoch 108/1500\n",
      "603/603 [==============================] - 1s 995us/step - loss: 0.0692 - val_loss: 0.0724\n",
      "Epoch 109/1500\n",
      "603/603 [==============================] - 0s 805us/step - loss: 0.0691 - val_loss: 0.0720\n",
      "Epoch 110/1500\n",
      "603/603 [==============================] - 0s 710us/step - loss: 0.0690 - val_loss: 0.0721\n",
      "Epoch 111/1500\n",
      "603/603 [==============================] - 0s 705us/step - loss: 0.0691 - val_loss: 0.0723\n",
      "Epoch 112/1500\n",
      "603/603 [==============================] - 0s 680us/step - loss: 0.0691 - val_loss: 0.0721\n",
      "Epoch 113/1500\n",
      "603/603 [==============================] - 0s 732us/step - loss: 0.0690 - val_loss: 0.0723\n",
      "Epoch 114/1500\n",
      "603/603 [==============================] - 0s 730us/step - loss: 0.0691 - val_loss: 0.0721\n",
      "Epoch 115/1500\n",
      "603/603 [==============================] - 0s 735us/step - loss: 0.0690 - val_loss: 0.0723\n",
      "Epoch 116/1500\n",
      "603/603 [==============================] - 0s 791us/step - loss: 0.0691 - val_loss: 0.0722\n",
      "Epoch 117/1500\n",
      "603/603 [==============================] - 0s 805us/step - loss: 0.0692 - val_loss: 0.0721\n",
      "Epoch 118/1500\n",
      "603/603 [==============================] - 0s 779us/step - loss: 0.0691 - val_loss: 0.0722\n",
      "Epoch 119/1500\n",
      "603/603 [==============================] - 0s 489us/step - loss: 0.0690 - val_loss: 0.0721\n",
      "Epoch 120/1500\n",
      "603/603 [==============================] - 0s 374us/step - loss: 0.0690 - val_loss: 0.0722\n",
      "Epoch 121/1500\n",
      "603/603 [==============================] - 0s 526us/step - loss: 0.0692 - val_loss: 0.0722\n",
      "Epoch 122/1500\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.0692 - val_loss: 0.0723\n",
      "Epoch 123/1500\n",
      "603/603 [==============================] - 0s 738us/step - loss: 0.0691 - val_loss: 0.0725\n",
      "Epoch 124/1500\n",
      "603/603 [==============================] - 0s 448us/step - loss: 0.0692 - val_loss: 0.0722\n",
      "Epoch 125/1500\n",
      "603/603 [==============================] - 1s 905us/step - loss: 0.0689 - val_loss: 0.0720\n",
      "Epoch 126/1500\n",
      "603/603 [==============================] - 0s 812us/step - loss: 0.0690 - val_loss: 0.0722\n",
      "Epoch 127/1500\n",
      "603/603 [==============================] - 0s 661us/step - loss: 0.0690 - val_loss: 0.0722\n",
      "Epoch 128/1500\n",
      "603/603 [==============================] - 0s 729us/step - loss: 0.0689 - val_loss: 0.0721\n",
      "Epoch 129/1500\n",
      "603/603 [==============================] - 0s 615us/step - loss: 0.0690 - val_loss: 0.0721\n",
      "Epoch 130/1500\n",
      "603/603 [==============================] - 0s 580us/step - loss: 0.0690 - val_loss: 0.0722\n",
      "Epoch 131/1500\n",
      "603/603 [==============================] - 0s 737us/step - loss: 0.0690 - val_loss: 0.0722\n",
      "Epoch 132/1500\n",
      "603/603 [==============================] - 0s 810us/step - loss: 0.0691 - val_loss: 0.0721\n",
      "Epoch 133/1500\n",
      "603/603 [==============================] - 0s 770us/step - loss: 0.0690 - val_loss: 0.0723\n",
      "Epoch 134/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0719\n",
      "Epoch 135/1500\n",
      "603/603 [==============================] - 0s 403us/step - loss: 0.0690 - val_loss: 0.0720\n",
      "Epoch 136/1500\n",
      "603/603 [==============================] - 0s 431us/step - loss: 0.0689 - val_loss: 0.0720\n",
      "Epoch 137/1500\n",
      "603/603 [==============================] - 0s 397us/step - loss: 0.0689 - val_loss: 0.0718\n",
      "Epoch 138/1500\n",
      "603/603 [==============================] - 0s 403us/step - loss: 0.0688 - val_loss: 0.0719\n",
      "Epoch 139/1500\n",
      "603/603 [==============================] - 0s 397us/step - loss: 0.0689 - val_loss: 0.0720\n",
      "Epoch 140/1500\n",
      "603/603 [==============================] - 0s 402us/step - loss: 0.0688 - val_loss: 0.0719\n",
      "Epoch 141/1500\n",
      "603/603 [==============================] - 0s 343us/step - loss: 0.0688 - val_loss: 0.0720\n",
      "Epoch 142/1500\n",
      "603/603 [==============================] - 0s 422us/step - loss: 0.0688 - val_loss: 0.0721\n",
      "Epoch 143/1500\n",
      "603/603 [==============================] - 0s 436us/step - loss: 0.0689 - val_loss: 0.0722\n",
      "Epoch 144/1500\n",
      "603/603 [==============================] - 0s 366us/step - loss: 0.0689 - val_loss: 0.0722\n",
      "Epoch 145/1500\n",
      "603/603 [==============================] - 0s 548us/step - loss: 0.0687 - val_loss: 0.0722\n",
      "Epoch 146/1500\n",
      "603/603 [==============================] - 0s 779us/step - loss: 0.0688 - val_loss: 0.0719\n",
      "Epoch 147/1500\n",
      "603/603 [==============================] - 0s 632us/step - loss: 0.0687 - val_loss: 0.0721\n",
      "Epoch 148/1500\n",
      "603/603 [==============================] - 1s 929us/step - loss: 0.0687 - val_loss: 0.0718\n",
      "Epoch 149/1500\n",
      "603/603 [==============================] - 0s 799us/step - loss: 0.0688 - val_loss: 0.0721\n",
      "Epoch 150/1500\n",
      "603/603 [==============================] - 0s 667us/step - loss: 0.0689 - val_loss: 0.0719\n",
      "Epoch 151/1500\n",
      "603/603 [==============================] - 0s 422us/step - loss: 0.0689 - val_loss: 0.0719\n",
      "Epoch 152/1500\n",
      "603/603 [==============================] - 0s 503us/step - loss: 0.0688 - val_loss: 0.0723\n",
      "Epoch 153/1500\n",
      "603/603 [==============================] - 0s 569us/step - loss: 0.0687 - val_loss: 0.0721\n",
      "Epoch 154/1500\n",
      "603/603 [==============================] - 0s 685us/step - loss: 0.0687 - val_loss: 0.0720\n",
      "Epoch 155/1500\n",
      "603/603 [==============================] - 0s 688us/step - loss: 0.0687 - val_loss: 0.0719\n",
      "Epoch 156/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0687 - val_loss: 0.0720\n",
      "Epoch 157/1500\n",
      "603/603 [==============================] - 0s 777us/step - loss: 0.0688 - val_loss: 0.0720\n",
      "Epoch 158/1500\n",
      "603/603 [==============================] - 0s 460us/step - loss: 0.0687 - val_loss: 0.0720\n",
      "Epoch 159/1500\n",
      "603/603 [==============================] - 0s 776us/step - loss: 0.0688 - val_loss: 0.0719\n",
      "Epoch 160/1500\n",
      "603/603 [==============================] - 0s 713us/step - loss: 0.0686 - val_loss: 0.0724\n",
      "Epoch 161/1500\n",
      "603/603 [==============================] - 1s 849us/step - loss: 0.0687 - val_loss: 0.0721\n",
      "Epoch 162/1500\n",
      "603/603 [==============================] - 1s 830us/step - loss: 0.0687 - val_loss: 0.0718\n",
      "Epoch 163/1500\n",
      "603/603 [==============================] - 0s 717us/step - loss: 0.0687 - val_loss: 0.0722\n",
      "Epoch 164/1500\n",
      "603/603 [==============================] - 1s 949us/step - loss: 0.0687 - val_loss: 0.0720\n",
      "Epoch 165/1500\n",
      "603/603 [==============================] - 0s 718us/step - loss: 0.0687 - val_loss: 0.0720\n",
      "Epoch 166/1500\n",
      "603/603 [==============================] - 0s 762us/step - loss: 0.0687 - val_loss: 0.0719\n",
      "Epoch 167/1500\n",
      "603/603 [==============================] - 0s 684us/step - loss: 0.0687 - val_loss: 0.0722\n",
      "Epoch 168/1500\n",
      "603/603 [==============================] - 0s 775us/step - loss: 0.0688 - val_loss: 0.0721\n",
      "Epoch 169/1500\n",
      "603/603 [==============================] - 0s 506us/step - loss: 0.0687 - val_loss: 0.0722\n",
      "Epoch 170/1500\n",
      "603/603 [==============================] - 0s 532us/step - loss: 0.0685 - val_loss: 0.0720\n",
      "Epoch 171/1500\n",
      "603/603 [==============================] - 0s 688us/step - loss: 0.0686 - val_loss: 0.0721\n",
      "Epoch 172/1500\n",
      "603/603 [==============================] - 0s 713us/step - loss: 0.0686 - val_loss: 0.0719\n",
      "Epoch 173/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0721\n",
      "Epoch 174/1500\n",
      "603/603 [==============================] - 0s 305us/step - loss: 0.0686 - val_loss: 0.0719\n",
      "Epoch 175/1500\n",
      "603/603 [==============================] - 0s 582us/step - loss: 0.0686 - val_loss: 0.0721\n",
      "Epoch 176/1500\n",
      "603/603 [==============================] - 0s 339us/step - loss: 0.0685 - val_loss: 0.0719\n",
      "Epoch 177/1500\n",
      "603/603 [==============================] - 0s 716us/step - loss: 0.0686 - val_loss: 0.0718\n",
      "Epoch 178/1500\n",
      "603/603 [==============================] - 0s 550us/step - loss: 0.0685 - val_loss: 0.0722\n",
      "Epoch 179/1500\n",
      "603/603 [==============================] - 0s 449us/step - loss: 0.0686 - val_loss: 0.0723\n",
      "Epoch 180/1500\n",
      "603/603 [==============================] - 0s 715us/step - loss: 0.0686 - val_loss: 0.0721\n",
      "Epoch 181/1500\n",
      "603/603 [==============================] - 1s 846us/step - loss: 0.0685 - val_loss: 0.0724\n",
      "Epoch 182/1500\n",
      "603/603 [==============================] - 1s 861us/step - loss: 0.0685 - val_loss: 0.0721\n",
      "Epoch 183/1500\n",
      "603/603 [==============================] - 0s 764us/step - loss: 0.0685 - val_loss: 0.0720\n",
      "Epoch 184/1500\n",
      "603/603 [==============================] - 1s 943us/step - loss: 0.0685 - val_loss: 0.0722\n",
      "Epoch 185/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0686 - val_loss: 0.0720\n",
      "Epoch 186/1500\n",
      "603/603 [==============================] - 0s 805us/step - loss: 0.0684 - val_loss: 0.0720\n",
      "Epoch 187/1500\n",
      "603/603 [==============================] - 0s 428us/step - loss: 0.0685 - val_loss: 0.0719\n",
      "Epoch 188/1500\n",
      "603/603 [==============================] - 0s 585us/step - loss: 0.0684 - val_loss: 0.0722\n",
      "Epoch 189/1500\n",
      "603/603 [==============================] - 0s 307us/step - loss: 0.0686 - val_loss: 0.0720\n",
      "Epoch 190/1500\n",
      "603/603 [==============================] - 0s 346us/step - loss: 0.0685 - val_loss: 0.0721\n",
      "Epoch 191/1500\n",
      "603/603 [==============================] - 0s 475us/step - loss: 0.0685 - val_loss: 0.0722\n",
      "Epoch 192/1500\n",
      "603/603 [==============================] - 0s 347us/step - loss: 0.0685 - val_loss: 0.0718\n",
      "Epoch 193/1500\n",
      "603/603 [==============================] - 0s 326us/step - loss: 0.0684 - val_loss: 0.0718\n",
      "Epoch 194/1500\n",
      "603/603 [==============================] - 0s 340us/step - loss: 0.0685 - val_loss: 0.0720\n",
      "Epoch 195/1500\n",
      "603/603 [==============================] - 0s 331us/step - loss: 0.0685 - val_loss: 0.0722\n",
      "Epoch 196/1500\n",
      "603/603 [==============================] - 0s 319us/step - loss: 0.0683 - val_loss: 0.0720\n",
      "Epoch 197/1500\n",
      "603/603 [==============================] - 0s 366us/step - loss: 0.0685 - val_loss: 0.0722\n",
      "Epoch 198/1500\n",
      "603/603 [==============================] - 0s 336us/step - loss: 0.0685 - val_loss: 0.0722\n",
      "Epoch 199/1500\n",
      "603/603 [==============================] - 0s 282us/step - loss: 0.0684 - val_loss: 0.0722\n",
      "Epoch 200/1500\n",
      "603/603 [==============================] - 0s 297us/step - loss: 0.0683 - val_loss: 0.0719\n",
      "Epoch 201/1500\n",
      "603/603 [==============================] - 0s 332us/step - loss: 0.0682 - val_loss: 0.0718\n",
      "Epoch 202/1500\n",
      "603/603 [==============================] - 0s 341us/step - loss: 0.0682 - val_loss: 0.0720\n",
      "Epoch 203/1500\n",
      "603/603 [==============================] - 0s 317us/step - loss: 0.0684 - val_loss: 0.0718\n",
      "Epoch 204/1500\n",
      "603/603 [==============================] - 0s 321us/step - loss: 0.0683 - val_loss: 0.0718\n",
      "Epoch 205/1500\n",
      "603/603 [==============================] - 0s 389us/step - loss: 0.0683 - val_loss: 0.0722\n",
      "Epoch 206/1500\n",
      "603/603 [==============================] - 0s 724us/step - loss: 0.0684 - val_loss: 0.0721\n",
      "Epoch 207/1500\n",
      "603/603 [==============================] - 0s 323us/step - loss: 0.0682 - val_loss: 0.0717\n",
      "Epoch 208/1500\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.0682 - val_loss: 0.0721\n",
      "Epoch 209/1500\n",
      "603/603 [==============================] - 0s 657us/step - loss: 0.0682 - val_loss: 0.0721\n",
      "Epoch 210/1500\n",
      "603/603 [==============================] - 0s 681us/step - loss: 0.0684 - val_loss: 0.0721\n",
      "Epoch 211/1500\n",
      "603/603 [==============================] - 0s 667us/step - loss: 0.0682 - val_loss: 0.0720\n",
      "Epoch 212/1500\n",
      "603/603 [==============================] - 0s 340us/step - loss: 0.0682 - val_loss: 0.0725\n",
      "Epoch 213/1500\n",
      "603/603 [==============================] - 0s 362us/step - loss: 0.0682 - val_loss: 0.0718\n",
      "Epoch 214/1500\n",
      "603/603 [==============================] - 0s 743us/step - loss: 0.0682 - val_loss: 0.0720\n",
      "Epoch 215/1500\n",
      "603/603 [==============================] - 1s 893us/step - loss: 0.0682 - val_loss: 0.0721\n",
      "Epoch 216/1500\n",
      "603/603 [==============================] - 0s 604us/step - loss: 0.0681 - val_loss: 0.0723\n",
      "Epoch 217/1500\n",
      "603/603 [==============================] - 0s 588us/step - loss: 0.0682 - val_loss: 0.0723\n",
      "Epoch 218/1500\n",
      "603/603 [==============================] - 1s 950us/step - loss: 0.0681 - val_loss: 0.0722\n",
      "Epoch 219/1500\n",
      "603/603 [==============================] - 0s 686us/step - loss: 0.0681 - val_loss: 0.0720\n",
      "Epoch 220/1500\n",
      "603/603 [==============================] - 0s 721us/step - loss: 0.0682 - val_loss: 0.0721\n",
      "Epoch 221/1500\n",
      "603/603 [==============================] - 0s 323us/step - loss: 0.0682 - val_loss: 0.0721\n",
      "Epoch 222/1500\n",
      "603/603 [==============================] - 0s 342us/step - loss: 0.0683 - val_loss: 0.0721\n",
      "Epoch 223/1500\n",
      "603/603 [==============================] - 0s 391us/step - loss: 0.0681 - val_loss: 0.0725\n",
      "Epoch 224/1500\n",
      "603/603 [==============================] - 0s 432us/step - loss: 0.0681 - val_loss: 0.0719\n",
      "Epoch 225/1500\n",
      "603/603 [==============================] - 0s 384us/step - loss: 0.0681 - val_loss: 0.0723\n",
      "Epoch 226/1500\n",
      "603/603 [==============================] - 0s 546us/step - loss: 0.0681 - val_loss: 0.0722\n",
      "Epoch 227/1500\n",
      "603/603 [==============================] - 0s 410us/step - loss: 0.0680 - val_loss: 0.0720\n",
      "Epoch 228/1500\n",
      "603/603 [==============================] - 0s 405us/step - loss: 0.0682 - val_loss: 0.0719\n",
      "Epoch 229/1500\n",
      "603/603 [==============================] - 0s 371us/step - loss: 0.0680 - val_loss: 0.0721\n",
      "Epoch 230/1500\n",
      "603/603 [==============================] - 0s 410us/step - loss: 0.0680 - val_loss: 0.0722\n",
      "Epoch 231/1500\n",
      "603/603 [==============================] - 0s 529us/step - loss: 0.0681 - val_loss: 0.0721\n",
      "Epoch 232/1500\n",
      "603/603 [==============================] - 0s 596us/step - loss: 0.0680 - val_loss: 0.0720\n",
      "Epoch 233/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 779us/step - loss: 0.0681 - val_loss: 0.0720\n",
      "Epoch 234/1500\n",
      "603/603 [==============================] - 1s 854us/step - loss: 0.0679 - val_loss: 0.0721\n",
      "Epoch 235/1500\n",
      "603/603 [==============================] - 0s 690us/step - loss: 0.0680 - val_loss: 0.0723\n",
      "Epoch 236/1500\n",
      "603/603 [==============================] - 0s 622us/step - loss: 0.0679 - val_loss: 0.0725\n",
      "Epoch 237/1500\n",
      "603/603 [==============================] - 0s 818us/step - loss: 0.0679 - val_loss: 0.0720\n",
      "Epoch 238/1500\n",
      "603/603 [==============================] - 1s 939us/step - loss: 0.0678 - val_loss: 0.0720\n",
      "Epoch 239/1500\n",
      "603/603 [==============================] - 0s 604us/step - loss: 0.0678 - val_loss: 0.0723\n",
      "Epoch 240/1500\n",
      "603/603 [==============================] - 0s 623us/step - loss: 0.0679 - val_loss: 0.0722\n",
      "Epoch 241/1500\n",
      "603/603 [==============================] - 0s 662us/step - loss: 0.0681 - val_loss: 0.0724\n",
      "Epoch 242/1500\n",
      "603/603 [==============================] - 0s 672us/step - loss: 0.0680 - val_loss: 0.0721\n",
      "Epoch 243/1500\n",
      "603/603 [==============================] - 0s 545us/step - loss: 0.0678 - val_loss: 0.0722\n",
      "Epoch 244/1500\n",
      "603/603 [==============================] - 0s 683us/step - loss: 0.0678 - val_loss: 0.0719\n",
      "Epoch 245/1500\n",
      "603/603 [==============================] - 0s 405us/step - loss: 0.0678 - val_loss: 0.0723\n",
      "Epoch 246/1500\n",
      "603/603 [==============================] - 0s 702us/step - loss: 0.0679 - val_loss: 0.0722\n",
      "Epoch 247/1500\n",
      "603/603 [==============================] - 0s 549us/step - loss: 0.0681 - val_loss: 0.0720\n",
      "Epoch 248/1500\n",
      "603/603 [==============================] - 0s 387us/step - loss: 0.0677 - val_loss: 0.0720\n",
      "Epoch 249/1500\n",
      "603/603 [==============================] - 0s 644us/step - loss: 0.0677 - val_loss: 0.0721\n",
      "Epoch 250/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0677 - val_loss: 0.0721\n",
      "Epoch 251/1500\n",
      "603/603 [==============================] - 0s 753us/step - loss: 0.0677 - val_loss: 0.0722\n",
      "Epoch 252/1500\n",
      "603/603 [==============================] - 0s 353us/step - loss: 0.0677 - val_loss: 0.0721\n",
      "Epoch 253/1500\n",
      "603/603 [==============================] - 0s 554us/step - loss: 0.0678 - val_loss: 0.0724\n",
      "Epoch 254/1500\n",
      "603/603 [==============================] - 0s 570us/step - loss: 0.0677 - val_loss: 0.0723\n",
      "Epoch 255/1500\n",
      "603/603 [==============================] - 0s 437us/step - loss: 0.0677 - val_loss: 0.0722\n",
      "Epoch 256/1500\n",
      "603/603 [==============================] - 0s 379us/step - loss: 0.0678 - val_loss: 0.0722\n",
      "Epoch 257/1500\n",
      "603/603 [==============================] - 0s 413us/step - loss: 0.0677 - val_loss: 0.0722\n",
      "Epoch 258/1500\n",
      "603/603 [==============================] - 1s 961us/step - loss: 0.0678 - val_loss: 0.0723\n",
      "Epoch 259/1500\n",
      "603/603 [==============================] - 0s 824us/step - loss: 0.0677 - val_loss: 0.0724\n",
      "Epoch 260/1500\n",
      "603/603 [==============================] - 0s 804us/step - loss: 0.0679 - val_loss: 0.0723\n",
      "Epoch 261/1500\n",
      "603/603 [==============================] - 0s 584us/step - loss: 0.0676 - val_loss: 0.0722\n",
      "Epoch 262/1500\n",
      "603/603 [==============================] - 0s 628us/step - loss: 0.0676 - val_loss: 0.0722\n",
      "Epoch 263/1500\n",
      "603/603 [==============================] - 0s 660us/step - loss: 0.0677 - val_loss: 0.0721\n",
      "Epoch 264/1500\n",
      "603/603 [==============================] - 0s 811us/step - loss: 0.0677 - val_loss: 0.0724\n",
      "Epoch 265/1500\n",
      "603/603 [==============================] - 0s 559us/step - loss: 0.0675 - val_loss: 0.0722\n",
      "Epoch 266/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0676 - val_loss: 0.0721\n",
      "Epoch 267/1500\n",
      "603/603 [==============================] - 0s 739us/step - loss: 0.0675 - val_loss: 0.0720\n",
      "Epoch 268/1500\n",
      "603/603 [==============================] - 0s 547us/step - loss: 0.0675 - val_loss: 0.0722\n",
      "Epoch 269/1500\n",
      "603/603 [==============================] - 0s 381us/step - loss: 0.0676 - val_loss: 0.0724\n",
      "Epoch 270/1500\n",
      "603/603 [==============================] - 0s 650us/step - loss: 0.0676 - val_loss: 0.0722\n",
      "Epoch 271/1500\n",
      "603/603 [==============================] - 0s 439us/step - loss: 0.0676 - val_loss: 0.0724\n",
      "Epoch 272/1500\n",
      "603/603 [==============================] - 0s 384us/step - loss: 0.0675 - val_loss: 0.0725\n",
      "Epoch 273/1500\n",
      "603/603 [==============================] - 0s 429us/step - loss: 0.0675 - val_loss: 0.0723\n",
      "Epoch 274/1500\n",
      "603/603 [==============================] - 0s 410us/step - loss: 0.0675 - val_loss: 0.0724\n",
      "Epoch 275/1500\n",
      "603/603 [==============================] - 0s 339us/step - loss: 0.0676 - val_loss: 0.0720\n",
      "Epoch 276/1500\n",
      "603/603 [==============================] - 0s 704us/step - loss: 0.0675 - val_loss: 0.0723\n",
      "Epoch 277/1500\n",
      "603/603 [==============================] - 0s 773us/step - loss: 0.0675 - val_loss: 0.0721\n",
      "Epoch 278/1500\n",
      "603/603 [==============================] - 1s 947us/step - loss: 0.0674 - val_loss: 0.0722\n",
      "Epoch 279/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0718\n",
      "Epoch 280/1500\n",
      "603/603 [==============================] - 0s 714us/step - loss: 0.0674 - val_loss: 0.0721\n",
      "Epoch 281/1500\n",
      "603/603 [==============================] - 0s 785us/step - loss: 0.0676 - val_loss: 0.0723\n",
      "Epoch 282/1500\n",
      "603/603 [==============================] - 0s 403us/step - loss: 0.0675 - val_loss: 0.0721\n",
      "Epoch 283/1500\n",
      "603/603 [==============================] - 0s 388us/step - loss: 0.0673 - val_loss: 0.0726\n",
      "Epoch 284/1500\n",
      "603/603 [==============================] - 0s 393us/step - loss: 0.0674 - val_loss: 0.0723\n",
      "Epoch 285/1500\n",
      "603/603 [==============================] - 0s 357us/step - loss: 0.0674 - val_loss: 0.0722\n",
      "Epoch 286/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0674 - val_loss: 0.0723\n",
      "Epoch 287/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0675 - val_loss: 0.0724\n",
      "Epoch 288/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0674 - val_loss: 0.0724\n",
      "Epoch 289/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0674 - val_loss: 0.0724\n",
      "Epoch 290/1500\n",
      "603/603 [==============================] - 1s 943us/step - loss: 0.0675 - val_loss: 0.0724\n",
      "Epoch 291/1500\n",
      "603/603 [==============================] - 0s 692us/step - loss: 0.0672 - val_loss: 0.0724\n",
      "Epoch 292/1500\n",
      "603/603 [==============================] - 0s 553us/step - loss: 0.0673 - val_loss: 0.0725\n",
      "Epoch 293/1500\n",
      "603/603 [==============================] - 0s 620us/step - loss: 0.0674 - val_loss: 0.0723\n",
      "Epoch 294/1500\n",
      "603/603 [==============================] - 1s 831us/step - loss: 0.0674 - val_loss: 0.0724\n",
      "Epoch 295/1500\n",
      "603/603 [==============================] - 0s 535us/step - loss: 0.0673 - val_loss: 0.0722\n",
      "Epoch 296/1500\n",
      "603/603 [==============================] - 0s 305us/step - loss: 0.0673 - val_loss: 0.0720\n",
      "Epoch 297/1500\n",
      "603/603 [==============================] - 0s 664us/step - loss: 0.0672 - val_loss: 0.0724\n",
      "Epoch 298/1500\n",
      "603/603 [==============================] - 0s 368us/step - loss: 0.0672 - val_loss: 0.0723\n",
      "Epoch 299/1500\n",
      "603/603 [==============================] - 0s 402us/step - loss: 0.0672 - val_loss: 0.0726\n",
      "Epoch 300/1500\n",
      "603/603 [==============================] - 0s 552us/step - loss: 0.0673 - val_loss: 0.0724\n",
      "Epoch 301/1500\n",
      "603/603 [==============================] - 0s 823us/step - loss: 0.0671 - val_loss: 0.0723\n",
      "Epoch 302/1500\n",
      "603/603 [==============================] - 1s 965us/step - loss: 0.0672 - val_loss: 0.0721\n",
      "Epoch 303/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0723\n",
      "Epoch 304/1500\n",
      "603/603 [==============================] - 0s 400us/step - loss: 0.0671 - val_loss: 0.0726\n",
      "Epoch 305/1500\n",
      "603/603 [==============================] - 0s 329us/step - loss: 0.0671 - val_loss: 0.0725\n",
      "Epoch 306/1500\n",
      "603/603 [==============================] - 0s 361us/step - loss: 0.0671 - val_loss: 0.0723\n",
      "Epoch 307/1500\n",
      "603/603 [==============================] - 0s 313us/step - loss: 0.0673 - val_loss: 0.0725\n",
      "Epoch 308/1500\n",
      "603/603 [==============================] - 0s 791us/step - loss: 0.0672 - val_loss: 0.0721\n",
      "Epoch 309/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0672 - val_loss: 0.0725\n",
      "Epoch 310/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 410us/step - loss: 0.0672 - val_loss: 0.0724\n",
      "Epoch 311/1500\n",
      "603/603 [==============================] - 0s 430us/step - loss: 0.0671 - val_loss: 0.0724\n",
      "Epoch 312/1500\n",
      "603/603 [==============================] - 0s 466us/step - loss: 0.0672 - val_loss: 0.0724\n",
      "Epoch 313/1500\n",
      "603/603 [==============================] - 0s 676us/step - loss: 0.0670 - val_loss: 0.0726\n",
      "Epoch 314/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0727\n",
      "Epoch 315/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0671 - val_loss: 0.0724\n",
      "Epoch 316/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0669 - val_loss: 0.0722\n",
      "Epoch 317/1500\n",
      "603/603 [==============================] - 0s 776us/step - loss: 0.0671 - val_loss: 0.0724\n",
      "Epoch 318/1500\n",
      "603/603 [==============================] - 0s 779us/step - loss: 0.0671 - val_loss: 0.0725\n",
      "Epoch 319/1500\n",
      "603/603 [==============================] - 0s 744us/step - loss: 0.0670 - val_loss: 0.0726\n",
      "Epoch 320/1500\n",
      "603/603 [==============================] - 0s 822us/step - loss: 0.0669 - val_loss: 0.0725\n",
      "Epoch 321/1500\n",
      "603/603 [==============================] - 0s 719us/step - loss: 0.0671 - val_loss: 0.0726\n",
      "Epoch 322/1500\n",
      "603/603 [==============================] - 0s 748us/step - loss: 0.0672 - val_loss: 0.0724\n",
      "Epoch 323/1500\n",
      "603/603 [==============================] - 0s 789us/step - loss: 0.0669 - val_loss: 0.0724\n",
      "Epoch 324/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0668 - val_loss: 0.0723\n",
      "Epoch 325/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0668 - val_loss: 0.0724\n",
      "Epoch 326/1500\n",
      "603/603 [==============================] - 1s 949us/step - loss: 0.0668 - val_loss: 0.0726\n",
      "Epoch 327/1500\n",
      "603/603 [==============================] - 1s 910us/step - loss: 0.0668 - val_loss: 0.0725\n",
      "Epoch 328/1500\n",
      "603/603 [==============================] - 0s 697us/step - loss: 0.0671 - val_loss: 0.0722\n",
      "Epoch 329/1500\n",
      "603/603 [==============================] - 0s 313us/step - loss: 0.0671 - val_loss: 0.0726\n",
      "Epoch 330/1500\n",
      "603/603 [==============================] - 0s 540us/step - loss: 0.0669 - val_loss: 0.0726\n",
      "Epoch 331/1500\n",
      "603/603 [==============================] - 0s 535us/step - loss: 0.0668 - val_loss: 0.0724\n",
      "Epoch 332/1500\n",
      "603/603 [==============================] - 0s 412us/step - loss: 0.0669 - val_loss: 0.0727\n",
      "Epoch 333/1500\n",
      "603/603 [==============================] - 0s 465us/step - loss: 0.0667 - val_loss: 0.0722\n",
      "Epoch 334/1500\n",
      "603/603 [==============================] - 0s 613us/step - loss: 0.0668 - val_loss: 0.0725\n",
      "Epoch 335/1500\n",
      "603/603 [==============================] - 0s 496us/step - loss: 0.0669 - val_loss: 0.0723\n",
      "Epoch 336/1500\n",
      "603/603 [==============================] - 0s 671us/step - loss: 0.0669 - val_loss: 0.0727\n",
      "Epoch 337/1500\n",
      "603/603 [==============================] - 0s 616us/step - loss: 0.0667 - val_loss: 0.0723\n",
      "Epoch 338/1500\n",
      "603/603 [==============================] - 0s 687us/step - loss: 0.0667 - val_loss: 0.0724\n",
      "Epoch 339/1500\n",
      "603/603 [==============================] - 0s 700us/step - loss: 0.0669 - val_loss: 0.0725\n",
      "Epoch 340/1500\n",
      "603/603 [==============================] - 0s 446us/step - loss: 0.0667 - val_loss: 0.0726\n",
      "Epoch 341/1500\n",
      "603/603 [==============================] - 0s 411us/step - loss: 0.0668 - val_loss: 0.0727\n",
      "Epoch 342/1500\n",
      "603/603 [==============================] - 0s 346us/step - loss: 0.0668 - val_loss: 0.0724\n",
      "Epoch 343/1500\n",
      "603/603 [==============================] - 0s 574us/step - loss: 0.0668 - val_loss: 0.0725\n",
      "Epoch 344/1500\n",
      "603/603 [==============================] - 0s 408us/step - loss: 0.0668 - val_loss: 0.0725\n",
      "Epoch 345/1500\n",
      "603/603 [==============================] - 0s 320us/step - loss: 0.0666 - val_loss: 0.0722\n",
      "Epoch 346/1500\n",
      "603/603 [==============================] - 0s 336us/step - loss: 0.0667 - val_loss: 0.0724\n",
      "Epoch 347/1500\n",
      "603/603 [==============================] - 0s 349us/step - loss: 0.0667 - val_loss: 0.0724\n",
      "Epoch 348/1500\n",
      "603/603 [==============================] - 0s 339us/step - loss: 0.0666 - val_loss: 0.0725\n",
      "Epoch 349/1500\n",
      "603/603 [==============================] - 0s 323us/step - loss: 0.0665 - val_loss: 0.0726\n",
      "Epoch 350/1500\n",
      "603/603 [==============================] - 0s 402us/step - loss: 0.0666 - val_loss: 0.0724\n",
      "Epoch 351/1500\n",
      "603/603 [==============================] - 0s 416us/step - loss: 0.0667 - val_loss: 0.0725\n",
      "Epoch 352/1500\n",
      "603/603 [==============================] - 0s 416us/step - loss: 0.0667 - val_loss: 0.0726\n",
      "Epoch 353/1500\n",
      "603/603 [==============================] - 0s 702us/step - loss: 0.0667 - val_loss: 0.0728\n",
      "Epoch 354/1500\n",
      "603/603 [==============================] - 0s 792us/step - loss: 0.0665 - val_loss: 0.0724\n",
      "Epoch 355/1500\n",
      "603/603 [==============================] - 1s 929us/step - loss: 0.0665 - val_loss: 0.0726\n",
      "Epoch 356/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0665 - val_loss: 0.0725\n",
      "Epoch 357/1500\n",
      "603/603 [==============================] - 0s 417us/step - loss: 0.0665 - val_loss: 0.0723\n",
      "Epoch 358/1500\n",
      "603/603 [==============================] - 1s 894us/step - loss: 0.0666 - val_loss: 0.0726\n",
      "Epoch 359/1500\n",
      "603/603 [==============================] - 0s 807us/step - loss: 0.0666 - val_loss: 0.0730\n",
      "Epoch 360/1500\n",
      "603/603 [==============================] - 0s 690us/step - loss: 0.0665 - val_loss: 0.0724\n",
      "Epoch 361/1500\n",
      "603/603 [==============================] - 0s 411us/step - loss: 0.0665 - val_loss: 0.0725\n",
      "Epoch 362/1500\n",
      "603/603 [==============================] - 0s 331us/step - loss: 0.0665 - val_loss: 0.0723\n",
      "Epoch 363/1500\n",
      "603/603 [==============================] - 0s 316us/step - loss: 0.0665 - val_loss: 0.0726\n",
      "Epoch 364/1500\n",
      "603/603 [==============================] - 0s 375us/step - loss: 0.0665 - val_loss: 0.0725\n",
      "Epoch 365/1500\n",
      "603/603 [==============================] - 0s 294us/step - loss: 0.0665 - val_loss: 0.0725\n",
      "Epoch 366/1500\n",
      "603/603 [==============================] - 0s 374us/step - loss: 0.0664 - val_loss: 0.0725\n",
      "Epoch 367/1500\n",
      "603/603 [==============================] - 0s 357us/step - loss: 0.0666 - val_loss: 0.0723\n",
      "Epoch 368/1500\n",
      "603/603 [==============================] - 0s 310us/step - loss: 0.0663 - val_loss: 0.0724\n",
      "Epoch 369/1500\n",
      "603/603 [==============================] - 0s 725us/step - loss: 0.0663 - val_loss: 0.0725\n",
      "Epoch 370/1500\n",
      "603/603 [==============================] - 0s 822us/step - loss: 0.0663 - val_loss: 0.0727\n",
      "Epoch 371/1500\n",
      "603/603 [==============================] - 1s 859us/step - loss: 0.0663 - val_loss: 0.0723\n",
      "Epoch 372/1500\n",
      "603/603 [==============================] - 0s 431us/step - loss: 0.0663 - val_loss: 0.0728\n",
      "Epoch 373/1500\n",
      "603/603 [==============================] - 0s 292us/step - loss: 0.0662 - val_loss: 0.0723\n",
      "Epoch 374/1500\n",
      "603/603 [==============================] - 0s 311us/step - loss: 0.0663 - val_loss: 0.0726\n",
      "Epoch 375/1500\n",
      "603/603 [==============================] - 0s 349us/step - loss: 0.0665 - val_loss: 0.0728\n",
      "Epoch 376/1500\n",
      "603/603 [==============================] - 0s 807us/step - loss: 0.0663 - val_loss: 0.0727\n",
      "Epoch 377/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0664 - val_loss: 0.0724\n",
      "Epoch 378/1500\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 0.0662 - val_loss: 0.0727\n",
      "Epoch 379/1500\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.0662 - val_loss: 0.0724\n",
      "Epoch 380/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0662 - val_loss: 0.0726\n",
      "Epoch 381/1500\n",
      "603/603 [==============================] - 0s 692us/step - loss: 0.0661 - val_loss: 0.0727\n",
      "Epoch 382/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0663 - val_loss: 0.0730\n",
      "Epoch 383/1500\n",
      "603/603 [==============================] - 0s 739us/step - loss: 0.0662 - val_loss: 0.0727\n",
      "Epoch 384/1500\n",
      "603/603 [==============================] - 0s 366us/step - loss: 0.0661 - val_loss: 0.0727\n",
      "Epoch 385/1500\n",
      "603/603 [==============================] - 0s 827us/step - loss: 0.0662 - val_loss: 0.0728\n",
      "Epoch 386/1500\n",
      "603/603 [==============================] - 0s 493us/step - loss: 0.0661 - val_loss: 0.0727\n",
      "Epoch 387/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 328us/step - loss: 0.0660 - val_loss: 0.0725\n",
      "Epoch 388/1500\n",
      "603/603 [==============================] - 0s 539us/step - loss: 0.0660 - val_loss: 0.0728\n",
      "Epoch 389/1500\n",
      "603/603 [==============================] - 0s 475us/step - loss: 0.0661 - val_loss: 0.0726\n",
      "Epoch 390/1500\n",
      "603/603 [==============================] - 0s 802us/step - loss: 0.0662 - val_loss: 0.0728\n",
      "Epoch 391/1500\n",
      "603/603 [==============================] - 0s 675us/step - loss: 0.0661 - val_loss: 0.0724\n",
      "Epoch 392/1500\n",
      "603/603 [==============================] - 0s 404us/step - loss: 0.0660 - val_loss: 0.0724\n",
      "Epoch 393/1500\n",
      "603/603 [==============================] - 0s 443us/step - loss: 0.0660 - val_loss: 0.0727\n",
      "Epoch 394/1500\n",
      "603/603 [==============================] - 0s 821us/step - loss: 0.0659 - val_loss: 0.0724\n",
      "Epoch 395/1500\n",
      "603/603 [==============================] - 0s 675us/step - loss: 0.0659 - val_loss: 0.0727\n",
      "Epoch 396/1500\n",
      "603/603 [==============================] - 0s 778us/step - loss: 0.0661 - val_loss: 0.0728\n",
      "Epoch 397/1500\n",
      "603/603 [==============================] - 0s 491us/step - loss: 0.0661 - val_loss: 0.0727\n",
      "Epoch 398/1500\n",
      "603/603 [==============================] - 0s 459us/step - loss: 0.0660 - val_loss: 0.0725\n",
      "Epoch 399/1500\n",
      "603/603 [==============================] - 0s 304us/step - loss: 0.0660 - val_loss: 0.0724\n",
      "Epoch 400/1500\n",
      "603/603 [==============================] - 0s 427us/step - loss: 0.0659 - val_loss: 0.0724\n",
      "Epoch 401/1500\n",
      "603/603 [==============================] - 0s 308us/step - loss: 0.0658 - val_loss: 0.0727\n",
      "Epoch 402/1500\n",
      "603/603 [==============================] - 0s 310us/step - loss: 0.0660 - val_loss: 0.0727\n",
      "Epoch 403/1500\n",
      "603/603 [==============================] - 0s 329us/step - loss: 0.0660 - val_loss: 0.0727\n",
      "Epoch 404/1500\n",
      "603/603 [==============================] - 0s 295us/step - loss: 0.0658 - val_loss: 0.0728\n",
      "Epoch 405/1500\n",
      "603/603 [==============================] - 0s 376us/step - loss: 0.0659 - val_loss: 0.0725\n",
      "Epoch 406/1500\n",
      "603/603 [==============================] - 0s 303us/step - loss: 0.0658 - val_loss: 0.0726\n",
      "Epoch 407/1500\n",
      "603/603 [==============================] - 0s 302us/step - loss: 0.0659 - val_loss: 0.0728\n",
      "Epoch 408/1500\n",
      "603/603 [==============================] - 0s 482us/step - loss: 0.0659 - val_loss: 0.0730\n",
      "Epoch 409/1500\n",
      "603/603 [==============================] - 0s 776us/step - loss: 0.0658 - val_loss: 0.0726\n",
      "Epoch 410/1500\n",
      "603/603 [==============================] - 0s 526us/step - loss: 0.0659 - val_loss: 0.0727\n",
      "Epoch 411/1500\n",
      "603/603 [==============================] - 0s 460us/step - loss: 0.0660 - val_loss: 0.0725\n",
      "Epoch 412/1500\n",
      "603/603 [==============================] - 0s 524us/step - loss: 0.0658 - val_loss: 0.0724\n",
      "Epoch 413/1500\n",
      "603/603 [==============================] - 0s 739us/step - loss: 0.0657 - val_loss: 0.0724\n",
      "Epoch 414/1500\n",
      "603/603 [==============================] - 0s 707us/step - loss: 0.0657 - val_loss: 0.0726\n",
      "Epoch 415/1500\n",
      "603/603 [==============================] - 1s 882us/step - loss: 0.0657 - val_loss: 0.0725\n",
      "Epoch 416/1500\n",
      "603/603 [==============================] - 0s 355us/step - loss: 0.0657 - val_loss: 0.0727\n",
      "Epoch 417/1500\n",
      "603/603 [==============================] - 0s 327us/step - loss: 0.0656 - val_loss: 0.0726\n",
      "Epoch 418/1500\n",
      "603/603 [==============================] - 0s 386us/step - loss: 0.0657 - val_loss: 0.0726\n",
      "Epoch 419/1500\n",
      "603/603 [==============================] - 0s 298us/step - loss: 0.0658 - val_loss: 0.0727\n",
      "Epoch 420/1500\n",
      "603/603 [==============================] - 0s 309us/step - loss: 0.0657 - val_loss: 0.0727\n",
      "Epoch 421/1500\n",
      "603/603 [==============================] - 4s 6ms/step - loss: 0.0657 - val_loss: 0.0730\n",
      "Epoch 422/1500\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.0657 - val_loss: 0.0727\n",
      "Epoch 423/1500\n",
      "603/603 [==============================] - 3s 4ms/step - loss: 0.0657 - val_loss: 0.0729\n",
      "Epoch 424/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0656 - val_loss: 0.0728\n",
      "Epoch 425/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0657 - val_loss: 0.0726\n",
      "Epoch 426/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0655 - val_loss: 0.0728\n",
      "Epoch 427/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0656 - val_loss: 0.0729\n",
      "Epoch 428/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0655 - val_loss: 0.0726\n",
      "Epoch 429/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0656 - val_loss: 0.0726\n",
      "Epoch 430/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0656 - val_loss: 0.0725\n",
      "Epoch 431/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0655 - val_loss: 0.0728\n",
      "Epoch 432/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0656 - val_loss: 0.0726\n",
      "Epoch 433/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0656 - val_loss: 0.0725\n",
      "Epoch 434/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0654 - val_loss: 0.0724\n",
      "Epoch 435/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0653 - val_loss: 0.0729\n",
      "Epoch 436/1500\n",
      "603/603 [==============================] - 0s 585us/step - loss: 0.0654 - val_loss: 0.0731\n",
      "Epoch 437/1500\n",
      "603/603 [==============================] - 1s 839us/step - loss: 0.0655 - val_loss: 0.0730\n",
      "Epoch 438/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0654 - val_loss: 0.0730\n",
      "Epoch 439/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0653 - val_loss: 0.0732\n",
      "Epoch 440/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0654 - val_loss: 0.0728\n",
      "Epoch 441/1500\n",
      "603/603 [==============================] - 0s 710us/step - loss: 0.0655 - val_loss: 0.0727\n",
      "Epoch 442/1500\n",
      "603/603 [==============================] - 0s 814us/step - loss: 0.0653 - val_loss: 0.0728\n",
      "Epoch 443/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0654 - val_loss: 0.0726\n",
      "Epoch 444/1500\n",
      "603/603 [==============================] - 1s 980us/step - loss: 0.0652 - val_loss: 0.0732\n",
      "Epoch 445/1500\n",
      "603/603 [==============================] - 1s 962us/step - loss: 0.0654 - val_loss: 0.0726\n",
      "Epoch 446/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0654 - val_loss: 0.0726\n",
      "Epoch 447/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0652 - val_loss: 0.0726\n",
      "Epoch 448/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0654 - val_loss: 0.0727\n",
      "Epoch 449/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0653 - val_loss: 0.0726\n",
      "Epoch 450/1500\n",
      "603/603 [==============================] - 1s 934us/step - loss: 0.0654 - val_loss: 0.0728\n",
      "Epoch 451/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0654 - val_loss: 0.0729\n",
      "Epoch 452/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0654 - val_loss: 0.0728\n",
      "Epoch 453/1500\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 0.0652 - val_loss: 0.0730\n",
      "Epoch 454/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0654 - val_loss: 0.0727\n",
      "Epoch 455/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0652 - val_loss: 0.0731\n",
      "Epoch 456/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0652 - val_loss: 0.0730\n",
      "Epoch 457/1500\n",
      "603/603 [==============================] - 0s 761us/step - loss: 0.0652 - val_loss: 0.0727\n",
      "Epoch 458/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0651 - val_loss: 0.0727\n",
      "Epoch 459/1500\n",
      "603/603 [==============================] - 0s 769us/step - loss: 0.0653 - val_loss: 0.0729\n",
      "Epoch 460/1500\n",
      "603/603 [==============================] - 1s 870us/step - loss: 0.0651 - val_loss: 0.0726\n",
      "Epoch 461/1500\n",
      "603/603 [==============================] - 1s 838us/step - loss: 0.0650 - val_loss: 0.0729\n",
      "Epoch 462/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0650 - val_loss: 0.0730- ETA: 0s - l\n",
      "Epoch 463/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0649 - val_loss: 0.0727\n",
      "Epoch 464/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0650 - val_loss: 0.0729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0649 - val_loss: 0.0731\n",
      "Epoch 466/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0650 - val_loss: 0.0728\n",
      "Epoch 467/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0651 - val_loss: 0.0729\n",
      "Epoch 468/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0650 - val_loss: 0.0730\n",
      "Epoch 469/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0653 - val_loss: 0.0729\n",
      "Epoch 470/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0649 - val_loss: 0.0729\n",
      "Epoch 471/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0650 - val_loss: 0.0731\n",
      "Epoch 472/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0650 - val_loss: 0.0726\n",
      "Epoch 473/1500\n",
      "603/603 [==============================] - 1s 940us/step - loss: 0.0650 - val_loss: 0.0731\n",
      "Epoch 474/1500\n",
      "603/603 [==============================] - 1s 843us/step - loss: 0.0648 - val_loss: 0.0728\n",
      "Epoch 475/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0647 - val_loss: 0.0731\n",
      "Epoch 476/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0650 - val_loss: 0.0729\n",
      "Epoch 477/1500\n",
      "603/603 [==============================] - 1s 848us/step - loss: 0.0649 - val_loss: 0.0727\n",
      "Epoch 478/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0648 - val_loss: 0.0732\n",
      "Epoch 479/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0649 - val_loss: 0.0729\n",
      "Epoch 480/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0647 - val_loss: 0.0727\n",
      "Epoch 481/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0649 - val_loss: 0.0732\n",
      "Epoch 482/1500\n",
      "603/603 [==============================] - 1s 936us/step - loss: 0.0648 - val_loss: 0.0729\n",
      "Epoch 483/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0648 - val_loss: 0.0729\n",
      "Epoch 484/1500\n",
      "603/603 [==============================] - 1s 999us/step - loss: 0.0649 - val_loss: 0.0732\n",
      "Epoch 485/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0647 - val_loss: 0.0729\n",
      "Epoch 486/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0647 - val_loss: 0.0728\n",
      "Epoch 487/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0647 - val_loss: 0.0729\n",
      "Epoch 488/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0649 - val_loss: 0.0731\n",
      "Epoch 489/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0647 - val_loss: 0.0730\n",
      "Epoch 490/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0648 - val_loss: 0.0730\n",
      "Epoch 491/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0648 - val_loss: 0.0732\n",
      "Epoch 492/1500\n",
      "603/603 [==============================] - 0s 770us/step - loss: 0.0648 - val_loss: 0.0730\n",
      "Epoch 493/1500\n",
      "603/603 [==============================] - 0s 759us/step - loss: 0.0646 - val_loss: 0.0730\n",
      "Epoch 494/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0647 - val_loss: 0.0729\n",
      "Epoch 495/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0646 - val_loss: 0.0732\n",
      "Epoch 496/1500\n",
      "603/603 [==============================] - 0s 802us/step - loss: 0.0646 - val_loss: 0.0731\n",
      "Epoch 497/1500\n",
      "603/603 [==============================] - 1s 961us/step - loss: 0.0646 - val_loss: 0.0732\n",
      "Epoch 498/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0646 - val_loss: 0.0732\n",
      "Epoch 499/1500\n",
      "603/603 [==============================] - 1s 871us/step - loss: 0.0647 - val_loss: 0.0731\n",
      "Epoch 500/1500\n",
      "603/603 [==============================] - 0s 797us/step - loss: 0.0645 - val_loss: 0.0730\n",
      "Epoch 501/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0644 - val_loss: 0.0730\n",
      "Epoch 502/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0645 - val_loss: 0.0732\n",
      "Epoch 503/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0644 - val_loss: 0.0732\n",
      "Epoch 504/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0645 - val_loss: 0.0729\n",
      "Epoch 505/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0644 - val_loss: 0.0732\n",
      "Epoch 506/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0644 - val_loss: 0.0731\n",
      "Epoch 507/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0645 - val_loss: 0.0732\n",
      "Epoch 508/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0646 - val_loss: 0.0732\n",
      "Epoch 509/1500\n",
      "603/603 [==============================] - 0s 814us/step - loss: 0.0646 - val_loss: 0.0733\n",
      "Epoch 510/1500\n",
      "603/603 [==============================] - 1s 841us/step - loss: 0.0645 - val_loss: 0.0730\n",
      "Epoch 511/1500\n",
      "603/603 [==============================] - 0s 623us/step - loss: 0.0645 - val_loss: 0.0729\n",
      "Epoch 512/1500\n",
      "603/603 [==============================] - 0s 677us/step - loss: 0.0643 - val_loss: 0.0730\n",
      "Epoch 513/1500\n",
      "603/603 [==============================] - 0s 603us/step - loss: 0.0643 - val_loss: 0.0732\n",
      "Epoch 514/1500\n",
      "603/603 [==============================] - 0s 770us/step - loss: 0.0643 - val_loss: 0.0734\n",
      "Epoch 515/1500\n",
      "603/603 [==============================] - 0s 732us/step - loss: 0.0643 - val_loss: 0.0729\n",
      "Epoch 516/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0642 - val_loss: 0.0733\n",
      "Epoch 517/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0642 - val_loss: 0.0732\n",
      "Epoch 518/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0642 - val_loss: 0.0733\n",
      "Epoch 519/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0642 - val_loss: 0.0737\n",
      "Epoch 520/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0643 - val_loss: 0.0732\n",
      "Epoch 521/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0641 - val_loss: 0.0735\n",
      "Epoch 522/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0642 - val_loss: 0.0731\n",
      "Epoch 523/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0642 - val_loss: 0.0733\n",
      "Epoch 524/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0642 - val_loss: 0.0733\n",
      "Epoch 525/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0643 - val_loss: 0.0733\n",
      "Epoch 526/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0642 - val_loss: 0.0733\n",
      "Epoch 527/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0641 - val_loss: 0.0733\n",
      "Epoch 528/1500\n",
      "603/603 [==============================] - 1s 907us/step - loss: 0.0641 - val_loss: 0.0731\n",
      "Epoch 529/1500\n",
      "603/603 [==============================] - 1s 993us/step - loss: 0.0642 - val_loss: 0.0734\n",
      "Epoch 530/1500\n",
      "603/603 [==============================] - 1s 897us/step - loss: 0.0643 - val_loss: 0.0732\n",
      "Epoch 531/1500\n",
      "603/603 [==============================] - 1s 841us/step - loss: 0.0642 - val_loss: 0.0729\n",
      "Epoch 532/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0640 - val_loss: 0.0733\n",
      "Epoch 533/1500\n",
      "603/603 [==============================] - 1s 926us/step - loss: 0.0642 - val_loss: 0.0733\n",
      "Epoch 534/1500\n",
      "603/603 [==============================] - 0s 824us/step - loss: 0.0641 - val_loss: 0.0734\n",
      "Epoch 535/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0640 - val_loss: 0.0733\n",
      "Epoch 536/1500\n",
      "603/603 [==============================] - 1s 984us/step - loss: 0.0640 - val_loss: 0.0736\n",
      "Epoch 537/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0642 - val_loss: 0.0734\n",
      "Epoch 538/1500\n",
      "603/603 [==============================] - 0s 824us/step - loss: 0.0640 - val_loss: 0.0733\n",
      "Epoch 539/1500\n",
      "603/603 [==============================] - 0s 709us/step - loss: 0.0639 - val_loss: 0.0733\n",
      "Epoch 540/1500\n",
      "603/603 [==============================] - 0s 788us/step - loss: 0.0639 - val_loss: 0.0732\n",
      "Epoch 541/1500\n",
      "603/603 [==============================] - 0s 803us/step - loss: 0.0639 - val_loss: 0.0733\n",
      "Epoch 542/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0640 - val_loss: 0.0734\n",
      "Epoch 543/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 1s 852us/step - loss: 0.0640 - val_loss: 0.0733\n",
      "Epoch 544/1500\n",
      "603/603 [==============================] - 1s 832us/step - loss: 0.0639 - val_loss: 0.0734\n",
      "Epoch 545/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0639 - val_loss: 0.0734\n",
      "Epoch 546/1500\n",
      "603/603 [==============================] - 1s 890us/step - loss: 0.0639 - val_loss: 0.0731\n",
      "Epoch 547/1500\n",
      "603/603 [==============================] - 1s 965us/step - loss: 0.0638 - val_loss: 0.0737\n",
      "Epoch 548/1500\n",
      "603/603 [==============================] - 0s 764us/step - loss: 0.0640 - val_loss: 0.0731\n",
      "Epoch 549/1500\n",
      "603/603 [==============================] - 1s 895us/step - loss: 0.0637 - val_loss: 0.0737\n",
      "Epoch 550/1500\n",
      "603/603 [==============================] - 1s 926us/step - loss: 0.0638 - val_loss: 0.0735\n",
      "Epoch 551/1500\n",
      "603/603 [==============================] - 0s 774us/step - loss: 0.0638 - val_loss: 0.0736\n",
      "Epoch 552/1500\n",
      "603/603 [==============================] - 1s 948us/step - loss: 0.0638 - val_loss: 0.0733\n",
      "Epoch 553/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0638 - val_loss: 0.0735\n",
      "Epoch 554/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0638 - val_loss: 0.0736\n",
      "Epoch 555/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0637 - val_loss: 0.0733\n",
      "Epoch 556/1500\n",
      "603/603 [==============================] - 1s 985us/step - loss: 0.0636 - val_loss: 0.0735\n",
      "Epoch 557/1500\n",
      "603/603 [==============================] - 1s 893us/step - loss: 0.0637 - val_loss: 0.0735\n",
      "Epoch 558/1500\n",
      "603/603 [==============================] - 0s 753us/step - loss: 0.0636 - val_loss: 0.0733\n",
      "Epoch 559/1500\n",
      "603/603 [==============================] - 0s 702us/step - loss: 0.0637 - val_loss: 0.0733\n",
      "Epoch 560/1500\n",
      "603/603 [==============================] - 0s 758us/step - loss: 0.0637 - val_loss: 0.0735\n",
      "Epoch 561/1500\n",
      "603/603 [==============================] - 1s 876us/step - loss: 0.0636 - val_loss: 0.0734\n",
      "Epoch 562/1500\n",
      "603/603 [==============================] - 0s 806us/step - loss: 0.0636 - val_loss: 0.0736\n",
      "Epoch 563/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0637 - val_loss: 0.0737\n",
      "Epoch 564/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0635 - val_loss: 0.0731\n",
      "Epoch 565/1500\n",
      "603/603 [==============================] - 0s 773us/step - loss: 0.0635 - val_loss: 0.0737\n",
      "Epoch 566/1500\n",
      "603/603 [==============================] - 1s 839us/step - loss: 0.0636 - val_loss: 0.0734\n",
      "Epoch 567/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0637 - val_loss: 0.0736\n",
      "Epoch 568/1500\n",
      "603/603 [==============================] - 0s 799us/step - loss: 0.0635 - val_loss: 0.0732\n",
      "Epoch 569/1500\n",
      "603/603 [==============================] - 1s 864us/step - loss: 0.0636 - val_loss: 0.0735\n",
      "Epoch 570/1500\n",
      "603/603 [==============================] - 0s 743us/step - loss: 0.0635 - val_loss: 0.0739\n",
      "Epoch 571/1500\n",
      "603/603 [==============================] - 1s 967us/step - loss: 0.0636 - val_loss: 0.0734\n",
      "Epoch 572/1500\n",
      "603/603 [==============================] - 1s 871us/step - loss: 0.0635 - val_loss: 0.0735\n",
      "Epoch 573/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0634 - val_loss: 0.0736\n",
      "Epoch 574/1500\n",
      "603/603 [==============================] - 0s 732us/step - loss: 0.0635 - val_loss: 0.0736\n",
      "Epoch 575/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0634 - val_loss: 0.0734\n",
      "Epoch 576/1500\n",
      "603/603 [==============================] - 1s 841us/step - loss: 0.0639 - val_loss: 0.0737\n",
      "Epoch 577/1500\n",
      "603/603 [==============================] - 0s 817us/step - loss: 0.0634 - val_loss: 0.0737\n",
      "Epoch 578/1500\n",
      "603/603 [==============================] - 1s 846us/step - loss: 0.0634 - val_loss: 0.0735\n",
      "Epoch 579/1500\n",
      "603/603 [==============================] - 1s 863us/step - loss: 0.0633 - val_loss: 0.0735\n",
      "Epoch 580/1500\n",
      "603/603 [==============================] - 0s 735us/step - loss: 0.0634 - val_loss: 0.0737\n",
      "Epoch 581/1500\n",
      "603/603 [==============================] - 1s 956us/step - loss: 0.0634 - val_loss: 0.0735\n",
      "Epoch 582/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0634 - val_loss: 0.0736\n",
      "Epoch 583/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0633 - val_loss: 0.0733\n",
      "Epoch 584/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0633 - val_loss: 0.0734\n",
      "Epoch 585/1500\n",
      "603/603 [==============================] - 0s 815us/step - loss: 0.0634 - val_loss: 0.0736\n",
      "Epoch 586/1500\n",
      "603/603 [==============================] - 0s 824us/step - loss: 0.0633 - val_loss: 0.0733\n",
      "Epoch 587/1500\n",
      "603/603 [==============================] - 0s 746us/step - loss: 0.0632 - val_loss: 0.0736\n",
      "Epoch 588/1500\n",
      "603/603 [==============================] - 1s 944us/step - loss: 0.0632 - val_loss: 0.0740\n",
      "Epoch 589/1500\n",
      "603/603 [==============================] - 1s 930us/step - loss: 0.0633 - val_loss: 0.0739\n",
      "Epoch 590/1500\n",
      "603/603 [==============================] - 1s 879us/step - loss: 0.0633 - val_loss: 0.0737\n",
      "Epoch 591/1500\n",
      "603/603 [==============================] - 1s 875us/step - loss: 0.0632 - val_loss: 0.0735\n",
      "Epoch 592/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0633 - val_loss: 0.0736\n",
      "Epoch 593/1500\n",
      "603/603 [==============================] - 1s 860us/step - loss: 0.0630 - val_loss: 0.0735\n",
      "Epoch 594/1500\n",
      "603/603 [==============================] - 0s 813us/step - loss: 0.0631 - val_loss: 0.0737\n",
      "Epoch 595/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0632 - val_loss: 0.0735\n",
      "Epoch 596/1500\n",
      "603/603 [==============================] - 1s 898us/step - loss: 0.0631 - val_loss: 0.0737\n",
      "Epoch 597/1500\n",
      "603/603 [==============================] - 0s 749us/step - loss: 0.0632 - val_loss: 0.0738\n",
      "Epoch 598/1500\n",
      "603/603 [==============================] - 0s 793us/step - loss: 0.0630 - val_loss: 0.0738\n",
      "Epoch 599/1500\n",
      "603/603 [==============================] - 0s 756us/step - loss: 0.0631 - val_loss: 0.0739\n",
      "Epoch 600/1500\n",
      "603/603 [==============================] - 0s 799us/step - loss: 0.0631 - val_loss: 0.0737\n",
      "Epoch 601/1500\n",
      "603/603 [==============================] - 1s 905us/step - loss: 0.0631 - val_loss: 0.0735\n",
      "Epoch 602/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0630 - val_loss: 0.0739\n",
      "Epoch 603/1500\n",
      "603/603 [==============================] - 1s 914us/step - loss: 0.0630 - val_loss: 0.0738\n",
      "Epoch 604/1500\n",
      "603/603 [==============================] - 0s 732us/step - loss: 0.0630 - val_loss: 0.0737\n",
      "Epoch 605/1500\n",
      "603/603 [==============================] - 1s 968us/step - loss: 0.0630 - val_loss: 0.0738\n",
      "Epoch 606/1500\n",
      "603/603 [==============================] - 0s 674us/step - loss: 0.0631 - val_loss: 0.0740\n",
      "Epoch 607/1500\n",
      "603/603 [==============================] - 0s 790us/step - loss: 0.0630 - val_loss: 0.0736\n",
      "Epoch 608/1500\n",
      "603/603 [==============================] - 0s 777us/step - loss: 0.0630 - val_loss: 0.0734\n",
      "Epoch 609/1500\n",
      "603/603 [==============================] - 0s 748us/step - loss: 0.0629 - val_loss: 0.0734\n",
      "Epoch 610/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0628 - val_loss: 0.0741\n",
      "Epoch 611/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0628 - val_loss: 0.0736\n",
      "Epoch 612/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0630 - val_loss: 0.0738\n",
      "Epoch 613/1500\n",
      "603/603 [==============================] - 0s 760us/step - loss: 0.0630 - val_loss: 0.0738\n",
      "Epoch 614/1500\n",
      "603/603 [==============================] - 0s 762us/step - loss: 0.0629 - val_loss: 0.0740\n",
      "Epoch 615/1500\n",
      "603/603 [==============================] - 1s 850us/step - loss: 0.0629 - val_loss: 0.0740\n",
      "Epoch 616/1500\n",
      "603/603 [==============================] - 0s 797us/step - loss: 0.0628 - val_loss: 0.0739\n",
      "Epoch 617/1500\n",
      "603/603 [==============================] - 0s 817us/step - loss: 0.0630 - val_loss: 0.0738\n",
      "Epoch 618/1500\n",
      "603/603 [==============================] - 0s 793us/step - loss: 0.0629 - val_loss: 0.0738\n",
      "Epoch 619/1500\n",
      "603/603 [==============================] - 0s 753us/step - loss: 0.0629 - val_loss: 0.0741\n",
      "Epoch 620/1500\n",
      "603/603 [==============================] - 1s 866us/step - loss: 0.0627 - val_loss: 0.0736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 621/1500\n",
      "603/603 [==============================] - 0s 689us/step - loss: 0.0627 - val_loss: 0.0736\n",
      "Epoch 622/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0627 - val_loss: 0.0740\n",
      "Epoch 623/1500\n",
      "603/603 [==============================] - 0s 693us/step - loss: 0.0628 - val_loss: 0.0736\n",
      "Epoch 624/1500\n",
      "603/603 [==============================] - 0s 713us/step - loss: 0.0627 - val_loss: 0.0740\n",
      "Epoch 625/1500\n",
      "603/603 [==============================] - 0s 768us/step - loss: 0.0628 - val_loss: 0.0737\n",
      "Epoch 626/1500\n",
      "603/603 [==============================] - 0s 774us/step - loss: 0.0627 - val_loss: 0.0737\n",
      "Epoch 627/1500\n",
      "603/603 [==============================] - 0s 672us/step - loss: 0.0627 - val_loss: 0.0739\n",
      "Epoch 628/1500\n",
      "603/603 [==============================] - 0s 663us/step - loss: 0.0627 - val_loss: 0.0737\n",
      "Epoch 629/1500\n",
      "603/603 [==============================] - 0s 694us/step - loss: 0.0627 - val_loss: 0.0741\n",
      "Epoch 630/1500\n",
      "603/603 [==============================] - 0s 727us/step - loss: 0.0626 - val_loss: 0.0738\n",
      "Epoch 631/1500\n",
      "603/603 [==============================] - 0s 793us/step - loss: 0.0626 - val_loss: 0.0740\n",
      "Epoch 632/1500\n",
      "603/603 [==============================] - 1s 879us/step - loss: 0.0625 - val_loss: 0.0739\n",
      "Epoch 633/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0625 - val_loss: 0.0741\n",
      "Epoch 634/1500\n",
      "603/603 [==============================] - 0s 782us/step - loss: 0.0625 - val_loss: 0.0741\n",
      "Epoch 635/1500\n",
      "603/603 [==============================] - 0s 717us/step - loss: 0.0626 - val_loss: 0.0744\n",
      "Epoch 636/1500\n",
      "603/603 [==============================] - 0s 798us/step - loss: 0.0626 - val_loss: 0.0741\n",
      "Epoch 637/1500\n",
      "603/603 [==============================] - 0s 668us/step - loss: 0.0626 - val_loss: 0.0738\n",
      "Epoch 638/1500\n",
      "603/603 [==============================] - 0s 764us/step - loss: 0.0626 - val_loss: 0.0737\n",
      "Epoch 639/1500\n",
      "603/603 [==============================] - 0s 806us/step - loss: 0.0625 - val_loss: 0.0739\n",
      "Epoch 640/1500\n",
      "603/603 [==============================] - 0s 713us/step - loss: 0.0625 - val_loss: 0.0739\n",
      "Epoch 641/1500\n",
      "603/603 [==============================] - 0s 712us/step - loss: 0.0625 - val_loss: 0.0740\n",
      "Epoch 642/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0624 - val_loss: 0.0738\n",
      "Epoch 643/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0623 - val_loss: 0.0739\n",
      "Epoch 644/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0624 - val_loss: 0.0742\n",
      "Epoch 645/1500\n",
      "603/603 [==============================] - 0s 758us/step - loss: 0.0624 - val_loss: 0.0739\n",
      "Epoch 646/1500\n",
      "603/603 [==============================] - 0s 712us/step - loss: 0.0623 - val_loss: 0.0741\n",
      "Epoch 647/1500\n",
      "603/603 [==============================] - 1s 843us/step - loss: 0.0624 - val_loss: 0.0740\n",
      "Epoch 648/1500\n",
      "603/603 [==============================] - 1s 973us/step - loss: 0.0625 - val_loss: 0.0739\n",
      "Epoch 649/1500\n",
      "603/603 [==============================] - 0s 692us/step - loss: 0.0624 - val_loss: 0.0742\n",
      "Epoch 650/1500\n",
      "603/603 [==============================] - 0s 804us/step - loss: 0.0624 - val_loss: 0.0740\n",
      "Epoch 651/1500\n",
      "603/603 [==============================] - 0s 766us/step - loss: 0.0623 - val_loss: 0.0738\n",
      "Epoch 652/1500\n",
      "603/603 [==============================] - 0s 639us/step - loss: 0.0624 - val_loss: 0.0740\n",
      "Epoch 653/1500\n",
      "603/603 [==============================] - 0s 687us/step - loss: 0.0623 - val_loss: 0.0739\n",
      "Epoch 654/1500\n",
      "603/603 [==============================] - 1s 969us/step - loss: 0.0622 - val_loss: 0.0742\n",
      "Epoch 655/1500\n",
      "603/603 [==============================] - 0s 763us/step - loss: 0.0624 - val_loss: 0.0738\n",
      "Epoch 656/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0623 - val_loss: 0.0741\n",
      "Epoch 657/1500\n",
      "603/603 [==============================] - 0s 816us/step - loss: 0.0622 - val_loss: 0.0740\n",
      "Epoch 658/1500\n",
      "603/603 [==============================] - 0s 819us/step - loss: 0.0622 - val_loss: 0.0742\n",
      "Epoch 659/1500\n",
      "603/603 [==============================] - 0s 713us/step - loss: 0.0621 - val_loss: 0.0742\n",
      "Epoch 660/1500\n",
      "603/603 [==============================] - 0s 704us/step - loss: 0.0622 - val_loss: 0.0741\n",
      "Epoch 661/1500\n",
      "603/603 [==============================] - 0s 731us/step - loss: 0.0620 - val_loss: 0.0740\n",
      "Epoch 662/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0621 - val_loss: 0.0742\n",
      "Epoch 663/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0621 - val_loss: 0.0737\n",
      "Epoch 664/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0622 - val_loss: 0.0739\n",
      "Epoch 665/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0622 - val_loss: 0.0739\n",
      "Epoch 666/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0621 - val_loss: 0.0739 - ETA: 0s - lo\n",
      "Epoch 667/1500\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 0.0620 - val_loss: 0.0740 -\n",
      "Epoch 668/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0622 - val_loss: 0.0741\n",
      "Epoch 669/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0620 - val_loss: 0.0741\n",
      "Epoch 670/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0620 - val_loss: 0.0739\n",
      "Epoch 671/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0620 - val_loss: 0.0739\n",
      "Epoch 672/1500\n",
      "603/603 [==============================] - 1s 868us/step - loss: 0.0620 - val_loss: 0.0740\n",
      "Epoch 673/1500\n",
      "603/603 [==============================] - 1s 960us/step - loss: 0.0620 - val_loss: 0.0742\n",
      "Epoch 674/1500\n",
      "603/603 [==============================] - 0s 822us/step - loss: 0.0620 - val_loss: 0.0743\n",
      "Epoch 675/1500\n",
      "603/603 [==============================] - 0s 783us/step - loss: 0.0620 - val_loss: 0.0744\n",
      "Epoch 676/1500\n",
      "603/603 [==============================] - 1s 854us/step - loss: 0.0621 - val_loss: 0.0740\n",
      "Epoch 677/1500\n",
      "603/603 [==============================] - 0s 796us/step - loss: 0.0619 - val_loss: 0.0739\n",
      "Epoch 678/1500\n",
      "603/603 [==============================] - 0s 642us/step - loss: 0.0618 - val_loss: 0.0742\n",
      "Epoch 679/1500\n",
      "603/603 [==============================] - 0s 732us/step - loss: 0.0620 - val_loss: 0.0740\n",
      "Epoch 680/1500\n",
      "603/603 [==============================] - 0s 716us/step - loss: 0.0620 - val_loss: 0.0740\n",
      "Epoch 681/1500\n",
      "603/603 [==============================] - 0s 803us/step - loss: 0.0618 - val_loss: 0.0744\n",
      "Epoch 682/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0619 - val_loss: 0.0743\n",
      "Epoch 683/1500\n",
      "603/603 [==============================] - 0s 692us/step - loss: 0.0618 - val_loss: 0.0744\n",
      "Epoch 684/1500\n",
      "603/603 [==============================] - 0s 751us/step - loss: 0.0621 - val_loss: 0.0739\n",
      "Epoch 685/1500\n",
      "603/603 [==============================] - 0s 718us/step - loss: 0.0619 - val_loss: 0.0741\n",
      "Epoch 686/1500\n",
      "603/603 [==============================] - 0s 686us/step - loss: 0.0616 - val_loss: 0.0743\n",
      "Epoch 687/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0619 - val_loss: 0.0740\n",
      "Epoch 688/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0619 - val_loss: 0.0745\n",
      "Epoch 689/1500\n",
      "603/603 [==============================] - 0s 807us/step - loss: 0.0618 - val_loss: 0.0744\n",
      "Epoch 690/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0617 - val_loss: 0.0740\n",
      "Epoch 691/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0616 - val_loss: 0.0741\n",
      "Epoch 692/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0616 - val_loss: 0.0741\n",
      "Epoch 693/1500\n",
      "603/603 [==============================] - 0s 688us/step - loss: 0.0617 - val_loss: 0.0742\n",
      "Epoch 694/1500\n",
      "603/603 [==============================] - 0s 697us/step - loss: 0.0617 - val_loss: 0.0742\n",
      "Epoch 695/1500\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.061 - 0s 682us/step - loss: 0.0617 - val_loss: 0.0740\n",
      "Epoch 696/1500\n",
      "603/603 [==============================] - 0s 642us/step - loss: 0.0617 - val_loss: 0.0745\n",
      "Epoch 697/1500\n",
      "603/603 [==============================] - 0s 714us/step - loss: 0.0616 - val_loss: 0.0738\n",
      "Epoch 698/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 803us/step - loss: 0.0617 - val_loss: 0.0741\n",
      "Epoch 699/1500\n",
      "603/603 [==============================] - 0s 735us/step - loss: 0.0616 - val_loss: 0.0743\n",
      "Epoch 700/1500\n",
      "603/603 [==============================] - 1s 853us/step - loss: 0.0617 - val_loss: 0.0740\n",
      "Epoch 701/1500\n",
      "603/603 [==============================] - 0s 810us/step - loss: 0.0616 - val_loss: 0.0741\n",
      "Epoch 702/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0617 - val_loss: 0.0744\n",
      "Epoch 703/1500\n",
      "603/603 [==============================] - 0s 782us/step - loss: 0.0615 - val_loss: 0.0739\n",
      "Epoch 704/1500\n",
      "603/603 [==============================] - 0s 699us/step - loss: 0.0615 - val_loss: 0.0741\n",
      "Epoch 705/1500\n",
      "603/603 [==============================] - 0s 696us/step - loss: 0.0615 - val_loss: 0.0740\n",
      "Epoch 706/1500\n",
      "603/603 [==============================] - 1s 855us/step - loss: 0.0615 - val_loss: 0.0741\n",
      "Epoch 707/1500\n",
      "603/603 [==============================] - 0s 710us/step - loss: 0.0615 - val_loss: 0.0741\n",
      "Epoch 708/1500\n",
      "603/603 [==============================] - 1s 842us/step - loss: 0.0614 - val_loss: 0.0743\n",
      "Epoch 709/1500\n",
      "603/603 [==============================] - 1s 836us/step - loss: 0.0615 - val_loss: 0.0742\n",
      "Epoch 710/1500\n",
      "603/603 [==============================] - 0s 735us/step - loss: 0.0614 - val_loss: 0.0746\n",
      "Epoch 711/1500\n",
      "603/603 [==============================] - 0s 788us/step - loss: 0.0615 - val_loss: 0.0740\n",
      "Epoch 712/1500\n",
      "603/603 [==============================] - 0s 791us/step - loss: 0.0614 - val_loss: 0.0746\n",
      "Epoch 713/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0615 - val_loss: 0.0741\n",
      "Epoch 714/1500\n",
      "603/603 [==============================] - 1s 925us/step - loss: 0.0614 - val_loss: 0.0742\n",
      "Epoch 715/1500\n",
      "603/603 [==============================] - 0s 782us/step - loss: 0.0616 - val_loss: 0.0740\n",
      "Epoch 716/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0613 - val_loss: 0.0745\n",
      "Epoch 717/1500\n",
      "603/603 [==============================] - 0s 641us/step - loss: 0.0615 - val_loss: 0.0745\n",
      "Epoch 718/1500\n",
      "603/603 [==============================] - 0s 747us/step - loss: 0.0615 - val_loss: 0.0743\n",
      "Epoch 719/1500\n",
      "603/603 [==============================] - 0s 711us/step - loss: 0.0614 - val_loss: 0.0743\n",
      "Epoch 720/1500\n",
      "603/603 [==============================] - 1s 871us/step - loss: 0.0617 - val_loss: 0.0746\n",
      "Epoch 721/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0613 - val_loss: 0.0743\n",
      "Epoch 722/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0613 - val_loss: 0.0745\n",
      "Epoch 723/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0614 - val_loss: 0.0744\n",
      "Epoch 724/1500\n",
      "603/603 [==============================] - 0s 791us/step - loss: 0.0615 - val_loss: 0.0743\n",
      "Epoch 725/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0613 - val_loss: 0.0744\n",
      "Epoch 726/1500\n",
      "603/603 [==============================] - 0s 750us/step - loss: 0.0612 - val_loss: 0.0747\n",
      "Epoch 727/1500\n",
      "603/603 [==============================] - 1s 921us/step - loss: 0.0613 - val_loss: 0.0745\n",
      "Epoch 728/1500\n",
      "603/603 [==============================] - 0s 700us/step - loss: 0.0612 - val_loss: 0.0746\n",
      "Epoch 729/1500\n",
      "603/603 [==============================] - 0s 791us/step - loss: 0.0612 - val_loss: 0.0742\n",
      "Epoch 730/1500\n",
      "603/603 [==============================] - 1s 926us/step - loss: 0.0612 - val_loss: 0.0741\n",
      "Epoch 731/1500\n",
      "603/603 [==============================] - 1s 903us/step - loss: 0.0613 - val_loss: 0.0745\n",
      "Epoch 732/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0611 - val_loss: 0.0746\n",
      "Epoch 733/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0611 - val_loss: 0.0742\n",
      "Epoch 734/1500\n",
      "603/603 [==============================] - 1s 884us/step - loss: 0.0611 - val_loss: 0.0744\n",
      "Epoch 735/1500\n",
      "603/603 [==============================] - 1s 853us/step - loss: 0.0610 - val_loss: 0.0744\n",
      "Epoch 736/1500\n",
      "603/603 [==============================] - 0s 724us/step - loss: 0.0610 - val_loss: 0.0745\n",
      "Epoch 737/1500\n",
      "603/603 [==============================] - 1s 830us/step - loss: 0.0610 - val_loss: 0.0748\n",
      "Epoch 738/1500\n",
      "603/603 [==============================] - 0s 758us/step - loss: 0.0610 - val_loss: 0.0742\n",
      "Epoch 739/1500\n",
      "603/603 [==============================] - 0s 729us/step - loss: 0.0610 - val_loss: 0.0744\n",
      "Epoch 740/1500\n",
      "603/603 [==============================] - 0s 778us/step - loss: 0.0612 - val_loss: 0.0748\n",
      "Epoch 741/1500\n",
      "603/603 [==============================] - 0s 768us/step - loss: 0.0611 - val_loss: 0.0748\n",
      "Epoch 742/1500\n",
      "603/603 [==============================] - 0s 817us/step - loss: 0.0609 - val_loss: 0.0748\n",
      "Epoch 743/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0611 - val_loss: 0.0743\n",
      "Epoch 744/1500\n",
      "603/603 [==============================] - 0s 698us/step - loss: 0.0609 - val_loss: 0.0743\n",
      "Epoch 745/1500\n",
      "603/603 [==============================] - 0s 777us/step - loss: 0.0609 - val_loss: 0.0749\n",
      "Epoch 746/1500\n",
      "603/603 [==============================] - 0s 739us/step - loss: 0.0610 - val_loss: 0.0746\n",
      "Epoch 747/1500\n",
      "603/603 [==============================] - 0s 717us/step - loss: 0.0609 - val_loss: 0.0745\n",
      "Epoch 748/1500\n",
      "603/603 [==============================] - 0s 656us/step - loss: 0.0609 - val_loss: 0.0748\n",
      "Epoch 749/1500\n",
      "603/603 [==============================] - 0s 748us/step - loss: 0.0609 - val_loss: 0.0745\n",
      "Epoch 750/1500\n",
      "603/603 [==============================] - 0s 667us/step - loss: 0.0609 - val_loss: 0.0743\n",
      "Epoch 751/1500\n",
      "603/603 [==============================] - 0s 792us/step - loss: 0.0608 - val_loss: 0.0746\n",
      "Epoch 752/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0610 - val_loss: 0.0746\n",
      "Epoch 753/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0609 - val_loss: 0.0743\n",
      "Epoch 754/1500\n",
      "603/603 [==============================] - 1s 953us/step - loss: 0.0609 - val_loss: 0.0751\n",
      "Epoch 755/1500\n",
      "603/603 [==============================] - 0s 568us/step - loss: 0.0608 - val_loss: 0.0747\n",
      "Epoch 756/1500\n",
      "603/603 [==============================] - 0s 798us/step - loss: 0.0608 - val_loss: 0.0745\n",
      "Epoch 757/1500\n",
      "603/603 [==============================] - 0s 805us/step - loss: 0.0608 - val_loss: 0.0747\n",
      "Epoch 758/1500\n",
      "603/603 [==============================] - 0s 595us/step - loss: 0.0608 - val_loss: 0.0748\n",
      "Epoch 759/1500\n",
      "603/603 [==============================] - 0s 747us/step - loss: 0.0609 - val_loss: 0.0749\n",
      "Epoch 760/1500\n",
      "603/603 [==============================] - 0s 752us/step - loss: 0.0609 - val_loss: 0.0745\n",
      "Epoch 761/1500\n",
      "603/603 [==============================] - 0s 730us/step - loss: 0.0608 - val_loss: 0.0745\n",
      "Epoch 762/1500\n",
      "603/603 [==============================] - 0s 603us/step - loss: 0.0608 - val_loss: 0.0748\n",
      "Epoch 763/1500\n",
      "603/603 [==============================] - 0s 676us/step - loss: 0.0608 - val_loss: 0.0749\n",
      "Epoch 764/1500\n",
      "603/603 [==============================] - 0s 680us/step - loss: 0.0610 - val_loss: 0.0746\n",
      "Epoch 765/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0608 - val_loss: 0.0746\n",
      "Epoch 766/1500\n",
      "603/603 [==============================] - 1s 829us/step - loss: 0.0607 - val_loss: 0.0746\n",
      "Epoch 767/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0608 - val_loss: 0.0750\n",
      "Epoch 768/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0607 - val_loss: 0.0748\n",
      "Epoch 769/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0606 - val_loss: 0.0746\n",
      "Epoch 770/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0606 - val_loss: 0.0745\n",
      "Epoch 771/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0607 - val_loss: 0.0745\n",
      "Epoch 772/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0607 - val_loss: 0.0746\n",
      "Epoch 773/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0607 - val_loss: 0.0745\n",
      "Epoch 774/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0605 - val_loss: 0.0748\n",
      "Epoch 775/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0605 - val_loss: 0.0746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 776/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0606 - val_loss: 0.0746\n",
      "Epoch 777/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0606 - val_loss: 0.0747\n",
      "Epoch 778/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0607 - val_loss: 0.0745\n",
      "Epoch 779/1500\n",
      "603/603 [==============================] - 1s 911us/step - loss: 0.0607 - val_loss: 0.0747\n",
      "Epoch 780/1500\n",
      "603/603 [==============================] - 0s 713us/step - loss: 0.0606 - val_loss: 0.0745\n",
      "Epoch 781/1500\n",
      "603/603 [==============================] - 0s 714us/step - loss: 0.0606 - val_loss: 0.0748\n",
      "Epoch 782/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0606 - val_loss: 0.0747\n",
      "Epoch 783/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0604 - val_loss: 0.0743\n",
      "Epoch 784/1500\n",
      "603/603 [==============================] - 1s 953us/step - loss: 0.0603 - val_loss: 0.0747\n",
      "Epoch 785/1500\n",
      "603/603 [==============================] - 0s 720us/step - loss: 0.0603 - val_loss: 0.0745\n",
      "Epoch 786/1500\n",
      "603/603 [==============================] - 0s 675us/step - loss: 0.0603 - val_loss: 0.0747\n",
      "Epoch 787/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0604 - val_loss: 0.0747\n",
      "Epoch 788/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0601 - val_loss: 0.0749\n",
      "Epoch 789/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0604 - val_loss: 0.0746\n",
      "Epoch 790/1500\n",
      "603/603 [==============================] - 1s 839us/step - loss: 0.0603 - val_loss: 0.0750\n",
      "Epoch 791/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0603 - val_loss: 0.0748\n",
      "Epoch 792/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0605 - val_loss: 0.0747\n",
      "Epoch 793/1500\n",
      "603/603 [==============================] - 0s 805us/step - loss: 0.0603 - val_loss: 0.0748\n",
      "Epoch 794/1500\n",
      "603/603 [==============================] - 0s 645us/step - loss: 0.0604 - val_loss: 0.0748\n",
      "Epoch 795/1500\n",
      "603/603 [==============================] - 1s 973us/step - loss: 0.0603 - val_loss: 0.0745\n",
      "Epoch 796/1500\n",
      "603/603 [==============================] - 1s 840us/step - loss: 0.0603 - val_loss: 0.0745\n",
      "Epoch 797/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0602 - val_loss: 0.0750\n",
      "Epoch 798/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0604 - val_loss: 0.0748\n",
      "Epoch 799/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0603 - val_loss: 0.0746\n",
      "Epoch 800/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0604 - val_loss: 0.0747\n",
      "Epoch 801/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0602 - val_loss: 0.0747\n",
      "Epoch 802/1500\n",
      "603/603 [==============================] - 1s 906us/step - loss: 0.0602 - val_loss: 0.0749\n",
      "Epoch 803/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0600 - val_loss: 0.0749\n",
      "Epoch 804/1500\n",
      "603/603 [==============================] - 0s 602us/step - loss: 0.0601 - val_loss: 0.0746\n",
      "Epoch 805/1500\n",
      "603/603 [==============================] - 1s 878us/step - loss: 0.0601 - val_loss: 0.0748\n",
      "Epoch 806/1500\n",
      "603/603 [==============================] - 1s 985us/step - loss: 0.0602 - val_loss: 0.0744\n",
      "Epoch 807/1500\n",
      "603/603 [==============================] - 1s 938us/step - loss: 0.0602 - val_loss: 0.0747\n",
      "Epoch 808/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0602 - val_loss: 0.0749\n",
      "Epoch 809/1500\n",
      "603/603 [==============================] - 1s 859us/step - loss: 0.0600 - val_loss: 0.0747\n",
      "Epoch 810/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0600 - val_loss: 0.0749\n",
      "Epoch 811/1500\n",
      "603/603 [==============================] - 0s 815us/step - loss: 0.0600 - val_loss: 0.0747\n",
      "Epoch 812/1500\n",
      "603/603 [==============================] - 0s 665us/step - loss: 0.0600 - val_loss: 0.0749\n",
      "Epoch 813/1500\n",
      "603/603 [==============================] - 0s 640us/step - loss: 0.0600 - val_loss: 0.0749\n",
      "Epoch 814/1500\n",
      "603/603 [==============================] - 0s 720us/step - loss: 0.0601 - val_loss: 0.0748\n",
      "Epoch 815/1500\n",
      "603/603 [==============================] - 1s 894us/step - loss: 0.0601 - val_loss: 0.0752\n",
      "Epoch 816/1500\n",
      "603/603 [==============================] - 0s 820us/step - loss: 0.0600 - val_loss: 0.0751\n",
      "Epoch 817/1500\n",
      "603/603 [==============================] - 1s 933us/step - loss: 0.0601 - val_loss: 0.0745\n",
      "Epoch 818/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0601 - val_loss: 0.0748\n",
      "Epoch 819/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0600 - val_loss: 0.0749\n",
      "Epoch 820/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0599 - val_loss: 0.0748\n",
      "Epoch 821/1500\n",
      "603/603 [==============================] - 1s 873us/step - loss: 0.0599 - val_loss: 0.0748\n",
      "Epoch 822/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0600 - val_loss: 0.0751\n",
      "Epoch 823/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0600 - val_loss: 0.0748\n",
      "Epoch 824/1500\n",
      "603/603 [==============================] - 1s 928us/step - loss: 0.0599 - val_loss: 0.0748\n",
      "Epoch 825/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0599 - val_loss: 0.0747\n",
      "Epoch 826/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0601 - val_loss: 0.0748\n",
      "Epoch 827/1500\n",
      "603/603 [==============================] - 0s 618us/step - loss: 0.0599 - val_loss: 0.0749\n",
      "Epoch 828/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0598 - val_loss: 0.0748\n",
      "Epoch 829/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0599 - val_loss: 0.0749\n",
      "Epoch 830/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0598 - val_loss: 0.0749\n",
      "Epoch 831/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0600 - val_loss: 0.0749\n",
      "Epoch 832/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0597 - val_loss: 0.0752\n",
      "Epoch 833/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0598 - val_loss: 0.0750\n",
      "Epoch 834/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0597 - val_loss: 0.0750\n",
      "Epoch 835/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0597 - val_loss: 0.0751\n",
      "Epoch 836/1500\n",
      "603/603 [==============================] - 0s 615us/step - loss: 0.0598 - val_loss: 0.0752\n",
      "Epoch 837/1500\n",
      "603/603 [==============================] - 0s 618us/step - loss: 0.0597 - val_loss: 0.0751\n",
      "Epoch 838/1500\n",
      "603/603 [==============================] - 0s 560us/step - loss: 0.0599 - val_loss: 0.0751\n",
      "Epoch 839/1500\n",
      "603/603 [==============================] - 0s 651us/step - loss: 0.0597 - val_loss: 0.0752\n",
      "Epoch 840/1500\n",
      "603/603 [==============================] - 0s 793us/step - loss: 0.0596 - val_loss: 0.0754\n",
      "Epoch 841/1500\n",
      "603/603 [==============================] - 1s 898us/step - loss: 0.0596 - val_loss: 0.0750\n",
      "Epoch 842/1500\n",
      "603/603 [==============================] - 1s 955us/step - loss: 0.0597 - val_loss: 0.0748\n",
      "Epoch 843/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0597 - val_loss: 0.0753\n",
      "Epoch 844/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0597 - val_loss: 0.0752\n",
      "Epoch 845/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0597 - val_loss: 0.0752\n",
      "Epoch 846/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0597 - val_loss: 0.0750\n",
      "Epoch 847/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0598 - val_loss: 0.0753\n",
      "Epoch 848/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0597 - val_loss: 0.0751\n",
      "Epoch 849/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0596 - val_loss: 0.0750\n",
      "Epoch 850/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0597 - val_loss: 0.0754\n",
      "Epoch 851/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0596 - val_loss: 0.0750\n",
      "Epoch 852/1500\n",
      "603/603 [==============================] - 0s 731us/step - loss: 0.0596 - val_loss: 0.0749\n",
      "Epoch 853/1500\n",
      "603/603 [==============================] - 1s 993us/step - loss: 0.0595 - val_loss: 0.0751\n",
      "Epoch 854/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 711us/step - loss: 0.0597 - val_loss: 0.0749\n",
      "Epoch 855/1500\n",
      "603/603 [==============================] - 1s 843us/step - loss: 0.0595 - val_loss: 0.0755\n",
      "Epoch 856/1500\n",
      "603/603 [==============================] - 0s 756us/step - loss: 0.0595 - val_loss: 0.0752\n",
      "Epoch 857/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0596 - val_loss: 0.0754\n",
      "Epoch 858/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0596 - val_loss: 0.0752\n",
      "Epoch 859/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0595 - val_loss: 0.0751\n",
      "Epoch 860/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0595 - val_loss: 0.0753\n",
      "Epoch 861/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0595 - val_loss: 0.0754\n",
      "Epoch 862/1500\n",
      "603/603 [==============================] - 1s 963us/step - loss: 0.0594 - val_loss: 0.0753\n",
      "Epoch 863/1500\n",
      "603/603 [==============================] - 0s 825us/step - loss: 0.0595 - val_loss: 0.0751\n",
      "Epoch 864/1500\n",
      "603/603 [==============================] - 0s 662us/step - loss: 0.0594 - val_loss: 0.0752\n",
      "Epoch 865/1500\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.059 - 1s 1ms/step - loss: 0.0596 - val_loss: 0.0754\n",
      "Epoch 866/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0594 - val_loss: 0.0753\n",
      "Epoch 867/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0593 - val_loss: 0.0748\n",
      "Epoch 868/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0593 - val_loss: 0.0751\n",
      "Epoch 869/1500\n",
      "603/603 [==============================] - 0s 768us/step - loss: 0.0593 - val_loss: 0.0754\n",
      "Epoch 870/1500\n",
      "603/603 [==============================] - 1s 907us/step - loss: 0.0594 - val_loss: 0.0753\n",
      "Epoch 871/1500\n",
      "603/603 [==============================] - 0s 728us/step - loss: 0.0594 - val_loss: 0.0752\n",
      "Epoch 872/1500\n",
      "603/603 [==============================] - 1s 916us/step - loss: 0.0593 - val_loss: 0.0757\n",
      "Epoch 873/1500\n",
      "603/603 [==============================] - 0s 780us/step - loss: 0.0595 - val_loss: 0.0751\n",
      "Epoch 874/1500\n",
      "603/603 [==============================] - 0s 741us/step - loss: 0.0594 - val_loss: 0.0753\n",
      "Epoch 875/1500\n",
      "603/603 [==============================] - 0s 783us/step - loss: 0.0593 - val_loss: 0.0756\n",
      "Epoch 876/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0594 - val_loss: 0.0755\n",
      "Epoch 877/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0593 - val_loss: 0.0755\n",
      "Epoch 878/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0592 - val_loss: 0.0754\n",
      "Epoch 879/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0593 - val_loss: 0.0753\n",
      "Epoch 880/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0592 - val_loss: 0.0754\n",
      "Epoch 881/1500\n",
      "603/603 [==============================] - 1s 831us/step - loss: 0.0593 - val_loss: 0.0751\n",
      "Epoch 882/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0593 - val_loss: 0.0756\n",
      "Epoch 883/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0591 - val_loss: 0.0752\n",
      "Epoch 884/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0591 - val_loss: 0.0755\n",
      "Epoch 885/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0592 - val_loss: 0.0751\n",
      "Epoch 886/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0592 - val_loss: 0.0750\n",
      "Epoch 887/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0592 - val_loss: 0.0754\n",
      "Epoch 888/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0592 - val_loss: 0.0755\n",
      "Epoch 889/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0590 - val_loss: 0.0755\n",
      "Epoch 890/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0591 - val_loss: 0.0756\n",
      "Epoch 891/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0591 - val_loss: 0.0754\n",
      "Epoch 892/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0591 - val_loss: 0.0753\n",
      "Epoch 893/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0591 - val_loss: 0.0752\n",
      "Epoch 894/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0589 - val_loss: 0.0748\n",
      "Epoch 895/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0590 - val_loss: 0.0752\n",
      "Epoch 896/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0590 - val_loss: 0.0752\n",
      "Epoch 897/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0589 - val_loss: 0.0751\n",
      "Epoch 898/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0589 - val_loss: 0.0756\n",
      "Epoch 899/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0591 - val_loss: 0.0754\n",
      "Epoch 900/1500\n",
      "603/603 [==============================] - 0s 669us/step - loss: 0.0591 - val_loss: 0.0756\n",
      "Epoch 901/1500\n",
      "603/603 [==============================] - 1s 912us/step - loss: 0.0591 - val_loss: 0.0755: 0s - loss: 0.059\n",
      "Epoch 902/1500\n",
      "603/603 [==============================] - 0s 648us/step - loss: 0.0590 - val_loss: 0.0755\n",
      "Epoch 903/1500\n",
      "603/603 [==============================] - 1s 944us/step - loss: 0.0589 - val_loss: 0.0756\n",
      "Epoch 904/1500\n",
      "603/603 [==============================] - 1s 936us/step - loss: 0.0589 - val_loss: 0.0754\n",
      "Epoch 905/1500\n",
      "603/603 [==============================] - 1s 854us/step - loss: 0.0589 - val_loss: 0.0753\n",
      "Epoch 906/1500\n",
      "603/603 [==============================] - 0s 712us/step - loss: 0.0588 - val_loss: 0.0754\n",
      "Epoch 907/1500\n",
      "603/603 [==============================] - 0s 813us/step - loss: 0.0589 - val_loss: 0.0752\n",
      "Epoch 908/1500\n",
      "603/603 [==============================] - 0s 798us/step - loss: 0.0588 - val_loss: 0.0754\n",
      "Epoch 909/1500\n",
      "603/603 [==============================] - 0s 773us/step - loss: 0.0588 - val_loss: 0.0755\n",
      "Epoch 910/1500\n",
      "603/603 [==============================] - 1s 964us/step - loss: 0.0589 - val_loss: 0.0752\n",
      "Epoch 911/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0589 - val_loss: 0.0753\n",
      "Epoch 912/1500\n",
      "603/603 [==============================] - 0s 788us/step - loss: 0.0587 - val_loss: 0.0757\n",
      "Epoch 913/1500\n",
      "603/603 [==============================] - 0s 539us/step - loss: 0.0587 - val_loss: 0.0754\n",
      "Epoch 914/1500\n",
      "603/603 [==============================] - 1s 830us/step - loss: 0.0587 - val_loss: 0.0756\n",
      "Epoch 915/1500\n",
      "603/603 [==============================] - 0s 692us/step - loss: 0.0587 - val_loss: 0.0754\n",
      "Epoch 916/1500\n",
      "603/603 [==============================] - 0s 822us/step - loss: 0.0588 - val_loss: 0.0757\n",
      "Epoch 917/1500\n",
      "603/603 [==============================] - 1s 988us/step - loss: 0.0588 - val_loss: 0.0757\n",
      "Epoch 918/1500\n",
      "603/603 [==============================] - 1s 836us/step - loss: 0.0586 - val_loss: 0.0756\n",
      "Epoch 919/1500\n",
      "603/603 [==============================] - 1s 842us/step - loss: 0.0587 - val_loss: 0.0754\n",
      "Epoch 920/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0587 - val_loss: 0.0756\n",
      "Epoch 921/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0587 - val_loss: 0.0756\n",
      "Epoch 922/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0588 - val_loss: 0.0757\n",
      "Epoch 923/1500\n",
      "603/603 [==============================] - 1s 908us/step - loss: 0.0588 - val_loss: 0.0757\n",
      "Epoch 924/1500\n",
      "603/603 [==============================] - 0s 814us/step - loss: 0.0587 - val_loss: 0.0755\n",
      "Epoch 925/1500\n",
      "603/603 [==============================] - 1s 898us/step - loss: 0.0588 - val_loss: 0.0759\n",
      "Epoch 926/1500\n",
      "603/603 [==============================] - 0s 686us/step - loss: 0.0586 - val_loss: 0.0756\n",
      "Epoch 927/1500\n",
      "603/603 [==============================] - 0s 667us/step - loss: 0.0588 - val_loss: 0.0758\n",
      "Epoch 928/1500\n",
      "603/603 [==============================] - 0s 770us/step - loss: 0.0586 - val_loss: 0.0755\n",
      "Epoch 929/1500\n",
      "603/603 [==============================] - 0s 731us/step - loss: 0.0587 - val_loss: 0.0753\n",
      "Epoch 930/1500\n",
      "603/603 [==============================] - 0s 689us/step - loss: 0.0585 - val_loss: 0.0754\n",
      "Epoch 931/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 797us/step - loss: 0.0586 - val_loss: 0.0753\n",
      "Epoch 932/1500\n",
      "603/603 [==============================] - 1s 847us/step - loss: 0.0586 - val_loss: 0.0755\n",
      "Epoch 933/1500\n",
      "603/603 [==============================] - 0s 676us/step - loss: 0.0586 - val_loss: 0.0754\n",
      "Epoch 934/1500\n",
      "603/603 [==============================] - 1s 849us/step - loss: 0.0585 - val_loss: 0.0755\n",
      "Epoch 935/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0586 - val_loss: 0.0753\n",
      "Epoch 936/1500\n",
      "603/603 [==============================] - 0s 812us/step - loss: 0.0588 - val_loss: 0.0756\n",
      "Epoch 937/1500\n",
      "603/603 [==============================] - 0s 709us/step - loss: 0.0585 - val_loss: 0.0756\n",
      "Epoch 938/1500\n",
      "603/603 [==============================] - 0s 777us/step - loss: 0.0585 - val_loss: 0.0756\n",
      "Epoch 939/1500\n",
      "603/603 [==============================] - 0s 759us/step - loss: 0.0586 - val_loss: 0.0752\n",
      "Epoch 940/1500\n",
      "603/603 [==============================] - 0s 734us/step - loss: 0.0587 - val_loss: 0.0753\n",
      "Epoch 941/1500\n",
      "603/603 [==============================] - 0s 729us/step - loss: 0.0586 - val_loss: 0.0754\n",
      "Epoch 942/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0585 - val_loss: 0.0757\n",
      "Epoch 943/1500\n",
      "603/603 [==============================] - 0s 761us/step - loss: 0.0584 - val_loss: 0.0759\n",
      "Epoch 944/1500\n",
      "603/603 [==============================] - 1s 840us/step - loss: 0.0587 - val_loss: 0.0755\n",
      "Epoch 945/1500\n",
      "603/603 [==============================] - 0s 824us/step - loss: 0.0585 - val_loss: 0.0755\n",
      "Epoch 946/1500\n",
      "603/603 [==============================] - 1s 902us/step - loss: 0.0585 - val_loss: 0.0757\n",
      "Epoch 947/1500\n",
      "603/603 [==============================] - 0s 754us/step - loss: 0.0584 - val_loss: 0.0756\n",
      "Epoch 948/1500\n",
      "603/603 [==============================] - 1s 900us/step - loss: 0.0583 - val_loss: 0.0755\n",
      "Epoch 949/1500\n",
      "603/603 [==============================] - 1s 852us/step - loss: 0.0583 - val_loss: 0.0759\n",
      "Epoch 950/1500\n",
      "603/603 [==============================] - 1s 888us/step - loss: 0.0584 - val_loss: 0.0760\n",
      "Epoch 951/1500\n",
      "603/603 [==============================] - 1s 984us/step - loss: 0.0584 - val_loss: 0.0757\n",
      "Epoch 952/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0585 - val_loss: 0.0756\n",
      "Epoch 953/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0583 - val_loss: 0.0757\n",
      "Epoch 954/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0583 - val_loss: 0.0760\n",
      "Epoch 955/1500\n",
      "603/603 [==============================] - 1s 982us/step - loss: 0.0584 - val_loss: 0.0754\n",
      "Epoch 956/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0583 - val_loss: 0.0758\n",
      "Epoch 957/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0583 - val_loss: 0.0759\n",
      "Epoch 958/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0581 - val_loss: 0.0756\n",
      "Epoch 959/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0581 - val_loss: 0.0759\n",
      "Epoch 960/1500\n",
      "603/603 [==============================] - 0s 823us/step - loss: 0.0582 - val_loss: 0.0759\n",
      "Epoch 961/1500\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.058 - 1s 868us/step - loss: 0.0583 - val_loss: 0.0759\n",
      "Epoch 962/1500\n",
      "603/603 [==============================] - 0s 812us/step - loss: 0.0583 - val_loss: 0.0760\n",
      "Epoch 963/1500\n",
      "603/603 [==============================] - 0s 745us/step - loss: 0.0585 - val_loss: 0.0760\n",
      "Epoch 964/1500\n",
      "603/603 [==============================] - 0s 759us/step - loss: 0.0583 - val_loss: 0.0755\n",
      "Epoch 965/1500\n",
      "603/603 [==============================] - 0s 725us/step - loss: 0.0583 - val_loss: 0.0759\n",
      "Epoch 966/1500\n",
      "603/603 [==============================] - 0s 715us/step - loss: 0.0584 - val_loss: 0.0761\n",
      "Epoch 967/1500\n",
      "603/603 [==============================] - 0s 704us/step - loss: 0.0582 - val_loss: 0.0756\n",
      "Epoch 968/1500\n",
      "603/603 [==============================] - 0s 662us/step - loss: 0.0582 - val_loss: 0.0758\n",
      "Epoch 969/1500\n",
      "603/603 [==============================] - 0s 600us/step - loss: 0.0582 - val_loss: 0.0758\n",
      "Epoch 970/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0581 - val_loss: 0.0760\n",
      "Epoch 971/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0583 - val_loss: 0.0757\n",
      "Epoch 972/1500\n",
      "603/603 [==============================] - 0s 696us/step - loss: 0.0581 - val_loss: 0.0758\n",
      "Epoch 973/1500\n",
      "603/603 [==============================] - 0s 806us/step - loss: 0.0582 - val_loss: 0.0759\n",
      "Epoch 974/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0581 - val_loss: 0.0757\n",
      "Epoch 975/1500\n",
      "603/603 [==============================] - 1s 969us/step - loss: 0.0581 - val_loss: 0.0759\n",
      "Epoch 976/1500\n",
      "603/603 [==============================] - 0s 776us/step - loss: 0.0582 - val_loss: 0.0762\n",
      "Epoch 977/1500\n",
      "603/603 [==============================] - 1s 890us/step - loss: 0.0580 - val_loss: 0.0762\n",
      "Epoch 978/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0580 - val_loss: 0.0759\n",
      "Epoch 979/1500\n",
      "603/603 [==============================] - 1s 950us/step - loss: 0.0580 - val_loss: 0.0758\n",
      "Epoch 980/1500\n",
      "603/603 [==============================] - 0s 621us/step - loss: 0.0582 - val_loss: 0.0756\n",
      "Epoch 981/1500\n",
      "603/603 [==============================] - 0s 530us/step - loss: 0.0580 - val_loss: 0.0760\n",
      "Epoch 982/1500\n",
      "603/603 [==============================] - 0s 671us/step - loss: 0.0579 - val_loss: 0.0760\n",
      "Epoch 983/1500\n",
      "603/603 [==============================] - 0s 624us/step - loss: 0.0582 - val_loss: 0.0759\n",
      "Epoch 984/1500\n",
      "603/603 [==============================] - 0s 693us/step - loss: 0.0580 - val_loss: 0.0758\n",
      "Epoch 985/1500\n",
      "603/603 [==============================] - 0s 536us/step - loss: 0.0579 - val_loss: 0.0760\n",
      "Epoch 986/1500\n",
      "603/603 [==============================] - 0s 593us/step - loss: 0.0580 - val_loss: 0.0759\n",
      "Epoch 987/1500\n",
      "603/603 [==============================] - 0s 637us/step - loss: 0.0579 - val_loss: 0.0757\n",
      "Epoch 988/1500\n",
      "603/603 [==============================] - 0s 735us/step - loss: 0.0580 - val_loss: 0.0757\n",
      "Epoch 989/1500\n",
      "603/603 [==============================] - 1s 975us/step - loss: 0.0579 - val_loss: 0.0757\n",
      "Epoch 990/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0580 - val_loss: 0.0758\n",
      "Epoch 991/1500\n",
      "603/603 [==============================] - 1s 935us/step - loss: 0.0580 - val_loss: 0.0759\n",
      "Epoch 992/1500\n",
      "603/603 [==============================] - 0s 809us/step - loss: 0.0579 - val_loss: 0.0761\n",
      "Epoch 993/1500\n",
      "603/603 [==============================] - 1s 839us/step - loss: 0.0579 - val_loss: 0.0759\n",
      "Epoch 994/1500\n",
      "603/603 [==============================] - 0s 828us/step - loss: 0.0578 - val_loss: 0.0756\n",
      "Epoch 995/1500\n",
      "603/603 [==============================] - 1s 868us/step - loss: 0.0580 - val_loss: 0.0760\n",
      "Epoch 996/1500\n",
      "603/603 [==============================] - 1s 836us/step - loss: 0.0579 - val_loss: 0.0762\n",
      "Epoch 997/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0579 - val_loss: 0.0761\n",
      "Epoch 998/1500\n",
      "603/603 [==============================] - 0s 811us/step - loss: 0.0580 - val_loss: 0.0758\n",
      "Epoch 999/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0581 - val_loss: 0.0761\n",
      "Epoch 1000/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0579 - val_loss: 0.0763\n",
      "Epoch 1001/1500\n",
      "603/603 [==============================] - 1s 853us/step - loss: 0.0578 - val_loss: 0.0762\n",
      "Epoch 1002/1500\n",
      "603/603 [==============================] - 1s 963us/step - loss: 0.0580 - val_loss: 0.0761\n",
      "Epoch 1003/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0579 - val_loss: 0.0761\n",
      "Epoch 1004/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0579 - val_loss: 0.0762\n",
      "Epoch 1005/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0580 - val_loss: 0.0761\n",
      "Epoch 1006/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0582 - val_loss: 0.0761\n",
      "Epoch 1007/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0578 - val_loss: 0.0759\n",
      "Epoch 1008/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 751us/step - loss: 0.0578 - val_loss: 0.0762\n",
      "Epoch 1009/1500\n",
      "603/603 [==============================] - 0s 721us/step - loss: 0.0578 - val_loss: 0.0761\n",
      "Epoch 1010/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0578 - val_loss: 0.0758\n",
      "Epoch 1011/1500\n",
      "603/603 [==============================] - 0s 594us/step - loss: 0.0577 - val_loss: 0.0761\n",
      "Epoch 1012/1500\n",
      "603/603 [==============================] - 0s 624us/step - loss: 0.0576 - val_loss: 0.0760\n",
      "Epoch 1013/1500\n",
      "603/603 [==============================] - 0s 642us/step - loss: 0.0578 - val_loss: 0.0765\n",
      "Epoch 1014/1500\n",
      "603/603 [==============================] - 0s 609us/step - loss: 0.0578 - val_loss: 0.0761\n",
      "Epoch 1015/1500\n",
      "603/603 [==============================] - 1s 980us/step - loss: 0.0579 - val_loss: 0.0763\n",
      "Epoch 1016/1500\n",
      "603/603 [==============================] - 0s 584us/step - loss: 0.0576 - val_loss: 0.0763\n",
      "Epoch 1017/1500\n",
      "603/603 [==============================] - 0s 669us/step - loss: 0.0578 - val_loss: 0.0762\n",
      "Epoch 1018/1500\n",
      "603/603 [==============================] - 0s 672us/step - loss: 0.0579 - val_loss: 0.0761\n",
      "Epoch 1019/1500\n",
      "603/603 [==============================] - 1s 869us/step - loss: 0.0577 - val_loss: 0.0765\n",
      "Epoch 1020/1500\n",
      "603/603 [==============================] - 0s 829us/step - loss: 0.0576 - val_loss: 0.0760\n",
      "Epoch 1021/1500\n",
      "603/603 [==============================] - 0s 687us/step - loss: 0.0577 - val_loss: 0.0761\n",
      "Epoch 1022/1500\n",
      "603/603 [==============================] - 0s 705us/step - loss: 0.0578 - val_loss: 0.0765\n",
      "Epoch 1023/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0576 - val_loss: 0.0761\n",
      "Epoch 1024/1500\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.057 - 1s 2ms/step - loss: 0.0577 - val_loss: 0.0763\n",
      "Epoch 1025/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0577 - val_loss: 0.0762\n",
      "Epoch 1026/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0576 - val_loss: 0.0759\n",
      "Epoch 1027/1500\n",
      "603/603 [==============================] - 0s 748us/step - loss: 0.0575 - val_loss: 0.0763\n",
      "Epoch 1028/1500\n",
      "603/603 [==============================] - 0s 749us/step - loss: 0.0575 - val_loss: 0.0761\n",
      "Epoch 1029/1500\n",
      "603/603 [==============================] - 1s 835us/step - loss: 0.0575 - val_loss: 0.0761\n",
      "Epoch 1030/1500\n",
      "603/603 [==============================] - 1s 865us/step - loss: 0.0576 - val_loss: 0.0766\n",
      "Epoch 1031/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0575 - val_loss: 0.0765TA: 0s - loss: 0.0\n",
      "Epoch 1032/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0576 - val_loss: 0.0765\n",
      "Epoch 1033/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0576 - val_loss: 0.0763\n",
      "Epoch 1034/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0576 - val_loss: 0.0766\n",
      "Epoch 1035/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0574 - val_loss: 0.0761\n",
      "Epoch 1036/1500\n",
      "603/603 [==============================] - 0s 756us/step - loss: 0.0576 - val_loss: 0.0765\n",
      "Epoch 1037/1500\n",
      "603/603 [==============================] - 0s 649us/step - loss: 0.0576 - val_loss: 0.0762\n",
      "Epoch 1038/1500\n",
      "603/603 [==============================] - 1s 975us/step - loss: 0.0574 - val_loss: 0.0765\n",
      "Epoch 1039/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0576 - val_loss: 0.0763\n",
      "Epoch 1040/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0574 - val_loss: 0.0769\n",
      "Epoch 1041/1500\n",
      "603/603 [==============================] - 0s 763us/step - loss: 0.0573 - val_loss: 0.0763\n",
      "Epoch 1042/1500\n",
      "603/603 [==============================] - 0s 723us/step - loss: 0.0575 - val_loss: 0.0767\n",
      "Epoch 1043/1500\n",
      "603/603 [==============================] - 0s 805us/step - loss: 0.0573 - val_loss: 0.0767\n",
      "Epoch 1044/1500\n",
      "603/603 [==============================] - 0s 718us/step - loss: 0.0574 - val_loss: 0.0767\n",
      "Epoch 1045/1500\n",
      "603/603 [==============================] - 0s 631us/step - loss: 0.0576 - val_loss: 0.0766\n",
      "Epoch 1046/1500\n",
      "603/603 [==============================] - 0s 742us/step - loss: 0.0574 - val_loss: 0.0763\n",
      "Epoch 1047/1500\n",
      "603/603 [==============================] - 0s 565us/step - loss: 0.0573 - val_loss: 0.0763\n",
      "Epoch 1048/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0574 - val_loss: 0.0762\n",
      "Epoch 1049/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0574 - val_loss: 0.0768\n",
      "Epoch 1050/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0574 - val_loss: 0.0765\n",
      "Epoch 1051/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0572 - val_loss: 0.0763\n",
      "Epoch 1052/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0573 - val_loss: 0.0765\n",
      "Epoch 1053/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0571 - val_loss: 0.0768\n",
      "Epoch 1054/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0573 - val_loss: 0.0767\n",
      "Epoch 1055/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0574 - val_loss: 0.0763\n",
      "Epoch 1056/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0572 - val_loss: 0.0764\n",
      "Epoch 1057/1500\n",
      "603/603 [==============================] - 1s 983us/step - loss: 0.0573 - val_loss: 0.0769\n",
      "Epoch 1058/1500\n",
      "603/603 [==============================] - 0s 688us/step - loss: 0.0574 - val_loss: 0.0763\n",
      "Epoch 1059/1500\n",
      "603/603 [==============================] - 0s 773us/step - loss: 0.0573 - val_loss: 0.0766\n",
      "Epoch 1060/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0573 - val_loss: 0.0765\n",
      "Epoch 1061/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0573 - val_loss: 0.0764\n",
      "Epoch 1062/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0571 - val_loss: 0.0767\n",
      "Epoch 1063/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0572 - val_loss: 0.0764\n",
      "Epoch 1064/1500\n",
      "603/603 [==============================] - 0s 773us/step - loss: 0.0571 - val_loss: 0.0763\n",
      "Epoch 1065/1500\n",
      "603/603 [==============================] - 1s 951us/step - loss: 0.0572 - val_loss: 0.0768\n",
      "Epoch 1066/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0572 - val_loss: 0.0764\n",
      "Epoch 1067/1500\n",
      "603/603 [==============================] - 0s 823us/step - loss: 0.0572 - val_loss: 0.0765\n",
      "Epoch 1068/1500\n",
      "603/603 [==============================] - 0s 682us/step - loss: 0.0571 - val_loss: 0.0766\n",
      "Epoch 1069/1500\n",
      "603/603 [==============================] - 0s 614us/step - loss: 0.0571 - val_loss: 0.0769\n",
      "Epoch 1070/1500\n",
      "603/603 [==============================] - 1s 861us/step - loss: 0.0572 - val_loss: 0.0768\n",
      "Epoch 1071/1500\n",
      "603/603 [==============================] - 0s 806us/step - loss: 0.0573 - val_loss: 0.0768\n",
      "Epoch 1072/1500\n",
      "603/603 [==============================] - 1s 832us/step - loss: 0.0572 - val_loss: 0.0767\n",
      "Epoch 1073/1500\n",
      "603/603 [==============================] - 1s 960us/step - loss: 0.0572 - val_loss: 0.0764\n",
      "Epoch 1074/1500\n",
      "603/603 [==============================] - 1s 977us/step - loss: 0.0571 - val_loss: 0.0763\n",
      "Epoch 1075/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0570 - val_loss: 0.0763\n",
      "Epoch 1076/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0569 - val_loss: 0.0766\n",
      "Epoch 1077/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0571 - val_loss: 0.0769\n",
      "Epoch 1078/1500\n",
      "603/603 [==============================] - 1s 970us/step - loss: 0.0571 - val_loss: 0.0765\n",
      "Epoch 1079/1500\n",
      "603/603 [==============================] - 1s 982us/step - loss: 0.0571 - val_loss: 0.0770\n",
      "Epoch 1080/1500\n",
      "603/603 [==============================] - 1s 920us/step - loss: 0.0570 - val_loss: 0.0768\n",
      "Epoch 1081/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0571 - val_loss: 0.0770\n",
      "Epoch 1082/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0570 - val_loss: 0.0767\n",
      "Epoch 1083/1500\n",
      "603/603 [==============================] - 0s 653us/step - loss: 0.0570 - val_loss: 0.0765\n",
      "Epoch 1084/1500\n",
      "603/603 [==============================] - 0s 812us/step - loss: 0.0570 - val_loss: 0.0772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1085/1500\n",
      "603/603 [==============================] - 0s 732us/step - loss: 0.0570 - val_loss: 0.0766\n",
      "Epoch 1086/1500\n",
      "603/603 [==============================] - 0s 781us/step - loss: 0.0570 - val_loss: 0.0765\n",
      "Epoch 1087/1500\n",
      "603/603 [==============================] - 0s 769us/step - loss: 0.0569 - val_loss: 0.0769\n",
      "Epoch 1088/1500\n",
      "603/603 [==============================] - 0s 789us/step - loss: 0.0570 - val_loss: 0.0769\n",
      "Epoch 1089/1500\n",
      "603/603 [==============================] - 0s 714us/step - loss: 0.0568 - val_loss: 0.0768\n",
      "Epoch 1090/1500\n",
      "603/603 [==============================] - 1s 846us/step - loss: 0.0569 - val_loss: 0.0767\n",
      "Epoch 1091/1500\n",
      "603/603 [==============================] - 1s 895us/step - loss: 0.0571 - val_loss: 0.0765\n",
      "Epoch 1092/1500\n",
      "603/603 [==============================] - 1s 836us/step - loss: 0.0568 - val_loss: 0.0765\n",
      "Epoch 1093/1500\n",
      "603/603 [==============================] - 0s 619us/step - loss: 0.0569 - val_loss: 0.0765\n",
      "Epoch 1094/1500\n",
      "603/603 [==============================] - 1s 916us/step - loss: 0.0570 - val_loss: 0.0767\n",
      "Epoch 1095/1500\n",
      "603/603 [==============================] - 0s 755us/step - loss: 0.0570 - val_loss: 0.0767\n",
      "Epoch 1096/1500\n",
      "603/603 [==============================] - 1s 835us/step - loss: 0.0570 - val_loss: 0.0764\n",
      "Epoch 1097/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0567 - val_loss: 0.0769\n",
      "Epoch 1098/1500\n",
      "603/603 [==============================] - 0s 715us/step - loss: 0.0569 - val_loss: 0.0769\n",
      "Epoch 1099/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0568 - val_loss: 0.0767\n",
      "Epoch 1100/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0567 - val_loss: 0.0771\n",
      "Epoch 1101/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0569 - val_loss: 0.0769\n",
      "Epoch 1102/1500\n",
      "603/603 [==============================] - 1s 879us/step - loss: 0.0568 - val_loss: 0.0768\n",
      "Epoch 1103/1500\n",
      "603/603 [==============================] - 0s 768us/step - loss: 0.0569 - val_loss: 0.0767\n",
      "Epoch 1104/1500\n",
      "603/603 [==============================] - 0s 812us/step - loss: 0.0566 - val_loss: 0.0765\n",
      "Epoch 1105/1500\n",
      "603/603 [==============================] - 0s 759us/step - loss: 0.0568 - val_loss: 0.0764\n",
      "Epoch 1106/1500\n",
      "603/603 [==============================] - 1s 917us/step - loss: 0.0566 - val_loss: 0.0768\n",
      "Epoch 1107/1500\n",
      "603/603 [==============================] - 0s 766us/step - loss: 0.0568 - val_loss: 0.0767\n",
      "Epoch 1108/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0568 - val_loss: 0.0769\n",
      "Epoch 1109/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0568 - val_loss: 0.0768\n",
      "Epoch 1110/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0567 - val_loss: 0.0773\n",
      "Epoch 1111/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0567 - val_loss: 0.0771\n",
      "Epoch 1112/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0568 - val_loss: 0.0771\n",
      "Epoch 1113/1500\n",
      "603/603 [==============================] - 0s 733us/step - loss: 0.0567 - val_loss: 0.0772\n",
      "Epoch 1114/1500\n",
      "603/603 [==============================] - 0s 774us/step - loss: 0.0567 - val_loss: 0.0768\n",
      "Epoch 1115/1500\n",
      "603/603 [==============================] - 0s 768us/step - loss: 0.0567 - val_loss: 0.0773\n",
      "Epoch 1116/1500\n",
      "603/603 [==============================] - 1s 875us/step - loss: 0.0566 - val_loss: 0.0770\n",
      "Epoch 1117/1500\n",
      "603/603 [==============================] - 1s 831us/step - loss: 0.0566 - val_loss: 0.0771\n",
      "Epoch 1118/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0565 - val_loss: 0.0769\n",
      "Epoch 1119/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0567 - val_loss: 0.0772\n",
      "Epoch 1120/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0566 - val_loss: 0.0770\n",
      "Epoch 1121/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0565 - val_loss: 0.0772\n",
      "Epoch 1122/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0565 - val_loss: 0.0768\n",
      "Epoch 1123/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0567 - val_loss: 0.0768\n",
      "Epoch 1124/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0564 - val_loss: 0.0770\n",
      "Epoch 1125/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0564 - val_loss: 0.0769\n",
      "Epoch 1126/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0566 - val_loss: 0.0773- ETA: 0s - loss: 0.05\n",
      "Epoch 1127/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0566 - val_loss: 0.0769\n",
      "Epoch 1128/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0564 - val_loss: 0.0774\n",
      "Epoch 1129/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0565 - val_loss: 0.0773\n",
      "Epoch 1130/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0565 - val_loss: 0.0775\n",
      "Epoch 1131/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0565 - val_loss: 0.0776\n",
      "Epoch 1132/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0565 - val_loss: 0.0773\n",
      "Epoch 1133/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0566 - val_loss: 0.07730s - loss: 0\n",
      "Epoch 1134/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0567 - val_loss: 0.0771\n",
      "Epoch 1135/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0565 - val_loss: 0.0773\n",
      "Epoch 1136/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0566 - val_loss: 0.0773\n",
      "Epoch 1137/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0564 - val_loss: 0.0768\n",
      "Epoch 1138/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0564 - val_loss: 0.0769\n",
      "Epoch 1139/1500\n",
      "603/603 [==============================] - 0s 805us/step - loss: 0.0565 - val_loss: 0.0770\n",
      "Epoch 1140/1500\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.056 - 1s 967us/step - loss: 0.0564 - val_loss: 0.0770\n",
      "Epoch 1141/1500\n",
      "603/603 [==============================] - 1s 917us/step - loss: 0.0564 - val_loss: 0.0771\n",
      "Epoch 1142/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0564 - val_loss: 0.0773\n",
      "Epoch 1143/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0564 - val_loss: 0.0770\n",
      "Epoch 1144/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0564 - val_loss: 0.0774\n",
      "Epoch 1145/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0563 - val_loss: 0.0770\n",
      "Epoch 1146/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0565 - val_loss: 0.0771\n",
      "Epoch 1147/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0564 - val_loss: 0.0774\n",
      "Epoch 1148/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0562 - val_loss: 0.0774\n",
      "Epoch 1149/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0562 - val_loss: 0.0772 ETA: 0s - loss: 0.0 - ETA: 0s - lo\n",
      "Epoch 1150/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0563 - val_loss: 0.0775\n",
      "Epoch 1151/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0563 - val_loss: 0.0776\n",
      "Epoch 1152/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0563 - val_loss: 0.0775\n",
      "Epoch 1153/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0562 - val_loss: 0.0770\n",
      "Epoch 1154/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0561 - val_loss: 0.0776\n",
      "Epoch 1155/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0562 - val_loss: 0.0776\n",
      "Epoch 1156/1500\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.0563- ETA: 0s - loss: 0. - 1s 2ms/step - loss: 0.0562 - val_loss: 0.0771\n",
      "Epoch 1157/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0562 - val_loss: 0.0774\n",
      "Epoch 1158/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0563 - val_loss: 0.0773\n",
      "Epoch 1159/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0560 - val_loss: 0.0769\n",
      "Epoch 1160/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0563 - val_loss: 0.0778\n",
      "Epoch 1161/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0563 - val_loss: 0.0776\n",
      "Epoch 1162/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0561 - val_loss: 0.0777\n",
      "Epoch 1163/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0563 - val_loss: 0.0776\n",
      "Epoch 1164/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0560 - val_loss: 0.0775\n",
      "Epoch 1165/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0561 - val_loss: 0.0777\n",
      "Epoch 1166/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0562 - val_loss: 0.0777\n",
      "Epoch 1167/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0561 - val_loss: 0.0775\n",
      "Epoch 1168/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0562 - val_loss: 0.0774\n",
      "Epoch 1169/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0562 - val_loss: 0.0778\n",
      "Epoch 1170/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0560 - val_loss: 0.0775\n",
      "Epoch 1171/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0561 - val_loss: 0.0775\n",
      "Epoch 1172/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0561 - val_loss: 0.0773\n",
      "Epoch 1173/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0560 - val_loss: 0.0778\n",
      "Epoch 1174/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0561 - val_loss: 0.0777\n",
      "Epoch 1175/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0560 - val_loss: 0.0778\n",
      "Epoch 1176/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0563 - val_loss: 0.0778\n",
      "Epoch 1177/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0561 - val_loss: 0.0774\n",
      "Epoch 1178/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0561 - val_loss: 0.0775\n",
      "Epoch 1179/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0560 - val_loss: 0.0774\n",
      "Epoch 1180/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0560 - val_loss: 0.0774\n",
      "Epoch 1181/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0560 - val_loss: 0.0776\n",
      "Epoch 1182/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0559 - val_loss: 0.0778\n",
      "Epoch 1183/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0561 - val_loss: 0.0777\n",
      "Epoch 1184/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0559 - val_loss: 0.0777\n",
      "Epoch 1185/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0558 - val_loss: 0.0775\n",
      "Epoch 1186/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0559 - val_loss: 0.0779\n",
      "Epoch 1187/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0560 - val_loss: 0.0773\n",
      "Epoch 1188/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0559 - val_loss: 0.0774\n",
      "Epoch 1189/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0558 - val_loss: 0.0772\n",
      "Epoch 1190/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0559 - val_loss: 0.0777\n",
      "Epoch 1191/1500\n",
      "603/603 [==============================] - 0s 657us/step - loss: 0.0559 - val_loss: 0.0778\n",
      "Epoch 1192/1500\n",
      "603/603 [==============================] - 0s 783us/step - loss: 0.0559 - val_loss: 0.0779\n",
      "Epoch 1193/1500\n",
      "603/603 [==============================] - 1s 887us/step - loss: 0.0557 - val_loss: 0.0775\n",
      "Epoch 1194/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0559 - val_loss: 0.0784\n",
      "Epoch 1195/1500\n",
      "603/603 [==============================] - 0s 759us/step - loss: 0.0558 - val_loss: 0.0776\n",
      "Epoch 1196/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0559 - val_loss: 0.0777\n",
      "Epoch 1197/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0558 - val_loss: 0.0775\n",
      "Epoch 1198/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0559 - val_loss: 0.0778\n",
      "Epoch 1199/1500\n",
      "603/603 [==============================] - 0s 655us/step - loss: 0.0558 - val_loss: 0.0779\n",
      "Epoch 1200/1500\n",
      "603/603 [==============================] - 1s 918us/step - loss: 0.0558 - val_loss: 0.0781\n",
      "Epoch 1201/1500\n",
      "603/603 [==============================] - 0s 732us/step - loss: 0.0558 - val_loss: 0.0776\n",
      "Epoch 1202/1500\n",
      "603/603 [==============================] - 0s 500us/step - loss: 0.0558 - val_loss: 0.0779\n",
      "Epoch 1203/1500\n",
      "603/603 [==============================] - 0s 608us/step - loss: 0.0557 - val_loss: 0.0777\n",
      "Epoch 1204/1500\n",
      "603/603 [==============================] - 1s 850us/step - loss: 0.0557 - val_loss: 0.0778\n",
      "Epoch 1205/1500\n",
      "603/603 [==============================] - 0s 782us/step - loss: 0.0558 - val_loss: 0.0778\n",
      "Epoch 1206/1500\n",
      "603/603 [==============================] - 1s 973us/step - loss: 0.0558 - val_loss: 0.0777\n",
      "Epoch 1207/1500\n",
      "603/603 [==============================] - 0s 806us/step - loss: 0.0557 - val_loss: 0.0779\n",
      "Epoch 1208/1500\n",
      "603/603 [==============================] - 0s 795us/step - loss: 0.0558 - val_loss: 0.0776\n",
      "Epoch 1209/1500\n",
      "603/603 [==============================] - 0s 743us/step - loss: 0.0556 - val_loss: 0.0780\n",
      "Epoch 1210/1500\n",
      "603/603 [==============================] - 0s 762us/step - loss: 0.0556 - val_loss: 0.0780\n",
      "Epoch 1211/1500\n",
      "603/603 [==============================] - 1s 843us/step - loss: 0.0557 - val_loss: 0.0779\n",
      "Epoch 1212/1500\n",
      "603/603 [==============================] - 0s 728us/step - loss: 0.0555 - val_loss: 0.0776\n",
      "Epoch 1213/1500\n",
      "603/603 [==============================] - 0s 729us/step - loss: 0.0557 - val_loss: 0.0776\n",
      "Epoch 1214/1500\n",
      "603/603 [==============================] - 0s 668us/step - loss: 0.0557 - val_loss: 0.0781\n",
      "Epoch 1215/1500\n",
      "603/603 [==============================] - 0s 781us/step - loss: 0.0556 - val_loss: 0.0782\n",
      "Epoch 1216/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0556 - val_loss: 0.0778\n",
      "Epoch 1217/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0558 - val_loss: 0.0777\n",
      "Epoch 1218/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0556 - val_loss: 0.0779\n",
      "Epoch 1219/1500\n",
      "603/603 [==============================] - 1s 971us/step - loss: 0.0556 - val_loss: 0.0783\n",
      "Epoch 1220/1500\n",
      "603/603 [==============================] - 1s 836us/step - loss: 0.0559 - val_loss: 0.0779\n",
      "Epoch 1221/1500\n",
      "603/603 [==============================] - 0s 806us/step - loss: 0.0556 - val_loss: 0.0780\n",
      "Epoch 1222/1500\n",
      "603/603 [==============================] - 1s 835us/step - loss: 0.0555 - val_loss: 0.0777\n",
      "Epoch 1223/1500\n",
      "603/603 [==============================] - 0s 800us/step - loss: 0.0554 - val_loss: 0.0779\n",
      "Epoch 1224/1500\n",
      "603/603 [==============================] - 1s 909us/step - loss: 0.0556 - val_loss: 0.0778\n",
      "Epoch 1225/1500\n",
      "603/603 [==============================] - 0s 788us/step - loss: 0.0554 - val_loss: 0.0778\n",
      "Epoch 1226/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0554 - val_loss: 0.0783\n",
      "Epoch 1227/1500\n",
      "603/603 [==============================] - 0s 768us/step - loss: 0.0555 - val_loss: 0.0778\n",
      "Epoch 1228/1500\n",
      "603/603 [==============================] - 0s 770us/step - loss: 0.0554 - val_loss: 0.0781\n",
      "Epoch 1229/1500\n",
      "603/603 [==============================] - 0s 768us/step - loss: 0.0555 - val_loss: 0.0780\n",
      "Epoch 1230/1500\n",
      "603/603 [==============================] - 0s 761us/step - loss: 0.0555 - val_loss: 0.0782\n",
      "Epoch 1231/1500\n",
      "603/603 [==============================] - 0s 750us/step - loss: 0.0554 - val_loss: 0.0784\n",
      "Epoch 1232/1500\n",
      "603/603 [==============================] - 1s 848us/step - loss: 0.0554 - val_loss: 0.0781\n",
      "Epoch 1233/1500\n",
      "603/603 [==============================] - 0s 753us/step - loss: 0.0555 - val_loss: 0.0780\n",
      "Epoch 1234/1500\n",
      "603/603 [==============================] - 0s 675us/step - loss: 0.0553 - val_loss: 0.0780\n",
      "Epoch 1235/1500\n",
      "603/603 [==============================] - 0s 695us/step - loss: 0.0553 - val_loss: 0.0782\n",
      "Epoch 1236/1500\n",
      "603/603 [==============================] - 0s 698us/step - loss: 0.0556 - val_loss: 0.0781\n",
      "Epoch 1237/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0554 - val_loss: 0.0775\n",
      "Epoch 1238/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 706us/step - loss: 0.0555 - val_loss: 0.0779\n",
      "Epoch 1239/1500\n",
      "603/603 [==============================] - 0s 787us/step - loss: 0.0554 - val_loss: 0.0781\n",
      "Epoch 1240/1500\n",
      "603/603 [==============================] - 0s 689us/step - loss: 0.0553 - val_loss: 0.0781\n",
      "Epoch 1241/1500\n",
      "603/603 [==============================] - 0s 670us/step - loss: 0.0554 - val_loss: 0.0785\n",
      "Epoch 1242/1500\n",
      "603/603 [==============================] - 0s 678us/step - loss: 0.0553 - val_loss: 0.0784\n",
      "Epoch 1243/1500\n",
      "603/603 [==============================] - 0s 733us/step - loss: 0.0552 - val_loss: 0.0783\n",
      "Epoch 1244/1500\n",
      "603/603 [==============================] - 0s 796us/step - loss: 0.0554 - val_loss: 0.0780\n",
      "Epoch 1245/1500\n",
      "603/603 [==============================] - 1s 843us/step - loss: 0.0554 - val_loss: 0.0783\n",
      "Epoch 1246/1500\n",
      "603/603 [==============================] - 0s 771us/step - loss: 0.0553 - val_loss: 0.0779\n",
      "Epoch 1247/1500\n",
      "603/603 [==============================] - 0s 645us/step - loss: 0.0551 - val_loss: 0.0779\n",
      "Epoch 1248/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0553 - val_loss: 0.0778\n",
      "Epoch 1249/1500\n",
      "603/603 [==============================] - 1s 991us/step - loss: 0.0553 - val_loss: 0.0778\n",
      "Epoch 1250/1500\n",
      "603/603 [==============================] - 1s 965us/step - loss: 0.0553 - val_loss: 0.0778\n",
      "Epoch 1251/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0553 - val_loss: 0.0785\n",
      "Epoch 1252/1500\n",
      "603/603 [==============================] - 1s 845us/step - loss: 0.0552 - val_loss: 0.0778\n",
      "Epoch 1253/1500\n",
      "603/603 [==============================] - 1s 871us/step - loss: 0.0552 - val_loss: 0.0779\n",
      "Epoch 1254/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0553 - val_loss: 0.0785\n",
      "Epoch 1255/1500\n",
      "603/603 [==============================] - 0s 827us/step - loss: 0.0552 - val_loss: 0.0781\n",
      "Epoch 1256/1500\n",
      "603/603 [==============================] - 0s 736us/step - loss: 0.0553 - val_loss: 0.0783\n",
      "Epoch 1257/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0551 - val_loss: 0.0781\n",
      "Epoch 1258/1500\n",
      "603/603 [==============================] - 1s 859us/step - loss: 0.0551 - val_loss: 0.0783\n",
      "Epoch 1259/1500\n",
      "603/603 [==============================] - 0s 758us/step - loss: 0.0553 - val_loss: 0.0783\n",
      "Epoch 1260/1500\n",
      "603/603 [==============================] - 0s 813us/step - loss: 0.0552 - val_loss: 0.0783\n",
      "Epoch 1261/1500\n",
      "603/603 [==============================] - 1s 872us/step - loss: 0.0552 - val_loss: 0.0782\n",
      "Epoch 1262/1500\n",
      "603/603 [==============================] - 1s 850us/step - loss: 0.0553 - val_loss: 0.0781\n",
      "Epoch 1263/1500\n",
      "603/603 [==============================] - 0s 818us/step - loss: 0.0551 - val_loss: 0.0787\n",
      "Epoch 1264/1500\n",
      "603/603 [==============================] - 0s 824us/step - loss: 0.0550 - val_loss: 0.0783\n",
      "Epoch 1265/1500\n",
      "603/603 [==============================] - 1s 926us/step - loss: 0.0551 - val_loss: 0.0784\n",
      "Epoch 1266/1500\n",
      "603/603 [==============================] - 0s 721us/step - loss: 0.0552 - val_loss: 0.0781\n",
      "Epoch 1267/1500\n",
      "603/603 [==============================] - 0s 651us/step - loss: 0.0551 - val_loss: 0.0783\n",
      "Epoch 1268/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0550 - val_loss: 0.0780\n",
      "Epoch 1269/1500\n",
      "603/603 [==============================] - 0s 691us/step - loss: 0.0551 - val_loss: 0.0783\n",
      "Epoch 1270/1500\n",
      "603/603 [==============================] - 0s 670us/step - loss: 0.0551 - val_loss: 0.0779\n",
      "Epoch 1271/1500\n",
      "603/603 [==============================] - 0s 785us/step - loss: 0.0551 - val_loss: 0.0789\n",
      "Epoch 1272/1500\n",
      "603/603 [==============================] - 0s 739us/step - loss: 0.0550 - val_loss: 0.0783\n",
      "Epoch 1273/1500\n",
      "603/603 [==============================] - 0s 800us/step - loss: 0.0549 - val_loss: 0.0781\n",
      "Epoch 1274/1500\n",
      "603/603 [==============================] - 0s 744us/step - loss: 0.0550 - val_loss: 0.0781\n",
      "Epoch 1275/1500\n",
      "603/603 [==============================] - 0s 666us/step - loss: 0.0549 - val_loss: 0.0779\n",
      "Epoch 1276/1500\n",
      "603/603 [==============================] - 0s 759us/step - loss: 0.0550 - val_loss: 0.0784\n",
      "Epoch 1277/1500\n",
      "603/603 [==============================] - 1s 889us/step - loss: 0.0552 - val_loss: 0.0787\n",
      "Epoch 1278/1500\n",
      "603/603 [==============================] - 0s 788us/step - loss: 0.0551 - val_loss: 0.0779\n",
      "Epoch 1279/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0550 - val_loss: 0.0782\n",
      "Epoch 1280/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0548 - val_loss: 0.0782\n",
      "Epoch 1281/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0549 - val_loss: 0.0787\n",
      "Epoch 1282/1500\n",
      "603/603 [==============================] - 0s 766us/step - loss: 0.0549 - val_loss: 0.0783\n",
      "Epoch 1283/1500\n",
      "603/603 [==============================] - 1s 933us/step - loss: 0.0549 - val_loss: 0.0786\n",
      "Epoch 1284/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0550 - val_loss: 0.0787\n",
      "Epoch 1285/1500\n",
      "603/603 [==============================] - 1s 993us/step - loss: 0.0548 - val_loss: 0.0784\n",
      "Epoch 1286/1500\n",
      "603/603 [==============================] - 1s 867us/step - loss: 0.0548 - val_loss: 0.0786\n",
      "Epoch 1287/1500\n",
      "603/603 [==============================] - 1s 836us/step - loss: 0.0550 - val_loss: 0.0784\n",
      "Epoch 1288/1500\n",
      "603/603 [==============================] - 1s 909us/step - loss: 0.0548 - val_loss: 0.0782\n",
      "Epoch 1289/1500\n",
      "603/603 [==============================] - 0s 794us/step - loss: 0.0549 - val_loss: 0.0788\n",
      "Epoch 1290/1500\n",
      "603/603 [==============================] - 1s 910us/step - loss: 0.0548 - val_loss: 0.0783\n",
      "Epoch 1291/1500\n",
      "603/603 [==============================] - 1s 903us/step - loss: 0.0549 - val_loss: 0.0787\n",
      "Epoch 1292/1500\n",
      "603/603 [==============================] - 0s 754us/step - loss: 0.0549 - val_loss: 0.0783\n",
      "Epoch 1293/1500\n",
      "603/603 [==============================] - 1s 901us/step - loss: 0.0549 - val_loss: 0.0785\n",
      "Epoch 1294/1500\n",
      "603/603 [==============================] - 0s 786us/step - loss: 0.0550 - val_loss: 0.0786\n",
      "Epoch 1295/1500\n",
      "603/603 [==============================] - 0s 676us/step - loss: 0.0547 - val_loss: 0.0783\n",
      "Epoch 1296/1500\n",
      "603/603 [==============================] - 0s 805us/step - loss: 0.0547 - val_loss: 0.0783\n",
      "Epoch 1297/1500\n",
      "603/603 [==============================] - 0s 794us/step - loss: 0.0547 - val_loss: 0.0783\n",
      "Epoch 1298/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0546 - val_loss: 0.0785\n",
      "Epoch 1299/1500\n",
      "603/603 [==============================] - 1s 841us/step - loss: 0.0549 - val_loss: 0.0789\n",
      "Epoch 1300/1500\n",
      "603/603 [==============================] - 0s 816us/step - loss: 0.0548 - val_loss: 0.0790\n",
      "Epoch 1301/1500\n",
      "603/603 [==============================] - 1s 913us/step - loss: 0.0549 - val_loss: 0.0790\n",
      "Epoch 1302/1500\n",
      "603/603 [==============================] - 1s 955us/step - loss: 0.0548 - val_loss: 0.0785\n",
      "Epoch 1303/1500\n",
      "603/603 [==============================] - 1s 943us/step - loss: 0.0547 - val_loss: 0.0789\n",
      "Epoch 1304/1500\n",
      "603/603 [==============================] - 1s 865us/step - loss: 0.0546 - val_loss: 0.0786\n",
      "Epoch 1305/1500\n",
      "603/603 [==============================] - 0s 815us/step - loss: 0.0548 - val_loss: 0.0787\n",
      "Epoch 1306/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0548 - val_loss: 0.0786\n",
      "Epoch 1307/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0546 - val_loss: 0.0784\n",
      "Epoch 1308/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0544 - val_loss: 0.0788\n",
      "Epoch 1309/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0546 - val_loss: 0.0788\n",
      "Epoch 1310/1500\n",
      "603/603 [==============================] - 1s 924us/step - loss: 0.0546 - val_loss: 0.0786\n",
      "Epoch 1311/1500\n",
      "603/603 [==============================] - 0s 812us/step - loss: 0.0547 - val_loss: 0.0787\n",
      "Epoch 1312/1500\n",
      "603/603 [==============================] - 0s 746us/step - loss: 0.0546 - val_loss: 0.0784\n",
      "Epoch 1313/1500\n",
      "603/603 [==============================] - 0s 738us/step - loss: 0.0546 - val_loss: 0.0788\n",
      "Epoch 1314/1500\n",
      "603/603 [==============================] - 0s 781us/step - loss: 0.0547 - val_loss: 0.0785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1315/1500\n",
      "603/603 [==============================] - 0s 742us/step - loss: 0.0545 - val_loss: 0.0785\n",
      "Epoch 1316/1500\n",
      "603/603 [==============================] - 0s 818us/step - loss: 0.0546 - val_loss: 0.0788\n",
      "Epoch 1317/1500\n",
      "603/603 [==============================] - 1s 1000us/step - loss: 0.0545 - val_loss: 0.0784\n",
      "Epoch 1318/1500\n",
      "603/603 [==============================] - 0s 661us/step - loss: 0.0545 - val_loss: 0.0786\n",
      "Epoch 1319/1500\n",
      "603/603 [==============================] - 1s 837us/step - loss: 0.0546 - val_loss: 0.0785\n",
      "Epoch 1320/1500\n",
      "603/603 [==============================] - 0s 762us/step - loss: 0.0545 - val_loss: 0.0786\n",
      "Epoch 1321/1500\n",
      "603/603 [==============================] - 0s 821us/step - loss: 0.0546 - val_loss: 0.0787\n",
      "Epoch 1322/1500\n",
      "603/603 [==============================] - 0s 732us/step - loss: 0.0545 - val_loss: 0.0785\n",
      "Epoch 1323/1500\n",
      "603/603 [==============================] - 0s 799us/step - loss: 0.0545 - val_loss: 0.0784\n",
      "Epoch 1324/1500\n",
      "603/603 [==============================] - 0s 708us/step - loss: 0.0545 - val_loss: 0.0786\n",
      "Epoch 1325/1500\n",
      "603/603 [==============================] - 0s 731us/step - loss: 0.0545 - val_loss: 0.0785\n",
      "Epoch 1326/1500\n",
      "603/603 [==============================] - 0s 756us/step - loss: 0.0546 - val_loss: 0.0788\n",
      "Epoch 1327/1500\n",
      "603/603 [==============================] - 0s 759us/step - loss: 0.0545 - val_loss: 0.0786\n",
      "Epoch 1328/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0544 - val_loss: 0.0784\n",
      "Epoch 1329/1500\n",
      "603/603 [==============================] - 0s 771us/step - loss: 0.0543 - val_loss: 0.0792\n",
      "Epoch 1330/1500\n",
      "603/603 [==============================] - 1s 830us/step - loss: 0.0544 - val_loss: 0.0786\n",
      "Epoch 1331/1500\n",
      "603/603 [==============================] - 1s 853us/step - loss: 0.0542 - val_loss: 0.0790\n",
      "Epoch 1332/1500\n",
      "603/603 [==============================] - 1s 829us/step - loss: 0.0544 - val_loss: 0.0790\n",
      "Epoch 1333/1500\n",
      "603/603 [==============================] - 0s 714us/step - loss: 0.0545 - val_loss: 0.0784\n",
      "Epoch 1334/1500\n",
      "603/603 [==============================] - 0s 647us/step - loss: 0.0545 - val_loss: 0.0789\n",
      "Epoch 1335/1500\n",
      "603/603 [==============================] - 0s 695us/step - loss: 0.0544 - val_loss: 0.0792\n",
      "Epoch 1336/1500\n",
      "603/603 [==============================] - 0s 747us/step - loss: 0.0544 - val_loss: 0.0791\n",
      "Epoch 1337/1500\n",
      "603/603 [==============================] - 0s 724us/step - loss: 0.0545 - val_loss: 0.0793\n",
      "Epoch 1338/1500\n",
      "603/603 [==============================] - 0s 804us/step - loss: 0.0545 - val_loss: 0.0790\n",
      "Epoch 1339/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0544 - val_loss: 0.0790\n",
      "Epoch 1340/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0546 - val_loss: 0.0787\n",
      "Epoch 1341/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0543 - val_loss: 0.0785\n",
      "Epoch 1342/1500\n",
      "603/603 [==============================] - 0s 742us/step - loss: 0.0544 - val_loss: 0.0793\n",
      "Epoch 1343/1500\n",
      "603/603 [==============================] - 0s 767us/step - loss: 0.0544 - val_loss: 0.0788\n",
      "Epoch 1344/1500\n",
      "603/603 [==============================] - 0s 739us/step - loss: 0.0543 - val_loss: 0.0788\n",
      "Epoch 1345/1500\n",
      "603/603 [==============================] - 0s 737us/step - loss: 0.0545 - val_loss: 0.0791\n",
      "Epoch 1346/1500\n",
      "603/603 [==============================] - 0s 679us/step - loss: 0.0543 - val_loss: 0.0789\n",
      "Epoch 1347/1500\n",
      "603/603 [==============================] - 1s 855us/step - loss: 0.0544 - val_loss: 0.0793\n",
      "Epoch 1348/1500\n",
      "603/603 [==============================] - 0s 686us/step - loss: 0.0543 - val_loss: 0.0792\n",
      "Epoch 1349/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0544 - val_loss: 0.0791\n",
      "Epoch 1350/1500\n",
      "603/603 [==============================] - 0s 714us/step - loss: 0.0542 - val_loss: 0.0791\n",
      "Epoch 1351/1500\n",
      "603/603 [==============================] - 0s 807us/step - loss: 0.0544 - val_loss: 0.0786\n",
      "Epoch 1352/1500\n",
      "603/603 [==============================] - 0s 740us/step - loss: 0.0542 - val_loss: 0.0788\n",
      "Epoch 1353/1500\n",
      "603/603 [==============================] - 0s 711us/step - loss: 0.0544 - val_loss: 0.0786\n",
      "Epoch 1354/1500\n",
      "603/603 [==============================] - 0s 723us/step - loss: 0.0542 - val_loss: 0.0793\n",
      "Epoch 1355/1500\n",
      "603/603 [==============================] - 0s 660us/step - loss: 0.0540 - val_loss: 0.0788\n",
      "Epoch 1356/1500\n",
      "603/603 [==============================] - 0s 673us/step - loss: 0.0540 - val_loss: 0.0789\n",
      "Epoch 1357/1500\n",
      "603/603 [==============================] - 0s 724us/step - loss: 0.0540 - val_loss: 0.0786\n",
      "Epoch 1358/1500\n",
      "603/603 [==============================] - 0s 664us/step - loss: 0.0543 - val_loss: 0.0793\n",
      "Epoch 1359/1500\n",
      "603/603 [==============================] - 0s 773us/step - loss: 0.0542 - val_loss: 0.0793\n",
      "Epoch 1360/1500\n",
      "603/603 [==============================] - 1s 986us/step - loss: 0.0543 - val_loss: 0.0786\n",
      "Epoch 1361/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0543 - val_loss: 0.0790\n",
      "Epoch 1362/1500\n",
      "603/603 [==============================] - 0s 748us/step - loss: 0.0542 - val_loss: 0.0789\n",
      "Epoch 1363/1500\n",
      "603/603 [==============================] - 0s 782us/step - loss: 0.0541 - val_loss: 0.0791\n",
      "Epoch 1364/1500\n",
      "603/603 [==============================] - 0s 698us/step - loss: 0.0542 - val_loss: 0.0789\n",
      "Epoch 1365/1500\n",
      "603/603 [==============================] - 0s 673us/step - loss: 0.0541 - val_loss: 0.0789\n",
      "Epoch 1366/1500\n",
      "603/603 [==============================] - 1s 834us/step - loss: 0.0541 - val_loss: 0.0788\n",
      "Epoch 1367/1500\n",
      "603/603 [==============================] - 0s 746us/step - loss: 0.0541 - val_loss: 0.0788\n",
      "Epoch 1368/1500\n",
      "603/603 [==============================] - 0s 626us/step - loss: 0.0543 - val_loss: 0.0791\n",
      "Epoch 1369/1500\n",
      "603/603 [==============================] - 0s 818us/step - loss: 0.0541 - val_loss: 0.0791\n",
      "Epoch 1370/1500\n",
      "603/603 [==============================] - 1s 858us/step - loss: 0.0541 - val_loss: 0.0791\n",
      "Epoch 1371/1500\n",
      "603/603 [==============================] - 1s 990us/step - loss: 0.0541 - val_loss: 0.0787\n",
      "Epoch 1372/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0540 - val_loss: 0.0794\n",
      "Epoch 1373/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0541 - val_loss: 0.0787\n",
      "Epoch 1374/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0539 - val_loss: 0.0788\n",
      "Epoch 1375/1500\n",
      "603/603 [==============================] - 0s 694us/step - loss: 0.0540 - val_loss: 0.0793\n",
      "Epoch 1376/1500\n",
      "603/603 [==============================] - 0s 625us/step - loss: 0.0540 - val_loss: 0.0788\n",
      "Epoch 1377/1500\n",
      "603/603 [==============================] - 0s 689us/step - loss: 0.0540 - val_loss: 0.0791\n",
      "Epoch 1378/1500\n",
      "603/603 [==============================] - 0s 789us/step - loss: 0.0539 - val_loss: 0.0791\n",
      "Epoch 1379/1500\n",
      "603/603 [==============================] - 1s 911us/step - loss: 0.0540 - val_loss: 0.0789\n",
      "Epoch 1380/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0539 - val_loss: 0.0795\n",
      "Epoch 1381/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0540 - val_loss: 0.0792\n",
      "Epoch 1382/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0539 - val_loss: 0.0788\n",
      "Epoch 1383/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0538 - val_loss: 0.0791\n",
      "Epoch 1384/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0540 - val_loss: 0.0789\n",
      "Epoch 1385/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0540 - val_loss: 0.0791\n",
      "Epoch 1386/1500\n",
      "603/603 [==============================] - 1s 887us/step - loss: 0.0538 - val_loss: 0.0789\n",
      "Epoch 1387/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0538 - val_loss: 0.0794\n",
      "Epoch 1388/1500\n",
      "603/603 [==============================] - 0s 686us/step - loss: 0.0539 - val_loss: 0.0792\n",
      "Epoch 1389/1500\n",
      "603/603 [==============================] - 0s 691us/step - loss: 0.0541 - val_loss: 0.0789\n",
      "Epoch 1390/1500\n",
      "603/603 [==============================] - 0s 678us/step - loss: 0.0540 - val_loss: 0.0792\n",
      "Epoch 1391/1500\n",
      "603/603 [==============================] - 0s 738us/step - loss: 0.0540 - val_loss: 0.0796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1392/1500\n",
      "603/603 [==============================] - 0s 674us/step - loss: 0.0538 - val_loss: 0.0793\n",
      "Epoch 1393/1500\n",
      "603/603 [==============================] - 0s 749us/step - loss: 0.0541 - val_loss: 0.0792\n",
      "Epoch 1394/1500\n",
      "603/603 [==============================] - 0s 751us/step - loss: 0.0541 - val_loss: 0.0793\n",
      "Epoch 1395/1500\n",
      "603/603 [==============================] - 0s 818us/step - loss: 0.0538 - val_loss: 0.0792\n",
      "Epoch 1396/1500\n",
      "603/603 [==============================] - 1s 875us/step - loss: 0.0538 - val_loss: 0.0791\n",
      "Epoch 1397/1500\n",
      "603/603 [==============================] - 0s 776us/step - loss: 0.0538 - val_loss: 0.0789\n",
      "Epoch 1398/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0536 - val_loss: 0.0792\n",
      "Epoch 1399/1500\n",
      "603/603 [==============================] - 1s 918us/step - loss: 0.0537 - val_loss: 0.0789\n",
      "Epoch 1400/1500\n",
      "603/603 [==============================] - 1s 882us/step - loss: 0.0536 - val_loss: 0.0797\n",
      "Epoch 1401/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0539 - val_loss: 0.0789\n",
      "Epoch 1402/1500\n",
      "603/603 [==============================] - 0s 675us/step - loss: 0.0537 - val_loss: 0.0795\n",
      "Epoch 1403/1500\n",
      "603/603 [==============================] - 0s 706us/step - loss: 0.0538 - val_loss: 0.0792\n",
      "Epoch 1404/1500\n",
      "603/603 [==============================] - 0s 826us/step - loss: 0.0539 - val_loss: 0.0795\n",
      "Epoch 1405/1500\n",
      "603/603 [==============================] - 0s 651us/step - loss: 0.0537 - val_loss: 0.0793\n",
      "Epoch 1406/1500\n",
      "603/603 [==============================] - 0s 722us/step - loss: 0.0538 - val_loss: 0.0795\n",
      "Epoch 1407/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0536 - val_loss: 0.0791\n",
      "Epoch 1408/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0537 - val_loss: 0.0795\n",
      "Epoch 1409/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0538 - val_loss: 0.0792\n",
      "Epoch 1410/1500\n",
      "603/603 [==============================] - 0s 702us/step - loss: 0.0536 - val_loss: 0.0789\n",
      "Epoch 1411/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0537 - val_loss: 0.0789\n",
      "Epoch 1412/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0536 - val_loss: 0.0791\n",
      "Epoch 1413/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0537 - val_loss: 0.0794\n",
      "Epoch 1414/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0536 - val_loss: 0.0791\n",
      "Epoch 1415/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0535 - val_loss: 0.0789\n",
      "Epoch 1416/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0536 - val_loss: 0.0794\n",
      "Epoch 1417/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0538 - val_loss: 0.0798\n",
      "Epoch 1418/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0536 - val_loss: 0.0796\n",
      "Epoch 1419/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0538 - val_loss: 0.0797\n",
      "Epoch 1420/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0537 - val_loss: 0.0791\n",
      "Epoch 1421/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0535 - val_loss: 0.0791\n",
      "Epoch 1422/1500\n",
      "603/603 [==============================] - 0s 769us/step - loss: 0.0535 - val_loss: 0.0793\n",
      "Epoch 1423/1500\n",
      "603/603 [==============================] - 1s 847us/step - loss: 0.0535 - val_loss: 0.0789\n",
      "Epoch 1424/1500\n",
      "603/603 [==============================] - 0s 652us/step - loss: 0.0536 - val_loss: 0.0796\n",
      "Epoch 1425/1500\n",
      "603/603 [==============================] - 0s 645us/step - loss: 0.0536 - val_loss: 0.0793\n",
      "Epoch 1426/1500\n",
      "603/603 [==============================] - 0s 553us/step - loss: 0.0537 - val_loss: 0.0795\n",
      "Epoch 1427/1500\n",
      "603/603 [==============================] - 0s 556us/step - loss: 0.0538 - val_loss: 0.0796\n",
      "Epoch 1428/1500\n",
      "603/603 [==============================] - 0s 620us/step - loss: 0.0536 - val_loss: 0.0793\n",
      "Epoch 1429/1500\n",
      "603/603 [==============================] - 0s 791us/step - loss: 0.0535 - val_loss: 0.0794\n",
      "Epoch 1430/1500\n",
      "603/603 [==============================] - 1s 970us/step - loss: 0.0535 - val_loss: 0.0793\n",
      "Epoch 1431/1500\n",
      "603/603 [==============================] - 0s 681us/step - loss: 0.0536 - val_loss: 0.0795\n",
      "Epoch 1432/1500\n",
      "603/603 [==============================] - 0s 578us/step - loss: 0.0536 - val_loss: 0.0794\n",
      "Epoch 1433/1500\n",
      "603/603 [==============================] - 0s 614us/step - loss: 0.0536 - val_loss: 0.0794\n",
      "Epoch 1434/1500\n",
      "603/603 [==============================] - 0s 626us/step - loss: 0.0536 - val_loss: 0.0798\n",
      "Epoch 1435/1500\n",
      "603/603 [==============================] - 0s 619us/step - loss: 0.0536 - val_loss: 0.0793\n",
      "Epoch 1436/1500\n",
      "603/603 [==============================] - 0s 666us/step - loss: 0.0535 - val_loss: 0.0797\n",
      "Epoch 1437/1500\n",
      "603/603 [==============================] - 0s 552us/step - loss: 0.0534 - val_loss: 0.0796\n",
      "Epoch 1438/1500\n",
      "603/603 [==============================] - 0s 629us/step - loss: 0.0534 - val_loss: 0.0797\n",
      "Epoch 1439/1500\n",
      "603/603 [==============================] - 0s 609us/step - loss: 0.0535 - val_loss: 0.0793\n",
      "Epoch 1440/1500\n",
      "603/603 [==============================] - 0s 545us/step - loss: 0.0535 - val_loss: 0.0795\n",
      "Epoch 1441/1500\n",
      "603/603 [==============================] - 0s 635us/step - loss: 0.0533 - val_loss: 0.0791\n",
      "Epoch 1442/1500\n",
      "603/603 [==============================] - 0s 651us/step - loss: 0.0534 - val_loss: 0.0795\n",
      "Epoch 1443/1500\n",
      "603/603 [==============================] - 0s 718us/step - loss: 0.0535 - val_loss: 0.0795\n",
      "Epoch 1444/1500\n",
      "603/603 [==============================] - 1s 895us/step - loss: 0.0536 - val_loss: 0.0797\n",
      "Epoch 1445/1500\n",
      "603/603 [==============================] - 0s 680us/step - loss: 0.0536 - val_loss: 0.0797\n",
      "Epoch 1446/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0535 - val_loss: 0.0795\n",
      "Epoch 1447/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0534 - val_loss: 0.0797\n",
      "Epoch 1448/1500\n",
      "603/603 [==============================] - 0s 598us/step - loss: 0.0534 - val_loss: 0.0796\n",
      "Epoch 1449/1500\n",
      "603/603 [==============================] - 0s 628us/step - loss: 0.0536 - val_loss: 0.0798\n",
      "Epoch 1450/1500\n",
      "603/603 [==============================] - 0s 585us/step - loss: 0.0535 - val_loss: 0.0795\n",
      "Epoch 1451/1500\n",
      "603/603 [==============================] - 0s 656us/step - loss: 0.0535 - val_loss: 0.0794\n",
      "Epoch 1452/1500\n",
      "603/603 [==============================] - 0s 664us/step - loss: 0.0534 - val_loss: 0.0794\n",
      "Epoch 1453/1500\n",
      "603/603 [==============================] - 0s 690us/step - loss: 0.0533 - val_loss: 0.0793\n",
      "Epoch 1454/1500\n",
      "603/603 [==============================] - 0s 641us/step - loss: 0.0533 - val_loss: 0.0793\n",
      "Epoch 1455/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0533 - val_loss: 0.0794\n",
      "Epoch 1456/1500\n",
      "603/603 [==============================] - 0s 782us/step - loss: 0.0532 - val_loss: 0.0799\n",
      "Epoch 1457/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0532 - val_loss: 0.0795\n",
      "Epoch 1458/1500\n",
      "603/603 [==============================] - 0s 801us/step - loss: 0.0534 - val_loss: 0.0799\n",
      "Epoch 1459/1500\n",
      "603/603 [==============================] - 0s 641us/step - loss: 0.0533 - val_loss: 0.0796\n",
      "Epoch 1460/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0535 - val_loss: 0.0798\n",
      "Epoch 1461/1500\n",
      "603/603 [==============================] - 1s 846us/step - loss: 0.0533 - val_loss: 0.0796\n",
      "Epoch 1462/1500\n",
      "603/603 [==============================] - 0s 640us/step - loss: 0.0533 - val_loss: 0.0799\n",
      "Epoch 1463/1500\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.0533 - val_loss: 0.0796\n",
      "Epoch 1464/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0533 - val_loss: 0.0795\n",
      "Epoch 1465/1500\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.053 - 1s 2ms/step - loss: 0.0534 - val_loss: 0.0796\n",
      "Epoch 1466/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0532 - val_loss: 0.0794\n",
      "Epoch 1467/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0532 - val_loss: 0.0793\n",
      "Epoch 1468/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0532 - val_loss: 0.0794\n",
      "Epoch 1469/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0534 - val_loss: 0.0792 - ETA: 1s \n",
      "Epoch 1470/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0531 - val_loss: 0.0797\n",
      "Epoch 1471/1500\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 0.0532 - val_loss: 0.0795\n",
      "Epoch 1472/1500\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.0532 - val_loss: 0.0797\n",
      "Epoch 1473/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0532 - val_loss: 0.0802\n",
      "Epoch 1474/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0533 - val_loss: 0.0796\n",
      "Epoch 1475/1500\n",
      "603/603 [==============================] - 0s 816us/step - loss: 0.0532 - val_loss: 0.0799\n",
      "Epoch 1476/1500\n",
      "603/603 [==============================] - 1s 922us/step - loss: 0.0533 - val_loss: 0.0791\n",
      "Epoch 1477/1500\n",
      "603/603 [==============================] - 1s 941us/step - loss: 0.0533 - val_loss: 0.0796\n",
      "Epoch 1478/1500\n",
      "603/603 [==============================] - 1s 919us/step - loss: 0.0532 - val_loss: 0.0797\n",
      "Epoch 1479/1500\n",
      "603/603 [==============================] - 0s 816us/step - loss: 0.0531 - val_loss: 0.0796\n",
      "Epoch 1480/1500\n",
      "603/603 [==============================] - 0s 820us/step - loss: 0.0530 - val_loss: 0.0795\n",
      "Epoch 1481/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0534 - val_loss: 0.0793\n",
      "Epoch 1482/1500\n",
      "603/603 [==============================] - 1s 938us/step - loss: 0.0533 - val_loss: 0.0797\n",
      "Epoch 1483/1500\n",
      "603/603 [==============================] - 0s 754us/step - loss: 0.0532 - val_loss: 0.0799\n",
      "Epoch 1484/1500\n",
      "603/603 [==============================] - 1s 900us/step - loss: 0.0531 - val_loss: 0.0794\n",
      "Epoch 1485/1500\n",
      "603/603 [==============================] - 0s 770us/step - loss: 0.0531 - val_loss: 0.0799\n",
      "Epoch 1486/1500\n",
      "603/603 [==============================] - 0s 790us/step - loss: 0.0533 - val_loss: 0.0800\n",
      "Epoch 1487/1500\n",
      "603/603 [==============================] - 1s 927us/step - loss: 0.0531 - val_loss: 0.0794\n",
      "Epoch 1488/1500\n",
      "603/603 [==============================] - 0s 818us/step - loss: 0.0530 - val_loss: 0.0797\n",
      "Epoch 1489/1500\n",
      "603/603 [==============================] - 0s 738us/step - loss: 0.0530 - val_loss: 0.0805\n",
      "Epoch 1490/1500\n",
      "603/603 [==============================] - ETA: 0s - loss: 0.053 - 1s 889us/step - loss: 0.0533 - val_loss: 0.0797\n",
      "Epoch 1491/1500\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.0530 - val_loss: 0.0794\n",
      "Epoch 1492/1500\n",
      "603/603 [==============================] - 0s 825us/step - loss: 0.0531 - val_loss: 0.0793\n",
      "Epoch 1493/1500\n",
      "603/603 [==============================] - 0s 733us/step - loss: 0.0531 - val_loss: 0.0796\n",
      "Epoch 1494/1500\n",
      "603/603 [==============================] - 1s 894us/step - loss: 0.0532 - val_loss: 0.0794\n",
      "Epoch 1495/1500\n",
      "603/603 [==============================] - 0s 784us/step - loss: 0.0532 - val_loss: 0.0798\n",
      "Epoch 1496/1500\n",
      "603/603 [==============================] - 0s 740us/step - loss: 0.0530 - val_loss: 0.0800\n",
      "Epoch 1497/1500\n",
      "603/603 [==============================] - 0s 724us/step - loss: 0.0531 - val_loss: 0.0799\n",
      "Epoch 1498/1500\n",
      "603/603 [==============================] - 0s 769us/step - loss: 0.0530 - val_loss: 0.0798\n",
      "Epoch 1499/1500\n",
      "603/603 [==============================] - 0s 719us/step - loss: 0.0529 - val_loss: 0.0798\n",
      "Epoch 1500/1500\n",
      "603/603 [==============================] - 1s 990us/step - loss: 0.0528 - val_loss: 0.0800\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sa_data = pd.ExcelFile(\"SAAutoencoderGilmore.xlsx\") \n",
    "parsee = sa_data.sheet_names[0]\n",
    "data = sa_data.parse(parsee)\n",
    "data_features = data.loc[:, data.columns] \n",
    "data_features = data_features.drop(['ROI',11142,12142], axis=1)  \n",
    "scaled_data = scaler.transform(data_features)\n",
    "\n",
    "encoder = Model(input_data, encoded)\n",
    "encoded_data = encoder.predict(scaled_data)\n",
    "#I now have scaled data as encoded which is my input. This will compare predictions to my scaled_data.\n",
    "Y_train, Y_test = train_test_split(scaled_data, test_size=0.10, random_state=20) #Scaled data I want to compare to\n",
    "X_train, X_test = train_test_split(encoded_data, test_size=0.10, random_state=20) #Encoded data I will input\n",
    "\n",
    "dinput_size = 27\n",
    "hidden_size1 = 57\n",
    "hidden_size2 = 88\n",
    "hidden_size3 = 119\n",
    "decoded_dim = 148\n",
    "dinput_data = Input(shape=(dinput_size,))\n",
    "dhidden_d_1 = Dense(hidden_size1, activation='tanh')(dinput_data)\n",
    "dhidden_d_2 = Dense(hidden_size2, activation='tanh')(dhidden_d_1)\n",
    "dhidden_d_3 = Dense(hidden_size3, activation='tanh')(dhidden_d_2)\n",
    "predictedSA = Dense(decoded_dim, activation='tanh')(dhidden_d_3)\n",
    "\n",
    "predictor = Model(dinput_data, predictedSA)\n",
    "predictor.compile(optimizer='Adam', loss='mean_absolute_error')\n",
    "pn = predictor.fit(X_train, Y_train,\n",
    "epochs=1500,\n",
    "batch_size=15,\n",
    "shuffle=True,\n",
    "validation_data=(X_test, Y_test))\n",
    "\n",
    "#print(ac.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(pn.history['loss'])\n",
    "plt.plot(pn.history['val_loss'])\n",
    "#plt.set(xlim=(0, 50), ylim=(0.0, 1.0))\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, 1500, 0.0, 0.15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
