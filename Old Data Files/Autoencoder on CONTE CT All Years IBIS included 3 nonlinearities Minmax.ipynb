{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import losses\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import DataFrame\n",
    "import xlsxwriter\n",
    "\n",
    "\n",
    "\n",
    "#Bring in all data for all years. This notebook contains Joseph's classifiers from 0-3 for risk groups. Col 151 is risk groups.\n",
    "ct_sheet = pd.ExcelFile(\"SA_and_CT_AALandfROI_08272019.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destrieux_CT\n"
     ]
    }
   ],
   "source": [
    "print(ct_sheet.sheet_names[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1122 09:41:00.511995 19940 deprecation_wrapper.py:119] From C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1122 09:41:00.611241 19940 deprecation_wrapper.py:119] From C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1122 09:41:00.640990 19940 deprecation_wrapper.py:119] From C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1888, 148)\n",
      "Tensor(\"input_1:0\", shape=(?, 148), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1122 09:41:01.381709 19940 deprecation_wrapper.py:119] From C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1122 09:41:02.543722 19940 deprecation_wrapper.py:119] From C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W1122 09:41:04.923764 19940 deprecation_wrapper.py:119] From C:\\Users\\mattbeze\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1699 samples, validate on 189 samples\n",
      "Epoch 1/1500\n",
      "1699/1699 [==============================] - 12s 7ms/step - loss: 0.1073 - val_loss: 0.0794\n",
      "Epoch 2/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0786 - val_loss: 0.0732\n",
      "Epoch 3/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0743 - val_loss: 0.0701\n",
      "Epoch 4/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0705 - val_loss: 0.0688\n",
      "Epoch 5/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0691 - val_loss: 0.0677\n",
      "Epoch 6/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0676 - val_loss: 0.0655\n",
      "Epoch 7/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0670 - val_loss: 0.0653\n",
      "Epoch 8/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0655 - val_loss: 0.0646\n",
      "Epoch 9/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0649 - val_loss: 0.0644\n",
      "Epoch 10/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0641 - val_loss: 0.0635\n",
      "Epoch 11/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0639 - val_loss: 0.0637\n",
      "Epoch 12/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0639 - val_loss: 0.0623\n",
      "Epoch 13/1500\n",
      "1699/1699 [==============================] - 6s 3ms/step - loss: 0.0632 - val_loss: 0.0634\n",
      "Epoch 14/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0630 - val_loss: 0.0629\n",
      "Epoch 15/1500\n",
      "1699/1699 [==============================] - 5s 3ms/step - loss: 0.0626 - val_loss: 0.0623\n",
      "Epoch 16/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0622 - val_loss: 0.0629\n",
      "Epoch 17/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0627 - val_loss: 0.0624\n",
      "Epoch 18/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0626 - val_loss: 0.0612\n",
      "Epoch 19/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0622 - val_loss: 0.0623\n",
      "Epoch 20/1500\n",
      "1699/1699 [==============================] - 3s 1ms/step - loss: 0.0618 - val_loss: 0.0612\n",
      "Epoch 21/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0619 - val_loss: 0.0614\n",
      "Epoch 22/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0626 - val_loss: 0.0620\n",
      "Epoch 23/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0615 - val_loss: 0.0618\n",
      "Epoch 24/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0614 - val_loss: 0.0610\n",
      "Epoch 25/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0613 - val_loss: 0.0607\n",
      "Epoch 26/1500\n",
      "1699/1699 [==============================] - 2s 974us/step - loss: 0.0610 - val_loss: 0.0610\n",
      "Epoch 27/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0612 - val_loss: 0.0609\n",
      "Epoch 28/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0609 - val_loss: 0.0606\n",
      "Epoch 29/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0608 - val_loss: 0.0648\n",
      "Epoch 30/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0617 - val_loss: 0.0606\n",
      "Epoch 31/1500\n",
      "1699/1699 [==============================] - ETA: 0s - loss: 0.0607 - ETA: 0s - loss: 0.06 - 3s 2ms/step - loss: 0.0607 - val_loss: 0.0603\n",
      "Epoch 32/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0609 - val_loss: 0.0601\n",
      "Epoch 33/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0607 - val_loss: 0.0607\n",
      "Epoch 34/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0610 - val_loss: 0.0607\n",
      "Epoch 35/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0608 - val_loss: 0.0601\n",
      "Epoch 36/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0607 - val_loss: 0.0620\n",
      "Epoch 37/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0607 - val_loss: 0.0602\n",
      "Epoch 38/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0605 - val_loss: 0.0603\n",
      "Epoch 39/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0606 - val_loss: 0.0614\n",
      "Epoch 40/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0606 - val_loss: 0.0599\n",
      "Epoch 41/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0605 - val_loss: 0.0597\n",
      "Epoch 42/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0607 - val_loss: 0.0606 - ETA: 0s - \n",
      "Epoch 43/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0607 - val_loss: 0.0602\n",
      "Epoch 44/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0603 - val_loss: 0.0602\n",
      "Epoch 45/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0605 - val_loss: 0.0604\n",
      "Epoch 46/1500\n",
      "1699/1699 [==============================] - 2s 923us/step - loss: 0.0603 - val_loss: 0.0599\n",
      "Epoch 47/1500\n",
      "1699/1699 [==============================] - 2s 946us/step - loss: 0.0612 - val_loss: 0.0599\n",
      "Epoch 48/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0603 - val_loss: 0.0615\n",
      "Epoch 49/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0602 - val_loss: 0.0599\n",
      "Epoch 50/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0604 - val_loss: 0.0603\n",
      "Epoch 51/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0604 - val_loss: 0.0601\n",
      "Epoch 52/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0601 - val_loss: 0.0601\n",
      "Epoch 53/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0606 - val_loss: 0.0601\n",
      "Epoch 54/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0602 - val_loss: 0.0599\n",
      "Epoch 55/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0601 - val_loss: 0.0596\n",
      "Epoch 56/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0603 - val_loss: 0.0620\n",
      "Epoch 57/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0606 - val_loss: 0.0602\n",
      "Epoch 58/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0602 - val_loss: 0.0602\n",
      "Epoch 59/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0601 - val_loss: 0.0595\n",
      "Epoch 60/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0599 - val_loss: 0.0608\n",
      "Epoch 61/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0601 - val_loss: 0.0598\n",
      "Epoch 62/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0601 - val_loss: 0.0596\n",
      "Epoch 63/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0599 - val_loss: 0.0594\n",
      "Epoch 64/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0600 - val_loss: 0.0598\n",
      "Epoch 65/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0601 - val_loss: 0.0599\n",
      "Epoch 66/1500\n",
      "1699/1699 [==============================] - 2s 940us/step - loss: 0.0600 - val_loss: 0.0595\n",
      "Epoch 67/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0601 - val_loss: 0.0602\n",
      "Epoch 68/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0608 - val_loss: 0.0595\n",
      "Epoch 69/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0598 - val_loss: 0.0600\n",
      "Epoch 70/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0599 - val_loss: 0.0594\n",
      "Epoch 71/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0598 - val_loss: 0.0598\n",
      "Epoch 72/1500\n",
      "1699/1699 [==============================] - 5s 3ms/step - loss: 0.0601 - val_loss: 0.0609\n",
      "Epoch 73/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0609 - val_loss: 0.0604\n",
      "Epoch 74/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0601 - val_loss: 0.0599\n",
      "Epoch 75/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0597 - val_loss: 0.0597 - loss: - ETA: 0s - loss: 0.0\n",
      "Epoch 76/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0599 - val_loss: 0.0593\n",
      "Epoch 77/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0599 - val_loss: 0.0597\n",
      "Epoch 78/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0600 - val_loss: 0.0598\n",
      "Epoch 79/1500\n",
      "1699/1699 [==============================] - 4s 3ms/step - loss: 0.0599 - val_loss: 0.0596\n",
      "Epoch 80/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0597 - val_loss: 0.0596:\n",
      "Epoch 81/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0596 - val_loss: 0.0596\n",
      "Epoch 82/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0599 - val_loss: 0.0597\n",
      "Epoch 83/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0599 - val_loss: 0.0598\n",
      "Epoch 84/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0596 - val_loss: 0.0598- ETA: 1 - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.\n",
      "Epoch 85/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0595 - val_loss: 0.0594\n",
      "Epoch 86/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0596 - val_loss: 0.0595\n",
      "Epoch 87/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0596 - val_loss: 0.0598\n",
      "Epoch 88/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0599 - val_loss: 0.0595\n",
      "Epoch 89/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0596 - val_loss: 0.0616\n",
      "Epoch 90/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0606 - val_loss: 0.0598\n",
      "Epoch 91/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0596 - val_loss: 0.0593\n",
      "Epoch 92/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0595 - val_loss: 0.0597\n",
      "Epoch 93/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0596 - val_loss: 0.0600\n",
      "Epoch 94/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0597 - val_loss: 0.0596\n",
      "Epoch 95/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0595 - val_loss: 0.0593\n",
      "Epoch 96/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0596 - val_loss: 0.0601\n",
      "Epoch 97/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0594 - val_loss: 0.0598\n",
      "Epoch 98/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0595 - val_loss: 0.0594\n",
      "Epoch 99/1500\n",
      "1699/1699 [==============================] - 4s 3ms/step - loss: 0.0597 - val_loss: 0.0597\n",
      "Epoch 100/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0597 - val_loss: 0.0597\n",
      "Epoch 101/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0596 - val_loss: 0.0598\n",
      "Epoch 102/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0593 - val_loss: 0.0597\n",
      "Epoch 103/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0594 - val_loss: 0.0594\n",
      "Epoch 104/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0593 - val_loss: 0.0593\n",
      "Epoch 105/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0593 - val_loss: 0.0599\n",
      "Epoch 106/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0593 - val_loss: 0.0597\n",
      "Epoch 107/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0594 - val_loss: 0.0593\n",
      "Epoch 108/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0595 - val_loss: 0.0596\n",
      "Epoch 109/1500\n",
      "1699/1699 [==============================] - 2s 971us/step - loss: 0.0595 - val_loss: 0.0597\n",
      "Epoch 110/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0596 - val_loss: 0.0595\n",
      "Epoch 111/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0595 - val_loss: 0.0603\n",
      "Epoch 112/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0595 - val_loss: 0.0593\n",
      "Epoch 113/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0597 - val_loss: 0.0603\n",
      "Epoch 114/1500\n",
      "1699/1699 [==============================] - 5s 3ms/step - loss: 0.0596 - val_loss: 0.0589\n",
      "Epoch 115/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0595 - val_loss: 0.0594\n",
      "Epoch 116/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0594 - val_loss: 0.0595\n",
      "Epoch 117/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0593 - val_loss: 0.0600\n",
      "Epoch 118/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0597 - val_loss: 0.0597\n",
      "Epoch 119/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0591 - val_loss: 0.0596\n",
      "Epoch 120/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0592 - val_loss: 0.0593\n",
      "Epoch 121/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0594 - val_loss: 0.0615\n",
      "Epoch 122/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0598 - val_loss: 0.0597\n",
      "Epoch 123/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0593 - val_loss: 0.0592\n",
      "Epoch 124/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0593 - val_loss: 0.0592\n",
      "Epoch 125/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0591 - val_loss: 0.0597\n",
      "Epoch 126/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0591 - val_loss: 0.0590\n",
      "Epoch 127/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0589 - val_loss: 0.0599\n",
      "Epoch 128/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0595 - val_loss: 0.0596\n",
      "Epoch 129/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0593 - val_loss: 0.0591\n",
      "Epoch 130/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0591 - val_loss: 0.0591\n",
      "Epoch 131/1500\n",
      "1699/1699 [==============================] - 3s 1ms/step - loss: 0.0590 - val_loss: 0.0590\n",
      "Epoch 132/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0591 - val_loss: 0.0593\n",
      "Epoch 133/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0590 - val_loss: 0.0593- E\n",
      "Epoch 134/1500\n",
      "1699/1699 [==============================] - 3s 1ms/step - loss: 0.0594 - val_loss: 0.0591\n",
      "Epoch 135/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0591 - val_loss: 0.0591\n",
      "Epoch 136/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0592 - val_loss: 0.0600\n",
      "Epoch 137/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0591 - val_loss: 0.0597\n",
      "Epoch 138/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0592 - val_loss: 0.0590\n",
      "Epoch 139/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0590 - val_loss: 0.0597\n",
      "Epoch 140/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0591 - val_loss: 0.0591\n",
      "Epoch 141/1500\n",
      "1699/1699 [==============================] - ETA: 0s - loss: 0.059 - 2s 1ms/step - loss: 0.0591 - val_loss: 0.0593\n",
      "Epoch 142/1500\n",
      "1699/1699 [==============================] - 3s 1ms/step - loss: 0.0588 - val_loss: 0.0589\n",
      "Epoch 143/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0590 - val_loss: 0.0596\n",
      "Epoch 144/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0591 - val_loss: 0.0588\n",
      "Epoch 145/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0588 - val_loss: 0.0593\n",
      "Epoch 146/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0590 - val_loss: 0.0589\n",
      "Epoch 147/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0588 - val_loss: 0.0589\n",
      "Epoch 148/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0586 - val_loss: 0.0590\n",
      "Epoch 149/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0589 - val_loss: 0.0594\n",
      "Epoch 150/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0591 - val_loss: 0.0600\n",
      "Epoch 151/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0591 - val_loss: 0.0591\n",
      "Epoch 152/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0588 - val_loss: 0.0590\n",
      "Epoch 153/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0589 - val_loss: 0.0594\n",
      "Epoch 154/1500\n",
      "1699/1699 [==============================] - ETA: 0s - loss: 0.058 - 2s 1ms/step - loss: 0.0586 - val_loss: 0.0590\n",
      "Epoch 155/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0588 - val_loss: 0.0589\n",
      "Epoch 156/1500\n",
      "1699/1699 [==============================] - 2s 993us/step - loss: 0.0587 - val_loss: 0.0590\n",
      "Epoch 157/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0588 - val_loss: 0.0609\n",
      "Epoch 158/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0588 - val_loss: 0.0590\n",
      "Epoch 159/1500\n",
      "1699/1699 [==============================] - 2s 939us/step - loss: 0.0589 - val_loss: 0.0591\n",
      "Epoch 160/1500\n",
      "1699/1699 [==============================] - 2s 943us/step - loss: 0.0587 - val_loss: 0.0591\n",
      "Epoch 161/1500\n",
      "1699/1699 [==============================] - 2s 907us/step - loss: 0.0588 - val_loss: 0.0589\n",
      "Epoch 162/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0586 - val_loss: 0.0594\n",
      "Epoch 163/1500\n",
      "1699/1699 [==============================] - 2s 983us/step - loss: 0.0587 - val_loss: 0.0588\n",
      "Epoch 164/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0587 - val_loss: 0.0594\n",
      "Epoch 165/1500\n",
      "1699/1699 [==============================] - 2s 955us/step - loss: 0.0588 - val_loss: 0.0600\n",
      "Epoch 166/1500\n",
      "1699/1699 [==============================] - 2s 985us/step - loss: 0.0586 - val_loss: 0.0589\n",
      "Epoch 167/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0586 - val_loss: 0.0590\n",
      "Epoch 168/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0585 - val_loss: 0.0597 - loss:\n",
      "Epoch 169/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0587 - val_loss: 0.0590\n",
      "Epoch 170/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0588 - val_loss: 0.0588\n",
      "Epoch 171/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0587 - val_loss: 0.0589\n",
      "Epoch 172/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0590 - val_loss: 0.0597\n",
      "Epoch 173/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0586 - val_loss: 0.0593\n",
      "Epoch 174/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0585 - val_loss: 0.0594\n",
      "Epoch 175/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0587 - val_loss: 0.0589\n",
      "Epoch 176/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0589 - val_loss: 0.0586\n",
      "Epoch 177/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0586 - val_loss: 0.0587\n",
      "Epoch 178/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0584 - val_loss: 0.0592\n",
      "Epoch 179/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0585 - val_loss: 0.0597\n",
      "Epoch 180/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0588 - val_loss: 0.0596s - loss: 0.058\n",
      "Epoch 181/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0588 - val_loss: 0.0594\n",
      "Epoch 182/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0591 - val_loss: 0.0594\n",
      "Epoch 183/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0586 - val_loss: 0.0590\n",
      "Epoch 184/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0587 - val_loss: 0.0602\n",
      "Epoch 185/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0586 - val_loss: 0.0586\n",
      "Epoch 186/1500\n",
      "1699/1699 [==============================] - 4s 3ms/step - loss: 0.0586 - val_loss: 0.0591\n",
      "Epoch 187/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0585 - val_loss: 0.0594\n",
      "Epoch 188/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0587 - val_loss: 0.0590s\n",
      "Epoch 189/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0585 - val_loss: 0.0589\n",
      "Epoch 190/1500\n",
      "1699/1699 [==============================] - 2s 931us/step - loss: 0.0588 - val_loss: 0.0591\n",
      "Epoch 191/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0584 - val_loss: 0.0595\n",
      "Epoch 192/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0586 - val_loss: 0.0589\n",
      "Epoch 193/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0583 - val_loss: 0.0588\n",
      "Epoch 194/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0586 - val_loss: 0.0589\n",
      "Epoch 195/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0587 - val_loss: 0.0593\n",
      "Epoch 196/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0586 - val_loss: 0.0594\n",
      "Epoch 197/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0587 - val_loss: 0.0589\n",
      "Epoch 198/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0583 - val_loss: 0.0587\n",
      "Epoch 199/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0584 - val_loss: 0.0592\n",
      "Epoch 200/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0585 - val_loss: 0.0588\n",
      "Epoch 201/1500\n",
      "1699/1699 [==============================] - 5s 3ms/step - loss: 0.0586 - val_loss: 0.0591\n",
      "Epoch 202/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0589 - val_loss: 0.0592\n",
      "Epoch 203/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0588 - val_loss: 0.0596\n",
      "Epoch 204/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0588 - val_loss: 0.0590\n",
      "Epoch 205/1500\n",
      "1699/1699 [==============================] - ETA: 0s - loss: 0.058 - 4s 2ms/step - loss: 0.0585 - val_loss: 0.0588\n",
      "Epoch 206/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0583 - val_loss: 0.0587\n",
      "Epoch 207/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0590\n",
      "Epoch 208/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0584 - val_loss: 0.0591\n",
      "Epoch 209/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0584 - val_loss: 0.0589\n",
      "Epoch 210/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0585 - val_loss: 0.0589\n",
      "Epoch 211/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0585 - val_loss: 0.0587\n",
      "Epoch 212/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0589\n",
      "Epoch 213/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0584 - val_loss: 0.0594\n",
      "Epoch 214/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0589 - val_loss: 0.0590\n",
      "Epoch 215/1500\n",
      "1699/1699 [==============================] - 5s 3ms/step - loss: 0.0585 - val_loss: 0.0592\n",
      "Epoch 216/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0585 - val_loss: 0.0590\n",
      "Epoch 217/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0587 - val_loss: 0.0595\n",
      "Epoch 218/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0585 - val_loss: 0.0591\n",
      "Epoch 219/1500\n",
      "1699/1699 [==============================] - 3s 1ms/step - loss: 0.0583 - val_loss: 0.0591\n",
      "Epoch 220/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0584 - val_loss: 0.0587\n",
      "Epoch 221/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0586 - val_loss: 0.0589\n",
      "Epoch 222/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0586 - val_loss: 0.0587\n",
      "Epoch 223/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0584 - val_loss: 0.0593\n",
      "Epoch 224/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0586 - val_loss: 0.0590\n",
      "Epoch 225/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0582 - val_loss: 0.0591\n",
      "Epoch 226/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0585 - val_loss: 0.0588\n",
      "Epoch 227/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0583 - val_loss: 0.0590\n",
      "Epoch 228/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0588 - val_loss: 0.0595\n",
      "Epoch 229/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0584 - val_loss: 0.0589\n",
      "Epoch 230/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0582 - val_loss: 0.0590\n",
      "Epoch 231/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0584 - val_loss: 0.0588\n",
      "Epoch 232/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0583 - val_loss: 0.0593\n",
      "Epoch 233/1500\n",
      "1699/1699 [==============================] - 5s 3ms/step - loss: 0.0584 - val_loss: 0.0598\n",
      "Epoch 234/1500\n",
      "1699/1699 [==============================] - 4s 3ms/step - loss: 0.0584 - val_loss: 0.0586- ETA: 2s\n",
      "Epoch 235/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0582 - val_loss: 0.0589\n",
      "Epoch 236/1500\n",
      "1699/1699 [==============================] - 3s 1ms/step - loss: 0.0583 - val_loss: 0.0590\n",
      "Epoch 237/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0582 - val_loss: 0.0588\n",
      "Epoch 238/1500\n",
      "1699/1699 [==============================] - 5s 3ms/step - loss: 0.0588 - val_loss: 0.0590\n",
      "Epoch 239/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0585 - val_loss: 0.0594\n",
      "Epoch 240/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0584 - val_loss: 0.0586\n",
      "Epoch 241/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0591\n",
      "Epoch 242/1500\n",
      "1699/1699 [==============================] - 5s 3ms/step - loss: 0.0585 - val_loss: 0.0588\n",
      "Epoch 243/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0582 - val_loss: 0.0588\n",
      "Epoch 244/1500\n",
      "1699/1699 [==============================] - 2s 925us/step - loss: 0.0583 - val_loss: 0.0596\n",
      "Epoch 245/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0587 - val_loss: 0.0606\n",
      "Epoch 246/1500\n",
      "1699/1699 [==============================] - 2s 917us/step - loss: 0.0587 - val_loss: 0.0588\n",
      "Epoch 247/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0599\n",
      "Epoch 248/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0584 - val_loss: 0.0588\n",
      "Epoch 249/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0585 - val_loss: 0.0588\n",
      "Epoch 250/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0583 - val_loss: 0.0588\n",
      "Epoch 251/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0582 - val_loss: 0.0598\n",
      "Epoch 252/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0585 - val_loss: 0.0592\n",
      "Epoch 253/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0582 - val_loss: 0.0586\n",
      "Epoch 254/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0582 - val_loss: 0.0588\n",
      "Epoch 255/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0585 - val_loss: 0.0597\n",
      "Epoch 256/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0584 - val_loss: 0.0590\n",
      "Epoch 257/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0587 - val_loss: 0.0590\n",
      "Epoch 258/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0581 - val_loss: 0.0588\n",
      "Epoch 259/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0582 - val_loss: 0.0586\n",
      "Epoch 260/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0583 - val_loss: 0.0594\n",
      "Epoch 261/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0591\n",
      "Epoch 262/1500\n",
      "1699/1699 [==============================] - 2s 960us/step - loss: 0.0581 - val_loss: 0.0589\n",
      "Epoch 263/1500\n",
      "1699/1699 [==============================] - 2s 989us/step - loss: 0.0581 - val_loss: 0.0589\n",
      "Epoch 264/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0582 - val_loss: 0.0590\n",
      "Epoch 265/1500\n",
      "1699/1699 [==============================] - 2s 932us/step - loss: 0.0586 - val_loss: 0.0594\n",
      "Epoch 266/1500\n",
      "1699/1699 [==============================] - 1s 883us/step - loss: 0.0582 - val_loss: 0.0591\n",
      "Epoch 267/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0581 - val_loss: 0.0586\n",
      "Epoch 268/1500\n",
      "1699/1699 [==============================] - 2s 966us/step - loss: 0.0580 - val_loss: 0.0589\n",
      "Epoch 269/1500\n",
      "1699/1699 [==============================] - 2s 944us/step - loss: 0.0581 - val_loss: 0.0597\n",
      "Epoch 270/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0587 - val_loss: 0.0585\n",
      "Epoch 271/1500\n",
      "1699/1699 [==============================] - 2s 918us/step - loss: 0.0583 - val_loss: 0.0589\n",
      "Epoch 272/1500\n",
      "1699/1699 [==============================] - 2s 988us/step - loss: 0.0581 - val_loss: 0.0587\n",
      "Epoch 273/1500\n",
      "1699/1699 [==============================] - 2s 967us/step - loss: 0.0581 - val_loss: 0.0588\n",
      "Epoch 274/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0600\n",
      "Epoch 275/1500\n",
      "1699/1699 [==============================] - 2s 952us/step - loss: 0.0584 - val_loss: 0.0593\n",
      "Epoch 276/1500\n",
      "1699/1699 [==============================] - 2s 997us/step - loss: 0.0583 - val_loss: 0.0599\n",
      "Epoch 277/1500\n",
      "1699/1699 [==============================] - 2s 957us/step - loss: 0.0585 - val_loss: 0.0592\n",
      "Epoch 278/1500\n",
      "1699/1699 [==============================] - 2s 921us/step - loss: 0.0582 - val_loss: 0.0592\n",
      "Epoch 279/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0594\n",
      "Epoch 280/1500\n",
      "1699/1699 [==============================] - 2s 948us/step - loss: 0.0581 - val_loss: 0.0589\n",
      "Epoch 281/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0588\n",
      "Epoch 282/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0581 - val_loss: 0.0590\n",
      "Epoch 283/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0588\n",
      "Epoch 284/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0581 - val_loss: 0.0587\n",
      "Epoch 285/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0580 - val_loss: 0.0590\n",
      "Epoch 286/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0584 - val_loss: 0.0591\n",
      "Epoch 287/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0593\n",
      "Epoch 288/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0581 - val_loss: 0.0588- ETA\n",
      "Epoch 289/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0581 - val_loss: 0.0587\n",
      "Epoch 290/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0583 - val_loss: 0.0589\n",
      "Epoch 291/1500\n",
      "1699/1699 [==============================] - 4s 3ms/step - loss: 0.0583 - val_loss: 0.0597\n",
      "Epoch 292/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0581 - val_loss: 0.0592\n",
      "Epoch 293/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0582 - val_loss: 0.0590\n",
      "Epoch 294/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0580 - val_loss: 0.0592\n",
      "Epoch 295/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0587 - val_loss: 0.0594 0s \n",
      "Epoch 296/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0581 - val_loss: 0.0590\n",
      "Epoch 297/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0581 - val_loss: 0.0588\n",
      "Epoch 298/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0580 - val_loss: 0.0587\n",
      "Epoch 299/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0579 - val_loss: 0.0590\n",
      "Epoch 300/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0592\n",
      "Epoch 301/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0587\n",
      "Epoch 302/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0583 - val_loss: 0.0588\n",
      "Epoch 303/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0581 - val_loss: 0.0588\n",
      "Epoch 304/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0582 - val_loss: 0.0588\n",
      "Epoch 305/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0580 - val_loss: 0.0589\n",
      "Epoch 306/1500\n",
      "1699/1699 [==============================] - 5s 3ms/step - loss: 0.0584 - val_loss: 0.0590\n",
      "Epoch 307/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0581 - val_loss: 0.0591\n",
      "Epoch 308/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0590\n",
      "Epoch 309/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0599\n",
      "Epoch 310/1500\n",
      "1699/1699 [==============================] - 1s 871us/step - loss: 0.0582 - val_loss: 0.0590\n",
      "Epoch 311/1500\n",
      "1699/1699 [==============================] - 2s 920us/step - loss: 0.0580 - val_loss: 0.0586\n",
      "Epoch 312/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0579 - val_loss: 0.0588\n",
      "Epoch 313/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0581 - val_loss: 0.0592\n",
      "Epoch 314/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0580 - val_loss: 0.0587\n",
      "Epoch 315/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0581 - val_loss: 0.0595 ETA: 0s - loss: 0\n",
      "Epoch 316/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0581 - val_loss: 0.0592\n",
      "Epoch 317/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0582 - val_loss: 0.0587\n",
      "Epoch 318/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0580 - val_loss: 0.0592\n",
      "Epoch 319/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0582 - val_loss: 0.0589\n",
      "Epoch 320/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0580 - val_loss: 0.0590\n",
      "Epoch 321/1500\n",
      "1699/1699 [==============================] - 2s 959us/step - loss: 0.0581 - val_loss: 0.0589\n",
      "Epoch 322/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0580 - val_loss: 0.0593\n",
      "Epoch 323/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0579 - val_loss: 0.0591\n",
      "Epoch 324/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0581 - val_loss: 0.0590\n",
      "Epoch 325/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0580 - val_loss: 0.0589\n",
      "Epoch 326/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0579 - val_loss: 0.0588\n",
      "Epoch 327/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0582 - val_loss: 0.0594\n",
      "Epoch 328/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0581 - val_loss: 0.0589\n",
      "Epoch 329/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0580 - val_loss: 0.0587\n",
      "Epoch 330/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0580 - val_loss: 0.0591- ETA: 0s\n",
      "Epoch 331/1500\n",
      "1699/1699 [==============================] - 2s 921us/step - loss: 0.0582 - val_loss: 0.0593\n",
      "Epoch 332/1500\n",
      "1699/1699 [==============================] - 2s 884us/step - loss: 0.0580 - val_loss: 0.0588\n",
      "Epoch 333/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0579 - val_loss: 0.0589\n",
      "Epoch 334/1500\n",
      "1699/1699 [==============================] - 1s 878us/step - loss: 0.0580 - val_loss: 0.0588\n",
      "Epoch 335/1500\n",
      "1699/1699 [==============================] - 2s 920us/step - loss: 0.0580 - val_loss: 0.0588\n",
      "Epoch 336/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0580 - val_loss: 0.0589\n",
      "Epoch 337/1500\n",
      "1699/1699 [==============================] - 2s 986us/step - loss: 0.0580 - val_loss: 0.0591\n",
      "Epoch 338/1500\n",
      "1699/1699 [==============================] - 2s 937us/step - loss: 0.0581 - val_loss: 0.0592\n",
      "Epoch 339/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0583 - val_loss: 0.0590 0s - loss: 0\n",
      "Epoch 340/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0579 - val_loss: 0.0587\n",
      "Epoch 341/1500\n",
      "1699/1699 [==============================] - 2s 925us/step - loss: 0.0579 - val_loss: 0.0590\n",
      "Epoch 342/1500\n",
      "1699/1699 [==============================] - 2s 904us/step - loss: 0.0581 - val_loss: 0.0589\n",
      "Epoch 343/1500\n",
      "1699/1699 [==============================] - 2s 964us/step - loss: 0.0583 - val_loss: 0.0589\n",
      "Epoch 344/1500\n",
      "1699/1699 [==============================] - 2s 942us/step - loss: 0.0578 - val_loss: 0.0589\n",
      "Epoch 345/1500\n",
      "1699/1699 [==============================] - 2s 890us/step - loss: 0.0585 - val_loss: 0.0592\n",
      "Epoch 346/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0580 - val_loss: 0.0586\n",
      "Epoch 347/1500\n",
      "1699/1699 [==============================] - 2s 985us/step - loss: 0.0579 - val_loss: 0.0589\n",
      "Epoch 348/1500\n",
      "1699/1699 [==============================] - 2s 960us/step - loss: 0.0579 - val_loss: 0.0590\n",
      "Epoch 349/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0581 - val_loss: 0.0591\n",
      "Epoch 350/1500\n",
      "1699/1699 [==============================] - 2s 945us/step - loss: 0.0580 - val_loss: 0.0587\n",
      "Epoch 351/1500\n",
      "1699/1699 [==============================] - 2s 930us/step - loss: 0.0581 - val_loss: 0.0594\n",
      "Epoch 352/1500\n",
      "1699/1699 [==============================] - 2s 990us/step - loss: 0.0580 - val_loss: 0.0591\n",
      "Epoch 353/1500\n",
      "1699/1699 [==============================] - 2s 926us/step - loss: 0.0582 - val_loss: 0.0594\n",
      "Epoch 354/1500\n",
      "1699/1699 [==============================] - 2s 908us/step - loss: 0.0579 - val_loss: 0.0589\n",
      "Epoch 355/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0578 - val_loss: 0.0587\n",
      "Epoch 356/1500\n",
      "1699/1699 [==============================] - 1s 879us/step - loss: 0.0579 - val_loss: 0.0588\n",
      "Epoch 357/1500\n",
      "1699/1699 [==============================] - 2s 970us/step - loss: 0.0579 - val_loss: 0.0589\n",
      "Epoch 358/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0579 - val_loss: 0.0587\n",
      "Epoch 359/1500\n",
      "1699/1699 [==============================] - 2s 928us/step - loss: 0.0578 - val_loss: 0.0590\n",
      "Epoch 360/1500\n",
      "1699/1699 [==============================] - 2s 908us/step - loss: 0.0581 - val_loss: 0.0588\n",
      "Epoch 361/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0580 - val_loss: 0.0594\n",
      "Epoch 362/1500\n",
      "1699/1699 [==============================] - 2s 937us/step - loss: 0.0578 - val_loss: 0.0586\n",
      "Epoch 363/1500\n",
      "1699/1699 [==============================] - 2s 935us/step - loss: 0.0580 - val_loss: 0.0590\n",
      "Epoch 364/1500\n",
      "1699/1699 [==============================] - 2s 929us/step - loss: 0.0585 - val_loss: 0.0588\n",
      "Epoch 365/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0578 - val_loss: 0.0594\n",
      "Epoch 366/1500\n",
      "1699/1699 [==============================] - 2s 942us/step - loss: 0.0580 - val_loss: 0.0596\n",
      "Epoch 367/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0579 - val_loss: 0.0585\n",
      "Epoch 368/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0578 - val_loss: 0.0589\n",
      "Epoch 369/1500\n",
      "1699/1699 [==============================] - 2s 901us/step - loss: 0.0579 - val_loss: 0.0587\n",
      "Epoch 370/1500\n",
      "1699/1699 [==============================] - 2s 934us/step - loss: 0.0579 - val_loss: 0.0588\n",
      "Epoch 371/1500\n",
      "1699/1699 [==============================] - 2s 984us/step - loss: 0.0581 - val_loss: 0.0594\n",
      "Epoch 372/1500\n",
      "1699/1699 [==============================] - 1s 880us/step - loss: 0.0581 - val_loss: 0.0587\n",
      "Epoch 373/1500\n",
      "1699/1699 [==============================] - 2s 942us/step - loss: 0.0579 - val_loss: 0.0588\n",
      "Epoch 374/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0577 - val_loss: 0.0587\n",
      "Epoch 375/1500\n",
      "1699/1699 [==============================] - 2s 899us/step - loss: 0.0578 - val_loss: 0.0588\n",
      "Epoch 376/1500\n",
      "1699/1699 [==============================] - 2s 962us/step - loss: 0.0582 - val_loss: 0.0589\n",
      "Epoch 377/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0579 - val_loss: 0.0588\n",
      "Epoch 378/1500\n",
      "1699/1699 [==============================] - 2s 900us/step - loss: 0.0577 - val_loss: 0.0586\n",
      "Epoch 379/1500\n",
      "1699/1699 [==============================] - 2s 969us/step - loss: 0.0577 - val_loss: 0.0588\n",
      "Epoch 380/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0579 - val_loss: 0.0591\n",
      "Epoch 381/1500\n",
      "1699/1699 [==============================] - 2s 933us/step - loss: 0.0580 - val_loss: 0.0590\n",
      "Epoch 382/1500\n",
      "1699/1699 [==============================] - 2s 927us/step - loss: 0.0581 - val_loss: 0.0585\n",
      "Epoch 383/1500\n",
      "1699/1699 [==============================] - 2s 993us/step - loss: 0.0577 - val_loss: 0.0588\n",
      "Epoch 384/1500\n",
      "1699/1699 [==============================] - 2s 965us/step - loss: 0.0579 - val_loss: 0.0589\n",
      "Epoch 385/1500\n",
      "1699/1699 [==============================] - 2s 961us/step - loss: 0.0579 - val_loss: 0.0594\n",
      "Epoch 386/1500\n",
      "1699/1699 [==============================] - 7s 4ms/step - loss: 0.0579 - val_loss: 0.0589\n",
      "Epoch 387/1500\n",
      "1699/1699 [==============================] - 1s 849us/step - loss: 0.0580 - val_loss: 0.0593\n",
      "Epoch 388/1500\n",
      "1699/1699 [==============================] - 2s 908us/step - loss: 0.0580 - val_loss: 0.0585\n",
      "Epoch 389/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0579 - val_loss: 0.0590\n",
      "Epoch 390/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0576 - val_loss: 0.0586ETA: 0s - loss: 0.\n",
      "Epoch 391/1500\n",
      "1699/1699 [==============================] - 1s 746us/step - loss: 0.0577 - val_loss: 0.0584\n",
      "Epoch 392/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0578 - val_loss: 0.0586\n",
      "Epoch 393/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0578 - val_loss: 0.0588\n",
      "Epoch 394/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0577 - val_loss: 0.0588\n",
      "Epoch 395/1500\n",
      "1699/1699 [==============================] - 2s 942us/step - loss: 0.0580 - val_loss: 0.0594\n",
      "Epoch 396/1500\n",
      "1699/1699 [==============================] - 1s 849us/step - loss: 0.0580 - val_loss: 0.0592\n",
      "Epoch 397/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0578 - val_loss: 0.0591\n",
      "Epoch 398/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0578 - val_loss: 0.0596\n",
      "Epoch 399/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0578 - val_loss: 0.0588\n",
      "Epoch 400/1500\n",
      "1699/1699 [==============================] - 3s 1ms/step - loss: 0.0576 - val_loss: 0.0587\n",
      "Epoch 401/1500\n",
      "1699/1699 [==============================] - 1s 880us/step - loss: 0.0579 - val_loss: 0.0588\n",
      "Epoch 402/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0580 - val_loss: 0.0590\n",
      "Epoch 403/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0578 - val_loss: 0.0588\n",
      "Epoch 404/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0577 - val_loss: 0.0590\n",
      "Epoch 405/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0577 - val_loss: 0.0599\n",
      "Epoch 406/1500\n",
      "1699/1699 [==============================] - 1s 760us/step - loss: 0.0579 - val_loss: 0.0589\n",
      "Epoch 407/1500\n",
      "1699/1699 [==============================] - 1s 618us/step - loss: 0.0580 - val_loss: 0.0588\n",
      "Epoch 408/1500\n",
      "1699/1699 [==============================] - 2s 893us/step - loss: 0.0578 - val_loss: 0.0590\n",
      "Epoch 409/1500\n",
      "1699/1699 [==============================] - 1s 820us/step - loss: 0.0579 - val_loss: 0.0592\n",
      "Epoch 410/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0579 - val_loss: 0.0588\n",
      "Epoch 411/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0577 - val_loss: 0.0586\n",
      "Epoch 412/1500\n",
      "1699/1699 [==============================] - 2s 918us/step - loss: 0.0578 - val_loss: 0.0586\n",
      "Epoch 413/1500\n",
      "1699/1699 [==============================] - 1s 717us/step - loss: 0.0577 - val_loss: 0.0590\n",
      "Epoch 414/1500\n",
      "1699/1699 [==============================] - 1s 562us/step - loss: 0.0577 - val_loss: 0.0588\n",
      "Epoch 415/1500\n",
      "1699/1699 [==============================] - 1s 694us/step - loss: 0.0583 - val_loss: 0.0589\n",
      "Epoch 416/1500\n",
      "1699/1699 [==============================] - 1s 837us/step - loss: 0.0580 - val_loss: 0.0588\n",
      "Epoch 417/1500\n",
      "1699/1699 [==============================] - 1s 787us/step - loss: 0.0577 - val_loss: 0.0586\n",
      "Epoch 418/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0577 - val_loss: 0.0587\n",
      "Epoch 419/1500\n",
      "1699/1699 [==============================] - 1s 868us/step - loss: 0.0578 - val_loss: 0.0588\n",
      "Epoch 420/1500\n",
      "1699/1699 [==============================] - 2s 965us/step - loss: 0.0578 - val_loss: 0.0589\n",
      "Epoch 421/1500\n",
      "1699/1699 [==============================] - 2s 909us/step - loss: 0.0579 - val_loss: 0.0588\n",
      "Epoch 422/1500\n",
      "1699/1699 [==============================] - 1s 518us/step - loss: 0.0577 - val_loss: 0.0587\n",
      "Epoch 423/1500\n",
      "1699/1699 [==============================] - 1s 856us/step - loss: 0.0580 - val_loss: 0.0590\n",
      "Epoch 424/1500\n",
      "1699/1699 [==============================] - 4s 2ms/step - loss: 0.0577 - val_loss: 0.0590\n",
      "Epoch 425/1500\n",
      "1699/1699 [==============================] - 2s 988us/step - loss: 0.0579 - val_loss: 0.0587\n",
      "Epoch 426/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0577 - val_loss: 0.0586\n",
      "Epoch 427/1500\n",
      "1699/1699 [==============================] - 1s 853us/step - loss: 0.0576 - val_loss: 0.0588\n",
      "Epoch 428/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0577 - val_loss: 0.0590\n",
      "Epoch 429/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0578 - val_loss: 0.0592\n",
      "Epoch 430/1500\n",
      "1699/1699 [==============================] - 1s 682us/step - loss: 0.0580 - val_loss: 0.0589\n",
      "Epoch 431/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0578 - val_loss: 0.0588\n",
      "Epoch 432/1500\n",
      "1699/1699 [==============================] - 2s 899us/step - loss: 0.0577 - val_loss: 0.0589\n",
      "Epoch 433/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0578 - val_loss: 0.0590\n",
      "Epoch 434/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0578 - val_loss: 0.0591\n",
      "Epoch 435/1500\n",
      "1699/1699 [==============================] - 2s 884us/step - loss: 0.0578 - val_loss: 0.0588\n",
      "Epoch 436/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0578 - val_loss: 0.0589\n",
      "Epoch 437/1500\n",
      "1699/1699 [==============================] - 1s 697us/step - loss: 0.0577 - val_loss: 0.0585\n",
      "Epoch 438/1500\n",
      "1699/1699 [==============================] - 2s 928us/step - loss: 0.0578 - val_loss: 0.0589\n",
      "Epoch 439/1500\n",
      "1699/1699 [==============================] - 1s 743us/step - loss: 0.0578 - val_loss: 0.0587\n",
      "Epoch 440/1500\n",
      "1699/1699 [==============================] - 1s 718us/step - loss: 0.0577 - val_loss: 0.0597\n",
      "Epoch 441/1500\n",
      "1699/1699 [==============================] - 2s 950us/step - loss: 0.0576 - val_loss: 0.0588\n",
      "Epoch 442/1500\n",
      "1699/1699 [==============================] - 1s 872us/step - loss: 0.0577 - val_loss: 0.0587\n",
      "Epoch 443/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0577 - val_loss: 0.0592\n",
      "Epoch 444/1500\n",
      "1699/1699 [==============================] - 1s 639us/step - loss: 0.0582 - val_loss: 0.0601\n",
      "Epoch 445/1500\n",
      "1699/1699 [==============================] - 1s 799us/step - loss: 0.0579 - val_loss: 0.0591\n",
      "Epoch 446/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0576 - val_loss: 0.0591\n",
      "Epoch 447/1500\n",
      "1699/1699 [==============================] - 1s 797us/step - loss: 0.0578 - val_loss: 0.0586\n",
      "Epoch 448/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0576 - val_loss: 0.0588\n",
      "Epoch 449/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0577 - val_loss: 0.0593\n",
      "Epoch 450/1500\n",
      "1699/1699 [==============================] - ETA: 0s - loss: 0.0580- ETA: 0s - loss: 0.0 - 1s 736us/step - loss: 0.0579 - val_loss: 0.0588\n",
      "Epoch 451/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0577 - val_loss: 0.0587\n",
      "Epoch 452/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0577 - val_loss: 0.0591\n",
      "Epoch 453/1500\n",
      "1699/1699 [==============================] - 2s 977us/step - loss: 0.0578 - val_loss: 0.0589ETA: 0s - loss:\n",
      "Epoch 454/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0577 - val_loss: 0.0587\n",
      "Epoch 455/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0575 - val_loss: 0.0591\n",
      "Epoch 456/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0579 - val_loss: 0.0595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0577 - val_loss: 0.0588 - ETA: 0s - los\n",
      "Epoch 458/1500\n",
      "1699/1699 [==============================] - 1s 712us/step - loss: 0.0577 - val_loss: 0.0592\n",
      "Epoch 459/1500\n",
      "1699/1699 [==============================] - 1s 801us/step - loss: 0.0577 - val_loss: 0.0588\n",
      "Epoch 460/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0577 - val_loss: 0.0595\n",
      "Epoch 461/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0577 - val_loss: 0.0591\n",
      "Epoch 462/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0576 - val_loss: 0.0587\n",
      "Epoch 463/1500\n",
      "1699/1699 [==============================] - 1s 768us/step - loss: 0.0576 - val_loss: 0.0593\n",
      "Epoch 464/1500\n",
      "1699/1699 [==============================] - 2s 942us/step - loss: 0.0576 - val_loss: 0.0586\n",
      "Epoch 465/1500\n",
      "1699/1699 [==============================] - 2s 944us/step - loss: 0.0576 - val_loss: 0.0590\n",
      "Epoch 466/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0575 - val_loss: 0.0587\n",
      "Epoch 467/1500\n",
      "1699/1699 [==============================] - 1s 647us/step - loss: 0.0577 - val_loss: 0.0590\n",
      "Epoch 468/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0577 - val_loss: 0.0587\n",
      "Epoch 469/1500\n",
      "1699/1699 [==============================] - 2s 923us/step - loss: 0.0576 - val_loss: 0.0586\n",
      "Epoch 470/1500\n",
      "1699/1699 [==============================] - 1s 687us/step - loss: 0.0576 - val_loss: 0.0589\n",
      "Epoch 471/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0576 - val_loss: 0.0622\n",
      "Epoch 472/1500\n",
      "1699/1699 [==============================] - 1s 868us/step - loss: 0.0583 - val_loss: 0.0593\n",
      "Epoch 473/1500\n",
      "1699/1699 [==============================] - 2s 901us/step - loss: 0.0578 - val_loss: 0.0594\n",
      "Epoch 474/1500\n",
      "1699/1699 [==============================] - 1s 880us/step - loss: 0.0577 - val_loss: 0.0590\n",
      "Epoch 475/1500\n",
      "1699/1699 [==============================] - 1s 753us/step - loss: 0.0576 - val_loss: 0.0586\n",
      "Epoch 476/1500\n",
      "1699/1699 [==============================] - 2s 889us/step - loss: 0.0578 - val_loss: 0.0590\n",
      "Epoch 477/1500\n",
      "1699/1699 [==============================] - 1s 759us/step - loss: 0.0575 - val_loss: 0.0585\n",
      "Epoch 478/1500\n",
      "1699/1699 [==============================] - 2s 935us/step - loss: 0.0575 - val_loss: 0.0588\n",
      "Epoch 479/1500\n",
      "1699/1699 [==============================] - 3s 2ms/step - loss: 0.0575 - val_loss: 0.0587\n",
      "Epoch 480/1500\n",
      "1699/1699 [==============================] - 2s 965us/step - loss: 0.0576 - val_loss: 0.0588\n",
      "Epoch 481/1500\n",
      "1699/1699 [==============================] - 1s 659us/step - loss: 0.0578 - val_loss: 0.0589\n",
      "Epoch 482/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0575 - val_loss: 0.0590\n",
      "Epoch 483/1500\n",
      "1699/1699 [==============================] - 1s 485us/step - loss: 0.0578 - val_loss: 0.0587\n",
      "Epoch 484/1500\n",
      "1699/1699 [==============================] - 1s 500us/step - loss: 0.0577 - val_loss: 0.0590\n",
      "Epoch 485/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0577 - val_loss: 0.0589\n",
      "Epoch 486/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0577 - val_loss: 0.0589\n",
      "Epoch 487/1500\n",
      "1699/1699 [==============================] - 1s 540us/step - loss: 0.0576 - val_loss: 0.0586\n",
      "Epoch 488/1500\n",
      "1699/1699 [==============================] - 1s 503us/step - loss: 0.0576 - val_loss: 0.0589\n",
      "Epoch 489/1500\n",
      "1699/1699 [==============================] - 1s 518us/step - loss: 0.0577 - val_loss: 0.0589\n",
      "Epoch 490/1500\n",
      "1699/1699 [==============================] - 1s 485us/step - loss: 0.0578 - val_loss: 0.0589\n",
      "Epoch 491/1500\n",
      "1699/1699 [==============================] - 1s 492us/step - loss: 0.0576 - val_loss: 0.0585\n",
      "Epoch 492/1500\n",
      "1699/1699 [==============================] - 1s 488us/step - loss: 0.0577 - val_loss: 0.0586\n",
      "Epoch 493/1500\n",
      "1699/1699 [==============================] - 1s 540us/step - loss: 0.0575 - val_loss: 0.0591\n",
      "Epoch 494/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0576 - val_loss: 0.0590\n",
      "Epoch 495/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0575 - val_loss: 0.0587\n",
      "Epoch 496/1500\n",
      "1699/1699 [==============================] - 1s 712us/step - loss: 0.0577 - val_loss: 0.0587\n",
      "Epoch 497/1500\n",
      "1699/1699 [==============================] - 1s 490us/step - loss: 0.0579 - val_loss: 0.0587\n",
      "Epoch 498/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0575 - val_loss: 0.0586\n",
      "Epoch 499/1500\n",
      "1699/1699 [==============================] - 1s 550us/step - loss: 0.0575 - val_loss: 0.0590\n",
      "Epoch 500/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0577 - val_loss: 0.0587\n",
      "Epoch 501/1500\n",
      "1699/1699 [==============================] - 1s 444us/step - loss: 0.0575 - val_loss: 0.0589\n",
      "Epoch 502/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0576 - val_loss: 0.0585\n",
      "Epoch 503/1500\n",
      "1699/1699 [==============================] - 1s 512us/step - loss: 0.0574 - val_loss: 0.0588\n",
      "Epoch 504/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0575 - val_loss: 0.0586\n",
      "Epoch 505/1500\n",
      "1699/1699 [==============================] - 1s 531us/step - loss: 0.0577 - val_loss: 0.0589\n",
      "Epoch 506/1500\n",
      "1699/1699 [==============================] - 1s 487us/step - loss: 0.0578 - val_loss: 0.0591\n",
      "Epoch 507/1500\n",
      "1699/1699 [==============================] - 1s 510us/step - loss: 0.0577 - val_loss: 0.0588\n",
      "Epoch 508/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0578 - val_loss: 0.0587\n",
      "Epoch 509/1500\n",
      "1699/1699 [==============================] - 1s 513us/step - loss: 0.0576 - val_loss: 0.0586\n",
      "Epoch 510/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0578 - val_loss: 0.0591\n",
      "Epoch 511/1500\n",
      "1699/1699 [==============================] - 1s 531us/step - loss: 0.0576 - val_loss: 0.0586\n",
      "Epoch 512/1500\n",
      "1699/1699 [==============================] - 1s 486us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 513/1500\n",
      "1699/1699 [==============================] - 1s 474us/step - loss: 0.0575 - val_loss: 0.0590\n",
      "Epoch 514/1500\n",
      "1699/1699 [==============================] - 1s 581us/step - loss: 0.0575 - val_loss: 0.0589\n",
      "Epoch 515/1500\n",
      "1699/1699 [==============================] - 1s 612us/step - loss: 0.0576 - val_loss: 0.0589\n",
      "Epoch 516/1500\n",
      "1699/1699 [==============================] - 1s 500us/step - loss: 0.0575 - val_loss: 0.0587\n",
      "Epoch 517/1500\n",
      "1699/1699 [==============================] - 1s 522us/step - loss: 0.0575 - val_loss: 0.0587\n",
      "Epoch 518/1500\n",
      "1699/1699 [==============================] - 1s 491us/step - loss: 0.0576 - val_loss: 0.0587\n",
      "Epoch 519/1500\n",
      "1699/1699 [==============================] - 1s 485us/step - loss: 0.0575 - val_loss: 0.0587\n",
      "Epoch 520/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0575 - val_loss: 0.0585\n",
      "Epoch 521/1500\n",
      "1699/1699 [==============================] - 1s 500us/step - loss: 0.0575 - val_loss: 0.0590\n",
      "Epoch 522/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0575 - val_loss: 0.0603\n",
      "Epoch 523/1500\n",
      "1699/1699 [==============================] - 1s 513us/step - loss: 0.0577 - val_loss: 0.0589\n",
      "Epoch 524/1500\n",
      "1699/1699 [==============================] - 1s 503us/step - loss: 0.0575 - val_loss: 0.0587\n",
      "Epoch 525/1500\n",
      "1699/1699 [==============================] - 1s 509us/step - loss: 0.0574 - val_loss: 0.0589\n",
      "Epoch 526/1500\n",
      "1699/1699 [==============================] - 1s 503us/step - loss: 0.0575 - val_loss: 0.0590\n",
      "Epoch 527/1500\n",
      "1699/1699 [==============================] - 1s 471us/step - loss: 0.0577 - val_loss: 0.0588\n",
      "Epoch 528/1500\n",
      "1699/1699 [==============================] - 1s 432us/step - loss: 0.0576 - val_loss: 0.0589\n",
      "Epoch 529/1500\n",
      "1699/1699 [==============================] - 1s 553us/step - loss: 0.0577 - val_loss: 0.0586\n",
      "Epoch 530/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0576 - val_loss: 0.0591\n",
      "Epoch 531/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0575 - val_loss: 0.0591\n",
      "Epoch 532/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0576 - val_loss: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1500\n",
      "1699/1699 [==============================] - 1s 608us/step - loss: 0.0574 - val_loss: 0.0588\n",
      "Epoch 534/1500\n",
      "1699/1699 [==============================] - 1s 563us/step - loss: 0.0576 - val_loss: 0.0589\n",
      "Epoch 535/1500\n",
      "1699/1699 [==============================] - 1s 529us/step - loss: 0.0575 - val_loss: 0.0586\n",
      "Epoch 536/1500\n",
      "1699/1699 [==============================] - 1s 442us/step - loss: 0.0576 - val_loss: 0.0587\n",
      "Epoch 537/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0575 - val_loss: 0.0587\n",
      "Epoch 538/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0575 - val_loss: 0.0588\n",
      "Epoch 539/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0575 - val_loss: 0.0589\n",
      "Epoch 540/1500\n",
      "1699/1699 [==============================] - 1s 464us/step - loss: 0.0575 - val_loss: 0.0586\n",
      "Epoch 541/1500\n",
      "1699/1699 [==============================] - 1s 458us/step - loss: 0.0574 - val_loss: 0.0589\n",
      "Epoch 542/1500\n",
      "1699/1699 [==============================] - 1s 556us/step - loss: 0.0577 - val_loss: 0.0589\n",
      "Epoch 543/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 544/1500\n",
      "1699/1699 [==============================] - 1s 476us/step - loss: 0.0576 - val_loss: 0.0589\n",
      "Epoch 545/1500\n",
      "1699/1699 [==============================] - 1s 490us/step - loss: 0.0576 - val_loss: 0.0588\n",
      "Epoch 546/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0574 - val_loss: 0.0593\n",
      "Epoch 547/1500\n",
      "1699/1699 [==============================] - 1s 469us/step - loss: 0.0575 - val_loss: 0.0587\n",
      "Epoch 548/1500\n",
      "1699/1699 [==============================] - 1s 613us/step - loss: 0.0575 - val_loss: 0.0592\n",
      "Epoch 549/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0578 - val_loss: 0.0585\n",
      "Epoch 550/1500\n",
      "1699/1699 [==============================] - 1s 509us/step - loss: 0.0575 - val_loss: 0.0588\n",
      "Epoch 551/1500\n",
      "1699/1699 [==============================] - 1s 494us/step - loss: 0.0575 - val_loss: 0.0587\n",
      "Epoch 552/1500\n",
      "1699/1699 [==============================] - 1s 677us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 553/1500\n",
      "1699/1699 [==============================] - 1s 522us/step - loss: 0.0574 - val_loss: 0.0588\n",
      "Epoch 554/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0575 - val_loss: 0.0588\n",
      "Epoch 555/1500\n",
      "1699/1699 [==============================] - 1s 480us/step - loss: 0.0575 - val_loss: 0.0588\n",
      "Epoch 556/1500\n",
      "1699/1699 [==============================] - ETA: 0s - loss: 0.057 - 1s 493us/step - loss: 0.0575 - val_loss: 0.0589\n",
      "Epoch 557/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 558/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 559/1500\n",
      "1699/1699 [==============================] - 1s 500us/step - loss: 0.0575 - val_loss: 0.0586\n",
      "Epoch 560/1500\n",
      "1699/1699 [==============================] - 1s 553us/step - loss: 0.0575 - val_loss: 0.0586\n",
      "Epoch 561/1500\n",
      "1699/1699 [==============================] - 1s 522us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 562/1500\n",
      "1699/1699 [==============================] - 1s 498us/step - loss: 0.0576 - val_loss: 0.0589\n",
      "Epoch 563/1500\n",
      "1699/1699 [==============================] - 1s 512us/step - loss: 0.0577 - val_loss: 0.0587\n",
      "Epoch 564/1500\n",
      "1699/1699 [==============================] - 1s 491us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 565/1500\n",
      "1699/1699 [==============================] - 1s 454us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 566/1500\n",
      "1699/1699 [==============================] - 1s 531us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 567/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0574 - val_loss: 0.0591\n",
      "Epoch 568/1500\n",
      "1699/1699 [==============================] - 1s 467us/step - loss: 0.0574 - val_loss: 0.0588\n",
      "Epoch 569/1500\n",
      "1699/1699 [==============================] - 1s 467us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 570/1500\n",
      "1699/1699 [==============================] - 1s 500us/step - loss: 0.0576 - val_loss: 0.0600\n",
      "Epoch 571/1500\n",
      "1699/1699 [==============================] - 1s 612us/step - loss: 0.0578 - val_loss: 0.0589\n",
      "Epoch 572/1500\n",
      "1699/1699 [==============================] - 1s 540us/step - loss: 0.0573 - val_loss: 0.0592\n",
      "Epoch 573/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0575 - val_loss: 0.0590\n",
      "Epoch 574/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 575/1500\n",
      "1699/1699 [==============================] - 1s 480us/step - loss: 0.0573 - val_loss: 0.0585\n",
      "Epoch 576/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0572 - val_loss: 0.0586\n",
      "Epoch 577/1500\n",
      "1699/1699 [==============================] - 1s 490us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 578/1500\n",
      "1699/1699 [==============================] - 1s 538us/step - loss: 0.0573 - val_loss: 0.0587\n",
      "Epoch 579/1500\n",
      "1699/1699 [==============================] - 1s 522us/step - loss: 0.0574 - val_loss: 0.0591\n",
      "Epoch 580/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 581/1500\n",
      "1699/1699 [==============================] - 1s 474us/step - loss: 0.0575 - val_loss: 0.0588\n",
      "Epoch 582/1500\n",
      "1699/1699 [==============================] - 1s 492us/step - loss: 0.0575 - val_loss: 0.0595\n",
      "Epoch 583/1500\n",
      "1699/1699 [==============================] - 1s 490us/step - loss: 0.0575 - val_loss: 0.0586\n",
      "Epoch 584/1500\n",
      "1699/1699 [==============================] - 1s 531us/step - loss: 0.0575 - val_loss: 0.0586\n",
      "Epoch 585/1500\n",
      "1699/1699 [==============================] - 1s 499us/step - loss: 0.0575 - val_loss: 0.0588\n",
      "Epoch 586/1500\n",
      "1699/1699 [==============================] - 1s 584us/step - loss: 0.0577 - val_loss: 0.0592\n",
      "Epoch 587/1500\n",
      "1699/1699 [==============================] - 1s 488us/step - loss: 0.0576 - val_loss: 0.0588\n",
      "Epoch 588/1500\n",
      "1699/1699 [==============================] - 1s 494us/step - loss: 0.0574 - val_loss: 0.0588\n",
      "Epoch 589/1500\n",
      "1699/1699 [==============================] - 1s 649us/step - loss: 0.0574 - val_loss: 0.0589\n",
      "Epoch 590/1500\n",
      "1699/1699 [==============================] - 1s 559us/step - loss: 0.0573 - val_loss: 0.0592\n",
      "Epoch 591/1500\n",
      "1699/1699 [==============================] - 1s 465us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 592/1500\n",
      "1699/1699 [==============================] - 1s 489us/step - loss: 0.0573 - val_loss: 0.0588\n",
      "Epoch 593/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0573 - val_loss: 0.0586\n",
      "Epoch 594/1500\n",
      "1699/1699 [==============================] - 1s 495us/step - loss: 0.0573 - val_loss: 0.0588\n",
      "Epoch 595/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0573 - val_loss: 0.0593\n",
      "Epoch 596/1500\n",
      "1699/1699 [==============================] - 1s 590us/step - loss: 0.0576 - val_loss: 0.0586\n",
      "Epoch 597/1500\n",
      "1699/1699 [==============================] - 1s 541us/step - loss: 0.0573 - val_loss: 0.0588\n",
      "Epoch 598/1500\n",
      "1699/1699 [==============================] - 1s 454us/step - loss: 0.0577 - val_loss: 0.0589\n",
      "Epoch 599/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0574 - val_loss: 0.0589\n",
      "Epoch 600/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 601/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0574 - val_loss: 0.0590\n",
      "Epoch 602/1500\n",
      "1699/1699 [==============================] - 1s 509us/step - loss: 0.0575 - val_loss: 0.0592\n",
      "Epoch 603/1500\n",
      "1699/1699 [==============================] - 1s 504us/step - loss: 0.0574 - val_loss: 0.0592\n",
      "Epoch 604/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 605/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 606/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0573 - val_loss: 0.0592\n",
      "Epoch 607/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 608/1500\n",
      "1699/1699 [==============================] - 1s 726us/step - loss: 0.0574 - val_loss: 0.0593\n",
      "Epoch 609/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0573 - val_loss: 0.0603\n",
      "Epoch 610/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0580 - val_loss: 0.0587\n",
      "Epoch 611/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0573 - val_loss: 0.0586\n",
      "Epoch 612/1500\n",
      "1699/1699 [==============================] - 1s 444us/step - loss: 0.0572 - val_loss: 0.0589\n",
      "Epoch 613/1500\n",
      "1699/1699 [==============================] - 1s 490us/step - loss: 0.0573 - val_loss: 0.0585\n",
      "Epoch 614/1500\n",
      "1699/1699 [==============================] - 1s 547us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 615/1500\n",
      "1699/1699 [==============================] - 1s 444us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 616/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0573 - val_loss: 0.0588\n",
      "Epoch 617/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 618/1500\n",
      "1699/1699 [==============================] - 1s 550us/step - loss: 0.0573 - val_loss: 0.0587\n",
      "Epoch 619/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 620/1500\n",
      "1699/1699 [==============================] - 1s 559us/step - loss: 0.0573 - val_loss: 0.0588\n",
      "Epoch 621/1500\n",
      "1699/1699 [==============================] - 1s 500us/step - loss: 0.0573 - val_loss: 0.0586\n",
      "Epoch 622/1500\n",
      "1699/1699 [==============================] - 1s 485us/step - loss: 0.0573 - val_loss: 0.0588\n",
      "Epoch 623/1500\n",
      "1699/1699 [==============================] - 1s 506us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 624/1500\n",
      "1699/1699 [==============================] - 1s 497us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 625/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0573 - val_loss: 0.0587\n",
      "Epoch 626/1500\n",
      "1699/1699 [==============================] - 1s 531us/step - loss: 0.0575 - val_loss: 0.0593\n",
      "Epoch 627/1500\n",
      "1699/1699 [==============================] - 1s 659us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 628/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0574 - val_loss: 0.0592\n",
      "Epoch 629/1500\n",
      "1699/1699 [==============================] - 1s 494us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 630/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0576 - val_loss: 0.0588\n",
      "Epoch 631/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0573 - val_loss: 0.0586\n",
      "Epoch 632/1500\n",
      "1699/1699 [==============================] - 1s 536us/step - loss: 0.0572 - val_loss: 0.0587\n",
      "Epoch 633/1500\n",
      "1699/1699 [==============================] - 1s 495us/step - loss: 0.0574 - val_loss: 0.0588\n",
      "Epoch 634/1500\n",
      "1699/1699 [==============================] - 1s 504us/step - loss: 0.0572 - val_loss: 0.0586\n",
      "Epoch 635/1500\n",
      "1699/1699 [==============================] - 1s 509us/step - loss: 0.0573 - val_loss: 0.0589\n",
      "Epoch 636/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0573 - val_loss: 0.0587\n",
      "Epoch 637/1500\n",
      "1699/1699 [==============================] - 1s 494us/step - loss: 0.0575 - val_loss: 0.0589\n",
      "Epoch 638/1500\n",
      "1699/1699 [==============================] - 1s 514us/step - loss: 0.0573 - val_loss: 0.0588\n",
      "Epoch 639/1500\n",
      "1699/1699 [==============================] - 1s 480us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 640/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 641/1500\n",
      "1699/1699 [==============================] - 1s 500us/step - loss: 0.0572 - val_loss: 0.0584\n",
      "Epoch 642/1500\n",
      "1699/1699 [==============================] - 1s 522us/step - loss: 0.0574 - val_loss: 0.0591\n",
      "Epoch 643/1500\n",
      "1699/1699 [==============================] - 1s 490us/step - loss: 0.0574 - val_loss: 0.0592\n",
      "Epoch 644/1500\n",
      "1699/1699 [==============================] - 1s 531us/step - loss: 0.0574 - val_loss: 0.0589\n",
      "Epoch 645/1500\n",
      "1699/1699 [==============================] - 1s 690us/step - loss: 0.0573 - val_loss: 0.0586\n",
      "Epoch 646/1500\n",
      "1699/1699 [==============================] - 1s 503us/step - loss: 0.0572 - val_loss: 0.0592\n",
      "Epoch 647/1500\n",
      "1699/1699 [==============================] - 1s 480us/step - loss: 0.0574 - val_loss: 0.0585\n",
      "Epoch 648/1500\n",
      "1699/1699 [==============================] - 1s 470us/step - loss: 0.0572 - val_loss: 0.0588\n",
      "Epoch 649/1500\n",
      "1699/1699 [==============================] - 1s 537us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 650/1500\n",
      "1699/1699 [==============================] - 1s 549us/step - loss: 0.0575 - val_loss: 0.0590\n",
      "Epoch 651/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0575 - val_loss: 0.0588\n",
      "Epoch 652/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0572 - val_loss: 0.0586\n",
      "Epoch 653/1500\n",
      "1699/1699 [==============================] - 1s 513us/step - loss: 0.0573 - val_loss: 0.0587\n",
      "Epoch 654/1500\n",
      "1699/1699 [==============================] - 1s 522us/step - loss: 0.0572 - val_loss: 0.0590\n",
      "Epoch 655/1500\n",
      "1699/1699 [==============================] - 1s 479us/step - loss: 0.0573 - val_loss: 0.0587\n",
      "Epoch 656/1500\n",
      "1699/1699 [==============================] - 1s 522us/step - loss: 0.0572 - val_loss: 0.0587\n",
      "Epoch 657/1500\n",
      "1699/1699 [==============================] - 1s 518us/step - loss: 0.0576 - val_loss: 0.0588\n",
      "Epoch 658/1500\n",
      "1699/1699 [==============================] - 1s 490us/step - loss: 0.0573 - val_loss: 0.0591\n",
      "Epoch 659/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0574 - val_loss: 0.0588\n",
      "Epoch 660/1500\n",
      "1699/1699 [==============================] - 1s 490us/step - loss: 0.0574 - val_loss: 0.0590\n",
      "Epoch 661/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0574 - val_loss: 0.0585\n",
      "Epoch 662/1500\n",
      "1699/1699 [==============================] - 1s 531us/step - loss: 0.0574 - val_loss: 0.0588\n",
      "Epoch 663/1500\n",
      "1699/1699 [==============================] - 1s 531us/step - loss: 0.0574 - val_loss: 0.0585\n",
      "Epoch 664/1500\n",
      "1699/1699 [==============================] - 1s 631us/step - loss: 0.0572 - val_loss: 0.0587\n",
      "Epoch 665/1500\n",
      "1699/1699 [==============================] - 1s 490us/step - loss: 0.0572 - val_loss: 0.0588\n",
      "Epoch 666/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0572 - val_loss: 0.0590\n",
      "Epoch 667/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0572 - val_loss: 0.0585\n",
      "Epoch 668/1500\n",
      "1699/1699 [==============================] - 1s 522us/step - loss: 0.0572 - val_loss: 0.0586\n",
      "Epoch 669/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0572 - val_loss: 0.0585\n",
      "Epoch 670/1500\n",
      "1699/1699 [==============================] - 1s 522us/step - loss: 0.0572 - val_loss: 0.0588\n",
      "Epoch 671/1500\n",
      "1699/1699 [==============================] - 1s 490us/step - loss: 0.0572 - val_loss: 0.0586\n",
      "Epoch 672/1500\n",
      "1699/1699 [==============================] - 1s 494us/step - loss: 0.0573 - val_loss: 0.0594\n",
      "Epoch 673/1500\n",
      "1699/1699 [==============================] - 1s 500us/step - loss: 0.0573 - val_loss: 0.0590\n",
      "Epoch 674/1500\n",
      "1699/1699 [==============================] - 1s 531us/step - loss: 0.0571 - val_loss: 0.0587\n",
      "Epoch 675/1500\n",
      "1699/1699 [==============================] - 1s 503us/step - loss: 0.0571 - val_loss: 0.0590\n",
      "Epoch 676/1500\n",
      "1699/1699 [==============================] - 1s 503us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 677/1500\n",
      "1699/1699 [==============================] - 1s 509us/step - loss: 0.0572 - val_loss: 0.0588\n",
      "Epoch 678/1500\n",
      "1699/1699 [==============================] - 1s 490us/step - loss: 0.0572 - val_loss: 0.0588\n",
      "Epoch 679/1500\n",
      "1699/1699 [==============================] - 1s 494us/step - loss: 0.0571 - val_loss: 0.0592\n",
      "Epoch 680/1500\n",
      "1699/1699 [==============================] - 1s 531us/step - loss: 0.0572 - val_loss: 0.0588\n",
      "Epoch 681/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0572 - val_loss: 0.0588\n",
      "Epoch 682/1500\n",
      "1699/1699 [==============================] - 1s 676us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 683/1500\n",
      "1699/1699 [==============================] - 1s 503us/step - loss: 0.0571 - val_loss: 0.0585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/1500\n",
      "1699/1699 [==============================] - 1s 489us/step - loss: 0.0573 - val_loss: 0.0591\n",
      "Epoch 685/1500\n",
      "1699/1699 [==============================] - 1s 507us/step - loss: 0.0573 - val_loss: 0.0586\n",
      "Epoch 686/1500\n",
      "1699/1699 [==============================] - 1s 540us/step - loss: 0.0573 - val_loss: 0.0590\n",
      "Epoch 687/1500\n",
      "1699/1699 [==============================] - 1s 513us/step - loss: 0.0572 - val_loss: 0.0586\n",
      "Epoch 688/1500\n",
      "1699/1699 [==============================] - 1s 513us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 689/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0572 - val_loss: 0.0593\n",
      "Epoch 690/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0573 - val_loss: 0.0589\n",
      "Epoch 691/1500\n",
      "1699/1699 [==============================] - 1s 480us/step - loss: 0.0575 - val_loss: 0.0589\n",
      "Epoch 692/1500\n",
      "1699/1699 [==============================] - 1s 551us/step - loss: 0.0573 - val_loss: 0.0587\n",
      "Epoch 693/1500\n",
      "1699/1699 [==============================] - 1s 503us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 694/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0572 - val_loss: 0.0587\n",
      "Epoch 695/1500\n",
      "1699/1699 [==============================] - 1s 481us/step - loss: 0.0571 - val_loss: 0.0591\n",
      "Epoch 696/1500\n",
      "1699/1699 [==============================] - 1s 490us/step - loss: 0.0572 - val_loss: 0.0586\n",
      "Epoch 697/1500\n",
      "1699/1699 [==============================] - 1s 479us/step - loss: 0.0572 - val_loss: 0.0587\n",
      "Epoch 698/1500\n",
      "1699/1699 [==============================] - 1s 514us/step - loss: 0.0572 - val_loss: 0.0589\n",
      "Epoch 699/1500\n",
      "1699/1699 [==============================] - 1s 504us/step - loss: 0.0572 - val_loss: 0.0587\n",
      "Epoch 700/1500\n",
      "1699/1699 [==============================] - 1s 728us/step - loss: 0.0574 - val_loss: 0.0588\n",
      "Epoch 701/1500\n",
      "1699/1699 [==============================] - 1s 299us/step - loss: 0.0575 - val_loss: 0.0594\n",
      "Epoch 702/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0573 - val_loss: 0.0586\n",
      "Epoch 703/1500\n",
      "1699/1699 [==============================] - 0s 213us/step - loss: 0.0572 - val_loss: 0.0588\n",
      "Epoch 704/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0572 - val_loss: 0.0589\n",
      "Epoch 705/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0571 - val_loss: 0.0586\n",
      "Epoch 706/1500\n",
      "1699/1699 [==============================] - 0s 165us/step - loss: 0.0570 - val_loss: 0.0586\n",
      "Epoch 707/1500\n",
      "1699/1699 [==============================] - 0s 162us/step - loss: 0.0571 - val_loss: 0.0587\n",
      "Epoch 708/1500\n",
      "1699/1699 [==============================] - 0s 245us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 709/1500\n",
      "1699/1699 [==============================] - 0s 163us/step - loss: 0.0573 - val_loss: 0.0591\n",
      "Epoch 710/1500\n",
      "1699/1699 [==============================] - 0s 160us/step - loss: 0.0571 - val_loss: 0.0587\n",
      "Epoch 711/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0571 - val_loss: 0.0591\n",
      "Epoch 712/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0575 - val_loss: 0.0587\n",
      "Epoch 713/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0573 - val_loss: 0.0588\n",
      "Epoch 714/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0572 - val_loss: 0.0596\n",
      "Epoch 715/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0572 - val_loss: 0.0587\n",
      "Epoch 716/1500\n",
      "1699/1699 [==============================] - 0s 163us/step - loss: 0.0573 - val_loss: 0.0589\n",
      "Epoch 717/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 718/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 719/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 720/1500\n",
      "1699/1699 [==============================] - 0s 167us/step - loss: 0.0571 - val_loss: 0.0587\n",
      "Epoch 721/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0573 - val_loss: 0.0588\n",
      "Epoch 722/1500\n",
      "1699/1699 [==============================] - 0s 223us/step - loss: 0.0572 - val_loss: 0.0590\n",
      "Epoch 723/1500\n",
      "1699/1699 [==============================] - 0s 163us/step - loss: 0.0572 - val_loss: 0.0591\n",
      "Epoch 724/1500\n",
      "1699/1699 [==============================] - 0s 163us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 725/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0571 - val_loss: 0.0586\n",
      "Epoch 726/1500\n",
      "1699/1699 [==============================] - 0s 234us/step - loss: 0.0579 - val_loss: 0.0592\n",
      "Epoch 727/1500\n",
      "1699/1699 [==============================] - 0s 160us/step - loss: 0.0573 - val_loss: 0.0588\n",
      "Epoch 728/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0587\n",
      "Epoch 729/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0571 - val_loss: 0.0590\n",
      "Epoch 730/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0591\n",
      "Epoch 731/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0573 - val_loss: 0.0590\n",
      "Epoch 732/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 733/1500\n",
      "1699/1699 [==============================] - 0s 178us/step - loss: 0.0571 - val_loss: 0.0586\n",
      "Epoch 734/1500\n",
      "1699/1699 [==============================] - 0s 167us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 735/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0571 - val_loss: 0.0586\n",
      "Epoch 736/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 737/1500\n",
      "1699/1699 [==============================] - 0s 176us/step - loss: 0.0571 - val_loss: 0.0590\n",
      "Epoch 738/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0594\n",
      "Epoch 739/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0572 - val_loss: 0.0588\n",
      "Epoch 740/1500\n",
      "1699/1699 [==============================] - 0s 167us/step - loss: 0.0574 - val_loss: 0.0587\n",
      "Epoch 741/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 742/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 743/1500\n",
      "1699/1699 [==============================] - 0s 227us/step - loss: 0.0571 - val_loss: 0.0597\n",
      "Epoch 744/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0574 - val_loss: 0.0588\n",
      "Epoch 745/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0571 - val_loss: 0.0591\n",
      "Epoch 746/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0572 - val_loss: 0.0589\n",
      "Epoch 747/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0573 - val_loss: 0.0588\n",
      "Epoch 748/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 749/1500\n",
      "1699/1699 [==============================] - 0s 205us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 750/1500\n",
      "1699/1699 [==============================] - 0s 158us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 751/1500\n",
      "1699/1699 [==============================] - 0s 203us/step - loss: 0.0571 - val_loss: 0.0587\n",
      "Epoch 752/1500\n",
      "1699/1699 [==============================] - 1s 487us/step - loss: 0.0572 - val_loss: 0.0586\n",
      "Epoch 753/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0586\n",
      "Epoch 754/1500\n",
      "1699/1699 [==============================] - 0s 211us/step - loss: 0.0571 - val_loss: 0.0587\n",
      "Epoch 755/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0590\n",
      "Epoch 756/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0586\n",
      "Epoch 757/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0587\n",
      "Epoch 758/1500\n",
      "1699/1699 [==============================] - 0s 236us/step - loss: 0.0573 - val_loss: 0.0587\n",
      "Epoch 759/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0570 - val_loss: 0.0586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0571 - val_loss: 0.0591\n",
      "Epoch 761/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0593\n",
      "Epoch 762/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0571 - val_loss: 0.0586\n",
      "Epoch 763/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0591\n",
      "Epoch 764/1500\n",
      "1699/1699 [==============================] - 0s 190us/step - loss: 0.0571 - val_loss: 0.0591\n",
      "Epoch 765/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0574 - val_loss: 0.0590\n",
      "Epoch 766/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 767/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 768/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0570 - val_loss: 0.0587\n",
      "Epoch 769/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 770/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 771/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 772/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0570 - val_loss: 0.0587\n",
      "Epoch 773/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 774/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 775/1500\n",
      "1699/1699 [==============================] - 0s 227us/step - loss: 0.0570 - val_loss: 0.0587\n",
      "Epoch 776/1500\n",
      "1699/1699 [==============================] - 0s 195us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 777/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0586\n",
      "Epoch 778/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0571 - val_loss: 0.0587\n",
      "Epoch 779/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 780/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0571 - val_loss: 0.0592\n",
      "Epoch 781/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0590\n",
      "Epoch 782/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 783/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0570 - val_loss: 0.0594\n",
      "Epoch 784/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0592\n",
      "Epoch 785/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0570 - val_loss: 0.0586\n",
      "Epoch 786/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 787/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0572 - val_loss: 0.0588\n",
      "Epoch 788/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0587\n",
      "Epoch 789/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0594\n",
      "Epoch 790/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0591\n",
      "Epoch 791/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0587\n",
      "Epoch 792/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 793/1500\n",
      "1699/1699 [==============================] - 0s 236us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 794/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0572 - val_loss: 0.0592\n",
      "Epoch 795/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0573 - val_loss: 0.0587\n",
      "Epoch 796/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0593\n",
      "Epoch 797/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 798/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0572 - val_loss: 0.0588\n",
      "Epoch 799/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0590\n",
      "Epoch 800/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0572 - val_loss: 0.0587\n",
      "Epoch 801/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0591\n",
      "Epoch 802/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 803/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 804/1500\n",
      "1699/1699 [==============================] - 1s 472us/step - loss: 0.0571 - val_loss: 0.0585\n",
      "Epoch 805/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0599\n",
      "Epoch 806/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0571 - val_loss: 0.0586\n",
      "Epoch 807/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0569 - val_loss: 0.0587\n",
      "Epoch 808/1500\n",
      "1699/1699 [==============================] - 0s 205us/step - loss: 0.0568 - val_loss: 0.0586\n",
      "Epoch 809/1500\n",
      "1699/1699 [==============================] - 0s 199us/step - loss: 0.0570 - val_loss: 0.0586\n",
      "Epoch 810/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0590\n",
      "Epoch 811/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0570 - val_loss: 0.0593\n",
      "Epoch 812/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0571 - val_loss: 0.0590\n",
      "Epoch 813/1500\n",
      "1699/1699 [==============================] - 0s 163us/step - loss: 0.0570 - val_loss: 0.0587\n",
      "Epoch 814/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 815/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 816/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 817/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 818/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 819/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0586\n",
      "Epoch 820/1500\n",
      "1699/1699 [==============================] - 0s 169us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 821/1500\n",
      "1699/1699 [==============================] - 0s 158us/step - loss: 0.0571 - val_loss: 0.0587\n",
      "Epoch 822/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 823/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0570 - val_loss: 0.0587\n",
      "Epoch 824/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0570 - val_loss: 0.0587\n",
      "Epoch 825/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0569 - val_loss: 0.0590\n",
      "Epoch 826/1500\n",
      "1699/1699 [==============================] - 0s 227us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 827/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 828/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0591\n",
      "Epoch 829/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0590\n",
      "Epoch 830/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 831/1500\n",
      "1699/1699 [==============================] - 0s 163us/step - loss: 0.0570 - val_loss: 0.0586\n",
      "Epoch 832/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 833/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0570 - val_loss: 0.0587\n",
      "Epoch 834/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0587\n",
      "Epoch 835/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0571 - val_loss: 0.0587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0587\n",
      "Epoch 837/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0587\n",
      "Epoch 838/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 839/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 840/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 841/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 842/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 843/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0570 - val_loss: 0.0590\n",
      "Epoch 844/1500\n",
      "1699/1699 [==============================] - 0s 237us/step - loss: 0.0570 - val_loss: 0.0586\n",
      "Epoch 845/1500\n",
      "1699/1699 [==============================] - 0s 158us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 846/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0572 - val_loss: 0.0591\n",
      "Epoch 847/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 848/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0590\n",
      "Epoch 849/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 850/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 851/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 852/1500\n",
      "1699/1699 [==============================] - 0s 158us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 853/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0597\n",
      "Epoch 854/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 855/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0590\n",
      "Epoch 856/1500\n",
      "1699/1699 [==============================] - 0s 271us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 857/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 858/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0569 - val_loss: 0.0591\n",
      "Epoch 859/1500\n",
      "1699/1699 [==============================] - 0s 227us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 860/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0569 - val_loss: 0.0589\n",
      "Epoch 861/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 862/1500\n",
      "1699/1699 [==============================] - 0s 190us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 863/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 864/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0586\n",
      "Epoch 865/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0569 - val_loss: 0.0589\n",
      "Epoch 866/1500\n",
      "1699/1699 [==============================] - 0s 236us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 867/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 868/1500\n",
      "1699/1699 [==============================] - 0s 181us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 869/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0568 - val_loss: 0.0586\n",
      "Epoch 870/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0590\n",
      "Epoch 871/1500\n",
      "1699/1699 [==============================] - 1s 296us/step - loss: 0.0571 - val_loss: 0.0593\n",
      "Epoch 872/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0571 - val_loss: 0.0587\n",
      "Epoch 873/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 874/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0569 - val_loss: 0.0592\n",
      "Epoch 875/1500\n",
      "1699/1699 [==============================] - 0s 245us/step - loss: 0.0571 - val_loss: 0.0592\n",
      "Epoch 876/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0591\n",
      "Epoch 877/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0571 - val_loss: 0.0589\n",
      "Epoch 878/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0589\n",
      "Epoch 879/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0570 - val_loss: 0.0586\n",
      "Epoch 880/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0570 - val_loss: 0.0592\n",
      "Epoch 881/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0569 - val_loss: 0.0587\n",
      "Epoch 882/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0569 - val_loss: 0.0589\n",
      "Epoch 883/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0568 - val_loss: 0.0587\n",
      "Epoch 884/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0568 - val_loss: 0.0591\n",
      "Epoch 885/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 886/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0569 - val_loss: 0.0589\n",
      "Epoch 887/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0572 - val_loss: 0.0591\n",
      "Epoch 888/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 889/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0569 - val_loss: 0.0587\n",
      "Epoch 890/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0569 - val_loss: 0.0589\n",
      "Epoch 891/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0587\n",
      "Epoch 892/1500\n",
      "1699/1699 [==============================] - 0s 158us/step - loss: 0.0570 - val_loss: 0.0587\n",
      "Epoch 893/1500\n",
      "1699/1699 [==============================] - 0s 236us/step - loss: 0.0568 - val_loss: 0.0587\n",
      "Epoch 894/1500\n",
      "1699/1699 [==============================] - 0s 195us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 895/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0591\n",
      "Epoch 896/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0570 - val_loss: 0.0591\n",
      "Epoch 897/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 898/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0590\n",
      "Epoch 899/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 900/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0568 - val_loss: 0.0589\n",
      "Epoch 901/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0569 - val_loss: 0.0589\n",
      "Epoch 902/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0589\n",
      "Epoch 903/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 904/1500\n",
      "1699/1699 [==============================] - 0s 205us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 905/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0570 - val_loss: 0.0591\n",
      "Epoch 906/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0587\n",
      "Epoch 907/1500\n",
      "1699/1699 [==============================] - 1s 391us/step - loss: 0.0569 - val_loss: 0.0589\n",
      "Epoch 908/1500\n",
      "1699/1699 [==============================] - 1s 326us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 909/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 910/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0587\n",
      "Epoch 911/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0571 - val_loss: 0.0591\n",
      "Epoch 913/1500\n",
      "1699/1699 [==============================] - ETA: 0s - loss: 0.057 - 0s 169us/step - loss: 0.0571 - val_loss: 0.0593\n",
      "Epoch 914/1500\n",
      "1699/1699 [==============================] - 0s 157us/step - loss: 0.0569 - val_loss: 0.0591\n",
      "Epoch 915/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 916/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 917/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0586\n",
      "Epoch 918/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0572 - val_loss: 0.0591\n",
      "Epoch 919/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0586\n",
      "Epoch 920/1500\n",
      "1699/1699 [==============================] - 0s 166us/step - loss: 0.0568 - val_loss: 0.0589\n",
      "Epoch 921/1500\n",
      "1699/1699 [==============================] - 0s 165us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 922/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0568 - val_loss: 0.0590\n",
      "Epoch 923/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0568 - val_loss: 0.0592\n",
      "Epoch 924/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0569 - val_loss: 0.0594\n",
      "Epoch 925/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0569 - val_loss: 0.0589\n",
      "Epoch 926/1500\n",
      "1699/1699 [==============================] - 0s 254us/step - loss: 0.0568 - val_loss: 0.0589\n",
      "Epoch 927/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 928/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 929/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 930/1500\n",
      "1699/1699 [==============================] - 0s 169us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 931/1500\n",
      "1699/1699 [==============================] - 0s 166us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 932/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0568 - val_loss: 0.0589\n",
      "Epoch 933/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 934/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 935/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 936/1500\n",
      "1699/1699 [==============================] - 1s 440us/step - loss: 0.0568 - val_loss: 0.0593\n",
      "Epoch 937/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 938/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0568 - val_loss: 0.0591\n",
      "Epoch 939/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0589\n",
      "Epoch 940/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 941/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 942/1500\n",
      "1699/1699 [==============================] - 0s 267us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 943/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0568 - val_loss: 0.0587\n",
      "Epoch 944/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 945/1500\n",
      "1699/1699 [==============================] - 0s 187us/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 946/1500\n",
      "1699/1699 [==============================] - 0s 157us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 947/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0569 - val_loss: 0.0589\n",
      "Epoch 948/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 949/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 950/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0589\n",
      "Epoch 951/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 952/1500\n",
      "1699/1699 [==============================] - 0s 187us/step - loss: 0.0568 - val_loss: 0.0590\n",
      "Epoch 953/1500\n",
      "1699/1699 [==============================] - 0s 184us/step - loss: 0.0569 - val_loss: 0.0590\n",
      "Epoch 954/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 955/1500\n",
      "1699/1699 [==============================] - 0s 179us/step - loss: 0.0569 - val_loss: 0.0590\n",
      "Epoch 956/1500\n",
      "1699/1699 [==============================] - 0s 165us/step - loss: 0.0569 - val_loss: 0.0587\n",
      "Epoch 957/1500\n",
      "1699/1699 [==============================] - 0s 218us/step - loss: 0.0568 - val_loss: 0.0593\n",
      "Epoch 958/1500\n",
      "1699/1699 [==============================] - 1s 463us/step - loss: 0.0570 - val_loss: 0.0590\n",
      "Epoch 959/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 960/1500\n",
      "1699/1699 [==============================] - 0s 172us/step - loss: 0.0567 - val_loss: 0.0587\n",
      "Epoch 961/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0567 - val_loss: 0.0593\n",
      "Epoch 962/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 963/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0591\n",
      "Epoch 964/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0571 - val_loss: 0.0591\n",
      "Epoch 965/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 966/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 967/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0568 - val_loss: 0.0591\n",
      "Epoch 968/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0569 - val_loss: 0.0590\n",
      "Epoch 969/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0569 - val_loss: 0.0591\n",
      "Epoch 970/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0587\n",
      "Epoch 971/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 972/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 973/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0587\n",
      "Epoch 974/1500\n",
      "1699/1699 [==============================] - 0s 195us/step - loss: 0.0567 - val_loss: 0.0587\n",
      "Epoch 975/1500\n",
      "1699/1699 [==============================] - 0s 227us/step - loss: 0.0566 - val_loss: 0.0588\n",
      "Epoch 976/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0589\n",
      "Epoch 977/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 978/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 979/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0587\n",
      "Epoch 980/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0568 - val_loss: 0.0587\n",
      "Epoch 981/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 982/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0568 - val_loss: 0.0589\n",
      "Epoch 983/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 984/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0567 - val_loss: 0.0591\n",
      "Epoch 985/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0570 - val_loss: 0.0591\n",
      "Epoch 986/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 987/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 988/1500\n",
      "1699/1699 [==============================] - 0s 158us/step - loss: 0.0568 - val_loss: 0.0587\n",
      "Epoch 989/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0567 - val_loss: 0.0587\n",
      "Epoch 990/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0586\n",
      "Epoch 991/1500\n",
      "1699/1699 [==============================] - 0s 195us/step - loss: 0.0567 - val_loss: 0.0587\n",
      "Epoch 992/1500\n",
      "1699/1699 [==============================] - 0s 227us/step - loss: 0.0568 - val_loss: 0.0592\n",
      "Epoch 993/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 994/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 995/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 996/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0567 - val_loss: 0.0592\n",
      "Epoch 997/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0569 - val_loss: 0.0591\n",
      "Epoch 998/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0592\n",
      "Epoch 999/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0591\n",
      "Epoch 1000/1500\n",
      "1699/1699 [==============================] - 0s 195us/step - loss: 0.0567 - val_loss: 0.0587\n",
      "Epoch 1001/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0569 - val_loss: 0.0588\n",
      "Epoch 1002/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0567 - val_loss: 0.0587\n",
      "Epoch 1003/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0566 - val_loss: 0.0588\n",
      "Epoch 1004/1500\n",
      "1699/1699 [==============================] - 0s 178us/step - loss: 0.0566 - val_loss: 0.0588\n",
      "Epoch 1005/1500\n",
      "1699/1699 [==============================] - 0s 167us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 1006/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 1007/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1008/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0567 - val_loss: 0.0591\n",
      "Epoch 1009/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0569 - val_loss: 0.0590\n",
      "Epoch 1010/1500\n",
      "1699/1699 [==============================] - 1s 572us/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 1011/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0566 - val_loss: 0.0588\n",
      "Epoch 1012/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0591\n",
      "Epoch 1013/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1014/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0566 - val_loss: 0.0596\n",
      "Epoch 1015/1500\n",
      "1699/1699 [==============================] - 0s 195us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 1016/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0568 - val_loss: 0.0592\n",
      "Epoch 1017/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 1018/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1019/1500\n",
      "1699/1699 [==============================] - 0s 178us/step - loss: 0.0568 - val_loss: 0.0592\n",
      "Epoch 1020/1500\n",
      "1699/1699 [==============================] - 0s 167us/step - loss: 0.0568 - val_loss: 0.0591\n",
      "Epoch 1021/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1022/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1023/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0568 - val_loss: 0.0590\n",
      "Epoch 1024/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0568 - val_loss: 0.0589\n",
      "Epoch 1025/1500\n",
      "1699/1699 [==============================] - 0s 236us/step - loss: 0.0567 - val_loss: 0.0590\n",
      "Epoch 1026/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0568 - val_loss: 0.0589\n",
      "Epoch 1027/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0567 - val_loss: 0.0590\n",
      "Epoch 1028/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0567 - val_loss: 0.0590\n",
      "Epoch 1029/1500\n",
      "1699/1699 [==============================] - 0s 179us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1030/1500\n",
      "1699/1699 [==============================] - 0s 175us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1031/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1032/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0568 - val_loss: 0.0593\n",
      "Epoch 1033/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0567 - val_loss: 0.0593\n",
      "Epoch 1034/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0567 - val_loss: 0.0586\n",
      "Epoch 1035/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0593\n",
      "Epoch 1036/1500\n",
      "1699/1699 [==============================] - 0s 179us/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 1037/1500\n",
      "1699/1699 [==============================] - 0s 166us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1038/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0587\n",
      "Epoch 1039/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0566 - val_loss: 0.0587\n",
      "Epoch 1040/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1041/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1042/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 1043/1500\n",
      "1699/1699 [==============================] - 0s 236us/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 1044/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1045/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0590\n",
      "Epoch 1046/1500\n",
      "1699/1699 [==============================] - 0s 178us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1047/1500\n",
      "1699/1699 [==============================] - 0s 157us/step - loss: 0.0566 - val_loss: 0.0594\n",
      "Epoch 1048/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 1049/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0586\n",
      "Epoch 1050/1500\n",
      "1699/1699 [==============================] - 0s 227us/step - loss: 0.0566 - val_loss: 0.0597\n",
      "Epoch 1051/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0569 - val_loss: 0.0590\n",
      "Epoch 1052/1500\n",
      "1699/1699 [==============================] - 0s 201us/step - loss: 0.0567 - val_loss: 0.0590\n",
      "Epoch 1053/1500\n",
      "1699/1699 [==============================] - 0s 169us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1054/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1055/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0587\n",
      "Epoch 1056/1500\n",
      "1699/1699 [==============================] - 0s 188us/step - loss: 0.0567 - val_loss: 0.0587\n",
      "Epoch 1057/1500\n",
      "1699/1699 [==============================] - 0s 157us/step - loss: 0.0568 - val_loss: 0.0591\n",
      "Epoch 1058/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0567 - val_loss: 0.0591\n",
      "Epoch 1059/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1060/1500\n",
      "1699/1699 [==============================] - 0s 249us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1061/1500\n",
      "1699/1699 [==============================] - 0s 254us/step - loss: 0.0572 - val_loss: 0.0591\n",
      "Epoch 1062/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1699/1699 [==============================] - 1s 395us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1063/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1064/1500\n",
      "1699/1699 [==============================] - 0s 172us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1065/1500\n",
      "1699/1699 [==============================] - 0s 172us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1066/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0591\n",
      "Epoch 1067/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0592\n",
      "Epoch 1068/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 1069/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1070/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0566 - val_loss: 0.0594\n",
      "Epoch 1071/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 1072/1500\n",
      "1699/1699 [==============================] - 0s 171us/step - loss: 0.0565 - val_loss: 0.0588\n",
      "Epoch 1073/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0567 - val_loss: 0.0590\n",
      "Epoch 1074/1500\n",
      "1699/1699 [==============================] - 0s 195us/step - loss: 0.0568 - val_loss: 0.0591\n",
      "Epoch 1075/1500\n",
      "1699/1699 [==============================] - 0s 245us/step - loss: 0.0570 - val_loss: 0.0589\n",
      "Epoch 1076/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0566 - val_loss: 0.0587\n",
      "Epoch 1077/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0588\n",
      "Epoch 1078/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0565 - val_loss: 0.0592\n",
      "Epoch 1079/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1080/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0567 - val_loss: 0.0591\n",
      "Epoch 1081/1500\n",
      "1699/1699 [==============================] - 0s 212us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 1082/1500\n",
      "1699/1699 [==============================] - 0s 163us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1083/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1084/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1085/1500\n",
      "1699/1699 [==============================] - 0s 209us/step - loss: 0.0569 - val_loss: 0.0590\n",
      "Epoch 1086/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1087/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1088/1500\n",
      "1699/1699 [==============================] - 0s 199us/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 1089/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0565 - val_loss: 0.0592\n",
      "Epoch 1090/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 1091/1500\n",
      "1699/1699 [==============================] - 0s 208us/step - loss: 0.0567 - val_loss: 0.0590\n",
      "Epoch 1092/1500\n",
      "1699/1699 [==============================] - 0s 227us/step - loss: 0.0568 - val_loss: 0.0590\n",
      "Epoch 1093/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 1094/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0566 - val_loss: 0.0588\n",
      "Epoch 1095/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1096/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1097/1500\n",
      "1699/1699 [==============================] - 0s 185us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1098/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1099/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0588\n",
      "Epoch 1100/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0590\n",
      "Epoch 1101/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0566 - val_loss: 0.0588\n",
      "Epoch 1102/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1103/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1104/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0567 - val_loss: 0.0591\n",
      "Epoch 1105/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1106/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1107/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0588\n",
      "Epoch 1108/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0566 - val_loss: 0.0593\n",
      "Epoch 1109/1500\n",
      "1699/1699 [==============================] - 0s 227us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 1110/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0593\n",
      "Epoch 1111/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0566 - val_loss: 0.0601\n",
      "Epoch 1112/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1113/1500\n",
      "1699/1699 [==============================] - 1s 491us/step - loss: 0.0567 - val_loss: 0.0592\n",
      "Epoch 1114/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1115/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0566 - val_loss: 0.0602\n",
      "Epoch 1116/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0568 - val_loss: 0.0588\n",
      "Epoch 1117/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1118/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1119/1500\n",
      "1699/1699 [==============================] - 0s 187us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1120/1500\n",
      "1699/1699 [==============================] - 0s 176us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1121/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0570 - val_loss: 0.0588\n",
      "Epoch 1122/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1123/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1124/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0588\n",
      "Epoch 1125/1500\n",
      "1699/1699 [==============================] - 0s 236us/step - loss: 0.0565 - val_loss: 0.0588\n",
      "Epoch 1126/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1127/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0566 - val_loss: 0.0592\n",
      "Epoch 1128/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1129/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0591\n",
      "Epoch 1130/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0567 - val_loss: 0.0590\n",
      "Epoch 1131/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0566 - val_loss: 0.0594\n",
      "Epoch 1132/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1133/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0565 - val_loss: 0.0587\n",
      "Epoch 1134/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1135/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1136/1500\n",
      "1699/1699 [==============================] - 0s 172us/step - loss: 0.0568 - val_loss: 0.0594\n",
      "Epoch 1137/1500\n",
      "1699/1699 [==============================] - 0s 172us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1138/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1139/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0592\n",
      "Epoch 1140/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 1141/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0566 - val_loss: 0.0592\n",
      "Epoch 1142/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1143/1500\n",
      "1699/1699 [==============================] - 0s 245us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1144/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0599\n",
      "Epoch 1145/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1146/1500\n",
      "1699/1699 [==============================] - 0s 174us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1147/1500\n",
      "1699/1699 [==============================] - 0s 171us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1148/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1149/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1150/1500\n",
      "1699/1699 [==============================] - 0s 190us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1151/1500\n",
      "1699/1699 [==============================] - 0s 182us/step - loss: 0.0567 - val_loss: 0.0591\n",
      "Epoch 1152/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1153/1500\n",
      "1699/1699 [==============================] - 0s 181us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1154/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0565 - val_loss: 0.0594\n",
      "Epoch 1155/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0565 - val_loss: 0.0592\n",
      "Epoch 1156/1500\n",
      "1699/1699 [==============================] - 0s 172us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1157/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0565 - val_loss: 0.0588\n",
      "Epoch 1158/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1159/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1160/1500\n",
      "1699/1699 [==============================] - 0s 236us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1161/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0565 - val_loss: 0.0588\n",
      "Epoch 1162/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 1163/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1164/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1165/1500\n",
      "1699/1699 [==============================] - 0s 264us/step - loss: 0.0568 - val_loss: 0.0590\n",
      "Epoch 1166/1500\n",
      "1699/1699 [==============================] - 1s 385us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1167/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1168/1500\n",
      "1699/1699 [==============================] - 0s 162us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1169/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0567 - val_loss: 0.0595\n",
      "Epoch 1170/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1171/1500\n",
      "1699/1699 [==============================] - 0s 195us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1172/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1173/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0565 - val_loss: 0.0588\n",
      "Epoch 1174/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1175/1500\n",
      "1699/1699 [==============================] - 0s 165us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1176/1500\n",
      "1699/1699 [==============================] - 0s 226us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1177/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0565 - val_loss: 0.0592\n",
      "Epoch 1178/1500\n",
      "1699/1699 [==============================] - 0s 169us/step - loss: 0.0567 - val_loss: 0.0593\n",
      "Epoch 1179/1500\n",
      "1699/1699 [==============================] - 0s 167us/step - loss: 0.0566 - val_loss: 0.0594\n",
      "Epoch 1180/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0567 - val_loss: 0.0590\n",
      "Epoch 1181/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1182/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0566 - val_loss: 0.0593\n",
      "Epoch 1183/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0566 - val_loss: 0.0592\n",
      "Epoch 1184/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0566 - val_loss: 0.0592\n",
      "Epoch 1185/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0567 - val_loss: 0.0590\n",
      "Epoch 1186/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1187/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0565 - val_loss: 0.0588\n",
      "Epoch 1188/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0592\n",
      "Epoch 1189/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1190/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1191/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1192/1500\n",
      "1699/1699 [==============================] - 1s 394us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1193/1500\n",
      "1699/1699 [==============================] - 1s 307us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1194/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0565 - val_loss: 0.0588\n",
      "Epoch 1195/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0565 - val_loss: 0.0587\n",
      "Epoch 1196/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1197/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1198/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0593\n",
      "Epoch 1199/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0567 - val_loss: 0.0592\n",
      "Epoch 1200/1500\n",
      "1699/1699 [==============================] - 0s 170us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1201/1500\n",
      "1699/1699 [==============================] - 0s 166us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1202/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1203/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0606\n",
      "Epoch 1204/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0591\n",
      "Epoch 1205/1500\n",
      "1699/1699 [==============================] - 0s 195us/step - loss: 0.0565 - val_loss: 0.0587\n",
      "Epoch 1206/1500\n",
      "1699/1699 [==============================] - 1s 322us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1207/1500\n",
      "1699/1699 [==============================] - ETA: 0s - loss: 0.056 - 1s 376us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1208/1500\n",
      "1699/1699 [==============================] - 1s 308us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1209/1500\n",
      "1699/1699 [==============================] - 1s 323us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1210/1500\n",
      "1699/1699 [==============================] - 1s 326us/step - loss: 0.0568 - val_loss: 0.0592\n",
      "Epoch 1211/1500\n",
      "1699/1699 [==============================] - 1s 658us/step - loss: 0.0565 - val_loss: 0.0588\n",
      "Epoch 1212/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1699/1699 [==============================] - 1s 314us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1213/1500\n",
      "1699/1699 [==============================] - 1s 326us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1214/1500\n",
      "1699/1699 [==============================] - 1s 316us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1215/1500\n",
      "1699/1699 [==============================] - 1s 333us/step - loss: 0.0564 - val_loss: 0.0588\n",
      "Epoch 1216/1500\n",
      "1699/1699 [==============================] - 1s 381us/step - loss: 0.0565 - val_loss: 0.0592\n",
      "Epoch 1217/1500\n",
      "1699/1699 [==============================] - 1s 308us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1218/1500\n",
      "1699/1699 [==============================] - 1s 323us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1219/1500\n",
      "1699/1699 [==============================] - 1s 313us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1220/1500\n",
      "1699/1699 [==============================] - 1s 317us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1221/1500\n",
      "1699/1699 [==============================] - 1s 323us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1222/1500\n",
      "1699/1699 [==============================] - 1s 313us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1223/1500\n",
      "1699/1699 [==============================] - 1s 329us/step - loss: 0.0566 - val_loss: 0.0592\n",
      "Epoch 1224/1500\n",
      "1699/1699 [==============================] - 1s 324us/step - loss: 0.0565 - val_loss: 0.0593\n",
      "Epoch 1225/1500\n",
      "1699/1699 [==============================] - 1s 432us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1226/1500\n",
      "1699/1699 [==============================] - 1s 332us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1227/1500\n",
      "1699/1699 [==============================] - 1s 313us/step - loss: 0.0566 - val_loss: 0.0593\n",
      "Epoch 1228/1500\n",
      "1699/1699 [==============================] - 1s 357us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1229/1500\n",
      "1699/1699 [==============================] - 1s 330us/step - loss: 0.0565 - val_loss: 0.0592\n",
      "Epoch 1230/1500\n",
      "1699/1699 [==============================] - 1s 304us/step - loss: 0.0567 - val_loss: 0.0588\n",
      "Epoch 1231/1500\n",
      "1699/1699 [==============================] - 1s 317us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1232/1500\n",
      "1699/1699 [==============================] - 1s 313us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1233/1500\n",
      "1699/1699 [==============================] - 1s 314us/step - loss: 0.0566 - val_loss: 0.0596\n",
      "Epoch 1234/1500\n",
      "1699/1699 [==============================] - 1s 404us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1235/1500\n",
      "1699/1699 [==============================] - 1s 313us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1236/1500\n",
      "1699/1699 [==============================] - 1s 308us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1237/1500\n",
      "1699/1699 [==============================] - 1s 313us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1238/1500\n",
      "1699/1699 [==============================] - 1s 354us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1239/1500\n",
      "1699/1699 [==============================] - 1s 590us/step - loss: 0.0565 - val_loss: 0.0592\n",
      "Epoch 1240/1500\n",
      "1699/1699 [==============================] - 1s 336us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1241/1500\n",
      "1699/1699 [==============================] - 1s 332us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1242/1500\n",
      "1699/1699 [==============================] - 1s 345us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1243/1500\n",
      "1699/1699 [==============================] - 1s 354us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1244/1500\n",
      "1699/1699 [==============================] - 1s 322us/step - loss: 0.0570 - val_loss: 0.0593\n",
      "Epoch 1245/1500\n",
      "1699/1699 [==============================] - 1s 336us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1246/1500\n",
      "1699/1699 [==============================] - 1s 317us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1247/1500\n",
      "1699/1699 [==============================] - 1s 323us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1248/1500\n",
      "1699/1699 [==============================] - 1s 313us/step - loss: 0.0563 - val_loss: 0.0594\n",
      "Epoch 1249/1500\n",
      "1699/1699 [==============================] - 1s 336us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1250/1500\n",
      "1699/1699 [==============================] - 1s 304us/step - loss: 0.0565 - val_loss: 0.0593\n",
      "Epoch 1251/1500\n",
      "1699/1699 [==============================] - 1s 317us/step - loss: 0.0566 - val_loss: 0.0592\n",
      "Epoch 1252/1500\n",
      "1699/1699 [==============================] - 1s 332us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1253/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1254/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0566 - val_loss: 0.0593\n",
      "Epoch 1255/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1256/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1257/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1258/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0565 - val_loss: 0.0592\n",
      "Epoch 1259/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0588\n",
      "Epoch 1260/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1261/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1262/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1263/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1264/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0565 - val_loss: 0.0594\n",
      "Epoch 1265/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0566 - val_loss: 0.0592\n",
      "Epoch 1266/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0592\n",
      "Epoch 1267/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0595\n",
      "Epoch 1268/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0568 - val_loss: 0.0592\n",
      "Epoch 1269/1500\n",
      "1699/1699 [==============================] - 0s 227us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1270/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0563 - val_loss: 0.0588\n",
      "Epoch 1271/1500\n",
      "1699/1699 [==============================] - 0s 190us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1272/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1273/1500\n",
      "1699/1699 [==============================] - 0s 190us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1274/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1275/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0593\n",
      "Epoch 1276/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1277/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1278/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0567 - val_loss: 0.0589\n",
      "Epoch 1279/1500\n",
      "1699/1699 [==============================] - 1s 500us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1280/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0592\n",
      "Epoch 1281/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1282/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0588\n",
      "Epoch 1283/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0594\n",
      "Epoch 1284/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1285/1500\n",
      "1699/1699 [==============================] - 0s 232us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1286/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0593\n",
      "Epoch 1287/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1288/1500\n",
      "1699/1699 [==============================] - 0s 170us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1289/1500\n",
      "1699/1699 [==============================] - 0s 175us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1290/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1291/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1292/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0565 - val_loss: 0.0592\n",
      "Epoch 1293/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1294/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0563 - val_loss: 0.0592\n",
      "Epoch 1295/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0600\n",
      "Epoch 1296/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0589\n",
      "Epoch 1297/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1298/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1299/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0594\n",
      "Epoch 1300/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1301/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1302/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1303/1500\n",
      "1699/1699 [==============================] - 0s 209us/step - loss: 0.0564 - val_loss: 0.0594\n",
      "Epoch 1304/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1305/1500\n",
      "1699/1699 [==============================] - 0s 178us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1306/1500\n",
      "1699/1699 [==============================] - 0s 166us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1307/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0564 - val_loss: 0.0596\n",
      "Epoch 1308/1500\n",
      "1699/1699 [==============================] - 0s 183us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1309/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1310/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1311/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0594\n",
      "Epoch 1312/1500\n",
      "1699/1699 [==============================] - 0s 174us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1313/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1314/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1315/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0591\n",
      "Epoch 1316/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0588\n",
      "Epoch 1317/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1318/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0592\n",
      "Epoch 1319/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0564 - val_loss: 0.0593\n",
      "Epoch 1320/1500\n",
      "1699/1699 [==============================] - 0s 236us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1321/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1322/1500\n",
      "1699/1699 [==============================] - 0s 167us/step - loss: 0.0563 - val_loss: 0.0588\n",
      "Epoch 1323/1500\n",
      "1699/1699 [==============================] - 0s 149us/step - loss: 0.0564 - val_loss: 0.0592\n",
      "Epoch 1324/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0566 - val_loss: 0.0591\n",
      "Epoch 1325/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1326/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1327/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0565 - val_loss: 0.0588\n",
      "Epoch 1328/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1329/1500\n",
      "1699/1699 [==============================] - 0s 179us/step - loss: 0.0566 - val_loss: 0.0590\n",
      "Epoch 1330/1500\n",
      "1699/1699 [==============================] - 0s 184us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1331/1500\n",
      "1699/1699 [==============================] - 0s 245us/step - loss: 0.0562 - val_loss: 0.0592\n",
      "Epoch 1332/1500\n",
      "1699/1699 [==============================] - 1s 394us/step - loss: 0.0563 - val_loss: 0.0591\n",
      "Epoch 1333/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1334/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0591\n",
      "Epoch 1335/1500\n",
      "1699/1699 [==============================] - 0s 163us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1336/1500\n",
      "1699/1699 [==============================] - 0s 227us/step - loss: 0.0565 - val_loss: 0.0592\n",
      "Epoch 1337/1500\n",
      "1699/1699 [==============================] - 0s 190us/step - loss: 0.0564 - val_loss: 0.0592\n",
      "Epoch 1338/1500\n",
      "1699/1699 [==============================] - 0s 154us/step - loss: 0.0568 - val_loss: 0.0596\n",
      "Epoch 1339/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0592\n",
      "Epoch 1340/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0589\n",
      "Epoch 1341/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1342/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0562 - val_loss: 0.0589\n",
      "Epoch 1343/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0565 - val_loss: 0.0595\n",
      "Epoch 1344/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1345/1500\n",
      "1699/1699 [==============================] - 0s 158us/step - loss: 0.0565 - val_loss: 0.0593\n",
      "Epoch 1346/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0568 - val_loss: 0.0590\n",
      "Epoch 1347/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0562 - val_loss: 0.0588\n",
      "Epoch 1348/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1349/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1350/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1351/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0563 - val_loss: 0.0591\n",
      "Epoch 1352/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0592\n",
      "Epoch 1353/1500\n",
      "1699/1699 [==============================] - 0s 227us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1354/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0564 - val_loss: 0.0593\n",
      "Epoch 1355/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1356/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1357/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0588\n",
      "Epoch 1358/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0591\n",
      "Epoch 1359/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1360/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0588\n",
      "Epoch 1361/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1362/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0592\n",
      "Epoch 1363/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1364/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1365/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0593\n",
      "Epoch 1366/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0595\n",
      "Epoch 1367/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0565 - val_loss: 0.0595\n",
      "Epoch 1368/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1369/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1370/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1371/1500\n",
      "1699/1699 [==============================] - 0s 223us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1372/1500\n",
      "1699/1699 [==============================] - 0s 190us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1373/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0567 - val_loss: 0.0593\n",
      "Epoch 1374/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0596\n",
      "Epoch 1375/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0564 - val_loss: 0.0593\n",
      "Epoch 1376/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1377/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1378/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0593\n",
      "Epoch 1379/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0563 - val_loss: 0.0592\n",
      "Epoch 1380/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0563 - val_loss: 0.0592\n",
      "Epoch 1381/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1382/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0563 - val_loss: 0.0591\n",
      "Epoch 1383/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0593\n",
      "Epoch 1384/1500\n",
      "1699/1699 [==============================] - 0s 254us/step - loss: 0.0565 - val_loss: 0.0592\n",
      "Epoch 1385/1500\n",
      "1699/1699 [==============================] - 1s 386us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1386/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0564 - val_loss: 0.0592\n",
      "Epoch 1387/1500\n",
      "1699/1699 [==============================] - 0s 236us/step - loss: 0.0563 - val_loss: 0.0593\n",
      "Epoch 1388/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0563 - val_loss: 0.0592\n",
      "Epoch 1389/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1390/1500\n",
      "1699/1699 [==============================] - 0s 172us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1391/1500\n",
      "1699/1699 [==============================] - 0s 163us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1392/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0591\n",
      "Epoch 1393/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1394/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1395/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0596\n",
      "Epoch 1396/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0565 - val_loss: 0.0591\n",
      "Epoch 1397/1500\n",
      "1699/1699 [==============================] - 0s 226us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1398/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0563 - val_loss: 0.0591\n",
      "Epoch 1399/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1400/1500\n",
      "1699/1699 [==============================] - 0s 187us/step - loss: 0.0563 - val_loss: 0.0595\n",
      "Epoch 1401/1500\n",
      "1699/1699 [==============================] - 0s 157us/step - loss: 0.0564 - val_loss: 0.0592\n",
      "Epoch 1402/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0565 - val_loss: 0.0593\n",
      "Epoch 1403/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1404/1500\n",
      "1699/1699 [==============================] - 0s 245us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1405/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0564 - val_loss: 0.0588\n",
      "Epoch 1406/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1407/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0593\n",
      "Epoch 1408/1500\n",
      "1699/1699 [==============================] - 0s 211us/step - loss: 0.0564 - val_loss: 0.0592\n",
      "Epoch 1409/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0596\n",
      "Epoch 1410/1500\n",
      "1699/1699 [==============================] - 0s 170us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1411/1500\n",
      "1699/1699 [==============================] - 0s 165us/step - loss: 0.0564 - val_loss: 0.0592\n",
      "Epoch 1412/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0591\n",
      "Epoch 1413/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0564 - val_loss: 0.0592\n",
      "Epoch 1414/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1415/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1416/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1417/1500\n",
      "1699/1699 [==============================] - 0s 169us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1418/1500\n",
      "1699/1699 [==============================] - 0s 166us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1419/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0562 - val_loss: 0.0591\n",
      "Epoch 1420/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1421/1500\n",
      "1699/1699 [==============================] - 0s 236us/step - loss: 0.0564 - val_loss: 0.0594\n",
      "Epoch 1422/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0564 - val_loss: 0.0592\n",
      "Epoch 1423/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0562 - val_loss: 0.0593\n",
      "Epoch 1424/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1425/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1426/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0563 - val_loss: 0.0593\n",
      "Epoch 1427/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1428/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0562 - val_loss: 0.0592\n",
      "Epoch 1429/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0564 - val_loss: 0.0588\n",
      "Epoch 1430/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1431/1500\n",
      "1699/1699 [==============================] - 0s 195us/step - loss: 0.0564 - val_loss: 0.0594\n",
      "Epoch 1432/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1433/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1434/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1435/1500\n",
      "1699/1699 [==============================] - 0s 155us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1436/1500\n",
      "1699/1699 [==============================] - 1s 420us/step - loss: 0.0561 - val_loss: 0.0590\n",
      "Epoch 1437/1500\n",
      "1699/1699 [==============================] - 1s 328us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1438/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1439/1500\n",
      "1699/1699 [==============================] - 0s 214us/step - loss: 0.0563 - val_loss: 0.0591\n",
      "Epoch 1440/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1441/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0563 - val_loss: 0.0592\n",
      "Epoch 1442/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0567 - val_loss: 0.0593\n",
      "Epoch 1443/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1444/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1445/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1446/1500\n",
      "1699/1699 [==============================] - 0s 154us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1447/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1448/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1449/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0593\n",
      "Epoch 1450/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0566 - val_loss: 0.0592\n",
      "Epoch 1451/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1452/1500\n",
      "1699/1699 [==============================] - 0s 163us/step - loss: 0.0564 - val_loss: 0.0592\n",
      "Epoch 1453/1500\n",
      "1699/1699 [==============================] - 0s 154us/step - loss: 0.0562 - val_loss: 0.0589\n",
      "Epoch 1454/1500\n",
      "1699/1699 [==============================] - 0s 245us/step - loss: 0.0562 - val_loss: 0.0589\n",
      "Epoch 1455/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0562 - val_loss: 0.0594\n",
      "Epoch 1456/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0562 - val_loss: 0.0589\n",
      "Epoch 1457/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1458/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1459/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0562 - val_loss: 0.0591\n",
      "Epoch 1460/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0562 - val_loss: 0.0593\n",
      "Epoch 1461/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0563 - val_loss: 0.0592\n",
      "Epoch 1462/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0564 - val_loss: 0.0595\n",
      "Epoch 1463/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0591\n",
      "Epoch 1464/1500\n",
      "1699/1699 [==============================] - 0s 173us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1465/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0561 - val_loss: 0.0591\n",
      "Epoch 1466/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0593\n",
      "Epoch 1467/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1468/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0563 - val_loss: 0.0591\n",
      "Epoch 1469/1500\n",
      "1699/1699 [==============================] - 0s 159us/step - loss: 0.0562 - val_loss: 0.0592\n",
      "Epoch 1470/1500\n",
      "1699/1699 [==============================] - 0s 177us/step - loss: 0.0563 - val_loss: 0.0592\n",
      "Epoch 1471/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1472/1500\n",
      "1699/1699 [==============================] - 0s 227us/step - loss: 0.0565 - val_loss: 0.0596\n",
      "Epoch 1473/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0564 - val_loss: 0.0593\n",
      "Epoch 1474/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0564 - val_loss: 0.0589\n",
      "Epoch 1475/1500\n",
      "1699/1699 [==============================] - 0s 186us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1476/1500\n",
      "1699/1699 [==============================] - 0s 164us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1477/1500\n",
      "1699/1699 [==============================] - 0s 168us/step - loss: 0.0561 - val_loss: 0.0590\n",
      "Epoch 1478/1500\n",
      "1699/1699 [==============================] - 0s 208us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1479/1500\n",
      "1699/1699 [==============================] - 1s 308us/step - loss: 0.0562 - val_loss: 0.0592\n",
      "Epoch 1480/1500\n",
      "1699/1699 [==============================] - 1s 343us/step - loss: 0.0563 - val_loss: 0.0594\n",
      "Epoch 1481/1500\n",
      "1699/1699 [==============================] - 1s 612us/step - loss: 0.0563 - val_loss: 0.0589\n",
      "Epoch 1482/1500\n",
      "1699/1699 [==============================] - 2s 1ms/step - loss: 0.0562 - val_loss: 0.0592\n",
      "Epoch 1483/1500\n",
      "1699/1699 [==============================] - 1s 354us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1484/1500\n",
      "1699/1699 [==============================] - 0s 293us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1485/1500\n",
      "1699/1699 [==============================] - 0s 224us/step - loss: 0.0562 - val_loss: 0.0593\n",
      "Epoch 1486/1500\n",
      "1699/1699 [==============================] - 0s 189us/step - loss: 0.0563 - val_loss: 0.0600\n",
      "Epoch 1487/1500\n",
      "1699/1699 [==============================] - 1s 317us/step - loss: 0.0565 - val_loss: 0.0590\n",
      "Epoch 1488/1500\n",
      "1699/1699 [==============================] - 0s 260us/step - loss: 0.0562 - val_loss: 0.0590\n",
      "Epoch 1489/1500\n",
      "1699/1699 [==============================] - 0s 271us/step - loss: 0.0562 - val_loss: 0.0591\n",
      "Epoch 1490/1500\n",
      "1699/1699 [==============================] - 0s 288us/step - loss: 0.0561 - val_loss: 0.0590\n",
      "Epoch 1491/1500\n",
      "1699/1699 [==============================] - 0s 240us/step - loss: 0.0562 - val_loss: 0.0593\n",
      "Epoch 1492/1500\n",
      "1699/1699 [==============================] - 1s 305us/step - loss: 0.0563 - val_loss: 0.0593\n",
      "Epoch 1493/1500\n",
      "1699/1699 [==============================] - 1s 312us/step - loss: 0.0564 - val_loss: 0.0592\n",
      "Epoch 1494/1500\n",
      "1699/1699 [==============================] - 0s 291us/step - loss: 0.0563 - val_loss: 0.0591\n",
      "Epoch 1495/1500\n",
      "1699/1699 [==============================] - 0s 247us/step - loss: 0.0564 - val_loss: 0.0590\n",
      "Epoch 1496/1500\n",
      "1699/1699 [==============================] - 0s 259us/step - loss: 0.0563 - val_loss: 0.0592\n",
      "Epoch 1497/1500\n",
      "1699/1699 [==============================] - 0s 268us/step - loss: 0.0562 - val_loss: 0.0592\n",
      "Epoch 1498/1500\n",
      "1699/1699 [==============================] - 0s 234us/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 1499/1500\n",
      "1699/1699 [==============================] - 0s 253us/step - loss: 0.0563 - val_loss: 0.0592\n",
      "Epoch 1500/1500\n",
      "1699/1699 [==============================] - 1s 332us/step - loss: 0.0562 - val_loss: 0.0592\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Will create a large function to apply to the 4 CT Scans for each year.\n",
    "parsee = ct_sheet.sheet_names[9]\n",
    "data = ct_sheet.parse(parsee)\n",
    "data_features = data.loc[:, data.columns] \n",
    "data_features = data_features.drop(['Case','Visit','ROI42','ROI117'], axis=1)  \n",
    "#Get rid of subject names to only have features now. #Need to remove ROIs. They don't convert to floats.\n",
    "#Get rid of ctx_rh_Medial_wall and ctx_lh_Medial_wall, not needed for analysis.\n",
    "#Have to standardize data. Scikit learn here. Need to create stratified K folds to avoid uneven distribution of risk groups.pcaCT1Y = PCA(n_components=150) #150 Features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data_features)\n",
    "\n",
    "ct_sheet = pd.ExcelFile(\"ctAutoEncoder.xlsx\") \n",
    "parsee = ct_sheet.sheet_names[0]\n",
    "data = ct_sheet.parse(parsee)\n",
    "data_features = data.loc[:, data.columns] \n",
    "data_features = data_features.drop(['norm_id','AtRisk',11142,12142,'Age'], axis=1)  \n",
    "scaled_data = scaler.transform(data_features)\n",
    "\n",
    "print(scaled_data.shape)\n",
    "X_train, X_test = train_test_split(scaled_data, test_size=0.10, random_state=20)\n",
    "\n",
    "#Size of encoded representation\n",
    "input_size = 148\n",
    "hidden_size3 = 120\n",
    "hidden_size2 = 65\n",
    "hidden_size1 = 30\n",
    "encoding_dim = 13 # 13 floats -> compression of factor ~11.5, assuming the input is 150 floats\n",
    "\n",
    "# Input Placeholder\n",
    "input_data = Input(shape=(input_size,))\n",
    "print(input_data)\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "hidden_e_3 = Dense(hidden_size3, activation='tanh')(input_data)\n",
    "hidden_e_2 = Dense(hidden_size2, activation='tanh')(hidden_e_3)\n",
    "hidden_e_1 = Dense(hidden_size1, activation='tanh')(hidden_e_2) \n",
    "encoded = Dense(encoding_dim, activation='tanh')(hidden_e_1)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "hidden_d_1 = Dense(hidden_size1, activation='tanh')(encoded)\n",
    "hidden_d_2 = Dense(hidden_size2, activation='tanh')(hidden_d_1)\n",
    "hidden_d_3 = Dense(hidden_size3, activation='tanh')(hidden_d_2)\n",
    "decoded = Dense(input_size, activation='tanh')(hidden_d_3) #Decoded layers and activation function. Needs to return to 151.\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_data, decoded)\n",
    "# configure our model to use mean_absolute_error loss function, and the Adam optimizer:\n",
    "autoencoder.compile(optimizer='Adam', loss='mean_absolute_error')\n",
    "\n",
    "ac = autoencoder.fit(X_train, X_train,\n",
    "epochs=1500,\n",
    "batch_size=15,\n",
    "shuffle=True,\n",
    "validation_data=(X_test, X_test))\n",
    "\n",
    "#print(ac.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(ac.history['loss'])\n",
    "plt.plot(ac.history['val_loss'])\n",
    "#plt.set(xlim=(0, 50), ylim=(0.0, 1.0))\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, 1500, 0.0, 0.15])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 602 samples, validate on 67 samples\n",
      "Epoch 1/1500\n",
      "602/602 [==============================] - 2s 4ms/step - loss: 0.1036 - val_loss: 0.0755\n",
      "Epoch 2/1500\n",
      "602/602 [==============================] - 1s 911us/step - loss: 0.0718 - val_loss: 0.0670\n",
      "Epoch 3/1500\n",
      "602/602 [==============================] - 1s 880us/step - loss: 0.0660 - val_loss: 0.0634\n",
      "Epoch 4/1500\n",
      "602/602 [==============================] - 1s 918us/step - loss: 0.0629 - val_loss: 0.0624\n",
      "Epoch 5/1500\n",
      "602/602 [==============================] - 1s 996us/step - loss: 0.0607 - val_loss: 0.0596\n",
      "Epoch 6/1500\n",
      "602/602 [==============================] - 1s 936us/step - loss: 0.0590 - val_loss: 0.0583\n",
      "Epoch 7/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0575 - val_loss: 0.0571\n",
      "Epoch 8/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0565 - val_loss: 0.0566\n",
      "Epoch 9/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0557 - val_loss: 0.0554\n",
      "Epoch 10/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0547 - val_loss: 0.0551\n",
      "Epoch 11/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0542 - val_loss: 0.0544\n",
      "Epoch 12/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0538 - val_loss: 0.0541ETA: 0s - loss: 0.0\n",
      "Epoch 13/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0536 - val_loss: 0.0548\n",
      "Epoch 14/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0536 - val_loss: 0.0540\n",
      "Epoch 15/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0532 - val_loss: 0.0539\n",
      "Epoch 16/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0530 - val_loss: 0.0537\n",
      "Epoch 17/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0529 - val_loss: 0.0535\n",
      "Epoch 18/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0528 - val_loss: 0.0536\n",
      "Epoch 19/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0526 - val_loss: 0.0535\n",
      "Epoch 20/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0526 - val_loss: 0.0540\n",
      "Epoch 21/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0529 - val_loss: 0.0537\n",
      "Epoch 22/1500\n",
      "602/602 [==============================] - 1s 994us/step - loss: 0.0526 - val_loss: 0.0535\n",
      "Epoch 23/1500\n",
      "602/602 [==============================] - 0s 812us/step - loss: 0.0526 - val_loss: 0.0538\n",
      "Epoch 24/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0534 - val_loss: 0.0535\n",
      "Epoch 25/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0529 - val_loss: 0.0535\n",
      "Epoch 26/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0524 - val_loss: 0.0534\n",
      "Epoch 27/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0524 - val_loss: 0.0533\n",
      "Epoch 28/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0523 - val_loss: 0.0537\n",
      "Epoch 29/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0524 - val_loss: 0.0536\n",
      "Epoch 30/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0525 - val_loss: 0.0536 - ETA: 0s - loss: 0.\n",
      "Epoch 31/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0525 - val_loss: 0.0534\n",
      "Epoch 32/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0523 - val_loss: 0.0533\n",
      "Epoch 33/1500\n",
      "602/602 [==============================] - 1s 844us/step - loss: 0.0523 - val_loss: 0.0533\n",
      "Epoch 34/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0522 - val_loss: 0.0532\n",
      "Epoch 35/1500\n",
      "602/602 [==============================] - 1s 837us/step - loss: 0.0522 - val_loss: 0.0537\n",
      "Epoch 36/1500\n",
      "602/602 [==============================] - 1s 953us/step - loss: 0.0521 - val_loss: 0.0533\n",
      "Epoch 37/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0522 - val_loss: 0.0530\n",
      "Epoch 38/1500\n",
      "602/602 [==============================] - 1s 993us/step - loss: 0.0522 - val_loss: 0.0529\n",
      "Epoch 39/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0520 - val_loss: 0.0532\n",
      "Epoch 40/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0521 - val_loss: 0.0532\n",
      "Epoch 41/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0521 - val_loss: 0.0534\n",
      "Epoch 42/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0522 - val_loss: 0.0536\n",
      "Epoch 43/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0521 - val_loss: 0.0532\n",
      "Epoch 44/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0522 - val_loss: 0.0532\n",
      "Epoch 45/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0520 - val_loss: 0.0531\n",
      "Epoch 46/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0519 - val_loss: 0.0531\n",
      "Epoch 47/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0520 - val_loss: 0.0532\n",
      "Epoch 48/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0521 - val_loss: 0.0533\n",
      "Epoch 49/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0519 - val_loss: 0.0531\n",
      "Epoch 50/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0519 - val_loss: 0.0533\n",
      "Epoch 51/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0519 - val_loss: 0.0530\n",
      "Epoch 52/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0521 - val_loss: 0.0533\n",
      "Epoch 53/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0519 - val_loss: 0.0531\n",
      "Epoch 54/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0518 - val_loss: 0.0531\n",
      "Epoch 55/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0518 - val_loss: 0.0531\n",
      "Epoch 56/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0519 - val_loss: 0.0529\n",
      "Epoch 57/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0518 - val_loss: 0.0531\n",
      "Epoch 58/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0518 - val_loss: 0.0532\n",
      "Epoch 59/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0518 - val_loss: 0.0531\n",
      "Epoch 60/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0518 - val_loss: 0.0534\n",
      "Epoch 61/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0519 - val_loss: 0.0529\n",
      "Epoch 62/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0518 - val_loss: 0.0529\n",
      "Epoch 63/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0518 - val_loss: 0.0532\n",
      "Epoch 64/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0518 - val_loss: 0.0531\n",
      "Epoch 65/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0518 - val_loss: 0.0532 ETA: 0s - loss: 0\n",
      "Epoch 66/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0519 - val_loss: 0.0529\n",
      "Epoch 67/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0518 - val_loss: 0.0528\n",
      "Epoch 68/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0517 - val_loss: 0.0530\n",
      "Epoch 69/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0517 - val_loss: 0.0530\n",
      "Epoch 70/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0517 - val_loss: 0.0530\n",
      "Epoch 71/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0517 - val_loss: 0.0533\n",
      "Epoch 72/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0518 - val_loss: 0.0529\n",
      "Epoch 73/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0517 - val_loss: 0.0531\n",
      "Epoch 74/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0518 - val_loss: 0.0529\n",
      "Epoch 75/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0518 - val_loss: 0.0528\n",
      "Epoch 76/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0518 - val_loss: 0.0533\n",
      "Epoch 77/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0522 - val_loss: 0.0528\n",
      "Epoch 78/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0517 - val_loss: 0.0532\n",
      "Epoch 79/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0518 - val_loss: 0.0530\n",
      "Epoch 80/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0517 - val_loss: 0.0531\n",
      "Epoch 81/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0518 - val_loss: 0.0530\n",
      "Epoch 82/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0517 - val_loss: 0.0529\n",
      "Epoch 83/1500\n",
      "602/602 [==============================] - 1s 921us/step - loss: 0.0515 - val_loss: 0.0528\n",
      "Epoch 84/1500\n",
      "602/602 [==============================] - 1s 910us/step - loss: 0.0516 - val_loss: 0.0529\n",
      "Epoch 85/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0517 - val_loss: 0.0529\n",
      "Epoch 86/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0516 - val_loss: 0.0528\n",
      "Epoch 87/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0516 - val_loss: 0.0528\n",
      "Epoch 88/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0516 - val_loss: 0.0527\n",
      "Epoch 89/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0515 - val_loss: 0.0532\n",
      "Epoch 90/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0516 - val_loss: 0.05300s - los\n",
      "Epoch 91/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0518 - val_loss: 0.0528\n",
      "Epoch 92/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0516 - val_loss: 0.0528\n",
      "Epoch 93/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0515 - val_loss: 0.0528ETA: 1s - loss: 0. - ETA: 0s - \n",
      "Epoch 94/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0515 - val_loss: 0.0528ETA:\n",
      "Epoch 95/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0515 - val_loss: 0.0528A: 0s\n",
      "Epoch 96/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0516 - val_loss: 0.0533\n",
      "Epoch 97/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0518 - val_loss: 0.0526\n",
      "Epoch 98/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0517 - val_loss: 0.0530s - loss: 0 - ETA: 0s - loss: 0.05\n",
      "Epoch 99/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0517 - val_loss: 0.0532\n",
      "Epoch 100/1500\n",
      "602/602 [==============================] - 1s 979us/step - loss: 0.0516 - val_loss: 0.0528\n",
      "Epoch 101/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0515 - val_loss: 0.0528 - loss: 0.0\n",
      "Epoch 102/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0515 - val_loss: 0.0527\n",
      "Epoch 103/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0516 - val_loss: 0.0528\n",
      "Epoch 104/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0515 - val_loss: 0.0528\n",
      "Epoch 105/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0515 - val_loss: 0.0528\n",
      "Epoch 106/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0515 - val_loss: 0.0528\n",
      "Epoch 107/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0515 - val_loss: 0.0528\n",
      "Epoch 108/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0516 - val_loss: 0.0528\n",
      "Epoch 109/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0518 - val_loss: 0.0528\n",
      "Epoch 110/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0516 - val_loss: 0.0526\n",
      "Epoch 111/1500\n",
      "602/602 [==============================] - 1s 998us/step - loss: 0.0516 - val_loss: 0.0528\n",
      "Epoch 112/1500\n",
      "602/602 [==============================] - 1s 949us/step - loss: 0.0515 - val_loss: 0.0529\n",
      "Epoch 113/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0517 - val_loss: 0.0527\n",
      "Epoch 114/1500\n",
      "602/602 [==============================] - 1s 971us/step - loss: 0.0516 - val_loss: 0.0529: 0s - loss: 0.05\n",
      "Epoch 115/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0518 - val_loss: 0.0529\n",
      "Epoch 116/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0515 - val_loss: 0.0531\n",
      "Epoch 117/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0516 - val_loss: 0.0528\n",
      "Epoch 118/1500\n",
      "602/602 [==============================] - 1s 989us/step - loss: 0.0514 - val_loss: 0.0527\n",
      "Epoch 119/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0514 - val_loss: 0.0527\n",
      "Epoch 120/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0514 - val_loss: 0.0526\n",
      "Epoch 121/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0520 - val_loss: 0.0527\n",
      "Epoch 122/1500\n",
      "602/602 [==============================] - 1s 941us/step - loss: 0.0515 - val_loss: 0.0528\n",
      "Epoch 123/1500\n",
      "602/602 [==============================] - 1s 989us/step - loss: 0.0514 - val_loss: 0.0528\n",
      "Epoch 124/1500\n",
      "602/602 [==============================] - 1s 897us/step - loss: 0.0514 - val_loss: 0.0529\n",
      "Epoch 125/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0514 - val_loss: 0.0526\n",
      "Epoch 126/1500\n",
      "602/602 [==============================] - 1s 989us/step - loss: 0.0515 - val_loss: 0.0528\n",
      "Epoch 127/1500\n",
      "602/602 [==============================] - 1s 987us/step - loss: 0.0516 - val_loss: 0.0528\n",
      "Epoch 128/1500\n",
      "602/602 [==============================] - 1s 947us/step - loss: 0.0514 - val_loss: 0.0526\n",
      "Epoch 129/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0513 - val_loss: 0.0529\n",
      "Epoch 130/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0514 - val_loss: 0.0527\n",
      "Epoch 131/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0514 - val_loss: 0.0529\n",
      "Epoch 132/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0513 - val_loss: 0.0527\n",
      "Epoch 133/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0513 - val_loss: 0.0526\n",
      "Epoch 134/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0513 - val_loss: 0.0526\n",
      "Epoch 135/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0514 - val_loss: 0.0526\n",
      "Epoch 136/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0513 - val_loss: 0.0527\n",
      "Epoch 137/1500\n",
      "602/602 [==============================] - 0s 775us/step - loss: 0.0514 - val_loss: 0.0527\n",
      "Epoch 138/1500\n",
      "602/602 [==============================] - 0s 826us/step - loss: 0.0513 - val_loss: 0.0525\n",
      "Epoch 139/1500\n",
      "602/602 [==============================] - 1s 904us/step - loss: 0.0513 - val_loss: 0.0527\n",
      "Epoch 140/1500\n",
      "602/602 [==============================] - 1s 920us/step - loss: 0.0514 - val_loss: 0.0528\n",
      "Epoch 141/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0513 - val_loss: 0.0526\n",
      "Epoch 142/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0512 - val_loss: 0.0529\n",
      "Epoch 143/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0514 - val_loss: 0.0528\n",
      "Epoch 144/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0513 - val_loss: 0.0528\n",
      "Epoch 145/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0514 - val_loss: 0.0527\n",
      "Epoch 146/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0512 - val_loss: 0.0524\n",
      "Epoch 147/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0516 - val_loss: 0.0526\n",
      "Epoch 148/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0514 - val_loss: 0.0529\n",
      "Epoch 149/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0512 - val_loss: 0.0528- ETA: 0s - loss: 0\n",
      "Epoch 150/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0513 - val_loss: 0.0528\n",
      "Epoch 151/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0513 - val_loss: 0.0527oss: 0.0\n",
      "Epoch 152/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0513 - val_loss: 0.0529\n",
      "Epoch 153/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0513 - val_loss: 0.0526\n",
      "Epoch 154/1500\n",
      "602/602 [==============================] - 1s 876us/step - loss: 0.0513 - val_loss: 0.0528\n",
      "Epoch 155/1500\n",
      "602/602 [==============================] - 0s 772us/step - loss: 0.0514 - val_loss: 0.0528\n",
      "Epoch 156/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 0s 716us/step - loss: 0.0513 - val_loss: 0.0529\n",
      "Epoch 157/1500\n",
      "602/602 [==============================] - 0s 724us/step - loss: 0.0513 - val_loss: 0.0528\n",
      "Epoch 158/1500\n",
      "602/602 [==============================] - 0s 782us/step - loss: 0.0512 - val_loss: 0.0526\n",
      "Epoch 159/1500\n",
      "602/602 [==============================] - 0s 733us/step - loss: 0.0512 - val_loss: 0.0527\n",
      "Epoch 160/1500\n",
      "602/602 [==============================] - 0s 708us/step - loss: 0.0512 - val_loss: 0.0527\n",
      "Epoch 161/1500\n",
      "602/602 [==============================] - 0s 748us/step - loss: 0.0512 - val_loss: 0.0527\n",
      "Epoch 162/1500\n",
      "602/602 [==============================] - 1s 974us/step - loss: 0.0515 - val_loss: 0.0527\n",
      "Epoch 163/1500\n",
      "602/602 [==============================] - 0s 739us/step - loss: 0.0513 - val_loss: 0.0526\n",
      "Epoch 164/1500\n",
      "602/602 [==============================] - 0s 686us/step - loss: 0.0513 - val_loss: 0.0526\n",
      "Epoch 165/1500\n",
      "602/602 [==============================] - 0s 786us/step - loss: 0.0512 - val_loss: 0.0527\n",
      "Epoch 166/1500\n",
      "602/602 [==============================] - 0s 689us/step - loss: 0.0512 - val_loss: 0.0527\n",
      "Epoch 167/1500\n",
      "602/602 [==============================] - 0s 750us/step - loss: 0.0511 - val_loss: 0.0527\n",
      "Epoch 168/1500\n",
      "602/602 [==============================] - 0s 707us/step - loss: 0.0513 - val_loss: 0.0527\n",
      "Epoch 169/1500\n",
      "602/602 [==============================] - 0s 691us/step - loss: 0.0512 - val_loss: 0.0528\n",
      "Epoch 170/1500\n",
      "602/602 [==============================] - 0s 768us/step - loss: 0.0513 - val_loss: 0.0528\n",
      "Epoch 171/1500\n",
      "602/602 [==============================] - 0s 732us/step - loss: 0.0513 - val_loss: 0.0526\n",
      "Epoch 172/1500\n",
      "602/602 [==============================] - 0s 799us/step - loss: 0.0513 - val_loss: 0.0526\n",
      "Epoch 173/1500\n",
      "602/602 [==============================] - 1s 898us/step - loss: 0.0513 - val_loss: 0.0527 0s - loss: 0.05\n",
      "Epoch 174/1500\n",
      "602/602 [==============================] - 0s 820us/step - loss: 0.0511 - val_loss: 0.0526\n",
      "Epoch 175/1500\n",
      "602/602 [==============================] - 0s 691us/step - loss: 0.0511 - val_loss: 0.0529\n",
      "Epoch 176/1500\n",
      "602/602 [==============================] - 0s 753us/step - loss: 0.0511 - val_loss: 0.0528\n",
      "Epoch 177/1500\n",
      "602/602 [==============================] - 0s 754us/step - loss: 0.0512 - val_loss: 0.0527\n",
      "Epoch 178/1500\n",
      "602/602 [==============================] - 0s 815us/step - loss: 0.0511 - val_loss: 0.0528\n",
      "Epoch 179/1500\n",
      "602/602 [==============================] - 0s 766us/step - loss: 0.0511 - val_loss: 0.0527\n",
      "Epoch 180/1500\n",
      "602/602 [==============================] - 1s 918us/step - loss: 0.0520 - val_loss: 0.0528\n",
      "Epoch 181/1500\n",
      "602/602 [==============================] - 1s 919us/step - loss: 0.0512 - val_loss: 0.0526\n",
      "Epoch 182/1500\n",
      "602/602 [==============================] - 1s 843us/step - loss: 0.0511 - val_loss: 0.0527\n",
      "Epoch 183/1500\n",
      "602/602 [==============================] - 0s 647us/step - loss: 0.0511 - val_loss: 0.0527\n",
      "Epoch 184/1500\n",
      "602/602 [==============================] - 1s 942us/step - loss: 0.0511 - val_loss: 0.0533\n",
      "Epoch 185/1500\n",
      "602/602 [==============================] - 0s 696us/step - loss: 0.0512 - val_loss: 0.0528\n",
      "Epoch 186/1500\n",
      "602/602 [==============================] - 0s 714us/step - loss: 0.0511 - val_loss: 0.0527\n",
      "Epoch 187/1500\n",
      "602/602 [==============================] - 0s 701us/step - loss: 0.0511 - val_loss: 0.0528\n",
      "Epoch 188/1500\n",
      "602/602 [==============================] - 0s 733us/step - loss: 0.0511 - val_loss: 0.0526\n",
      "Epoch 189/1500\n",
      "602/602 [==============================] - 0s 715us/step - loss: 0.0511 - val_loss: 0.0528\n",
      "Epoch 190/1500\n",
      "602/602 [==============================] - 0s 712us/step - loss: 0.0510 - val_loss: 0.0527\n",
      "Epoch 191/1500\n",
      "602/602 [==============================] - 0s 743us/step - loss: 0.0512 - val_loss: 0.0526\n",
      "Epoch 192/1500\n",
      "602/602 [==============================] - 0s 767us/step - loss: 0.0511 - val_loss: 0.0530\n",
      "Epoch 193/1500\n",
      "602/602 [==============================] - 0s 730us/step - loss: 0.0511 - val_loss: 0.0526\n",
      "Epoch 194/1500\n",
      "602/602 [==============================] - 0s 721us/step - loss: 0.0511 - val_loss: 0.0526\n",
      "Epoch 195/1500\n",
      "602/602 [==============================] - 0s 638us/step - loss: 0.0511 - val_loss: 0.0526\n",
      "Epoch 196/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0511 - val_loss: 0.0527\n",
      "Epoch 197/1500\n",
      "602/602 [==============================] - 0s 829us/step - loss: 0.0511 - val_loss: 0.0527\n",
      "Epoch 198/1500\n",
      "602/602 [==============================] - 0s 717us/step - loss: 0.0510 - val_loss: 0.0526\n",
      "Epoch 199/1500\n",
      "602/602 [==============================] - 0s 739us/step - loss: 0.0510 - val_loss: 0.0527\n",
      "Epoch 200/1500\n",
      "602/602 [==============================] - 0s 724us/step - loss: 0.0511 - val_loss: 0.0526\n",
      "Epoch 201/1500\n",
      "602/602 [==============================] - 0s 788us/step - loss: 0.0510 - val_loss: 0.0527\n",
      "Epoch 202/1500\n",
      "602/602 [==============================] - 0s 723us/step - loss: 0.0510 - val_loss: 0.0527\n",
      "Epoch 203/1500\n",
      "602/602 [==============================] - 0s 735us/step - loss: 0.0510 - val_loss: 0.0527\n",
      "Epoch 204/1500\n",
      "602/602 [==============================] - 1s 919us/step - loss: 0.0511 - val_loss: 0.0529\n",
      "Epoch 205/1500\n",
      "602/602 [==============================] - 0s 664us/step - loss: 0.0512 - val_loss: 0.0528\n",
      "Epoch 206/1500\n",
      "602/602 [==============================] - 0s 753us/step - loss: 0.0510 - val_loss: 0.0528\n",
      "Epoch 207/1500\n",
      "602/602 [==============================] - 1s 955us/step - loss: 0.0510 - val_loss: 0.0525\n",
      "Epoch 208/1500\n",
      "602/602 [==============================] - 0s 793us/step - loss: 0.0509 - val_loss: 0.0527\n",
      "Epoch 209/1500\n",
      "602/602 [==============================] - 0s 684us/step - loss: 0.0510 - val_loss: 0.0528\n",
      "Epoch 210/1500\n",
      "602/602 [==============================] - 0s 715us/step - loss: 0.0510 - val_loss: 0.0527\n",
      "Epoch 211/1500\n",
      "602/602 [==============================] - 1s 832us/step - loss: 0.0510 - val_loss: 0.0525\n",
      "Epoch 212/1500\n",
      "602/602 [==============================] - 1s 955us/step - loss: 0.0509 - val_loss: 0.0526\n",
      "Epoch 213/1500\n",
      "602/602 [==============================] - 1s 900us/step - loss: 0.0510 - val_loss: 0.0527\n",
      "Epoch 214/1500\n",
      "602/602 [==============================] - 0s 830us/step - loss: 0.0510 - val_loss: 0.0529\n",
      "Epoch 215/1500\n",
      "602/602 [==============================] - 1s 980us/step - loss: 0.0510 - val_loss: 0.0525\n",
      "Epoch 216/1500\n",
      "602/602 [==============================] - 0s 751us/step - loss: 0.0509 - val_loss: 0.0527\n",
      "Epoch 217/1500\n",
      "602/602 [==============================] - 0s 724us/step - loss: 0.0509 - val_loss: 0.0527\n",
      "Epoch 218/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0510 - val_loss: 0.0526\n",
      "Epoch 219/1500\n",
      "602/602 [==============================] - 0s 753us/step - loss: 0.0509 - val_loss: 0.0528\n",
      "Epoch 220/1500\n",
      "602/602 [==============================] - 0s 711us/step - loss: 0.0510 - val_loss: 0.0528\n",
      "Epoch 221/1500\n",
      "602/602 [==============================] - 0s 815us/step - loss: 0.0510 - val_loss: 0.0529\n",
      "Epoch 222/1500\n",
      "602/602 [==============================] - 1s 837us/step - loss: 0.0510 - val_loss: 0.0527\n",
      "Epoch 223/1500\n",
      "602/602 [==============================] - 0s 830us/step - loss: 0.0509 - val_loss: 0.0527\n",
      "Epoch 224/1500\n",
      "602/602 [==============================] - 0s 659us/step - loss: 0.0510 - val_loss: 0.0527\n",
      "Epoch 225/1500\n",
      "602/602 [==============================] - 0s 760us/step - loss: 0.0509 - val_loss: 0.0529\n",
      "Epoch 226/1500\n",
      "602/602 [==============================] - 0s 692us/step - loss: 0.0510 - val_loss: 0.0526\n",
      "Epoch 227/1500\n",
      "602/602 [==============================] - 0s 782us/step - loss: 0.0510 - val_loss: 0.0527\n",
      "Epoch 228/1500\n",
      "602/602 [==============================] - 0s 793us/step - loss: 0.0524 - val_loss: 0.0529\n",
      "Epoch 229/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0511 - val_loss: 0.0527\n",
      "Epoch 230/1500\n",
      "602/602 [==============================] - 0s 752us/step - loss: 0.0510 - val_loss: 0.0525\n",
      "Epoch 231/1500\n",
      "602/602 [==============================] - 0s 817us/step - loss: 0.0509 - val_loss: 0.0525\n",
      "Epoch 232/1500\n",
      "602/602 [==============================] - 0s 685us/step - loss: 0.0509 - val_loss: 0.0527\n",
      "Epoch 233/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 0s 756us/step - loss: 0.0510 - val_loss: 0.0526\n",
      "Epoch 234/1500\n",
      "602/602 [==============================] - 0s 707us/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 235/1500\n",
      "602/602 [==============================] - 0s 711us/step - loss: 0.0509 - val_loss: 0.0525\n",
      "Epoch 236/1500\n",
      "602/602 [==============================] - 0s 735us/step - loss: 0.0509 - val_loss: 0.0527\n",
      "Epoch 237/1500\n",
      "602/602 [==============================] - 1s 994us/step - loss: 0.0509 - val_loss: 0.0529\n",
      "Epoch 238/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0509 - val_loss: 0.0526\n",
      "Epoch 239/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0509 - val_loss: 0.0526\n",
      "Epoch 240/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0509 - val_loss: 0.0527\n",
      "Epoch 241/1500\n",
      "602/602 [==============================] - 1s 911us/step - loss: 0.0509 - val_loss: 0.0526\n",
      "Epoch 242/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0509 - val_loss: 0.0527\n",
      "Epoch 243/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0509 - val_loss: 0.0527\n",
      "Epoch 244/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 245/1500\n",
      "602/602 [==============================] - 1s 871us/step - loss: 0.0509 - val_loss: 0.0528\n",
      "Epoch 246/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 247/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 248/1500\n",
      "602/602 [==============================] - 1s 971us/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 249/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0509 - val_loss: 0.0529\n",
      "Epoch 250/1500\n",
      "602/602 [==============================] - 1s 840us/step - loss: 0.0508 - val_loss: 0.0527\n",
      "Epoch 251/1500\n",
      "602/602 [==============================] - 0s 806us/step - loss: 0.0508 - val_loss: 0.0525\n",
      "Epoch 252/1500\n",
      "602/602 [==============================] - 1s 994us/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 253/1500\n",
      "602/602 [==============================] - 0s 696us/step - loss: 0.0509 - val_loss: 0.0526\n",
      "Epoch 254/1500\n",
      "602/602 [==============================] - 0s 669us/step - loss: 0.0510 - val_loss: 0.0528\n",
      "Epoch 255/1500\n",
      "602/602 [==============================] - 0s 714us/step - loss: 0.0509 - val_loss: 0.0526\n",
      "Epoch 256/1500\n",
      "602/602 [==============================] - 0s 763us/step - loss: 0.0509 - val_loss: 0.0525\n",
      "Epoch 257/1500\n",
      "602/602 [==============================] - 0s 632us/step - loss: 0.0512 - val_loss: 0.0527\n",
      "Epoch 258/1500\n",
      "602/602 [==============================] - 0s 694us/step - loss: 0.0509 - val_loss: 0.0526\n",
      "Epoch 259/1500\n",
      "602/602 [==============================] - 0s 580us/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 260/1500\n",
      "602/602 [==============================] - 0s 716us/step - loss: 0.0509 - val_loss: 0.0526\n",
      "Epoch 261/1500\n",
      "602/602 [==============================] - 0s 662us/step - loss: 0.0508 - val_loss: 0.0527\n",
      "Epoch 262/1500\n",
      "602/602 [==============================] - 1s 843us/step - loss: 0.0508 - val_loss: 0.0528\n",
      "Epoch 263/1500\n",
      "602/602 [==============================] - 0s 690us/step - loss: 0.0510 - val_loss: 0.0529\n",
      "Epoch 264/1500\n",
      "602/602 [==============================] - 1s 976us/step - loss: 0.0509 - val_loss: 0.0525\n",
      "Epoch 265/1500\n",
      "602/602 [==============================] - 0s 713us/step - loss: 0.0509 - val_loss: 0.0526\n",
      "Epoch 266/1500\n",
      "602/602 [==============================] - 0s 780us/step - loss: 0.0508 - val_loss: 0.0528\n",
      "Epoch 267/1500\n",
      "602/602 [==============================] - 0s 759us/step - loss: 0.0510 - val_loss: 0.0531\n",
      "Epoch 268/1500\n",
      "602/602 [==============================] - 0s 755us/step - loss: 0.0510 - val_loss: 0.0525\n",
      "Epoch 269/1500\n",
      "602/602 [==============================] - 0s 793us/step - loss: 0.0507 - val_loss: 0.0526\n",
      "Epoch 270/1500\n",
      "602/602 [==============================] - 1s 900us/step - loss: 0.0508 - val_loss: 0.0528\n",
      "Epoch 271/1500\n",
      "602/602 [==============================] - 0s 807us/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 272/1500\n",
      "602/602 [==============================] - 1s 880us/step - loss: 0.0510 - val_loss: 0.0528\n",
      "Epoch 273/1500\n",
      "602/602 [==============================] - 0s 802us/step - loss: 0.0508 - val_loss: 0.0527\n",
      "Epoch 274/1500\n",
      "602/602 [==============================] - 0s 752us/step - loss: 0.0507 - val_loss: 0.0527\n",
      "Epoch 275/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0526\n",
      "Epoch 276/1500\n",
      "602/602 [==============================] - 0s 697us/step - loss: 0.0509 - val_loss: 0.0526\n",
      "Epoch 277/1500\n",
      "602/602 [==============================] - 0s 673us/step - loss: 0.0514 - val_loss: 0.0525\n",
      "Epoch 278/1500\n",
      "602/602 [==============================] - 0s 770us/step - loss: 0.0512 - val_loss: 0.0526\n",
      "Epoch 279/1500\n",
      "602/602 [==============================] - 0s 765us/step - loss: 0.0510 - val_loss: 0.0526\n",
      "Epoch 280/1500\n",
      "602/602 [==============================] - 0s 735us/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 281/1500\n",
      "602/602 [==============================] - 0s 664us/step - loss: 0.0509 - val_loss: 0.0528\n",
      "Epoch 282/1500\n",
      "602/602 [==============================] - 0s 696us/step - loss: 0.0508 - val_loss: 0.0525\n",
      "Epoch 283/1500\n",
      "602/602 [==============================] - 0s 684us/step - loss: 0.0508 - val_loss: 0.0525\n",
      "Epoch 284/1500\n",
      "602/602 [==============================] - 0s 703us/step - loss: 0.0507 - val_loss: 0.0528\n",
      "Epoch 285/1500\n",
      "602/602 [==============================] - 0s 796us/step - loss: 0.0508 - val_loss: 0.0527\n",
      "Epoch 286/1500\n",
      "602/602 [==============================] - 0s 753us/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 287/1500\n",
      "602/602 [==============================] - 0s 780us/step - loss: 0.0507 - val_loss: 0.0525\n",
      "Epoch 288/1500\n",
      "602/602 [==============================] - 0s 642us/step - loss: 0.0507 - val_loss: 0.0526\n",
      "Epoch 289/1500\n",
      "602/602 [==============================] - 0s 674us/step - loss: 0.0507 - val_loss: 0.0527\n",
      "Epoch 290/1500\n",
      "602/602 [==============================] - 0s 690us/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 291/1500\n",
      "602/602 [==============================] - 0s 631us/step - loss: 0.0507 - val_loss: 0.0526\n",
      "Epoch 292/1500\n",
      "602/602 [==============================] - 0s 716us/step - loss: 0.0509 - val_loss: 0.0526\n",
      "Epoch 293/1500\n",
      "602/602 [==============================] - 0s 675us/step - loss: 0.0507 - val_loss: 0.0526\n",
      "Epoch 294/1500\n",
      "602/602 [==============================] - 0s 822us/step - loss: 0.0507 - val_loss: 0.0526\n",
      "Epoch 295/1500\n",
      "602/602 [==============================] - 0s 686us/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 296/1500\n",
      "602/602 [==============================] - 0s 645us/step - loss: 0.0509 - val_loss: 0.0527\n",
      "Epoch 297/1500\n",
      "602/602 [==============================] - 0s 782us/step - loss: 0.0509 - val_loss: 0.0526\n",
      "Epoch 298/1500\n",
      "602/602 [==============================] - 0s 723us/step - loss: 0.0508 - val_loss: 0.0527\n",
      "Epoch 299/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0527\n",
      "Epoch 300/1500\n",
      "602/602 [==============================] - 0s 821us/step - loss: 0.0507 - val_loss: 0.0527\n",
      "Epoch 301/1500\n",
      "602/602 [==============================] - 0s 705us/step - loss: 0.0508 - val_loss: 0.0528\n",
      "Epoch 302/1500\n",
      "602/602 [==============================] - 0s 763us/step - loss: 0.0507 - val_loss: 0.0528\n",
      "Epoch 303/1500\n",
      "602/602 [==============================] - 0s 790us/step - loss: 0.0506 - val_loss: 0.0527\n",
      "Epoch 304/1500\n",
      "602/602 [==============================] - 1s 938us/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 305/1500\n",
      "602/602 [==============================] - 0s 763us/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 306/1500\n",
      "602/602 [==============================] - 1s 893us/step - loss: 0.0513 - val_loss: 0.0525\n",
      "Epoch 307/1500\n",
      "602/602 [==============================] - 0s 766us/step - loss: 0.0510 - val_loss: 0.0528\n",
      "Epoch 308/1500\n",
      "602/602 [==============================] - 0s 745us/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 309/1500\n",
      "602/602 [==============================] - 0s 718us/step - loss: 0.0507 - val_loss: 0.0528\n",
      "Epoch 310/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0525\n",
      "Epoch 311/1500\n",
      "602/602 [==============================] - 0s 703us/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 312/1500\n",
      "602/602 [==============================] - 0s 762us/step - loss: 0.0506 - val_loss: 0.0525\n",
      "Epoch 313/1500\n",
      "602/602 [==============================] - 0s 726us/step - loss: 0.0506 - val_loss: 0.0528\n",
      "Epoch 314/1500\n",
      "602/602 [==============================] - 0s 720us/step - loss: 0.0508 - val_loss: 0.0528\n",
      "Epoch 315/1500\n",
      "602/602 [==============================] - 0s 716us/step - loss: 0.0507 - val_loss: 0.0527\n",
      "Epoch 316/1500\n",
      "602/602 [==============================] - 0s 723us/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 317/1500\n",
      "602/602 [==============================] - 0s 780us/step - loss: 0.0506 - val_loss: 0.0530\n",
      "Epoch 318/1500\n",
      "602/602 [==============================] - 1s 990us/step - loss: 0.0507 - val_loss: 0.0527\n",
      "Epoch 319/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0508 - val_loss: 0.0529\n",
      "Epoch 320/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0508 - val_loss: 0.0525\n",
      "Epoch 321/1500\n",
      "602/602 [==============================] - 1s 958us/step - loss: 0.0508 - val_loss: 0.0527\n",
      "Epoch 322/1500\n",
      "602/602 [==============================] - 0s 742us/step - loss: 0.0509 - val_loss: 0.0527\n",
      "Epoch 323/1500\n",
      "602/602 [==============================] - 0s 749us/step - loss: 0.0507 - val_loss: 0.0527\n",
      "Epoch 324/1500\n",
      "602/602 [==============================] - 0s 802us/step - loss: 0.0507 - val_loss: 0.0528\n",
      "Epoch 325/1500\n",
      "602/602 [==============================] - 1s 976us/step - loss: 0.0507 - val_loss: 0.0524\n",
      "Epoch 326/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0506 - val_loss: 0.0528\n",
      "Epoch 327/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0526\n",
      "Epoch 328/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0507 - val_loss: 0.0526\n",
      "Epoch 329/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0525\n",
      "Epoch 330/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 331/1500\n",
      "602/602 [==============================] - 1s 941us/step - loss: 0.0508 - val_loss: 0.0527\n",
      "Epoch 332/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0526\n",
      "Epoch 333/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0506 - val_loss: 0.0527\n",
      "Epoch 334/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 335/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0528\n",
      "Epoch 336/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0506 - val_loss: 0.0525\n",
      "Epoch 337/1500\n",
      "602/602 [==============================] - 0s 813us/step - loss: 0.0508 - val_loss: 0.0525\n",
      "Epoch 338/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0527\n",
      "Epoch 339/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0508 - val_loss: 0.0527\n",
      "Epoch 340/1500\n",
      "602/602 [==============================] - 0s 744us/step - loss: 0.0506 - val_loss: 0.0523\n",
      "Epoch 341/1500\n",
      "602/602 [==============================] - 0s 728us/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 342/1500\n",
      "602/602 [==============================] - 0s 812us/step - loss: 0.0508 - val_loss: 0.0527\n",
      "Epoch 343/1500\n",
      "602/602 [==============================] - 0s 778us/step - loss: 0.0506 - val_loss: 0.0527\n",
      "Epoch 344/1500\n",
      "602/602 [==============================] - 1s 882us/step - loss: 0.0506 - val_loss: 0.0527\n",
      "Epoch 345/1500\n",
      "602/602 [==============================] - 0s 782us/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 346/1500\n",
      "602/602 [==============================] - 0s 684us/step - loss: 0.0507 - val_loss: 0.0524\n",
      "Epoch 347/1500\n",
      "602/602 [==============================] - 0s 679us/step - loss: 0.0506 - val_loss: 0.0525\n",
      "Epoch 348/1500\n",
      "602/602 [==============================] - 0s 771us/step - loss: 0.0506 - val_loss: 0.0527\n",
      "Epoch 349/1500\n",
      "602/602 [==============================] - 1s 876us/step - loss: 0.0505 - val_loss: 0.0528\n",
      "Epoch 350/1500\n",
      "602/602 [==============================] - 0s 716us/step - loss: 0.0507 - val_loss: 0.0525\n",
      "Epoch 351/1500\n",
      "602/602 [==============================] - 1s 854us/step - loss: 0.0506 - val_loss: 0.0525\n",
      "Epoch 352/1500\n",
      "602/602 [==============================] - 1s 846us/step - loss: 0.0505 - val_loss: 0.0528\n",
      "Epoch 353/1500\n",
      "602/602 [==============================] - 1s 968us/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 354/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 355/1500\n",
      "602/602 [==============================] - 1s 888us/step - loss: 0.0506 - val_loss: 0.0525\n",
      "Epoch 356/1500\n",
      "602/602 [==============================] - 0s 730us/step - loss: 0.0507 - val_loss: 0.0528\n",
      "Epoch 357/1500\n",
      "602/602 [==============================] - 0s 702us/step - loss: 0.0507 - val_loss: 0.0525\n",
      "Epoch 358/1500\n",
      "602/602 [==============================] - 0s 741us/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 359/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 360/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0506 - val_loss: 0.0527\n",
      "Epoch 361/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0506 - val_loss: 0.0525\n",
      "Epoch 362/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0506 - val_loss: 0.0527ETA: 0s - loss\n",
      "Epoch 363/1500\n",
      "602/602 [==============================] - 0s 771us/step - loss: 0.0506 - val_loss: 0.0527\n",
      "Epoch 364/1500\n",
      "602/602 [==============================] - 0s 733us/step - loss: 0.0506 - val_loss: 0.0528\n",
      "Epoch 365/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 366/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0505 - val_loss: 0.0527\n",
      "Epoch 367/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0507 - val_loss: 0.0527\n",
      "Epoch 368/1500\n",
      "602/602 [==============================] - 1s 843us/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 369/1500\n",
      "602/602 [==============================] - 0s 767us/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 370/1500\n",
      "602/602 [==============================] - 0s 790us/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 371/1500\n",
      "602/602 [==============================] - 1s 873us/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 372/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0506 - val_loss: 0.0524\n",
      "Epoch 373/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0524\n",
      "Epoch 374/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0524\n",
      "Epoch 375/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0527\n",
      "Epoch 376/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 377/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0507 - val_loss: 0.0526\n",
      "Epoch 378/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 379/1500\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.050 - 1s 2ms/step - loss: 0.0506 - val_loss: 0.0529\n",
      "Epoch 380/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0525\n",
      "Epoch 381/1500\n",
      "602/602 [==============================] - 1s 872us/step - loss: 0.0506 - val_loss: 0.0525\n",
      "Epoch 382/1500\n",
      "602/602 [==============================] - 0s 717us/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 383/1500\n",
      "602/602 [==============================] - 1s 955us/step - loss: 0.0505 - val_loss: 0.0529\n",
      "Epoch 384/1500\n",
      "602/602 [==============================] - 0s 785us/step - loss: 0.0507 - val_loss: 0.0527\n",
      "Epoch 385/1500\n",
      "602/602 [==============================] - 0s 809us/step - loss: 0.0507 - val_loss: 0.0526\n",
      "Epoch 386/1500\n",
      "602/602 [==============================] - 1s 844us/step - loss: 0.0505 - val_loss: 0.0529\n",
      "Epoch 387/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0506 - val_loss: 0.0527\n",
      "Epoch 388/1500\n",
      "602/602 [==============================] - 1s 882us/step - loss: 0.0506 - val_loss: 0.0527\n",
      "Epoch 389/1500\n",
      "602/602 [==============================] - 1s 861us/step - loss: 0.0506 - val_loss: 0.0525\n",
      "Epoch 390/1500\n",
      "602/602 [==============================] - 1s 906us/step - loss: 0.0509 - val_loss: 0.0525\n",
      "Epoch 391/1500\n",
      "602/602 [==============================] - 1s 882us/step - loss: 0.0505 - val_loss: 0.0524\n",
      "Epoch 392/1500\n",
      "602/602 [==============================] - 0s 824us/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 393/1500\n",
      "602/602 [==============================] - 0s 810us/step - loss: 0.0505 - val_loss: 0.0524\n",
      "Epoch 394/1500\n",
      "602/602 [==============================] - 1s 867us/step - loss: 0.0505 - val_loss: 0.0527\n",
      "Epoch 395/1500\n",
      "602/602 [==============================] - 1s 895us/step - loss: 0.0506 - val_loss: 0.0527\n",
      "Epoch 396/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0506 - val_loss: 0.0527\n",
      "Epoch 397/1500\n",
      "602/602 [==============================] - 0s 806us/step - loss: 0.0505 - val_loss: 0.0524\n",
      "Epoch 398/1500\n",
      "602/602 [==============================] - 1s 898us/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 399/1500\n",
      "602/602 [==============================] - 1s 982us/step - loss: 0.0504 - val_loss: 0.0524\n",
      "Epoch 400/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 401/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 402/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 403/1500\n",
      "602/602 [==============================] - 1s 894us/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 404/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 405/1500\n",
      "602/602 [==============================] - 1s 907us/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 406/1500\n",
      "602/602 [==============================] - 1s 911us/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 407/1500\n",
      "602/602 [==============================] - 0s 729us/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 408/1500\n",
      "602/602 [==============================] - 0s 684us/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 409/1500\n",
      "602/602 [==============================] - 0s 730us/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 410/1500\n",
      "602/602 [==============================] - 0s 698us/step - loss: 0.0506 - val_loss: 0.0529\n",
      "Epoch 411/1500\n",
      "602/602 [==============================] - 0s 720us/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 412/1500\n",
      "602/602 [==============================] - 0s 772us/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 413/1500\n",
      "602/602 [==============================] - 0s 716us/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 414/1500\n",
      "602/602 [==============================] - 0s 689us/step - loss: 0.0506 - val_loss: 0.0528\n",
      "Epoch 415/1500\n",
      "602/602 [==============================] - 1s 849us/step - loss: 0.0505 - val_loss: 0.0527\n",
      "Epoch 416/1500\n",
      "602/602 [==============================] - 1s 938us/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 417/1500\n",
      "602/602 [==============================] - 1s 939us/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 418/1500\n",
      "602/602 [==============================] - 1s 848us/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 419/1500\n",
      "602/602 [==============================] - 1s 851us/step - loss: 0.0506 - val_loss: 0.0525\n",
      "Epoch 420/1500\n",
      "602/602 [==============================] - 0s 752us/step - loss: 0.0504 - val_loss: 0.0524\n",
      "Epoch 421/1500\n",
      "602/602 [==============================] - 0s 814us/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 422/1500\n",
      "602/602 [==============================] - 0s 779us/step - loss: 0.0505 - val_loss: 0.0529\n",
      "Epoch 423/1500\n",
      "602/602 [==============================] - 0s 779us/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 424/1500\n",
      "602/602 [==============================] - 0s 802us/step - loss: 0.0504 - val_loss: 0.0528\n",
      "Epoch 425/1500\n",
      "602/602 [==============================] - 1s 945us/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 426/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 427/1500\n",
      "602/602 [==============================] - 1s 949us/step - loss: 0.0506 - val_loss: 0.0525\n",
      "Epoch 428/1500\n",
      "602/602 [==============================] - 1s 936us/step - loss: 0.0504 - val_loss: 0.0527\n",
      "Epoch 429/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0527\n",
      "Epoch 430/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0524\n",
      "Epoch 431/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 432/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0527\n",
      "Epoch 433/1500\n",
      "602/602 [==============================] - 1s 838us/step - loss: 0.0503 - val_loss: 0.0523\n",
      "Epoch 434/1500\n",
      "602/602 [==============================] - 0s 827us/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 435/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0511 - val_loss: 0.0524\n",
      "Epoch 436/1500\n",
      "602/602 [==============================] - 1s 888us/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 437/1500\n",
      "602/602 [==============================] - 1s 888us/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 438/1500\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.0503- ETA: 0s - loss - 1s 855us/step - loss: 0.0504 - val_loss: 0.0523\n",
      "Epoch 439/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 440/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0526\n",
      "Epoch 441/1500\n",
      "602/602 [==============================] - 1s 950us/step - loss: 0.0511 - val_loss: 0.0529\n",
      "Epoch 442/1500\n",
      "602/602 [==============================] - 1s 841us/step - loss: 0.0506 - val_loss: 0.0524\n",
      "Epoch 443/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 444/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 445/1500\n",
      "602/602 [==============================] - 1s 913us/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 446/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0527\n",
      "Epoch 447/1500\n",
      "602/602 [==============================] - 1s 989us/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 448/1500\n",
      "602/602 [==============================] - 1s 992us/step - loss: 0.0504 - val_loss: 0.0524\n",
      "Epoch 449/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 450/1500\n",
      "602/602 [==============================] - 1s 834us/step - loss: 0.0504 - val_loss: 0.0528\n",
      "Epoch 451/1500\n",
      "602/602 [==============================] - 0s 819us/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 452/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0526\n",
      "Epoch 453/1500\n",
      "602/602 [==============================] - 1s 904us/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 454/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 455/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 456/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0524\n",
      "Epoch 457/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0527\n",
      "Epoch 458/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0527\n",
      "Epoch 459/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 460/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 461/1500\n",
      "602/602 [==============================] - 1s 954us/step - loss: 0.0503 - val_loss: 0.0527\n",
      "Epoch 462/1500\n",
      "602/602 [==============================] - 0s 761us/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 463/1500\n",
      "602/602 [==============================] - 1s 999us/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 464/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 1s 856us/step - loss: 0.0506 - val_loss: 0.0524\n",
      "Epoch 465/1500\n",
      "602/602 [==============================] - 1s 942us/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 466/1500\n",
      "602/602 [==============================] - 1s 864us/step - loss: 0.0503 - val_loss: 0.0527\n",
      "Epoch 467/1500\n",
      "602/602 [==============================] - 1s 925us/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 468/1500\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.050 - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0524\n",
      "Epoch 469/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0503 - val_loss: 0.0524\n",
      "Epoch 470/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0503 - val_loss: 0.0523\n",
      "Epoch 471/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0504 - val_loss: 0.0527\n",
      "Epoch 472/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0506 - val_loss: 0.0526s - lo\n",
      "Epoch 473/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0503 - val_loss: 0.0526\n",
      "Epoch 474/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0524\n",
      "Epoch 475/1500\n",
      "602/602 [==============================] - 1s 942us/step - loss: 0.0503 - val_loss: 0.0526\n",
      "Epoch 476/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0524\n",
      "Epoch 477/1500\n",
      "602/602 [==============================] - 1s 854us/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 478/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 479/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 480/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0527\n",
      "Epoch 481/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 482/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0524\n",
      "Epoch 483/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 484/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 485/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0526\n",
      "Epoch 486/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0527\n",
      "Epoch 487/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0509 - val_loss: 0.0525\n",
      "Epoch 488/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 489/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0506 - val_loss: 0.0526\n",
      "Epoch 490/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 491/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 492/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0526\n",
      "Epoch 493/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 494/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0524A: 0s - loss: 0.0\n",
      "Epoch 495/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0523\n",
      "Epoch 496/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0528 0s - loss: 0.05\n",
      "Epoch 497/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 498/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0527\n",
      "Epoch 499/1500\n",
      "602/602 [==============================] - 1s 966us/step - loss: 0.0504 - val_loss: 0.0524\n",
      "Epoch 500/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0526\n",
      "Epoch 501/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 502/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 503/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 504/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0523\n",
      "Epoch 505/1500\n",
      "602/602 [==============================] - 1s 994us/step - loss: 0.0502 - val_loss: 0.0524\n",
      "Epoch 506/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 507/1500\n",
      "602/602 [==============================] - 0s 821us/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 508/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 509/1500\n",
      "602/602 [==============================] - 1s 909us/step - loss: 0.0501 - val_loss: 0.0525\n",
      "Epoch 510/1500\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.0504- ETA: 0s - loss: - 1s 2ms/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 511/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 512/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0509 - val_loss: 0.0533\n",
      "Epoch 513/1500\n",
      "602/602 [==============================] - 1s 845us/step - loss: 0.0506 - val_loss: 0.0525\n",
      "Epoch 514/1500\n",
      "602/602 [==============================] - 1s 954us/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 515/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 516/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0524\n",
      "Epoch 517/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 518/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 519/1500\n",
      "602/602 [==============================] - 1s 917us/step - loss: 0.0501 - val_loss: 0.0530\n",
      "Epoch 520/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0526\n",
      "Epoch 521/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 522/1500\n",
      "602/602 [==============================] - 1s 949us/step - loss: 0.0502 - val_loss: 0.0526\n",
      "Epoch 523/1500\n",
      "602/602 [==============================] - 0s 818us/step - loss: 0.0502 - val_loss: 0.0529\n",
      "Epoch 524/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0524\n",
      "Epoch 525/1500\n",
      "602/602 [==============================] - 1s 895us/step - loss: 0.0509 - val_loss: 0.0528\n",
      "Epoch 526/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0524\n",
      "Epoch 527/1500\n",
      "602/602 [==============================] - 1s 951us/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 528/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0525 ETA: 0s - loss: 0.050\n",
      "Epoch 529/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 530/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0528\n",
      "Epoch 531/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 532/1500\n",
      "602/602 [==============================] - 1s 944us/step - loss: 0.0504 - val_loss: 0.0527\n",
      "Epoch 533/1500\n",
      "602/602 [==============================] - 1s 912us/step - loss: 0.0502 - val_loss: 0.0527\n",
      "Epoch 534/1500\n",
      "602/602 [==============================] - 1s 899us/step - loss: 0.0501 - val_loss: 0.0523\n",
      "Epoch 535/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0523\n",
      "Epoch 536/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0501 - val_loss: 0.0525 0s - loss: 0.050\n",
      "Epoch 537/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 538/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0503 - val_loss: 0.0526\n",
      "Epoch 539/1500\n",
      "602/602 [==============================] - 1s 922us/step - loss: 0.0502 - val_loss: 0.0524\n",
      "Epoch 540/1500\n",
      "602/602 [==============================] - 0s 742us/step - loss: 0.0501 - val_loss: 0.0525\n",
      "Epoch 541/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 542/1500\n",
      "602/602 [==============================] - 1s 988us/step - loss: 0.0501 - val_loss: 0.0528\n",
      "Epoch 543/1500\n",
      "602/602 [==============================] - 0s 796us/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 544/1500\n",
      "602/602 [==============================] - 0s 717us/step - loss: 0.0502 - val_loss: 0.0524\n",
      "Epoch 545/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0501 - val_loss: 0.0523\n",
      "Epoch 546/1500\n",
      "602/602 [==============================] - 0s 712us/step - loss: 0.0507 - val_loss: 0.0525\n",
      "Epoch 547/1500\n",
      "602/602 [==============================] - 0s 788us/step - loss: 0.0502 - val_loss: 0.0523\n",
      "Epoch 548/1500\n",
      "602/602 [==============================] - 0s 639us/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 549/1500\n",
      "602/602 [==============================] - 1s 893us/step - loss: 0.0502 - val_loss: 0.0524\n",
      "Epoch 550/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 551/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0501 - val_loss: 0.0525\n",
      "Epoch 552/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 553/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 554/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 555/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0526\n",
      "Epoch 556/1500\n",
      "602/602 [==============================] - 0s 688us/step - loss: 0.0501 - val_loss: 0.0525\n",
      "Epoch 557/1500\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.049 - 1s 862us/step - loss: 0.0502 - val_loss: 0.0524\n",
      "Epoch 558/1500\n",
      "602/602 [==============================] - 1s 927us/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 559/1500\n",
      "602/602 [==============================] - 1s 854us/step - loss: 0.0501 - val_loss: 0.0525\n",
      "Epoch 560/1500\n",
      "602/602 [==============================] - 0s 815us/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 561/1500\n",
      "602/602 [==============================] - 1s 888us/step - loss: 0.0501 - val_loss: 0.0523\n",
      "Epoch 562/1500\n",
      "602/602 [==============================] - 0s 669us/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 563/1500\n",
      "602/602 [==============================] - 1s 939us/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 564/1500\n",
      "602/602 [==============================] - 1s 856us/step - loss: 0.0502 - val_loss: 0.0524\n",
      "Epoch 565/1500\n",
      "602/602 [==============================] - 1s 838us/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 566/1500\n",
      "602/602 [==============================] - 1s 834us/step - loss: 0.0501 - val_loss: 0.0525\n",
      "Epoch 567/1500\n",
      "602/602 [==============================] - 1s 852us/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 568/1500\n",
      "602/602 [==============================] - 1s 874us/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 569/1500\n",
      "602/602 [==============================] - 0s 794us/step - loss: 0.0502 - val_loss: 0.0526\n",
      "Epoch 570/1500\n",
      "602/602 [==============================] - 1s 964us/step - loss: 0.0500 - val_loss: 0.0523\n",
      "Epoch 571/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0524\n",
      "Epoch 572/1500\n",
      "602/602 [==============================] - 0s 794us/step - loss: 0.0501 - val_loss: 0.0523\n",
      "Epoch 573/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 574/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0527\n",
      "Epoch 575/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0500 - val_loss: 0.0524\n",
      "Epoch 576/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 577/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0523\n",
      "Epoch 578/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0526\n",
      "Epoch 579/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 580/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0501 - val_loss: 0.0529\n",
      "Epoch 581/1500\n",
      "602/602 [==============================] - 1s 854us/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 582/1500\n",
      "602/602 [==============================] - 1s 996us/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 583/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0529\n",
      "Epoch 584/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 585/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 586/1500\n",
      "602/602 [==============================] - 1s 954us/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 587/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 588/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0524A: 0s - loss: \n",
      "Epoch 589/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 590/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 591/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 592/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0500 - val_loss: 0.0522\n",
      "Epoch 593/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0523\n",
      "Epoch 594/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 595/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 596/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 597/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 598/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0505 - val_loss: 0.0526\n",
      "Epoch 599/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 600/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0500 - val_loss: 0.0524\n",
      "Epoch 601/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0524\n",
      "Epoch 602/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0524\n",
      "Epoch 603/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 604/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0523\n",
      "Epoch 605/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 606/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 607/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 608/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0499 - val_loss: 0.0525s: 0.0\n",
      "Epoch 609/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0514 - val_loss: 0.0527\n",
      "Epoch 610/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0510 - val_loss: 0.0525\n",
      "Epoch 611/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0503 - val_loss: 0.0524\n",
      "Epoch 612/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 613/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 614/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0524ETA: 0s - los\n",
      "Epoch 615/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0525 loss: 0.050\n",
      "Epoch 616/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 617/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 618/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0505 - val_loss: 0.0524\n",
      "Epoch 619/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0505 - val_loss: 0.0527\n",
      "Epoch 620/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 621/1500\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.0500- ETA: 0s - loss - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 622/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0524\n",
      "Epoch 623/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 624/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 625/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0500 - val_loss: 0.05240s - loss: \n",
      "Epoch 626/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0524\n",
      "Epoch 627/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 628/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0499 - val_loss: 0.0525: 0s - loss: 0.05\n",
      "Epoch 629/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 630/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0523\n",
      "Epoch 631/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 632/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 633/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 634/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 635/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 636/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 637/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 638/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0527\n",
      "Epoch 639/1500\n",
      "602/602 [==============================] - 1s 895us/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 640/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0525: 0s - loss: 0.0\n",
      "Epoch 641/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 642/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0526\n",
      "Epoch 643/1500\n",
      "602/602 [==============================] - 1s 924us/step - loss: 0.0500 - val_loss: 0.0524\n",
      "Epoch 644/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0501 - val_loss: 0.0527\n",
      "Epoch 645/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 646/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 647/1500\n",
      "602/602 [==============================] - 1s 969us/step - loss: 0.0503 - val_loss: 0.0523\n",
      "Epoch 648/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 649/1500\n",
      "602/602 [==============================] - 1s 967us/step - loss: 0.0499 - val_loss: 0.0522\n",
      "Epoch 650/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0523\n",
      "Epoch 651/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 652/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0523\n",
      "Epoch 653/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 654/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 655/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 656/1500\n",
      "602/602 [==============================] - 0s 757us/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 657/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 658/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0529\n",
      "Epoch 659/1500\n",
      "602/602 [==============================] - 1s 856us/step - loss: 0.0501 - val_loss: 0.0524\n",
      "Epoch 660/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 661/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 662/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 663/1500\n",
      "602/602 [==============================] - 1s 870us/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 664/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 665/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0524s - loss: 0.050 - ETA: 0s - loss: 0.049\n",
      "Epoch 666/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 667/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 668/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0525\n",
      "Epoch 669/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0524\n",
      "Epoch 670/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0527\n",
      "Epoch 671/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 672/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 673/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 674/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 675/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 676/1500\n",
      "602/602 [==============================] - 1s 855us/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 677/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0526\n",
      "Epoch 678/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 679/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 680/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0527\n",
      "Epoch 681/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 682/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 683/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0526- ETA: 0s - loss: 0.050\n",
      "Epoch 684/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 685/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 686/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0527\n",
      "Epoch 687/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 688/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 689/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0527\n",
      "Epoch 690/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 691/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 692/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 693/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 694/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 695/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 1s 898us/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 696/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 697/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 698/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0525A: 0s - loss: 0.\n",
      "Epoch 699/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0523\n",
      "Epoch 700/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0523\n",
      "Epoch 701/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0526\n",
      "Epoch 702/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 703/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 704/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 705/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 706/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0527\n",
      "Epoch 707/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 708/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 709/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 710/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 711/1500\n",
      "602/602 [==============================] - 1s 984us/step - loss: 0.0498 - val_loss: 0.0523\n",
      "Epoch 712/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 713/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 714/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0528\n",
      "Epoch 715/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 716/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 717/1500\n",
      "602/602 [==============================] - 1s 953us/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 718/1500\n",
      "602/602 [==============================] - 1s 860us/step - loss: 0.0498 - val_loss: 0.0523\n",
      "Epoch 719/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 720/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 721/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 722/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0525\n",
      "Epoch 723/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0524\n",
      "Epoch 724/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 725/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0527\n",
      "Epoch 726/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 727/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0528\n",
      "Epoch 728/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 729/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 730/1500\n",
      "602/602 [==============================] - 0s 795us/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 731/1500\n",
      "602/602 [==============================] - 0s 770us/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 732/1500\n",
      "602/602 [==============================] - 0s 696us/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 733/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0527\n",
      "Epoch 734/1500\n",
      "602/602 [==============================] - 1s 867us/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 735/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 736/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 737/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 738/1500\n",
      "602/602 [==============================] - 0s 755us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 739/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0528\n",
      "Epoch 740/1500\n",
      "602/602 [==============================] - 1s 926us/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 741/1500\n",
      "602/602 [==============================] - 1s 906us/step - loss: 0.0498 - val_loss: 0.0526\n",
      "Epoch 742/1500\n",
      "602/602 [==============================] - 0s 798us/step - loss: 0.0498 - val_loss: 0.0526\n",
      "Epoch 743/1500\n",
      "602/602 [==============================] - 1s 983us/step - loss: 0.0500 - val_loss: 0.0525\n",
      "Epoch 744/1500\n",
      "602/602 [==============================] - 0s 776us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 745/1500\n",
      "602/602 [==============================] - 1s 844us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 746/1500\n",
      "602/602 [==============================] - 1s 968us/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 747/1500\n",
      "602/602 [==============================] - 0s 801us/step - loss: 0.0503 - val_loss: 0.0527\n",
      "Epoch 748/1500\n",
      "602/602 [==============================] - 0s 814us/step - loss: 0.0499 - val_loss: 0.0527\n",
      "Epoch 749/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 750/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0526\n",
      "Epoch 751/1500\n",
      "602/602 [==============================] - 1s 846us/step - loss: 0.0498 - val_loss: 0.0527\n",
      "Epoch 752/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0499 - val_loss: 0.0523ETA: 0s - loss: 0.0\n",
      "Epoch 753/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 754/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 755/1500\n",
      "602/602 [==============================] - 1s 900us/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 756/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 757/1500\n",
      "602/602 [==============================] - 1s 928us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 758/1500\n",
      "602/602 [==============================] - 1s 957us/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 759/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 760/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0500 - val_loss: 0.0528\n",
      "Epoch 761/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0501 - val_loss: 0.0523\n",
      "Epoch 762/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0523\n",
      "Epoch 763/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 764/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0501 - val_loss: 0.0523\n",
      "Epoch 765/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 766/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0500 - val_loss: 0.0524\n",
      "Epoch 767/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0522\n",
      "Epoch 768/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 769/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0498 - val_loss: 0.0526\n",
      "Epoch 770/1500\n",
      "602/602 [==============================] - 0s 423us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 771/1500\n",
      "602/602 [==============================] - 1s 854us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 772/1500\n",
      "602/602 [==============================] - 0s 577us/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 773/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 0s 639us/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 774/1500\n",
      "602/602 [==============================] - 0s 723us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 775/1500\n",
      "602/602 [==============================] - 0s 667us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 776/1500\n",
      "602/602 [==============================] - 0s 637us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 777/1500\n",
      "602/602 [==============================] - 0s 673us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 778/1500\n",
      "602/602 [==============================] - 1s 859us/step - loss: 0.0498 - val_loss: 0.0526\n",
      "Epoch 779/1500\n",
      "602/602 [==============================] - 0s 657us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 780/1500\n",
      "602/602 [==============================] - 0s 666us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 781/1500\n",
      "602/602 [==============================] - 0s 326us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 782/1500\n",
      "602/602 [==============================] - 0s 329us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 783/1500\n",
      "602/602 [==============================] - 0s 482us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 784/1500\n",
      "602/602 [==============================] - 0s 514us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 785/1500\n",
      "602/602 [==============================] - 0s 384us/step - loss: 0.0498 - val_loss: 0.0526\n",
      "Epoch 786/1500\n",
      "602/602 [==============================] - 1s 839us/step - loss: 0.0499 - val_loss: 0.0527\n",
      "Epoch 787/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0497 - val_loss: 0.0526\n",
      "Epoch 788/1500\n",
      "602/602 [==============================] - 1s 841us/step - loss: 0.0496 - val_loss: 0.0524\n",
      "Epoch 789/1500\n",
      "602/602 [==============================] - 1s 897us/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 790/1500\n",
      "602/602 [==============================] - 0s 464us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 791/1500\n",
      "602/602 [==============================] - 0s 504us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 792/1500\n",
      "602/602 [==============================] - 1s 961us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 793/1500\n",
      "602/602 [==============================] - 0s 731us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 794/1500\n",
      "602/602 [==============================] - 0s 684us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 795/1500\n",
      "602/602 [==============================] - 0s 722us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 796/1500\n",
      "602/602 [==============================] - 0s 704us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 797/1500\n",
      "602/602 [==============================] - 0s 718us/step - loss: 0.0497 - val_loss: 0.0526\n",
      "Epoch 798/1500\n",
      "602/602 [==============================] - 0s 698us/step - loss: 0.0497 - val_loss: 0.0526\n",
      "Epoch 799/1500\n",
      "602/602 [==============================] - 0s 697us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 800/1500\n",
      "602/602 [==============================] - 0s 552us/step - loss: 0.0496 - val_loss: 0.0523\n",
      "Epoch 801/1500\n",
      "602/602 [==============================] - 0s 510us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 802/1500\n",
      "602/602 [==============================] - 0s 534us/step - loss: 0.0498 - val_loss: 0.0526\n",
      "Epoch 803/1500\n",
      "602/602 [==============================] - 0s 469us/step - loss: 0.0497 - val_loss: 0.0523\n",
      "Epoch 804/1500\n",
      "602/602 [==============================] - 0s 494us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 805/1500\n",
      "602/602 [==============================] - 0s 454us/step - loss: 0.0496 - val_loss: 0.0523\n",
      "Epoch 806/1500\n",
      "602/602 [==============================] - 0s 643us/step - loss: 0.0496 - val_loss: 0.0524\n",
      "Epoch 807/1500\n",
      "602/602 [==============================] - 0s 321us/step - loss: 0.0502 - val_loss: 0.0525\n",
      "Epoch 808/1500\n",
      "602/602 [==============================] - 0s 296us/step - loss: 0.0498 - val_loss: 0.0523\n",
      "Epoch 809/1500\n",
      "602/602 [==============================] - 0s 331us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 810/1500\n",
      "602/602 [==============================] - 0s 459us/step - loss: 0.0496 - val_loss: 0.0527\n",
      "Epoch 811/1500\n",
      "602/602 [==============================] - 0s 521us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 812/1500\n",
      "602/602 [==============================] - 0s 555us/step - loss: 0.0501 - val_loss: 0.0525\n",
      "Epoch 813/1500\n",
      "602/602 [==============================] - 0s 356us/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 814/1500\n",
      "602/602 [==============================] - 0s 407us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 815/1500\n",
      "602/602 [==============================] - 0s 321us/step - loss: 0.0496 - val_loss: 0.0523\n",
      "Epoch 816/1500\n",
      "602/602 [==============================] - 0s 282us/step - loss: 0.0497 - val_loss: 0.0523\n",
      "Epoch 817/1500\n",
      "602/602 [==============================] - 0s 275us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 818/1500\n",
      "602/602 [==============================] - 0s 273us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 819/1500\n",
      "602/602 [==============================] - 0s 272us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 820/1500\n",
      "602/602 [==============================] - 0s 330us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 821/1500\n",
      "602/602 [==============================] - 0s 450us/step - loss: 0.0496 - val_loss: 0.0524\n",
      "Epoch 822/1500\n",
      "602/602 [==============================] - 0s 320us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 823/1500\n",
      "602/602 [==============================] - 0s 352us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 824/1500\n",
      "602/602 [==============================] - 0s 550us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 825/1500\n",
      "602/602 [==============================] - 0s 285us/step - loss: 0.0496 - val_loss: 0.0528\n",
      "Epoch 826/1500\n",
      "602/602 [==============================] - 0s 400us/step - loss: 0.0497 - val_loss: 0.0523\n",
      "Epoch 827/1500\n",
      "602/602 [==============================] - 0s 680us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 828/1500\n",
      "602/602 [==============================] - 0s 721us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 829/1500\n",
      "602/602 [==============================] - 0s 284us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 830/1500\n",
      "602/602 [==============================] - 0s 321us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 831/1500\n",
      "602/602 [==============================] - 0s 263us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 832/1500\n",
      "602/602 [==============================] - 0s 309us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 833/1500\n",
      "602/602 [==============================] - 0s 290us/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 834/1500\n",
      "602/602 [==============================] - 0s 278us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 835/1500\n",
      "602/602 [==============================] - 0s 279us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 836/1500\n",
      "602/602 [==============================] - 0s 331us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 837/1500\n",
      "602/602 [==============================] - 0s 283us/step - loss: 0.0497 - val_loss: 0.0526\n",
      "Epoch 838/1500\n",
      "602/602 [==============================] - 0s 300us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 839/1500\n",
      "602/602 [==============================] - 0s 310us/step - loss: 0.0496 - val_loss: 0.0527\n",
      "Epoch 840/1500\n",
      "602/602 [==============================] - 0s 281us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 841/1500\n",
      "602/602 [==============================] - 0s 583us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 842/1500\n",
      "602/602 [==============================] - 0s 665us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 843/1500\n",
      "602/602 [==============================] - 0s 526us/step - loss: 0.0497 - val_loss: 0.0526\n",
      "Epoch 844/1500\n",
      "602/602 [==============================] - 0s 500us/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 845/1500\n",
      "602/602 [==============================] - 0s 633us/step - loss: 0.0496 - val_loss: 0.0523\n",
      "Epoch 846/1500\n",
      "602/602 [==============================] - 0s 564us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 847/1500\n",
      "602/602 [==============================] - 0s 325us/step - loss: 0.0496 - val_loss: 0.0524\n",
      "Epoch 848/1500\n",
      "602/602 [==============================] - 0s 304us/step - loss: 0.0500 - val_loss: 0.0527\n",
      "Epoch 849/1500\n",
      "602/602 [==============================] - 0s 333us/step - loss: 0.0497 - val_loss: 0.0526\n",
      "Epoch 850/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 0s 661us/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 851/1500\n",
      "602/602 [==============================] - 0s 353us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 852/1500\n",
      "602/602 [==============================] - 0s 291us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 853/1500\n",
      "602/602 [==============================] - 0s 342us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 854/1500\n",
      "602/602 [==============================] - 0s 279us/step - loss: 0.0507 - val_loss: 0.0525\n",
      "Epoch 855/1500\n",
      "602/602 [==============================] - 0s 401us/step - loss: 0.0500 - val_loss: 0.0524\n",
      "Epoch 856/1500\n",
      "602/602 [==============================] - 0s 623us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 857/1500\n",
      "602/602 [==============================] - 0s 686us/step - loss: 0.0496 - val_loss: 0.0524\n",
      "Epoch 858/1500\n",
      "602/602 [==============================] - 0s 443us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 859/1500\n",
      "602/602 [==============================] - 0s 321us/step - loss: 0.0496 - val_loss: 0.0528\n",
      "Epoch 860/1500\n",
      "602/602 [==============================] - 0s 690us/step - loss: 0.0497 - val_loss: 0.0526\n",
      "Epoch 861/1500\n",
      "602/602 [==============================] - 0s 556us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 862/1500\n",
      "602/602 [==============================] - 0s 418us/step - loss: 0.0496 - val_loss: 0.0524\n",
      "Epoch 863/1500\n",
      "602/602 [==============================] - 0s 329us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 864/1500\n",
      "602/602 [==============================] - 0s 480us/step - loss: 0.0495 - val_loss: 0.0527\n",
      "Epoch 865/1500\n",
      "602/602 [==============================] - 0s 462us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 866/1500\n",
      "602/602 [==============================] - 0s 346us/step - loss: 0.0502 - val_loss: 0.0527\n",
      "Epoch 867/1500\n",
      "602/602 [==============================] - 0s 424us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 868/1500\n",
      "602/602 [==============================] - 0s 301us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 869/1500\n",
      "602/602 [==============================] - 0s 282us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 870/1500\n",
      "602/602 [==============================] - 0s 818us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 871/1500\n",
      "602/602 [==============================] - 0s 562us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 872/1500\n",
      "602/602 [==============================] - 0s 365us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 873/1500\n",
      "602/602 [==============================] - 0s 342us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 874/1500\n",
      "602/602 [==============================] - 0s 704us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 875/1500\n",
      "602/602 [==============================] - 0s 725us/step - loss: 0.0497 - val_loss: 0.0528\n",
      "Epoch 876/1500\n",
      "602/602 [==============================] - 0s 589us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 877/1500\n",
      "602/602 [==============================] - 0s 773us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 878/1500\n",
      "602/602 [==============================] - 0s 636us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 879/1500\n",
      "602/602 [==============================] - 0s 314us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 880/1500\n",
      "602/602 [==============================] - 0s 624us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 881/1500\n",
      "602/602 [==============================] - 1s 875us/step - loss: 0.0498 - val_loss: 0.0527\n",
      "Epoch 882/1500\n",
      "602/602 [==============================] - 0s 473us/step - loss: 0.0497 - val_loss: 0.0523\n",
      "Epoch 883/1500\n",
      "602/602 [==============================] - 0s 309us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 884/1500\n",
      "602/602 [==============================] - 0s 320us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 885/1500\n",
      "602/602 [==============================] - 0s 293us/step - loss: 0.0496 - val_loss: 0.0524\n",
      "Epoch 886/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 887/1500\n",
      "602/602 [==============================] - 0s 628us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 888/1500\n",
      "602/602 [==============================] - 0s 780us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 889/1500\n",
      "602/602 [==============================] - 0s 639us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 890/1500\n",
      "602/602 [==============================] - 0s 675us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 891/1500\n",
      "602/602 [==============================] - 0s 743us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 892/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 893/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 894/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 895/1500\n",
      "602/602 [==============================] - 0s 507us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 896/1500\n",
      "602/602 [==============================] - 0s 690us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 897/1500\n",
      "602/602 [==============================] - 0s 732us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 898/1500\n",
      "602/602 [==============================] - 0s 483us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 899/1500\n",
      "602/602 [==============================] - 0s 385us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 900/1500\n",
      "602/602 [==============================] - 0s 525us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 901/1500\n",
      "602/602 [==============================] - 0s 340us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 902/1500\n",
      "602/602 [==============================] - 0s 300us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 903/1500\n",
      "602/602 [==============================] - 0s 556us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 904/1500\n",
      "602/602 [==============================] - 0s 697us/step - loss: 0.0496 - val_loss: 0.0527\n",
      "Epoch 905/1500\n",
      "602/602 [==============================] - 0s 654us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 906/1500\n",
      "602/602 [==============================] - 0s 643us/step - loss: 0.0495 - val_loss: 0.0522\n",
      "Epoch 907/1500\n",
      "602/602 [==============================] - 0s 645us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 908/1500\n",
      "602/602 [==============================] - 0s 745us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 909/1500\n",
      "602/602 [==============================] - 0s 647us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 910/1500\n",
      "602/602 [==============================] - 0s 694us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 911/1500\n",
      "602/602 [==============================] - 0s 585us/step - loss: 0.0495 - val_loss: 0.0523\n",
      "Epoch 912/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 913/1500\n",
      "602/602 [==============================] - 0s 593us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 914/1500\n",
      "602/602 [==============================] - 0s 622us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 915/1500\n",
      "602/602 [==============================] - 0s 403us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 916/1500\n",
      "602/602 [==============================] - 0s 807us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 917/1500\n",
      "602/602 [==============================] - 1s 864us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 918/1500\n",
      "602/602 [==============================] - 0s 528us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 919/1500\n",
      "602/602 [==============================] - 0s 725us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 920/1500\n",
      "602/602 [==============================] - 0s 524us/step - loss: 0.0495 - val_loss: 0.0528\n",
      "Epoch 921/1500\n",
      "602/602 [==============================] - 0s 381us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 922/1500\n",
      "602/602 [==============================] - 0s 547us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 923/1500\n",
      "602/602 [==============================] - 0s 795us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 924/1500\n",
      "602/602 [==============================] - 0s 716us/step - loss: 0.0495 - val_loss: 0.0523\n",
      "Epoch 925/1500\n",
      "602/602 [==============================] - 1s 917us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 926/1500\n",
      "602/602 [==============================] - 0s 525us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 927/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 0s 542us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 928/1500\n",
      "602/602 [==============================] - 0s 330us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 929/1500\n",
      "602/602 [==============================] - 0s 385us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 930/1500\n",
      "602/602 [==============================] - 0s 309us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 931/1500\n",
      "602/602 [==============================] - 0s 307us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 932/1500\n",
      "602/602 [==============================] - 0s 271us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 933/1500\n",
      "602/602 [==============================] - 0s 358us/step - loss: 0.0499 - val_loss: 0.0525\n",
      "Epoch 934/1500\n",
      "602/602 [==============================] - 0s 311us/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 935/1500\n",
      "602/602 [==============================] - 0s 406us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 936/1500\n",
      "602/602 [==============================] - 0s 603us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 937/1500\n",
      "602/602 [==============================] - 0s 750us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 938/1500\n",
      "602/602 [==============================] - 0s 541us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 939/1500\n",
      "602/602 [==============================] - 0s 643us/step - loss: 0.0496 - val_loss: 0.0527\n",
      "Epoch 940/1500\n",
      "602/602 [==============================] - 0s 715us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 941/1500\n",
      "602/602 [==============================] - 0s 312us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 942/1500\n",
      "602/602 [==============================] - 0s 291us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 943/1500\n",
      "602/602 [==============================] - 0s 394us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 944/1500\n",
      "602/602 [==============================] - 0s 641us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 945/1500\n",
      "602/602 [==============================] - 0s 515us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 946/1500\n",
      "602/602 [==============================] - 0s 682us/step - loss: 0.0496 - val_loss: 0.0524\n",
      "Epoch 947/1500\n",
      "602/602 [==============================] - 0s 777us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 948/1500\n",
      "602/602 [==============================] - 0s 666us/step - loss: 0.0495 - val_loss: 0.0527\n",
      "Epoch 949/1500\n",
      "602/602 [==============================] - 0s 664us/step - loss: 0.0495 - val_loss: 0.0527\n",
      "Epoch 950/1500\n",
      "602/602 [==============================] - 0s 737us/step - loss: 0.0495 - val_loss: 0.0523\n",
      "Epoch 951/1500\n",
      "602/602 [==============================] - 0s 723us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 952/1500\n",
      "602/602 [==============================] - 0s 662us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 953/1500\n",
      "602/602 [==============================] - 0s 698us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 954/1500\n",
      "602/602 [==============================] - 0s 688us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 955/1500\n",
      "602/602 [==============================] - 0s 726us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 956/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 957/1500\n",
      "602/602 [==============================] - 0s 681us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 958/1500\n",
      "602/602 [==============================] - 0s 658us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 959/1500\n",
      "602/602 [==============================] - 0s 823us/step - loss: 0.0502 - val_loss: 0.0526\n",
      "Epoch 960/1500\n",
      "602/602 [==============================] - 0s 701us/step - loss: 0.0497 - val_loss: 0.0525\n",
      "Epoch 961/1500\n",
      "602/602 [==============================] - 0s 667us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 962/1500\n",
      "602/602 [==============================] - 0s 770us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 963/1500\n",
      "602/602 [==============================] - 0s 647us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 964/1500\n",
      "602/602 [==============================] - 0s 652us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 965/1500\n",
      "602/602 [==============================] - 0s 725us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 966/1500\n",
      "602/602 [==============================] - 0s 668us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 967/1500\n",
      "602/602 [==============================] - 0s 730us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 968/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 969/1500\n",
      "602/602 [==============================] - 0s 740us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 970/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0495 - val_loss: 0.0524TA: 0s - loss: \n",
      "Epoch 971/1500\n",
      "602/602 [==============================] - 0s 798us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 972/1500\n",
      "602/602 [==============================] - 0s 778us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 973/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 974/1500\n",
      "602/602 [==============================] - 1s 932us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 975/1500\n",
      "602/602 [==============================] - 1s 910us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 976/1500\n",
      "602/602 [==============================] - 0s 591us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 977/1500\n",
      "602/602 [==============================] - 0s 381us/step - loss: 0.0500 - val_loss: 0.0526\n",
      "Epoch 978/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 979/1500\n",
      "602/602 [==============================] - 0s 564us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 980/1500\n",
      "602/602 [==============================] - 0s 374us/step - loss: 0.0494 - val_loss: 0.0523\n",
      "Epoch 981/1500\n",
      "602/602 [==============================] - 0s 526us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 982/1500\n",
      "602/602 [==============================] - 0s 610us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 983/1500\n",
      "602/602 [==============================] - 0s 742us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 984/1500\n",
      "602/602 [==============================] - 0s 693us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 985/1500\n",
      "602/602 [==============================] - 0s 660us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 986/1500\n",
      "602/602 [==============================] - 0s 660us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 987/1500\n",
      "602/602 [==============================] - 0s 697us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 988/1500\n",
      "602/602 [==============================] - 0s 641us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 989/1500\n",
      "602/602 [==============================] - 0s 730us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 990/1500\n",
      "602/602 [==============================] - 0s 680us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 991/1500\n",
      "602/602 [==============================] - 1s 934us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 992/1500\n",
      "602/602 [==============================] - 0s 468us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 993/1500\n",
      "602/602 [==============================] - 0s 334us/step - loss: 0.0494 - val_loss: 0.0527\n",
      "Epoch 994/1500\n",
      "602/602 [==============================] - 0s 349us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 995/1500\n",
      "602/602 [==============================] - 0s 704us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 996/1500\n",
      "602/602 [==============================] - 0s 675us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 997/1500\n",
      "602/602 [==============================] - 0s 424us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 998/1500\n",
      "602/602 [==============================] - 0s 348us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 999/1500\n",
      "602/602 [==============================] - 0s 322us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1000/1500\n",
      "602/602 [==============================] - 0s 271us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 1001/1500\n",
      "602/602 [==============================] - 0s 269us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 1002/1500\n",
      "602/602 [==============================] - 0s 278us/step - loss: 0.0497 - val_loss: 0.0528\n",
      "Epoch 1003/1500\n",
      "602/602 [==============================] - 0s 656us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1004/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 0s 665us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 1005/1500\n",
      "602/602 [==============================] - 0s 405us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1006/1500\n",
      "602/602 [==============================] - 0s 550us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1007/1500\n",
      "602/602 [==============================] - 0s 385us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1008/1500\n",
      "602/602 [==============================] - 0s 434us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1009/1500\n",
      "602/602 [==============================] - 0s 380us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1010/1500\n",
      "602/602 [==============================] - 1s 907us/step - loss: 0.0495 - val_loss: 0.0528\n",
      "Epoch 1011/1500\n",
      "602/602 [==============================] - 0s 684us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 1012/1500\n",
      "602/602 [==============================] - 0s 558us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 1013/1500\n",
      "602/602 [==============================] - 0s 600us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 1014/1500\n",
      "602/602 [==============================] - 0s 430us/step - loss: 0.0494 - val_loss: 0.0523\n",
      "Epoch 1015/1500\n",
      "602/602 [==============================] - 0s 495us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1016/1500\n",
      "602/602 [==============================] - 0s 450us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1017/1500\n",
      "602/602 [==============================] - 0s 298us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 1018/1500\n",
      "602/602 [==============================] - 1s 957us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 1019/1500\n",
      "602/602 [==============================] - 0s 736us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1020/1500\n",
      "602/602 [==============================] - 0s 572us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1021/1500\n",
      "602/602 [==============================] - 1s 913us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 1022/1500\n",
      "602/602 [==============================] - 0s 367us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 1023/1500\n",
      "602/602 [==============================] - 0s 461us/step - loss: 0.0494 - val_loss: 0.0528\n",
      "Epoch 1024/1500\n",
      "602/602 [==============================] - 0s 820us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 1025/1500\n",
      "602/602 [==============================] - 0s 390us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1026/1500\n",
      "602/602 [==============================] - 0s 334us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 1027/1500\n",
      "602/602 [==============================] - 0s 468us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 1028/1500\n",
      "602/602 [==============================] - 0s 381us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1029/1500\n",
      "602/602 [==============================] - 0s 269us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 1030/1500\n",
      "602/602 [==============================] - 0s 304us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1031/1500\n",
      "602/602 [==============================] - 0s 276us/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 1032/1500\n",
      "602/602 [==============================] - 0s 297us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1033/1500\n",
      "602/602 [==============================] - 0s 389us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1034/1500\n",
      "602/602 [==============================] - 0s 280us/step - loss: 0.0494 - val_loss: 0.0523\n",
      "Epoch 1035/1500\n",
      "602/602 [==============================] - 0s 278us/step - loss: 0.0499 - val_loss: 0.0523\n",
      "Epoch 1036/1500\n",
      "602/602 [==============================] - 0s 276us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1037/1500\n",
      "602/602 [==============================] - 0s 281us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1038/1500\n",
      "602/602 [==============================] - 0s 311us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1039/1500\n",
      "602/602 [==============================] - 0s 314us/step - loss: 0.0498 - val_loss: 0.0526\n",
      "Epoch 1040/1500\n",
      "602/602 [==============================] - 0s 276us/step - loss: 0.0496 - val_loss: 0.0524\n",
      "Epoch 1041/1500\n",
      "602/602 [==============================] - 0s 322us/step - loss: 0.0496 - val_loss: 0.0524\n",
      "Epoch 1042/1500\n",
      "602/602 [==============================] - 0s 451us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 1043/1500\n",
      "602/602 [==============================] - 0s 343us/step - loss: 0.0498 - val_loss: 0.0523\n",
      "Epoch 1044/1500\n",
      "602/602 [==============================] - 0s 303us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1045/1500\n",
      "602/602 [==============================] - 0s 269us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1046/1500\n",
      "602/602 [==============================] - 0s 256us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 1047/1500\n",
      "602/602 [==============================] - 0s 271us/step - loss: 0.0494 - val_loss: 0.0529\n",
      "Epoch 1048/1500\n",
      "602/602 [==============================] - 0s 274us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1049/1500\n",
      "602/602 [==============================] - 0s 325us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1050/1500\n",
      "602/602 [==============================] - 0s 310us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1051/1500\n",
      "602/602 [==============================] - 0s 685us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1052/1500\n",
      "602/602 [==============================] - 0s 287us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1053/1500\n",
      "602/602 [==============================] - 0s 332us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1054/1500\n",
      "602/602 [==============================] - 0s 293us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1055/1500\n",
      "602/602 [==============================] - 0s 290us/step - loss: 0.0493 - val_loss: 0.0522\n",
      "Epoch 1056/1500\n",
      "602/602 [==============================] - 0s 274us/step - loss: 0.0493 - val_loss: 0.0528\n",
      "Epoch 1057/1500\n",
      "602/602 [==============================] - 0s 355us/step - loss: 0.0493 - val_loss: 0.0523\n",
      "Epoch 1058/1500\n",
      "602/602 [==============================] - 0s 264us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1059/1500\n",
      "602/602 [==============================] - 0s 305us/step - loss: 0.0496 - val_loss: 0.0526\n",
      "Epoch 1060/1500\n",
      "602/602 [==============================] - 0s 325us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1061/1500\n",
      "602/602 [==============================] - 0s 274us/step - loss: 0.0505 - val_loss: 0.0527\n",
      "Epoch 1062/1500\n",
      "602/602 [==============================] - 0s 270us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 1063/1500\n",
      "602/602 [==============================] - 0s 299us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1064/1500\n",
      "602/602 [==============================] - 0s 269us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1065/1500\n",
      "602/602 [==============================] - 0s 318us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 1066/1500\n",
      "602/602 [==============================] - 0s 273us/step - loss: 0.0493 - val_loss: 0.0523\n",
      "Epoch 1067/1500\n",
      "602/602 [==============================] - 0s 286us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1068/1500\n",
      "602/602 [==============================] - 0s 280us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1069/1500\n",
      "602/602 [==============================] - 0s 294us/step - loss: 0.0497 - val_loss: 0.0527\n",
      "Epoch 1070/1500\n",
      "602/602 [==============================] - 0s 277us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1071/1500\n",
      "602/602 [==============================] - 0s 342us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1072/1500\n",
      "602/602 [==============================] - 0s 287us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1073/1500\n",
      "602/602 [==============================] - 0s 297us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1074/1500\n",
      "602/602 [==============================] - 0s 314us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1075/1500\n",
      "602/602 [==============================] - 0s 412us/step - loss: 0.0494 - val_loss: 0.0523\n",
      "Epoch 1076/1500\n",
      "602/602 [==============================] - 0s 351us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1077/1500\n",
      "602/602 [==============================] - 0s 292us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1078/1500\n",
      "602/602 [==============================] - 0s 270us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1079/1500\n",
      "602/602 [==============================] - 0s 687us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1080/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 0s 312us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1081/1500\n",
      "602/602 [==============================] - 0s 315us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 1082/1500\n",
      "602/602 [==============================] - 0s 284us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1083/1500\n",
      "602/602 [==============================] - 0s 299us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1084/1500\n",
      "602/602 [==============================] - 0s 305us/step - loss: 0.0493 - val_loss: 0.0523\n",
      "Epoch 1085/1500\n",
      "602/602 [==============================] - 0s 282us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1086/1500\n",
      "602/602 [==============================] - 0s 305us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1087/1500\n",
      "602/602 [==============================] - 0s 278us/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 1088/1500\n",
      "602/602 [==============================] - 0s 272us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1089/1500\n",
      "602/602 [==============================] - 0s 296us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1090/1500\n",
      "602/602 [==============================] - 0s 284us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1091/1500\n",
      "602/602 [==============================] - 0s 298us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1092/1500\n",
      "602/602 [==============================] - 0s 366us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1093/1500\n",
      "602/602 [==============================] - 1s 842us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1094/1500\n",
      "602/602 [==============================] - 1s 944us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1095/1500\n",
      "602/602 [==============================] - 1s 955us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1096/1500\n",
      "602/602 [==============================] - 0s 358us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1097/1500\n",
      "602/602 [==============================] - 0s 305us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1098/1500\n",
      "602/602 [==============================] - 0s 420us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1099/1500\n",
      "602/602 [==============================] - 0s 359us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1100/1500\n",
      "602/602 [==============================] - 0s 686us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1101/1500\n",
      "602/602 [==============================] - 0s 395us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1102/1500\n",
      "602/602 [==============================] - 0s 335us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1103/1500\n",
      "602/602 [==============================] - 0s 329us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1104/1500\n",
      "602/602 [==============================] - 0s 299us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1105/1500\n",
      "602/602 [==============================] - 0s 305us/step - loss: 0.0492 - val_loss: 0.0523\n",
      "Epoch 1106/1500\n",
      "602/602 [==============================] - 0s 312us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1107/1500\n",
      "602/602 [==============================] - 0s 316us/step - loss: 0.0493 - val_loss: 0.0529\n",
      "Epoch 1108/1500\n",
      "602/602 [==============================] - 0s 406us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1109/1500\n",
      "602/602 [==============================] - 0s 642us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1110/1500\n",
      "602/602 [==============================] - 0s 358us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1111/1500\n",
      "602/602 [==============================] - 0s 586us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1112/1500\n",
      "602/602 [==============================] - 0s 659us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1113/1500\n",
      "602/602 [==============================] - 0s 631us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1114/1500\n",
      "602/602 [==============================] - 0s 465us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1115/1500\n",
      "602/602 [==============================] - 0s 711us/step - loss: 0.0493 - val_loss: 0.0522\n",
      "Epoch 1116/1500\n",
      "602/602 [==============================] - 0s 365us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1117/1500\n",
      "602/602 [==============================] - 0s 468us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1118/1500\n",
      "602/602 [==============================] - 0s 371us/step - loss: 0.0493 - val_loss: 0.0529\n",
      "Epoch 1119/1500\n",
      "602/602 [==============================] - 0s 721us/step - loss: 0.0494 - val_loss: 0.0529\n",
      "Epoch 1120/1500\n",
      "602/602 [==============================] - 0s 570us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1121/1500\n",
      "602/602 [==============================] - 0s 612us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1122/1500\n",
      "602/602 [==============================] - 0s 700us/step - loss: 0.0493 - val_loss: 0.0523\n",
      "Epoch 1123/1500\n",
      "602/602 [==============================] - 0s 429us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1124/1500\n",
      "602/602 [==============================] - 0s 302us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1125/1500\n",
      "602/602 [==============================] - 0s 366us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1126/1500\n",
      "602/602 [==============================] - 0s 640us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1127/1500\n",
      "602/602 [==============================] - 0s 667us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1128/1500\n",
      "602/602 [==============================] - 0s 767us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1129/1500\n",
      "602/602 [==============================] - 0s 659us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1130/1500\n",
      "602/602 [==============================] - 0s 403us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1131/1500\n",
      "602/602 [==============================] - 0s 489us/step - loss: 0.0494 - val_loss: 0.0527\n",
      "Epoch 1132/1500\n",
      "602/602 [==============================] - 0s 432us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1133/1500\n",
      "602/602 [==============================] - 0s 269us/step - loss: 0.0495 - val_loss: 0.0528\n",
      "Epoch 1134/1500\n",
      "602/602 [==============================] - 0s 265us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1135/1500\n",
      "602/602 [==============================] - 0s 303us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1136/1500\n",
      "602/602 [==============================] - 0s 692us/step - loss: 0.0498 - val_loss: 0.0524\n",
      "Epoch 1137/1500\n",
      "602/602 [==============================] - 0s 331us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1138/1500\n",
      "602/602 [==============================] - 0s 276us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1139/1500\n",
      "602/602 [==============================] - 0s 279us/step - loss: 0.0493 - val_loss: 0.0528\n",
      "Epoch 1140/1500\n",
      "602/602 [==============================] - 0s 333us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1141/1500\n",
      "602/602 [==============================] - 0s 322us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1142/1500\n",
      "602/602 [==============================] - 0s 320us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1143/1500\n",
      "602/602 [==============================] - 0s 281us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1144/1500\n",
      "602/602 [==============================] - 0s 277us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1145/1500\n",
      "602/602 [==============================] - 0s 341us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1146/1500\n",
      "602/602 [==============================] - 0s 378us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1147/1500\n",
      "602/602 [==============================] - 0s 346us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1148/1500\n",
      "602/602 [==============================] - 0s 747us/step - loss: 0.0497 - val_loss: 0.0524\n",
      "Epoch 1149/1500\n",
      "602/602 [==============================] - 1s 906us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 1150/1500\n",
      "602/602 [==============================] - 0s 805us/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 1151/1500\n",
      "602/602 [==============================] - 1s 995us/step - loss: 0.0495 - val_loss: 0.0527\n",
      "Epoch 1152/1500\n",
      "602/602 [==============================] - 0s 566us/step - loss: 0.0493 - val_loss: 0.0527\n",
      "Epoch 1153/1500\n",
      "602/602 [==============================] - 0s 534us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1154/1500\n",
      "602/602 [==============================] - 0s 632us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1155/1500\n",
      "602/602 [==============================] - 0s 804us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1156/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 0s 644us/step - loss: 0.0493 - val_loss: 0.0527\n",
      "Epoch 1157/1500\n",
      "602/602 [==============================] - 0s 351us/step - loss: 0.0493 - val_loss: 0.0523\n",
      "Epoch 1158/1500\n",
      "602/602 [==============================] - 0s 276us/step - loss: 0.0493 - val_loss: 0.0528\n",
      "Epoch 1159/1500\n",
      "602/602 [==============================] - 0s 306us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 1160/1500\n",
      "602/602 [==============================] - 0s 287us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 1161/1500\n",
      "602/602 [==============================] - 0s 412us/step - loss: 0.0493 - val_loss: 0.0528\n",
      "Epoch 1162/1500\n",
      "602/602 [==============================] - 0s 619us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1163/1500\n",
      "602/602 [==============================] - 0s 703us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1164/1500\n",
      "602/602 [==============================] - 0s 625us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1165/1500\n",
      "602/602 [==============================] - 0s 562us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1166/1500\n",
      "602/602 [==============================] - 0s 624us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1167/1500\n",
      "602/602 [==============================] - 0s 739us/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 1168/1500\n",
      "602/602 [==============================] - 0s 621us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1169/1500\n",
      "602/602 [==============================] - 0s 351us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1170/1500\n",
      "602/602 [==============================] - 1s 893us/step - loss: 0.0492 - val_loss: 0.0523\n",
      "Epoch 1171/1500\n",
      "602/602 [==============================] - 0s 771us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1172/1500\n",
      "602/602 [==============================] - 0s 515us/step - loss: 0.0493 - val_loss: 0.0527\n",
      "Epoch 1173/1500\n",
      "602/602 [==============================] - 0s 303us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1174/1500\n",
      "602/602 [==============================] - 0s 250us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1175/1500\n",
      "602/602 [==============================] - 0s 559us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1176/1500\n",
      "602/602 [==============================] - 0s 790us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1177/1500\n",
      "602/602 [==============================] - 0s 692us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1178/1500\n",
      "602/602 [==============================] - 0s 705us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1179/1500\n",
      "602/602 [==============================] - 0s 755us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1180/1500\n",
      "602/602 [==============================] - 0s 786us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1181/1500\n",
      "602/602 [==============================] - 0s 505us/step - loss: 0.0493 - val_loss: 0.0527\n",
      "Epoch 1182/1500\n",
      "602/602 [==============================] - 0s 334us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1183/1500\n",
      "602/602 [==============================] - 0s 306us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1184/1500\n",
      "602/602 [==============================] - 0s 277us/step - loss: 0.0493 - val_loss: 0.0522\n",
      "Epoch 1185/1500\n",
      "602/602 [==============================] - 0s 318us/step - loss: 0.0492 - val_loss: 0.0528\n",
      "Epoch 1186/1500\n",
      "602/602 [==============================] - 0s 267us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1187/1500\n",
      "602/602 [==============================] - 0s 637us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1188/1500\n",
      "602/602 [==============================] - 0s 309us/step - loss: 0.0493 - val_loss: 0.0527\n",
      "Epoch 1189/1500\n",
      "602/602 [==============================] - 0s 333us/step - loss: 0.0493 - val_loss: 0.0527\n",
      "Epoch 1190/1500\n",
      "602/602 [==============================] - 0s 260us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1191/1500\n",
      "602/602 [==============================] - 0s 274us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1192/1500\n",
      "602/602 [==============================] - 0s 295us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1193/1500\n",
      "602/602 [==============================] - 0s 300us/step - loss: 0.0497 - val_loss: 0.0528\n",
      "Epoch 1194/1500\n",
      "602/602 [==============================] - 0s 292us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1195/1500\n",
      "602/602 [==============================] - 0s 319us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1196/1500\n",
      "602/602 [==============================] - 0s 823us/step - loss: 0.0492 - val_loss: 0.0528\n",
      "Epoch 1197/1500\n",
      "602/602 [==============================] - 1s 915us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1198/1500\n",
      "602/602 [==============================] - 1s 946us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1199/1500\n",
      "602/602 [==============================] - 0s 696us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1200/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1201/1500\n",
      "602/602 [==============================] - 0s 524us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1202/1500\n",
      "602/602 [==============================] - 0s 481us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1203/1500\n",
      "602/602 [==============================] - 0s 319us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1204/1500\n",
      "602/602 [==============================] - 0s 726us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1205/1500\n",
      "602/602 [==============================] - 0s 471us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1206/1500\n",
      "602/602 [==============================] - 0s 625us/step - loss: 0.0492 - val_loss: 0.0523\n",
      "Epoch 1207/1500\n",
      "602/602 [==============================] - 0s 377us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1208/1500\n",
      "602/602 [==============================] - 0s 278us/step - loss: 0.0492 - val_loss: 0.0522\n",
      "Epoch 1209/1500\n",
      "602/602 [==============================] - 0s 332us/step - loss: 0.0494 - val_loss: 0.0524\n",
      "Epoch 1210/1500\n",
      "602/602 [==============================] - 0s 414us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1211/1500\n",
      "602/602 [==============================] - 0s 307us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1212/1500\n",
      "602/602 [==============================] - 0s 291us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1213/1500\n",
      "602/602 [==============================] - 0s 268us/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 1214/1500\n",
      "602/602 [==============================] - 0s 270us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1215/1500\n",
      "602/602 [==============================] - 0s 312us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1216/1500\n",
      "602/602 [==============================] - 0s 429us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1217/1500\n",
      "602/602 [==============================] - 0s 274us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1218/1500\n",
      "602/602 [==============================] - 0s 305us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1219/1500\n",
      "602/602 [==============================] - 0s 272us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1220/1500\n",
      "602/602 [==============================] - 0s 296us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1221/1500\n",
      "602/602 [==============================] - 0s 305us/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 1222/1500\n",
      "602/602 [==============================] - 0s 310us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1223/1500\n",
      "602/602 [==============================] - 0s 259us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1224/1500\n",
      "602/602 [==============================] - 0s 272us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1225/1500\n",
      "602/602 [==============================] - 0s 291us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1226/1500\n",
      "602/602 [==============================] - 0s 297us/step - loss: 0.0499 - val_loss: 0.0526\n",
      "Epoch 1227/1500\n",
      "602/602 [==============================] - 0s 314us/step - loss: 0.0495 - val_loss: 0.0524\n",
      "Epoch 1228/1500\n",
      "602/602 [==============================] - 0s 287us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1229/1500\n",
      "602/602 [==============================] - 0s 489us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1230/1500\n",
      "602/602 [==============================] - 0s 820us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1231/1500\n",
      "602/602 [==============================] - 0s 669us/step - loss: 0.0492 - val_loss: 0.0523\n",
      "Epoch 1232/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 0s 622us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1233/1500\n",
      "602/602 [==============================] - 0s 511us/step - loss: 0.0492 - val_loss: 0.0523\n",
      "Epoch 1234/1500\n",
      "602/602 [==============================] - 0s 489us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1235/1500\n",
      "602/602 [==============================] - 0s 327us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 1236/1500\n",
      "602/602 [==============================] - 0s 501us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1237/1500\n",
      "602/602 [==============================] - 0s 394us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1238/1500\n",
      "602/602 [==============================] - 0s 428us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1239/1500\n",
      "602/602 [==============================] - 0s 308us/step - loss: 0.0492 - val_loss: 0.0522\n",
      "Epoch 1240/1500\n",
      "602/602 [==============================] - 0s 546us/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 1241/1500\n",
      "602/602 [==============================] - 0s 324us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1242/1500\n",
      "602/602 [==============================] - 0s 433us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1243/1500\n",
      "602/602 [==============================] - 0s 736us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1244/1500\n",
      "602/602 [==============================] - 0s 363us/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 1245/1500\n",
      "602/602 [==============================] - 0s 574us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1246/1500\n",
      "602/602 [==============================] - 0s 451us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1247/1500\n",
      "602/602 [==============================] - 0s 768us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1248/1500\n",
      "602/602 [==============================] - 0s 389us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1249/1500\n",
      "602/602 [==============================] - 0s 528us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1250/1500\n",
      "602/602 [==============================] - 0s 659us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1251/1500\n",
      "602/602 [==============================] - 0s 698us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1252/1500\n",
      "602/602 [==============================] - 0s 657us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1253/1500\n",
      "602/602 [==============================] - 0s 691us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1254/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1255/1500\n",
      "602/602 [==============================] - 1s 953us/step - loss: 0.0492 - val_loss: 0.0523\n",
      "Epoch 1256/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1257/1500\n",
      "602/602 [==============================] - 0s 661us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1258/1500\n",
      "602/602 [==============================] - 0s 755us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1259/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0492 - val_loss: 0.0523\n",
      "Epoch 1260/1500\n",
      "602/602 [==============================] - 1s 884us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1261/1500\n",
      "602/602 [==============================] - 0s 662us/step - loss: 0.0492 - val_loss: 0.0529\n",
      "Epoch 1262/1500\n",
      "602/602 [==============================] - 0s 821us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1263/1500\n",
      "602/602 [==============================] - 0s 719us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1264/1500\n",
      "602/602 [==============================] - 0s 804us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1265/1500\n",
      "602/602 [==============================] - 0s 708us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1266/1500\n",
      "602/602 [==============================] - 0s 653us/step - loss: 0.0497 - val_loss: 0.0526\n",
      "Epoch 1267/1500\n",
      "602/602 [==============================] - 0s 646us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1268/1500\n",
      "602/602 [==============================] - 0s 619us/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 1269/1500\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.049 - 0s 662us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1270/1500\n",
      "602/602 [==============================] - 1s 945us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1271/1500\n",
      "602/602 [==============================] - 0s 685us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1272/1500\n",
      "602/602 [==============================] - 0s 634us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1273/1500\n",
      "602/602 [==============================] - 0s 807us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1274/1500\n",
      "602/602 [==============================] - 0s 756us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1275/1500\n",
      "602/602 [==============================] - 0s 659us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1276/1500\n",
      "602/602 [==============================] - 0s 660us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1277/1500\n",
      "602/602 [==============================] - 0s 694us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1278/1500\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.049 - 0s 672us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1279/1500\n",
      "602/602 [==============================] - 0s 709us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1280/1500\n",
      "602/602 [==============================] - 0s 787us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1281/1500\n",
      "602/602 [==============================] - 0s 529us/step - loss: 0.0493 - val_loss: 0.0529\n",
      "Epoch 1282/1500\n",
      "602/602 [==============================] - 0s 627us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1283/1500\n",
      "602/602 [==============================] - 0s 589us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1284/1500\n",
      "602/602 [==============================] - 0s 684us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1285/1500\n",
      "602/602 [==============================] - 0s 667us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1286/1500\n",
      "602/602 [==============================] - 0s 352us/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 1287/1500\n",
      "602/602 [==============================] - 0s 322us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1288/1500\n",
      "602/602 [==============================] - 0s 349us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1289/1500\n",
      "602/602 [==============================] - 0s 546us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1290/1500\n",
      "602/602 [==============================] - 0s 300us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1291/1500\n",
      "602/602 [==============================] - 0s 309us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1292/1500\n",
      "602/602 [==============================] - 0s 513us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1293/1500\n",
      "602/602 [==============================] - 0s 750us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1294/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1295/1500\n",
      "602/602 [==============================] - 1s 878us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1296/1500\n",
      "602/602 [==============================] - 0s 363us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1297/1500\n",
      "602/602 [==============================] - 0s 340us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1298/1500\n",
      "602/602 [==============================] - 0s 313us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1299/1500\n",
      "602/602 [==============================] - 0s 735us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1300/1500\n",
      "602/602 [==============================] - 0s 597us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1301/1500\n",
      "602/602 [==============================] - 0s 794us/step - loss: 0.0491 - val_loss: 0.0522\n",
      "Epoch 1302/1500\n",
      "602/602 [==============================] - 0s 438us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1303/1500\n",
      "602/602 [==============================] - 1s 877us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1304/1500\n",
      "602/602 [==============================] - 0s 551us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1305/1500\n",
      "602/602 [==============================] - 0s 306us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1306/1500\n",
      "602/602 [==============================] - 0s 334us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1307/1500\n",
      "602/602 [==============================] - 0s 523us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1308/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 0s 342us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1309/1500\n",
      "602/602 [==============================] - 0s 493us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1310/1500\n",
      "602/602 [==============================] - 0s 661us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1311/1500\n",
      "602/602 [==============================] - 0s 719us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1312/1500\n",
      "602/602 [==============================] - 0s 529us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1313/1500\n",
      "602/602 [==============================] - 0s 370us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1314/1500\n",
      "602/602 [==============================] - 0s 573us/step - loss: 0.0491 - val_loss: 0.0523\n",
      "Epoch 1315/1500\n",
      "602/602 [==============================] - 1s 975us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 1316/1500\n",
      "602/602 [==============================] - 0s 770us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1317/1500\n",
      "602/602 [==============================] - 0s 755us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1318/1500\n",
      "602/602 [==============================] - 1s 983us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1319/1500\n",
      "602/602 [==============================] - 0s 643us/step - loss: 0.0491 - val_loss: 0.0523\n",
      "Epoch 1320/1500\n",
      "602/602 [==============================] - 0s 633us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1321/1500\n",
      "602/602 [==============================] - 0s 371us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1322/1500\n",
      "602/602 [==============================] - 0s 273us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1323/1500\n",
      "602/602 [==============================] - 0s 357us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1324/1500\n",
      "602/602 [==============================] - 0s 386us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1325/1500\n",
      "602/602 [==============================] - 0s 420us/step - loss: 0.0491 - val_loss: 0.0528\n",
      "Epoch 1326/1500\n",
      "602/602 [==============================] - 0s 793us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1327/1500\n",
      "602/602 [==============================] - 0s 650us/step - loss: 0.0496 - val_loss: 0.0525\n",
      "Epoch 1328/1500\n",
      "602/602 [==============================] - 0s 625us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1329/1500\n",
      "602/602 [==============================] - 0s 435us/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 1330/1500\n",
      "602/602 [==============================] - 0s 623us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1331/1500\n",
      "602/602 [==============================] - 0s 329us/step - loss: 0.0490 - val_loss: 0.0524\n",
      "Epoch 1332/1500\n",
      "602/602 [==============================] - 0s 274us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1333/1500\n",
      "602/602 [==============================] - 0s 274us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1334/1500\n",
      "602/602 [==============================] - 0s 281us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1335/1500\n",
      "602/602 [==============================] - 0s 709us/step - loss: 0.0498 - val_loss: 0.0528\n",
      "Epoch 1336/1500\n",
      "602/602 [==============================] - 0s 525us/step - loss: 0.0496 - val_loss: 0.0527\n",
      "Epoch 1337/1500\n",
      "602/602 [==============================] - 0s 404us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1338/1500\n",
      "602/602 [==============================] - 0s 542us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1339/1500\n",
      "602/602 [==============================] - 0s 313us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1340/1500\n",
      "602/602 [==============================] - 0s 601us/step - loss: 0.0492 - val_loss: 0.0528\n",
      "Epoch 1341/1500\n",
      "602/602 [==============================] - 0s 796us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1342/1500\n",
      "602/602 [==============================] - 1s 886us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1343/1500\n",
      "602/602 [==============================] - 1s 928us/step - loss: 0.0494 - val_loss: 0.0530\n",
      "Epoch 1344/1500\n",
      "602/602 [==============================] - 0s 719us/step - loss: 0.0495 - val_loss: 0.0525\n",
      "Epoch 1345/1500\n",
      "602/602 [==============================] - 0s 779us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1346/1500\n",
      "602/602 [==============================] - 0s 365us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1347/1500\n",
      "602/602 [==============================] - 0s 308us/step - loss: 0.0491 - val_loss: 0.0528\n",
      "Epoch 1348/1500\n",
      "602/602 [==============================] - 0s 823us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1349/1500\n",
      "602/602 [==============================] - 0s 680us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1350/1500\n",
      "602/602 [==============================] - 0s 675us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1351/1500\n",
      "602/602 [==============================] - 0s 712us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1352/1500\n",
      "602/602 [==============================] - 0s 649us/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 1353/1500\n",
      "602/602 [==============================] - 1s 992us/step - loss: 0.0492 - val_loss: 0.0526TA: 0s - loss: 0.\n",
      "Epoch 1354/1500\n",
      "602/602 [==============================] - 0s 779us/step - loss: 0.0492 - val_loss: 0.0524\n",
      "Epoch 1355/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1356/1500\n",
      "602/602 [==============================] - 1s 929us/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 1357/1500\n",
      "602/602 [==============================] - 1s 870us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1358/1500\n",
      "602/602 [==============================] - 0s 830us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1359/1500\n",
      "602/602 [==============================] - 0s 639us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1360/1500\n",
      "602/602 [==============================] - 0s 520us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1361/1500\n",
      "602/602 [==============================] - 0s 517us/step - loss: 0.0490 - val_loss: 0.0528\n",
      "Epoch 1362/1500\n",
      "602/602 [==============================] - 0s 695us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1363/1500\n",
      "602/602 [==============================] - 0s 488us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1364/1500\n",
      "602/602 [==============================] - 0s 467us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1365/1500\n",
      "602/602 [==============================] - 0s 348us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1366/1500\n",
      "602/602 [==============================] - 0s 291us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1367/1500\n",
      "602/602 [==============================] - 0s 617us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1368/1500\n",
      "602/602 [==============================] - 0s 558us/step - loss: 0.0490 - val_loss: 0.0527\n",
      "Epoch 1369/1500\n",
      "602/602 [==============================] - 0s 530us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1370/1500\n",
      "602/602 [==============================] - 0s 506us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1371/1500\n",
      "602/602 [==============================] - 0s 442us/step - loss: 0.0492 - val_loss: 0.0528\n",
      "Epoch 1372/1500\n",
      "602/602 [==============================] - 1s 974us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1373/1500\n",
      "602/602 [==============================] - 0s 427us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1374/1500\n",
      "602/602 [==============================] - 0s 424us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1375/1500\n",
      "602/602 [==============================] - 0s 493us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1376/1500\n",
      "602/602 [==============================] - 0s 408us/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1377/1500\n",
      "602/602 [==============================] - 0s 302us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1378/1500\n",
      "602/602 [==============================] - 0s 381us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1379/1500\n",
      "602/602 [==============================] - 0s 421us/step - loss: 0.0491 - val_loss: 0.0523\n",
      "Epoch 1380/1500\n",
      "602/602 [==============================] - 0s 457us/step - loss: 0.0490 - val_loss: 0.0526\n",
      "Epoch 1381/1500\n",
      "602/602 [==============================] - 0s 589us/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 1382/1500\n",
      "602/602 [==============================] - 1s 839us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1383/1500\n",
      "602/602 [==============================] - 0s 746us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1384/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 0s 762us/step - loss: 0.0490 - val_loss: 0.0525\n",
      "Epoch 1385/1500\n",
      "602/602 [==============================] - 1s 968us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1386/1500\n",
      "602/602 [==============================] - 0s 734us/step - loss: 0.0490 - val_loss: 0.0525\n",
      "Epoch 1387/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1388/1500\n",
      "602/602 [==============================] - 1s 994us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1389/1500\n",
      "602/602 [==============================] - 0s 674us/step - loss: 0.0490 - val_loss: 0.0525\n",
      "Epoch 1390/1500\n",
      "602/602 [==============================] - 0s 384us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1391/1500\n",
      "602/602 [==============================] - 1s 884us/step - loss: 0.0490 - val_loss: 0.0526\n",
      "Epoch 1392/1500\n",
      "602/602 [==============================] - 1s 890us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1393/1500\n",
      "602/602 [==============================] - 1s 972us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1394/1500\n",
      "602/602 [==============================] - 1s 902us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1395/1500\n",
      "602/602 [==============================] - 1s 962us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1396/1500\n",
      "602/602 [==============================] - ETA: 0s - loss: 0.049 - 0s 514us/step - loss: 0.0490 - val_loss: 0.0524\n",
      "Epoch 1397/1500\n",
      "602/602 [==============================] - 0s 559us/step - loss: 0.0490 - val_loss: 0.0527\n",
      "Epoch 1398/1500\n",
      "602/602 [==============================] - 0s 759us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1399/1500\n",
      "602/602 [==============================] - 0s 378us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1400/1500\n",
      "602/602 [==============================] - 0s 371us/step - loss: 0.0491 - val_loss: 0.0528\n",
      "Epoch 1401/1500\n",
      "602/602 [==============================] - 0s 414us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1402/1500\n",
      "602/602 [==============================] - 0s 558us/step - loss: 0.0490 - val_loss: 0.0525\n",
      "Epoch 1403/1500\n",
      "602/602 [==============================] - 0s 660us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1404/1500\n",
      "602/602 [==============================] - 0s 774us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1405/1500\n",
      "602/602 [==============================] - 1s 863us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1406/1500\n",
      "602/602 [==============================] - 1s 922us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1407/1500\n",
      "602/602 [==============================] - 1s 954us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1408/1500\n",
      "602/602 [==============================] - 1s 900us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1409/1500\n",
      "602/602 [==============================] - 0s 806us/step - loss: 0.0490 - val_loss: 0.0525\n",
      "Epoch 1410/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0528\n",
      "Epoch 1411/1500\n",
      "602/602 [==============================] - 0s 809us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1412/1500\n",
      "602/602 [==============================] - 0s 425us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1413/1500\n",
      "602/602 [==============================] - 0s 374us/step - loss: 0.0490 - val_loss: 0.0526\n",
      "Epoch 1414/1500\n",
      "602/602 [==============================] - 0s 458us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1415/1500\n",
      "602/602 [==============================] - 0s 576us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1416/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0490 - val_loss: 0.0523\n",
      "Epoch 1417/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0489 - val_loss: 0.0525\n",
      "Epoch 1418/1500\n",
      "602/602 [==============================] - 0s 714us/step - loss: 0.0490 - val_loss: 0.0527\n",
      "Epoch 1419/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1420/1500\n",
      "602/602 [==============================] - 1s 849us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1421/1500\n",
      "602/602 [==============================] - 0s 570us/step - loss: 0.0490 - val_loss: 0.0527\n",
      "Epoch 1422/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1423/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1424/1500\n",
      "602/602 [==============================] - 1s 2ms/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1425/1500\n",
      "602/602 [==============================] - 2s 3ms/step - loss: 0.0490 - val_loss: 0.0527\n",
      "Epoch 1426/1500\n",
      "602/602 [==============================] - 1s 952us/step - loss: 0.0490 - val_loss: 0.0524\n",
      "Epoch 1427/1500\n",
      "602/602 [==============================] - 0s 712us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1428/1500\n",
      "602/602 [==============================] - 0s 572us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1429/1500\n",
      "602/602 [==============================] - 0s 782us/step - loss: 0.0493 - val_loss: 0.0524\n",
      "Epoch 1430/1500\n",
      "602/602 [==============================] - 0s 830us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1431/1500\n",
      "602/602 [==============================] - 0s 604us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1432/1500\n",
      "602/602 [==============================] - 0s 523us/step - loss: 0.0490 - val_loss: 0.0525\n",
      "Epoch 1433/1500\n",
      "602/602 [==============================] - 0s 589us/step - loss: 0.0490 - val_loss: 0.0526\n",
      "Epoch 1434/1500\n",
      "602/602 [==============================] - 0s 513us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1435/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1436/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1437/1500\n",
      "602/602 [==============================] - 0s 655us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1438/1500\n",
      "602/602 [==============================] - 0s 390us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1439/1500\n",
      "602/602 [==============================] - 1s 951us/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 1440/1500\n",
      "602/602 [==============================] - 0s 372us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1441/1500\n",
      "602/602 [==============================] - 0s 336us/step - loss: 0.0494 - val_loss: 0.0526\n",
      "Epoch 1442/1500\n",
      "602/602 [==============================] - 0s 475us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1443/1500\n",
      "602/602 [==============================] - 0s 435us/step - loss: 0.0490 - val_loss: 0.0527\n",
      "Epoch 1444/1500\n",
      "602/602 [==============================] - 0s 612us/step - loss: 0.0490 - val_loss: 0.0524\n",
      "Epoch 1445/1500\n",
      "602/602 [==============================] - 1s 940us/step - loss: 0.0490 - val_loss: 0.0523\n",
      "Epoch 1446/1500\n",
      "602/602 [==============================] - 1s 965us/step - loss: 0.0490 - val_loss: 0.0526\n",
      "Epoch 1447/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0523\n",
      "Epoch 1448/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0490 - val_loss: 0.0526\n",
      "Epoch 1449/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0490 - val_loss: 0.0526\n",
      "Epoch 1450/1500\n",
      "602/602 [==============================] - 0s 523us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1451/1500\n",
      "602/602 [==============================] - 0s 634us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1452/1500\n",
      "602/602 [==============================] - 0s 462us/step - loss: 0.0490 - val_loss: 0.0525\n",
      "Epoch 1453/1500\n",
      "602/602 [==============================] - 0s 528us/step - loss: 0.0490 - val_loss: 0.0527\n",
      "Epoch 1454/1500\n",
      "602/602 [==============================] - 0s 620us/step - loss: 0.0491 - val_loss: 0.0523\n",
      "Epoch 1455/1500\n",
      "602/602 [==============================] - 0s 607us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1456/1500\n",
      "602/602 [==============================] - 0s 434us/step - loss: 0.0491 - val_loss: 0.0523\n",
      "Epoch 1457/1500\n",
      "602/602 [==============================] - 0s 580us/step - loss: 0.0495 - val_loss: 0.0526\n",
      "Epoch 1458/1500\n",
      "602/602 [==============================] - 0s 510us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1459/1500\n",
      "602/602 [==============================] - 0s 558us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1460/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/602 [==============================] - 0s 549us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1461/1500\n",
      "602/602 [==============================] - 0s 453us/step - loss: 0.0490 - val_loss: 0.0524\n",
      "Epoch 1462/1500\n",
      "602/602 [==============================] - 0s 334us/step - loss: 0.0490 - val_loss: 0.0525\n",
      "Epoch 1463/1500\n",
      "602/602 [==============================] - 0s 338us/step - loss: 0.0490 - val_loss: 0.0524\n",
      "Epoch 1464/1500\n",
      "602/602 [==============================] - 0s 343us/step - loss: 0.0490 - val_loss: 0.0524\n",
      "Epoch 1465/1500\n",
      "602/602 [==============================] - 0s 366us/step - loss: 0.0492 - val_loss: 0.0527\n",
      "Epoch 1466/1500\n",
      "602/602 [==============================] - 1s 850us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1467/1500\n",
      "602/602 [==============================] - 0s 755us/step - loss: 0.0490 - val_loss: 0.0526\n",
      "Epoch 1468/1500\n",
      "602/602 [==============================] - 0s 708us/step - loss: 0.0489 - val_loss: 0.0525\n",
      "Epoch 1469/1500\n",
      "602/602 [==============================] - 0s 643us/step - loss: 0.0489 - val_loss: 0.0526\n",
      "Epoch 1470/1500\n",
      "602/602 [==============================] - 0s 571us/step - loss: 0.0490 - val_loss: 0.0524\n",
      "Epoch 1471/1500\n",
      "602/602 [==============================] - 0s 397us/step - loss: 0.0490 - val_loss: 0.0524\n",
      "Epoch 1472/1500\n",
      "602/602 [==============================] - 0s 324us/step - loss: 0.0489 - val_loss: 0.0525\n",
      "Epoch 1473/1500\n",
      "602/602 [==============================] - 0s 476us/step - loss: 0.0490 - val_loss: 0.0528\n",
      "Epoch 1474/1500\n",
      "602/602 [==============================] - 0s 433us/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1475/1500\n",
      "602/602 [==============================] - 0s 579us/step - loss: 0.0490 - val_loss: 0.0527\n",
      "Epoch 1476/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0490 - val_loss: 0.0526\n",
      "Epoch 1477/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1478/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0490 - val_loss: 0.0523\n",
      "Epoch 1479/1500\n",
      "602/602 [==============================] - 0s 753us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1480/1500\n",
      "602/602 [==============================] - 0s 749us/step - loss: 0.0490 - val_loss: 0.0527\n",
      "Epoch 1481/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0490 - val_loss: 0.0525\n",
      "Epoch 1482/1500\n",
      "602/602 [==============================] - 0s 688us/step - loss: 0.0498 - val_loss: 0.0526\n",
      "Epoch 1483/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0492 - val_loss: 0.0526\n",
      "Epoch 1484/1500\n",
      "602/602 [==============================] - 1s 995us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1485/1500\n",
      "602/602 [==============================] - 1s 867us/step - loss: 0.0490 - val_loss: 0.0525\n",
      "Epoch 1486/1500\n",
      "602/602 [==============================] - 0s 463us/step - loss: 0.0490 - val_loss: 0.0527\n",
      "Epoch 1487/1500\n",
      "602/602 [==============================] - 1s 832us/step - loss: 0.0493 - val_loss: 0.0527\n",
      "Epoch 1488/1500\n",
      "602/602 [==============================] - 0s 418us/step - loss: 0.0493 - val_loss: 0.0526\n",
      "Epoch 1489/1500\n",
      "602/602 [==============================] - 0s 487us/step - loss: 0.0492 - val_loss: 0.0525\n",
      "Epoch 1490/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0526\n",
      "Epoch 1491/1500\n",
      "602/602 [==============================] - 0s 615us/step - loss: 0.0491 - val_loss: 0.0525\n",
      "Epoch 1492/1500\n",
      "602/602 [==============================] - 0s 587us/step - loss: 0.0492 - val_loss: 0.0523\n",
      "Epoch 1493/1500\n",
      "602/602 [==============================] - 0s 638us/step - loss: 0.0489 - val_loss: 0.0526\n",
      "Epoch 1494/1500\n",
      "602/602 [==============================] - 1s 866us/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1495/1500\n",
      "602/602 [==============================] - 0s 477us/step - loss: 0.0491 - val_loss: 0.0527\n",
      "Epoch 1496/1500\n",
      "602/602 [==============================] - 0s 673us/step - loss: 0.0491 - val_loss: 0.0523\n",
      "Epoch 1497/1500\n",
      "602/602 [==============================] - 1s 844us/step - loss: 0.0489 - val_loss: 0.0527\n",
      "Epoch 1498/1500\n",
      "602/602 [==============================] - 1s 1ms/step - loss: 0.0490 - val_loss: 0.0526\n",
      "Epoch 1499/1500\n",
      "602/602 [==============================] - 1s 938us/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 1500/1500\n",
      "602/602 [==============================] - 0s 601us/step - loss: 0.0489 - val_loss: 0.0524\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sa_data = pd.ExcelFile(\"CTGilmore.xlsx\") \n",
    "parsee = sa_data.sheet_names[0]\n",
    "data = sa_data.parse(parsee)\n",
    "data_features = data.loc[:, data.columns] \n",
    "data_features = data_features.drop(['norm_id','AtRisk','Age',11142,12142], axis=1)  \n",
    "scaled_data = scaler.transform(data_features)\n",
    "\n",
    "encoder = Model(input_data, encoded)\n",
    "encoded_data = encoder.predict(scaled_data)\n",
    "#I now have scaled data as encoded which is my input. This will compare predictions to my scaled_data.\n",
    "Y_train, Y_test = train_test_split(scaled_data, test_size=0.10, random_state=20) #Scaled data I want to compare to\n",
    "X_train, X_test = train_test_split(encoded_data, test_size=0.10, random_state=20) #Encoded data I will input\n",
    "\n",
    "dinput_size = 13\n",
    "hidden_size1 = 30\n",
    "hidden_size2 = 65\n",
    "hidden_size3 = 120\n",
    "decoded_dim = 148\n",
    "dinput_data = Input(shape=(dinput_size,))\n",
    "dhidden_d_1 = Dense(hidden_size1, activation='tanh')(dinput_data)\n",
    "dhidden_d_2 = Dense(hidden_size2, activation='tanh')(dhidden_d_1)\n",
    "dhidden_d_3 = Dense(hidden_size3, activation='tanh')(dhidden_d_2)\n",
    "predictedSA = Dense(decoded_dim, activation='tanh')(dhidden_d_3)\n",
    "\n",
    "predictor = Model(dinput_data, predictedSA)\n",
    "predictor.compile(optimizer='Adam', loss='mean_absolute_error')\n",
    "pn = predictor.fit(X_train, Y_train,\n",
    "epochs=1500,\n",
    "batch_size=15,\n",
    "shuffle=True,\n",
    "validation_data=(X_test, Y_test))\n",
    "\n",
    "#print(ac.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(pn.history['loss'])\n",
    "plt.plot(pn.history['val_loss'])\n",
    "#plt.set(xlim=(0, 50), ylim=(0.0, 1.0))\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.axis([0, 1500, 0.0, 0.15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
